[
  {
    "objectID": "0_01_function.html",
    "href": "0_01_function.html",
    "title": "Functions and Models",
    "section": "",
    "text": "At the end of this lab, you will:\n\nHave reviewed the main concepts from introductory statistics.\nUnderstand the concept of a function.\nBe able to discuss what a statistical model is.\nUnderstand the link between models and functions.\n\n\n\n\n\nHave attended and/or watched Week 1 lectures.\nHave installed R and RStudio on your own computer (unless you have a Chromebook where you may continue to use the PPLS RStudio Server).\n\n\n\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\nggExtra\nkableExtra\n\n\n\n\nAll results should be presented following APA guidelines.If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\n\n\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/handheight.csv."
  },
  {
    "objectID": "0_01_function.html#functions-and-mathematical-models-plots",
    "href": "0_01_function.html#functions-and-mathematical-models-plots",
    "title": "Functions and Models",
    "section": "Functions and Mathematical Models: Plots",
    "text": "Functions and Mathematical Models: Plots\n\nQuestion 4\n\n\nCreate a data set called squares containing the perimeter of four squares having sides of length \\(0, 2, 5, 9\\) metres, and then plot the squares data as points on a scatterplot.\n\n\n\n\n\n\nHint\n\n\n\n\n\nRemember that to combine multiple numbers together we use the function c().\n\n\n\n\n\n\n\n Solution \n\n\nFirst, let’s make our squares data:\n\nsquares &lt;- tibble(\n  side = c(0, 2, 5, 9), \n  perimeter = 4 * side\n)\n\nsquares\n\n# A tibble: 4 × 2\n   side perimeter\n  &lt;dbl&gt;     &lt;dbl&gt;\n1     0         0\n2     2         8\n3     5        20\n4     9        36\n\n\nNext, lets plot it:\n\nggplot(data = squares, aes(x = side, y = perimeter)) +\n  geom_point() +   #specify `geom_point' as want to create a scatterplot\n  labs(x = 'Side (m)', y = 'Perimeter (m)')    #label x- and y-axis with new and clearer titles\n\n\n\n\nFigure 1: ?(caption)\n\n\n\n\n\n\n\n\n\nQuestion 5\n\n\nGenerate one hundred data points, and use them to visualise the relationship between side and perimeter of squares. To do so, you need to complete four steps:\n\nCreate a sequence of one hundred side lengths (x) going from 0 to 3 metres.\nCompute the corresponding perimeters (y).\nPlot the side and perimeter data as points on a graph.\nVisualise the functional relationship between side and perimeter of squares. To do so, use the function geom_line() to connect the computed points with lines.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo create a sequence of numbers, we can use the function seq(). We need to include within the seq() argument our from and to values (i.e., the lowest and highest values in the sequence), as well as length.out to specify the length of the sequence (i.e., how many 0-3’s do we want).\nIf you would like to change the colour of the line (step 4), you can specify geom_line(colour = \"insert_colour\")\n\n\n\n\n\n\n\n Solution \n\n\nSteps 1 & 2 - create the side and perimeter data:\n\nsquares_grid &lt;- tibble(\n  side = seq(0, 3, length.out = 100),\n  perimeter = 4 * side)\n\nStep 3 - plot the individual points:\n\nggplot(data = squares_grid, aes(x = side, y = perimeter)) +\n  geom_point() +\n  labs(x = 'Side (m)', y = 'Perimeter (m)', title = 'Perimeter = 4*Side')\n\n\n\n\n\n\n\n\nStep 4 - visualise the functional relationship by connecting the individual points with a line:\n\nggplot(data = squares_grid, aes(x = side, y = perimeter)) +\n  geom_point() +\n  geom_line(colour = 'blue') +\n  labs(x = 'Side (m)', y = 'Perimeter (m)', title = 'Perimeter = 4*Side')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\nThe function \\(y = 4 \\ x\\) that you plotted above is an example of a function representing a mathematical model.\nWe typically validate a model using experimental data. However, we all know how squares work and that two squares with the same side will have the same perimeter (more on this later).\n\n\n\n\n\n\n\n\nQuestion 6\n\n\nThe Scottish National Gallery kindly provided us with measurements of side and perimeter (in metres) for a sample of 10 square paintings.\nThe data are provided below:\n\nsng &lt;- tibble(\n  side = c(1.3, 0.75, 2, 0.5, 0.3, 1.1, 2.3, 0.85, 1.1, 0.2),\n  perimeter = c(5.2, 3.0, 8.0, 2.0, 1.2, 4.4, 9.2, 3.4, 4.4, 0.8)\n)\n\nPlot the mathematical model of the relationship between side and perimeter for squares, and superimpose on top the experimental data from the Scottish National Gallery.\n\n\n\n\n Solution \n\n\n\nsng &lt;- tibble(\n  side = c(1.3, 0.75, 2, 0.5, 0.3, 1.1, 2.3, 0.85, 1.1, 0.2),\n  perimeter = c(5.2, 3.0, 8.0, 2.0, 1.2, 4.4, 9.2, 3.4, 4.4, 0.8)\n)\n\nggplot() + \n  geom_line(data = squares_grid, aes(x = side, y = perimeter), colour = 'blue') + # add blue line\n  geom_point(data = sng, aes(x = side, y = perimeter), colour = 'black',  # add black points\n             alpha = 0.5, size = 3) + # make the points 0.5 transparency, size 3\n  labs(x = 'Side (m)', y = 'Perimeter (m)')\n\n\n\n\nFigure 2: The exact relationship between side and perimeter of squares\n\n\n\n\nThe above plot shows perfect agreement between the observed data and the model.\n\n\n\n\n\nQuestion 7\n\n\nUse the mathematical model to predict the perimeter of a painting with a side of 1.5 metres.\n\n\n\n\n\n\nHint\n\n\n\n\n\nDon’t forget to always include the measurement units when reporting/writing-up results!\n\n\n\n\n\n\n\n Solution \n\n\nWe do not have a painting with a side of 1.5 metres within the random sample of paintings from the Scottish National Gallery. However, we can predict the perimeter of an unobserved squared painting having a 1.5 metre side using the mathematical model.\nYou can obtain this prediction using either a visual approach or an algebraic one.\n\nVisual ApproachAlgebraic Approach\n\n\n\n\n\n\n\n\n\n\n\nSometimes we can directly read a predicted value from the graph of the functional relationship.\nConsider the plot created in the previous question. First, we need to check where x = 1.5. Then, we draw a vertical dashed line until it meets the blue line. The y value corresponding to x = 1.5 can be read off the y-axis.\nHowever, in this case it is not that easy to read it from the drawing…\n\n\nYou can substitute the x value in the formula and calculate the corresponding y value. \\[\ny = 4 * x = 4 * 1.5 = 6\n\\]\n\n\n\n\n\n\n\n\n\nThe predicted perimeter of squared paintings having a 1.5m side is 6m."
  },
  {
    "objectID": "0_01_function.html#study-overview",
    "href": "0_01_function.html#study-overview",
    "title": "Functions and Models",
    "section": "Study Overview",
    "text": "Study Overview\n\nResearch Question\nHow does handspan vary as a function of height?\n\nConsider now the association between height (in inches) and handspan (in cm). Utts and Heckard (2015) provided data for a sample of 167 students which reported their height and handspan as part of a class survey.\nUsing the handheight data you already loaded at the start of the lab, your task is to investigate how handspan varies as a function of height for the students in the sample.\n\n Handheight codebook.\n\n\nDescription\nThe data set records the height and handspan reported by a random sample of 167 students as part of a class survey.\nThe variables are:\n\nheight, measured in inches\nhandspan, measured in centimetres\n\nPreview\nThe first six rows of the data are:\n\n\n\n\n\nheight\nhandspan\n\n\n\n\n68\n21.5\n\n\n71\n23.5\n\n\n73\n22.5\n\n\n64\n18.0\n\n\n68\n23.5\n\n\n59\n20.0\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 8\n\n\nUsing a scatterplot (since the variables are numeric and continuous) to visualise the association between the two numeric variables, comment on any main differences you notice with the association between side and perimeter of squares. Note if you detected outliers or points that do not fit with the pattern in the rest of the data.\n\n\n\n\n Solution \n\n\n\nplt &lt;- ggplot(handheight, aes(x = height, y = handspan)) +\n  geom_point(size = 3, alpha = 0.5) +\n  labs(x = 'Height (in.)', y = 'Handspan (cm)')\n\nplt\n\n\n\n\nFigure 3: Simple Scatterplot\n\n\n\n\nWe can also add marginal boxplots for each variable using the package ggExtra.\n\nggMarginal(plt, type = 'boxplot')\n\n\n\n\nFigure 4: The statistical relationship between height and handspan\n\n\n\n\nOutliers are extreme observations that are not possible values of a variable or that do not seem to fit with the rest of the data. This could either be:\n\nmarginally along one axis: points that have an unusual (too high or too low) x-coordinate or y-coordinate;\njointly: observations that do not fit with the rest of the point cloud.\n\nThe boxplots in Figure 4 do not highlight any outliers in the marginal distributions of height and handspan. Furthermore, from the scatterplot we do not notice any extreme observations or points that do not fit with the rest of the point cloud.\nWe notice a moderate, positive linear association between height and handspan.\nRecall Figure 2, displaying the association between side and perimeters of squares. In the plot we notice two points on top of each other, reflecting the fact that two squares having the same side will always have the same perimeter. In fact, the data from the Scottish National Gallery include two squared paintings with a side of 1.1m, both having a measured perimeter of 4.4m.\nFigure 4, instead, displays the association between height and handspan of a sample of students. The first thing that grabs our attention is the fact that students having the same height do not necessarily have the same handspan. Rather, we clearly see a variety of handspan values for students all having a height of, for example, 70in. To be more precise, the seven students who are 70 in. tall all have differing handspans.\n\n\n\n\n\nQuestion 9\n\n\nUsing the following command, superimpose on top of the scatterplot a best-fit line describing how handspan varies as a function of height. For the moment, the argument se = FALSE tells R to not display uncertainty bands.\n\ngeom_smooth(method = lm, se = FALSE)\n\nComment on any differences between the lines representing the linear relationship between (a) the side and perimeter of square and (b) height and handspan.\n\n\n\n\n Solution \n\n\n\nggplot(handheight, aes(x = height, y = handspan)) +\n  geom_point(size = 3, alpha = 0.5) +\n  geom_smooth(method = lm, se = FALSE) +\n  labs(x = 'Height (in.)', y = 'Handspan (cm)')\n\n\n\n\nFigure 5: The best-fit line\n\n\n\n\nThe line representing the relationship between side and perimeter of squares is able to predict the actual perimeter value from the measurement of the side of a square. This is possible because the relationship between side and perimeter is an exact one.\nThat is, any squares having the same side will have the same perimeter, and there will be no variation in those values.\nThe line that best fits the relationship between height and handspan (see Figure 5), instead, is only able to predict the average handspan for a given value of height.\nThis is because there will be a distribution of handspans at each value of height. The line will fit the trend/pattern in the values, but there will be individual-to-individual variability that we must accept around that average pattern.\n\n\n\n\n\nQuestion 10\n\n\nThe line of best-fit is given by:1\n\\[\n\\widehat{Handspan} = -3 + 0.35 \\cdot Height\n\\]\nEstimate (or predict) handspan of a student who is (a) 73in tall, and (b) 5in tall.\n\n\n\n\n Solution \n\n\n\nThe predicted average handspan for students who are 73in tall is:  \\(-3 + (0.35 * 73) = 22.55\\)cm.  \nThe predicted average handspan for students who are 5in tall is:  \\(-3 + (0.35 * 5) = -1.25\\)cm.\n\nBut wait, handspan can not be negative… This does not make any sense! That’s right, we went too far off the range of the available data on heights, which were between 57in and 78in. We extrapolated. This is very dangerous…\n\n\n\n\n\nSource: Randall Munroe, xkcd.com"
  },
  {
    "objectID": "0_01_function.html#footnotes",
    "href": "0_01_function.html#footnotes",
    "title": "Functions and Models",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYes, the error term is gone. This is because the line of best-fit gives you the prediction of the average handspan for a given height, and not the individual handspan of a person, which will almost surely be different from the prediction of the line.↩︎"
  },
  {
    "objectID": "0_02_slr.html",
    "href": "0_02_slr.html",
    "title": "Simple Linear Regression",
    "section": "",
    "text": "At the end of this lab, you will:\n\nBe able to specify a simple linear model.\nUnderstand what fitted values and residuals are.\nBe able to interpret the coefficients of a fitted model.\n\n\nBe up to date with lectures from Weeks 1 & 2\nHave completed Week 1 lab exercises\n\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\nsjPlot\n\nAll results should be presented following APA guidelines.If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/riverview.csv."
  },
  {
    "objectID": "0_02_slr.html#data-exploration",
    "href": "0_02_slr.html#data-exploration",
    "title": "Simple Linear Regression",
    "section": "Data Exploration",
    "text": "Data Exploration\nThe common first port of call for almost any statistical analysis is to explore the data, and we can do this visually and/or numerically.\n\n\n\n\n\n\n\n\n\n================ Description\n\n\nMarginal Distributions\nThe distribution of each variable (e.g., employee incomes and education levels) without reference to the values of the other variables\n\n\nBivariate Associations\nDescribing the relationship between two numeric variables\n\n\n\n\n\n\n\n\nVisually \n\n\nPlot each variable individually.  You could use, for example, geom_density() for a density plot or geom_histogram() for a histogram to comment on and/or examine: \n\nThe shape of the distribution. Look at the shape, centre and spread of the distribution. Is it symmetric or skewed? Is it unimodal or bimodal?\n\n\nIdentify any unusual observations. Do you notice any extreme observations (i.e., outliers)?\n\n\n\nPlot associations among two variables. |  |  | You could use, for example, geom_point() for a scatterplot to comment on and/or examine:  |  |\n\nThe direction of the association indicates whether there is a positive or negative association\n\n\nThe form of association refers to whether the relationship between the variables can be summarized well with a straight line or some more complicated pattern\n\n\nThe strength of association entails how closely the points fall to a recognizable pattern such as a line\n\n\nUnusual observations that do not fit the pattern of the rest of the observations and which are worth examining in more detail\n\n\n\n\n\nNumerically \n\nCompute and report summary statistics e.g., mean, standard deviation, median, min, max, etc.  You could, for example, calculate summary statistics such as the mean (mean()) and standard deviation (sd()), etc. within summarize()\n\nCompute and report the correlation coefficient.  You can use the cor() function to calculate this\n\n\n\n\nMarginal Distributions\n\nQuestion 2\n\n\nVisualise and describe the marginal distributions of employee incomes and education level.\n\n\n\n\n Solution \n\n\n\n\nEmployee Incomes\nEmployee Education Levels\n\n\n\nVisualisation of distribution:\n\nggplot(data = riverview, aes(x = income)) +\n  geom_density() +\n  geom_boxplot(width = 1/300) +\n  labs(x = \"Income (in thousands of U.S. dollars)\", \n       y = \"Probability density\")\n\n\n\nFigure 1: Density plot and boxplot of employee incomes\n\n\n\nInitial observations from plot:\n\nThe distribution of employee incomes was unimodal\nMost of the incomes were between roughly $45,000 and $63,000\nThe lowest income in the sample was approximately $25,000 and the highest approximately $83,000. This suggested there was a fair high degree of variation in the data.\nThe boxplot did not highlight any outliers in the data.\n\nDescriptive (or summary) statistics for the employees’ incomes:\n\ndesc_income &lt;- riverview %&gt;% \n  summarize(\n    M = mean(income), \n    SD = sd(income)\n    )\ndesc_income\n\n# A tibble: 1 × 2\n      M    SD\n  &lt;dbl&gt; &lt;dbl&gt;\n1  53.7  14.6\n\n\nFollowing the exploration above, we can describe the income variable as follows:\n\n\n\n\n\n\nThe marginal distribution of income was unimodal with a mean of approximately $53,700. There was variation in employees’ salaries (SD = $14,553).\n\n\n\n\n\nVisualisation of distribution:\n\nggplot(data = riverview, aes(x = education)) +\n  geom_density() +\n  geom_boxplot(width = 1/100) +\n  labs(x = \"Education (in years)\", \n       y = \"Probability density\")\n\n\n\nFigure 2: Density plot and boxplot of employee education levels\n\n\n\nInitial observations from plot:\n\nThe distribution of employee education was unimodal\nMost of the employees received formal education for between 12 and 20 years\nThe fewest formal years of education was approximately 8 years, and the highest approximately 25. This suggested there was a fair high degree of variation in the data.\nThe boxplot did not highlight any outliers in the data\n\nDescriptive (or summary) statistics for the employees’ level of education:\n\ndesc_education &lt;- riverview %&gt;%\n  summarize(\n    M = mean(education),\n    SD = sd(education)\n    )\ndesc_education\n\n# A tibble: 1 × 2\n      M    SD\n  &lt;dbl&gt; &lt;dbl&gt;\n1    16  4.36\n\n\nFollowing the exploration above, we can describe the education variable as follows:\n\n\n\n\n\n\nThe marginal distribution of education was unimodal with an average of of 16 years. There was variation in employees’ level of education (SD = 4.4 years).\n\n\n\n\n\n\n\n\n\nAssociations among Variables\n\nQuestion 3\n\n\nCreate a scatterplot of income and education level before calculating the correlation between income and education level.\nMaking reference to both the plot and correlation coefficient, describe the association between income and level of education among the employees in the sample.\n\n\n\n\n\n\nHint\n\n\n\n\n\nWe are trying to investigate how income varies when varying years of formal education. Hence, income is the dependent variable (on the y-axis), and education is the independent variable (on the x-axis).\n\n\n\n\n\n\n\n Solution \n\n\nLet’s produce a scatterplot:\n\nggplot(data = riverview, aes(x = education, y = income)) +\n  geom_point() +\n  labs(x = \"Education (in years)\", \n       y = \"Income (in thousands of U.S. dollars)\")\n\n\n\nFigure 3: The association between employees’ education level and income\n\n\n\nTo comment on the strength of the linear association we compute the correlation coefficient:\n\ncorr &lt;- riverview %&gt;%\n  select(education, income) %&gt;%\n  cor()\ncorr\n\n          education    income\neducation 1.0000000 0.7947847\nincome    0.7947847 1.0000000\n\n\nthat is, \\[\nr_{\\text({education, income})} = 0.79\n\\] \n\n\n\n\n\n\nThere was a strong positive linear association between education level and income for the employees in the sample. High incomes tended to be observed, on average, with more years of formal education (\\(r\\) = .79)."
  },
  {
    "objectID": "0_02_slr.html#model-specification-and-fitting",
    "href": "0_02_slr.html#model-specification-and-fitting",
    "title": "Simple Linear Regression",
    "section": "Model Specification and Fitting",
    "text": "Model Specification and Fitting\nThe scatterplot highlighted a linear relationship, where the data points were scattered around an underlying linear pattern with a roughly-constant spread as x varied.\nHence, we will try to fit a simple (i.e., one x variable only) linear regression model:\n\\[\ny_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i\n\\\\\n\\quad \\text{where} \\quad \\epsilon_i \\sim N(0, \\sigma) \\text{ independently}\n\\]\n\n\n\n\n\n\nWhat does \\(y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i \\quad \\text{where} \\quad \\epsilon_i \\sim N(0, \\sigma) \\text{ independently}\\) mean?\n\n\n\n\n\nLets break the statement down into smaller parts:\n\\(y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i\\)\n\n\n\\(y_i\\) is our measured outcome variable (our DV)\n\n\\(x_i\\) is our measured predictor variable (our IV)\n\n\\(\\beta_0\\) is the model intercept\n\n\\(\\beta_1\\) is the model slope\n\\(\\epsilon \\sim N(0, \\sigma) \\text{ independently}\\)\n\n\n\\(\\epsilon\\) is the residual error\n\n\\(\\sim\\) means ‘distributed according to’\n\n\\(\\sim N(0, \\sigma) \\text{ independently}\\) means ‘normal distribution with a mean of 0 and a variance of \\(\\sigma\\)’\nTogether, we can say that the errors around the line have a mean of zero and constant spread as x varies.\n\n\n\n\n\n\nQuestion 4\n\n\nFirst, write the equation of the fitted line.\nNext, using the lm() function, fit a simple linear model to predict income (DV) by Education (IV), naming the output mdl.\nLastly, add update your equation of the fitted line to include the estimated coefficients.\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe syntax of the lm() function is:\n\n[model name] &lt;- lm([response variable i.e., dependent variable] ~ [explanatory variable i.e., independent variable], data = [dataframe])\n\n\n\n\n\n\n\n\n Solution \n\n\nFirst, lets specify the fitted model, which can be written either as:\n\n\nOption A\nOption B\n\n\n\n\\[\n\\widehat{Income} = \\hat \\beta_0 + \\hat \\beta_1 \\cdot Education\n\\]\n\n\n\\[\n\\widehat{Income} = \\hat \\beta_0 \\cdot 1 + \\hat \\beta_1 \\cdot Education\n\\]\n\n\n\nTo fit the model in R, as the variables are in the riverview dataframe, we would write:\n\n\nOption A\nOption B\n\n\n\n\nmdl &lt;- lm(income ~ education, data = riverview)\nmdl\n\n\nCall:\nlm(formula = income ~ education, data = riverview)\n\nCoefficients:\n(Intercept)    education  \n     11.321        2.651  \n\n\n\n\n\nmdl &lt;- lm(income ~ 1 + education, data = riverview)\nmdl\n\n\nCall:\nlm(formula = income ~ 1 + education, data = riverview)\n\nCoefficients:\n(Intercept)    education  \n     11.321        2.651  \n\n\n\n\n\n\n\n\n\n\n\nWhy is there a 1 in the Option B’s?\n\n\n\n\n\nWhen we specify the linear model in R, we include after the tilde sign (\\(\\sim\\)), the variables that appear to the right of the \\(\\hat \\beta\\)s. The intercept, or \\(\\beta_0\\), is a constant. That is, we could write it as multiplied by 1.\nIncluding the 1 explicitly is not necessary because it is included by default (you can check this by comparing the outputs of A & B above with and without the 1 included - the estimates are the same!). After a while, you will find you just want to drop the 1 (i.e., Option B) when calling lm() because you know that it’s going to be there, but in these early weeks we tried to keep it explicit to make it clear that you want to the intercept to be estimated.\n\n\n\nNote that by calling the name of the fitted model, mdl, you can see the estimated regression coefficients \\(\\hat \\beta_0\\) and \\(\\hat \\beta_1\\). We can add these values to the fitted line:\n\\[\n\\widehat{Income} = 11.32 + 2.65 \\cdot Education \\\\\n\\]\n\n\n\n\n\nQuestion 5\n\n\nExplore the following equivalent ways to obtain the estimated regression coefficients — that is, \\(\\hat \\beta_0\\) and \\(\\hat \\beta_1\\) — from the fitted model:\n\nmdl\nmdl$coefficients\ncoef(mdl)\ncoefficients(mdl)\nsummary(mdl)\n\n\n\n\n\n Solution \n\n\nThe estimated parameters returned by the below methods are all equivalent. However, summary() returns more information.\n\n\nmdl()\nmdl$coefficients\ncoef(mdl)\ncoefficients(mdl)\nsummary(mdl)\n\n\n\nSimply invoke the name of the fitted model:\n\nmdl\n\n\nCall:\nlm(formula = income ~ 1 + education, data = riverview)\n\nCoefficients:\n(Intercept)    education  \n     11.321        2.651  \n\n\n\n\n\nmdl$coefficients\n\n(Intercept)   education \n  11.321379    2.651297 \n\n\n\n\n\ncoef(mdl)\n\n(Intercept)   education \n  11.321379    2.651297 \n\n\n\n\n\ncoefficients(mdl)\n\n(Intercept)   education \n  11.321379    2.651297 \n\n\n\n\nLook under the “Estimate” column:\n\nsummary(mdl)\n\n\nCall:\nlm(formula = income ~ 1 + education, data = riverview)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.809  -5.783   2.088   5.127  18.379 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  11.3214     6.1232   1.849   0.0743 .  \neducation     2.6513     0.3696   7.173 5.56e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.978 on 30 degrees of freedom\nMultiple R-squared:  0.6317,    Adjusted R-squared:  0.6194 \nF-statistic: 51.45 on 1 and 30 DF,  p-value: 5.562e-08\n\n\n\n\n\n\n\n\n\n\n\nThe estimated intercept is \\(\\hat \\beta_0 = 11.32\\) and the estimated slope is \\(\\hat \\beta_1 = 2.65\\).\n\n\n\n\n\n\n\n\nQuestion 6\n\n\nExplore the following equivalent ways to obtain the estimated standard deviation of the errors — that is, \\(\\hat \\sigma\\) — from the fitted model mdl:\n\nsigma(mdl)\nsummary(mdl)\n\n\n Huh? What is \\(\\sigma\\)?\n\n\nThe standard deviation of the errors, denoted by \\(\\sigma\\), is an important quantity that our model estimates. It represents how much individual data points tend to deviate above and below the regression line.\nA small \\(\\sigma\\) indicates that the points hug the line closely and we should expect fairly accurate predictions, while a large \\(\\sigma\\) suggests that, even if we estimate the line perfectly, we can expect individual values to deviate from it by substantial amounts.\nThe estimated standard deviation of the errors is denoted \\(\\hat \\sigma\\), and is estimated by essentially averaging squared residuals (giving the variance) and taking the square-root:\n\\[\n\\begin{align}\n& \\hat \\sigma = \\sqrt{\\frac{SS_{Residual}}{n - k - 1}} \\\\\n\\qquad \\\\\n& \\text{where} \\\\\n& SS_{Residual} = \\textrm{Sum of Squared Residuals} = \\sum_{i=1}^n{(\\epsilon_i)^2}\n\\end{align}\n\\]\n\n\n\n\n\n\n\n Solution \n\n\nThe estimated standard deviation of the errors can be equivalently obtained by the below methods. However, summary() returns more information.\n\n\nsigma(mdl)\nsummary(mdl)\n\n\n\n\nsigma(mdl)\n\n[1] 8.978116\n\n\n\n\nLook at the “Residual standard error” entry of the summary(mdl) output:\n\nsummary(mdl)\n\n\nCall:\nlm(formula = income ~ 1 + education, data = riverview)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.809  -5.783   2.088   5.127  18.379 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  11.3214     6.1232   1.849   0.0743 .  \neducation     2.6513     0.3696   7.173 5.56e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.978 on 30 degrees of freedom\nMultiple R-squared:  0.6317,    Adjusted R-squared:  0.6194 \nF-statistic: 51.45 on 1 and 30 DF,  p-value: 5.562e-08\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe term “Residual standard error” is a misnomer, as the help page for sigma says (check ?sigma). However, it’s hard to get rid of this bad name as it has been used in too many books showing R output.\n\n\n\n\n\n\n\n\n\n\n\nThe estimated standard deviation of the errors is \\(\\hat \\sigma = 8.98\\).\n\n\n\n\n\n\n\n\nQuestion 7\n\n\nInterpret the estimated intercept, slope, and standard deviation of the errors in the context of the research question.\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo interpret the estimated standard deviation of the errors we can use the fact that about 95% of values from a normal distribution fall within two standard deviations of the centre.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nIntercept\nSlope\nStandard deviation of the errors\n\n\n\nThe estimated income associated to zero years of formal education is $11,321.\n\n\nThe estimated increase in income associated to a one year increase in education is $2,651.\n\n\nFor any particular level of education, employee incomes should be distributed above and below the regression line with standard deviation estimated to be \\(\\hat \\sigma = 8.98\\). Since \\(2 \\hat \\sigma = 2 (8.98) = 17.96\\), we expect most (about 95%) of the employee incomes to be within about $18,000 from the regression line.\n\n\n\n\n\n\n\n\nQuestion 8\n\n\nPlot the data and the fitted regression line. To do so:\n\nExtract the estimated regression coefficients e.g., via betas &lt;- coef(mdl)\n\nExtract the first entry of betas (i.e., the intercept) via betas[1]\n\nExtract the second entry of betas (i.e., the slope) via betas[2]\n\nProvide the intercept and slope to the function\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nExtracting values: The function coef(mdl) returns a vector: that is, a sequence of numbers all of the same type. To get the first element of the sequence you append [1], and [2] for the second.\nPlotting: In your ggplot(), you will need to specify geom_abline(). This might help get you started:\n\ngeom_abline(intercept = &lt;intercept&gt;, slope = &lt;slope&gt;)\n\n\n\n\n\n\n\n\n Solution \n\n\nFirst extract the values required:\n\nbetas &lt;- coef(mdl)\nintercept &lt;- betas[1]\nslope &lt;- betas[2]\n\nWe can plot the model as follows:\n\nggplot(data = riverview, aes(x = education, y = income)) +\n  geom_point() +\n  geom_abline(intercept = intercept, slope = slope, color = 'blue') + \n  labs(x = \"Education (in years)\", y = \"Income (in thousands of U.S. dollars)\")"
  },
  {
    "objectID": "0_02_slr.html#predicted-values-residuals",
    "href": "0_02_slr.html#predicted-values-residuals",
    "title": "Simple Linear Regression",
    "section": "Predicted Values & Residuals",
    "text": "Predicted Values & Residuals\n\nPredicted Values\nModel predicted values for sample data:\nWe can get out the model predicted values for \\(y\\), the “y hats” (\\(\\hat y\\)), for the data in the sample using various functions:\n\npredict(&lt;fitted model&gt;)\nfitted(&lt;fitted model&gt;)\nfitted.values(&lt;fitted model&gt;)\nmdl$fitted.values\n\nFor example, this will give us the estimated income (point on our regression line) for each observed value of education level.\n\npredict(mdl)\n\n       1        2        3        4        5        6        7        8 \n32.53175 32.53175 37.83435 37.83435 37.83435 43.13694 43.13694 43.13694 \n       9       10       11       12       13       14       15       16 \n43.13694 48.43953 48.43953 48.43953 51.09083 53.74212 53.74212 53.74212 \n      17       18       19       20       21       22       23       24 \n53.74212 53.74212 56.39342 59.04472 59.04472 61.69601 61.69601 64.34731 \n      25       26       27       28       29       30       31       32 \n64.34731 64.34731 64.34731 66.99861 66.99861 69.64990 69.64990 74.95250 \n\n\nModel predicted values for other (unobserved) data:\nTo compute the model-predicted values for unobserved data (i.e., data not contained in the sample), we can use the following function:\n\npredict(&lt;fitted model&gt;, newdata = &lt;dataframe&gt;)\n\nFor this example, we first need to remember that the model predicts income using the independent variable education. Hence, if we want predictions for new (unobserved) data, we first need to create a tibble with a column called education containing the years of education for which we want the prediction, and store this as a dataframe.\n\n#Create dataframe 'newdata' containing education years of 7, 11 and 25\nnewdata &lt;- tibble(education = c(7, 11, 25))\nnewdata\n\n# A tibble: 3 × 1\n  education\n      &lt;dbl&gt;\n1         7\n2        11\n3        25\n\n\nThen we take newdata and add a new column called income_hat, computed as the prediction from the fitted mdl using the newdata above:\n\nnewdata &lt;- newdata %&gt;%\n  mutate(\n    income_hat = predict(mdl, newdata = newdata)\n  )\nnewdata\n\n# A tibble: 3 × 2\n  education income_hat\n      &lt;dbl&gt;      &lt;dbl&gt;\n1         7       29.9\n2        11       40.5\n3        25       77.6\n\n\nResiduals\nThe residuals represent the deviations between the actual responses and the predicted responses and can be obtained either as\n\nmdl$residuals\nresid(mdl)\nresiduals(mdl)\ncomputing them as the difference between the response (\\(y_i\\)) and the predicted response (\\(\\hat y_i\\))\n\n\n\n\nQuestion 9\n\n\nUse predict(mdl) to compute the fitted values and residuals. Mutate the riverview dataframe to include the fitted values and residuals as extra columns.\nAssign to the following symbols the corresponding numerical values:\n\n\n\\(y_{3}\\) (response variable for unit \\(i = 3\\) in the sample data)\n\n\\(\\hat y_{3}\\) (fitted value for the third unit)\n\n\\(\\hat \\epsilon_{5}\\) (the residual corresponding to the 5th unit, i.e., \\(y_{5} - \\hat y_{5}\\))\n\n\n\n\n\n Solution \n\n\n\nriverview_fitted &lt;- riverview %&gt;%\n  mutate(\n    income_hat = predict(mdl),\n    resid = income - income_hat\n  )\n\nhead(riverview_fitted)\n\n# A tibble: 6 × 8\n  education income seniority gender  male party       income_hat  resid\n      &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;  &lt;dbl&gt;\n1         8   37.4         7 male       1 Democrat          32.5   4.92\n2         8   26.4         9 female     0 Independent       32.5  -6.10\n3        10   47.0        14 male       1 Democrat          37.8   9.20\n4        10   34.2        16 female     0 Independent       37.8  -3.65\n5        10   25.5         1 female     0 Republican        37.8 -12.4 \n6        12   46.5        11 female     0 Democrat          43.1   3.35\n\n\n\n\n\\(y_{3}\\) = 47.03 (see row 3, column 2)\n\n\\(\\hat y_{3}\\) = 37.83 (see row 3, column 7)\n\n\\(\\hat \\epsilon_{5} = y_{5} - \\hat y_{5}\\) = -12.36 (see row 5, columns 2 and 7)\n\n\n\n\n\n\nQuestion 10\n\n\nDescribe the design of the study, and the analyses that you undertook. Interpret your results in the context of the research question and report your model results in full.\nProvide key model results in a formatted table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse tab_model() from the sjPlot package.\nRemember that you can rename your DV and IV labels by specifying dv.labels and pred.labels.\nMake sure to write your results up following APA guidelines\n\n\n\n\n\n\n\n Solution \n\n\nBefore we write up our analyses & results, lets first create the table of results:\n\ntab_model(mdl,\n          dv.labels = \"Income (in thousands of US dollars)\",\n          pred.labels = c(\"education\" = \"Education (years)\"),\n          title = \"Regression Table for Income Model\")\n\n\n\nTable 1: Regression Table for Income Model\n\n\n \nIncome (in thousands of US dollars)\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n11.32\n-1.18 – 23.83\n0.074\n\n\nEducation (years)\n2.65\n1.90 – 3.41\n&lt;0.001\n\n\nObservations\n32\n\n\nR2 / R2 adjusted\n0.632 / 0.619\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe riverview dataset contained information on 32 participants who worked in the hypothetical city of Riverview, US. Using a between-subjects design, the researchers collected information on participants’ sex, income, education, and seniority level.\nTo investigate whether there was an association between income and education level, the following simple linear regression model was used:\n\\[\n\\text{Income}= \\beta_0 + \\beta_1 \\cdot \\text{Education}\n\\]\nFull regression results are displayed in Table 1. The estimated income associated with no formal years of education was $11,321. Each additional year of formal education was associated with an income increase of $2,651."
  },
  {
    "objectID": "1_01_slr.html",
    "href": "1_01_slr.html",
    "title": "Simple Linear Regression",
    "section": "",
    "text": "At the end of this lab, you will:\n\nBe able to specify a simple linear model\n\nUnderstand what fitted values and residuals are\nBe able to interpret the coefficients of a fitted model\n\n\nBe up to date with lectures\n\nHave watched course intro video in Week 0 folder, and completed associated tasks\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\nsjPlot\nkableExtra\n\nAll results should be presented following APA guidelines.If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/wellbeing_rural.csv."
  },
  {
    "objectID": "1_01_slr.html#data-exploration",
    "href": "1_01_slr.html#data-exploration",
    "title": "Simple Linear Regression",
    "section": "Data Exploration",
    "text": "Data Exploration\nThe common first port of call for almost any statistical analysis is to explore the data, and we can do this visually and/or numerically.\n\n\n\n\n\n\n\n\nMarginal Distributions\nBivariate Associations\n\n\n\nDescription\nThe distribution of each variable without reference to the values of the other variables\nDescribing the association between two numeric variables\n\n\n\nVisually \n\n\nPlot each variable individually.  You could use, for example, geom_density() for a density plot or geom_histogram() for a histogram to comment on and/or examine: \n\nThe shape of the distribution. Look at the shape, centre and spread of the distribution. Is it symmetric or skewed? Is it unimodal or bimodal?\n\n\nIdentify any unusual observations. Do you notice any extreme observations (i.e., outliers)?\n\n\n\nPlot associations among two variables.  You could use, for example, geom_point() for a scatterplot to comment on and/or examine: \nThe direction of the association indicates whether there is a positive or negative association\n\n\nThe form of association refers to whether the relationship between the variables can be summarized well with a straight line or some more complicated pattern\n\n\nThe strength of association entails how closely the points fall to a recognizable pattern such as a line\n\n\nUnusual observations that do not fit the pattern of the rest of the observations and which are worth examining in more detail\n\n\n\n\n\nNumerically \n\nCompute and report summary statistics e.g., mean, standard deviation, median, min, max, etc.  You could, for example, calculate summary statistics such as the mean (mean()) and standard deviation (sd()), etc. within summarize()\n\nCompute and report the correlation coefficient.  You can use the cor() function to calculate this\n\n\n\nMarginal Distributions\n\nQuestion 1\n\n\nVisualise and describe the marginal distributions of wellbeing scores and social interactions.\n\n\n\n\n\n\nHint\n\n\n\n\n\nPlot interpretation\n- The shape, center and spread of the distribution\n- Whether the distribution is symmetric or skewed\n- Whether the distribution is unimodal or bimodal\nPlotting tips\n- Use \\n to wrap text in your titles and or axis labels\n- The patchwork package allows us to arrange multiple plots in two ways - | arranges the plots adjacent to one another, and / arranges the plots on top of one another\nTable tips\n- The kableExtra package allows us to produce well formatted tables for our descriptive statistics. To do so, you need to specify the kable() and kable_styling() arguments\n- Review the guidance on the rmd bootcamp, particularly Lesson 4\n\n\n\n\n\n\n\n Solution \n\n\n\n\nWellbeing (WEMWBS) Scores\nSocial Interactions\n\n\n\nVisualisation of distribution:\n\nggplot(data = mwdata, aes(x = wellbeing)) +\n  geom_density() +\n  labs(x = \"Wellbeing (WEMWBS) Scores\", \n       y = \"Probability density\")\n\n\n\nFigure 1: Distribution of Wellbeing (WEMWBS) Scores\n\n\n\nInitial observations from plot:\n\nThe distribution of wellbeing scores was unimodal\nMost of the wellbeing scores were between roughly 30 and 45\nThe lowest wellbeing in the sample was approximately 22 and the highest approximately 59. This suggested there was a fair high degree of variation in the data\nScores were within the range of possible values\n\nDescriptive (or summary) statistics for wellbeing scores:\n\nmwdata %&gt;% \n  summarize(\n    M = mean(wellbeing), \n    SD = sd(wellbeing)\n    ) %&gt;%\n    kable(caption = \"Wellbeing Descriptive Statistics\", align = \"c\", digits = 2) %&gt;%\n    kable_styling(full_width = FALSE)\n\n\n\nTable 1: Wellbeing Descriptive Statistics\n\nM\nSD\n\n\n36.3\n5.39\n\n\n\n\n\n\n\nFollowing the exploration above, we can describe the wellbeing variable as follows:\n\n\n\n\n\n\nThe marginal distribution of scores on the WEMWBS was unimodal with a mean of approximately 36.3. There was variation in WEMWBS scores (SD = 5.39)\n\n\n\n\n\nVisualisation of distribution:\n\nggplot(data = mwdata, aes(x = social_int)) +\n  geom_density() +\n  labs(x = \"Social Interactions (Number per Week)\", \n       y = \"Probability density\")\n\n\n\nFigure 2: Distribution of Number of Social Interactions\n\n\n\nInitial observations from plot:\n\nThe distribution of social interactions was unimodal\nMost of the participants had between 8 and 15 social interactions per week\nThe fewest social interactions per week was approximately 3, and the highest approximately 24. This suggested there was a fair high degree of variation in the data\n\nDescriptive (or summary) statistics for the number of weekly social interactions per week:\n\nmwdata %&gt;% \n  summarize(\n    M = mean(social_int), \n    SD = sd(social_int)\n    ) %&gt;%\n    kable(caption = \"Social Interactions Descriptive Statistics\", align = \"c\", digits = 2) %&gt;%\n    kable_styling(full_width = FALSE)\n\n\n\nTable 2: Social Interactions Descriptive Statistics\n\nM\nSD\n\n\n12.06\n4.02\n\n\n\n\n\n\n\nFollowing the exploration above, we can describe the social interactions variable as follows:\n\n\n\n\n\n\nThe marginal distribution of numbers of social interactions per week was unimodal with a mean of approximately 12.06. There was variation in numbers of social interactions (SD = 4.02)\n\n\n\n\n\n\n\n\n\nAssociations among Variables\n\nCorrelation Matrix\nA table showing the correlation coefficients - \\(r_{(x,y)}=\\frac{\\mathrm{cov}(x,y)}{s_xs_y}\\) - between variables. Each cell in the table shows the association between two variables. The diagonals show the correlation of a variable with itself (and are therefore always equal to 1).\n\nIn R, we can create a correlation matrix by giving the cor() function a dataframe. However, we only want to give it 2 columns here. Think about how we select specific columns, either giving the column numbers inside [], or using select().\n\n\n\n\nQuestion 2\n\n\nCreate a scatterplot of wellbeing score and social interactions before calculating the correlation between them.\nMaking reference to both the plot and correlation coefficient, describe the association between wellbeing and social interactions among participants in the Edinburgh & Lothians sample.\n\n\n\n\n\n\nHint\n\n\n\n\n\nPlot\nWe are trying to investigate how wellbeing varies by varying numbers of weekly social interactions. Hence, wellbeing is the dependent variable (on the y-axis), and social interactions is the independent variable (on the x-axis).\nCorrelation\nMake sure to round your numbers in-line with APA 7th edition guidelines. The round() function will come in handy here, as might this APA numbers and statistics guide!\n\n\n\n\n\n\n\n Solution \n\n\nLet’s produce a scatterplot:\n\nggplot(data = mwdata, aes(x = social_int, y = wellbeing)) +\n  geom_point() +\n  labs(x = \"Social Interactions (Number per Week)\", \n       y = \"Wellbeing (WEMWBS) Scores\")\n\n\n\nFigure 3: Association between Wellbeing and Social Interactions\n\n\n\nTo comment on the strength of the linear association we compute the correlation coefficient in either of the following ways:\n\n\nIndex dataframe ([])\nVariable selection (select())\n\n\n\n\n# correlation matrix of the two columns of interest - (check with columns we need, in this case 3 & 5)\nround(cor(mwdata[,c(3,5)]), digits = 2)\n\n           social_int wellbeing\nsocial_int       1.00      0.24\nwellbeing        0.24      1.00\n\n\n\n\n\n# select only the columns we want by name, and pass this to cor()\nmwdata %&gt;% \n  select(social_int, wellbeing) %&gt;%\n  cor() %&gt;%\n    round(digits = 2)\n\n           social_int wellbeing\nsocial_int       1.00      0.24\nwellbeing        0.24      1.00\n\n\n\n\n\nAnd we can see that via either method, the correlation is \\[\nr_{\\text({Social~Interactions,~~ Wellbeing})} = .24\n\\] \n\n\n\n\n\n\nThere was a weak, positive, linear association between the weekly number of social interactions and WEMWBS scores for the participants in the sample (\\(r\\) = .24). More social interactions were associated, on average, with higher wellbeing scores."
  },
  {
    "objectID": "1_01_slr.html#model-specification-and-fitting",
    "href": "1_01_slr.html#model-specification-and-fitting",
    "title": "Simple Linear Regression",
    "section": "Model Specification and Fitting",
    "text": "Model Specification and Fitting\nThe scatterplot highlighted a linear association, where the data points were scattered around an underlying linear pattern with a roughly-constant spread as x varied.\nHence, we will try to fit a simple (i.e., one x variable only) linear regression model:\n\\[\ny_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i\n\\\\\n\\quad \\text{where} \\quad \\epsilon_i \\sim N(0, \\sigma) \\text{ independently}\n\\]\n\n\n\n\n\n\nWhat does \\(y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i \\quad \\text{where} \\quad \\epsilon_i \\sim N(0, \\sigma) \\text{ independently}\\) mean?\n\n\n\n\n\nLets break the statement down into smaller parts:\n\\(y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i\\)\n\n\n\\(y_i\\) is our measured outcome variable (our DV)\n\n\\(x_i\\) is our measured predictor variable (our IV)\n\n\\(\\beta_0\\) is the model intercept\n\n\\(\\beta_1\\) is the model slope\n\\(\\epsilon \\sim N(0, \\sigma) \\text{ independently}\\)\n\n\n\\(\\epsilon\\) is the residual error\n\n\\(\\sim\\) means ‘distributed according to’\n\n\\(\\sim N(0, \\sigma) \\text{ independently}\\) means ‘normal distribution with a mean of 0 and a variance of \\(\\sigma\\)’\nTogether, we can say that the errors around the line have a mean of zero and constant spread as x varies.\n\n\n\n\n\n\nQuestion 3\n\n\nFirst, write the equation of the fitted line.\nNext, using the lm() function, fit a simple linear model to predict wellbeing (DV) by social interactions (IV), naming the output mdl.\nLastly, update your equation of the fitted line to include the estimated coefficients.\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe syntax of the lm() function is:\n\n model name &lt;- lm(dependent variable ~ independent variable, data = dataframe) \n\n\n\n\n\n\n\n\n Solution \n\n\nFirst, lets specify the fitted model, which can be written either as:\n\n\nOption A\nOption B\n\n\n\n\\[\n\\widehat{Wellbeing} = \\hat \\beta_0 + \\hat \\beta_1 \\cdot Social~Interactions\n\\]\n\n\n\\[\n\\widehat{Wellbeing} = \\hat \\beta_0 \\cdot 1 + \\hat \\beta_1 \\cdot Social~Interactions\n\\]\n\n\n\nTo fit the model in R, as the variables are in the mwdata dataframe, we would write:\n\n\nOption A\nOption B\n\n\n\n\nmdl &lt;- lm(wellbeing ~ social_int, data = mwdata)\nmdl\n\n\nCall:\nlm(formula = wellbeing ~ social_int, data = mwdata)\n\nCoefficients:\n(Intercept)   social_int  \n    32.4077       0.3222  \n\n\n\n\n\nmdl &lt;- lm(wellbeing ~ 1 + social_int, data = mwdata)\nmdl\n\n\nCall:\nlm(formula = wellbeing ~ 1 + social_int, data = mwdata)\n\nCoefficients:\n(Intercept)   social_int  \n    32.4077       0.3222  \n\n\n\n\n\n\n\n\n\n\n\nWhy is there a 1 in the Option B’s?\n\n\n\n\n\nWhen we specify the linear model in R, we include after the tilde sign (\\(\\sim\\)), the variables that appear to the right of the \\(\\hat \\beta\\)s. The intercept, or \\(\\beta_0\\), is a constant. That is, we could write it as multiplied by 1.\nIncluding the 1 explicitly is not necessary because it is included by default (you can check this by comparing the outputs of A & B above with and without the 1 included - the estimates are the same!). After a while, you will find you just want to drop the 1 (i.e., Option B) when calling lm() because you know that it’s going to be there, but in these early weeks we tried to keep it explicit to make it clear that you want to the intercept to be estimated.\n\n\n\nNote that by calling the name of the fitted model, mdl, you can see the estimated regression coefficients \\(\\hat \\beta_0\\) and \\(\\hat \\beta_1\\). We can add these values to the fitted line:\n\\[\n\\widehat{Wellbeing} = 32.41 + 0.32 \\cdot Social~Interactions \\\\\n\\]\n\n\n\n\n\nQuestion 4\n\n\nExplore the following equivalent ways to obtain the estimated regression coefficients — that is, \\(\\hat \\beta_0\\) and \\(\\hat \\beta_1\\) — from the fitted model:\n\nmdl\nmdl$coefficients\ncoef(mdl)\ncoefficients(mdl)\nsummary(mdl)\n\n\n\n\n\n Solution \n\n\nThe estimated parameters returned by the below methods are all equivalent. However, summary() returns more information.\n\n\nmdl()\nmdl$coefficients\ncoef(mdl)\ncoefficients(mdl)\nsummary(mdl)\n\n\n\nSimply invoke the name of the fitted model:\n\nmdl\n\n\nCall:\nlm(formula = wellbeing ~ 1 + social_int, data = mwdata)\n\nCoefficients:\n(Intercept)   social_int  \n    32.4077       0.3222  \n\n\n\n\n\nmdl$coefficients\n\n(Intercept)  social_int \n 32.4077070   0.3221959 \n\n\n\n\n\ncoef(mdl)\n\n(Intercept)  social_int \n 32.4077070   0.3221959 \n\n\n\n\n\ncoefficients(mdl)\n\n(Intercept)  social_int \n 32.4077070   0.3221959 \n\n\n\n\nLook under the “Estimate” column:\n\nsummary(mdl)\n\n\nCall:\nlm(formula = wellbeing ~ 1 + social_int, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.5628  -3.2741  -0.7908   3.3703  20.4706 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 32.40771    1.17532  27.573  &lt; 2e-16 ***\nsocial_int   0.32220    0.09243   3.486 0.000605 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.247 on 198 degrees of freedom\nMultiple R-squared:  0.05781,   Adjusted R-squared:  0.05306 \nF-statistic: 12.15 on 1 and 198 DF,  p-value: 0.0006045\n\n\n\n\n\n\n\n\n\n\n\nThe estimated intercept is \\(\\hat \\beta_0 = 32.41\\) and the estimated slope is \\(\\hat \\beta_1 = 0.32\\).\n\n\n\n\n\n\n\n\nQuestion 5\n\n\nExplore the following equivalent ways to obtain the estimated standard deviation of the errors — that is, \\(\\hat \\sigma\\) — from the fitted model mdl:\n\nsigma(mdl)\nsummary(mdl)\n\n\n Huh? What is \\(\\sigma\\)?\n\n\nThe standard deviation of the errors, denoted by \\(\\sigma\\), is an important quantity that our model estimates. It represents how much individual data points tend to deviate above and below the regression line.\nA small \\(\\sigma\\) indicates that the points hug the line closely and we should expect fairly accurate predictions, while a large \\(\\sigma\\) suggests that, even if we estimate the line perfectly, we can expect individual values to deviate from it by substantial amounts.\nThe estimated standard deviation of the errors is denoted \\(\\hat \\sigma\\), and is estimated by essentially averaging squared residuals (giving the variance) and taking the square-root:\n\\[\n\\begin{align}\n& \\hat \\sigma = \\sqrt{\\frac{SS_{Residual}}{n - k - 1}} \\\\\n\\qquad \\\\\n& \\text{where} \\\\\n& SS_{Residual} = \\textrm{Sum of Squared Residuals} = \\sum_{i=1}^n{(\\epsilon_i)^2}\n\\end{align}\n\\]\n\n\n\n\n\n\n\n Solution \n\n\nThe estimated standard deviation of the errors can be equivalently obtained by the below methods. However, summary() returns more information.\n\n\nsigma(mdl)\nsummary(mdl)\n\n\n\n\nsigma(mdl)\n\n[1] 5.246982\n\n\n\n\nLook at the “Residual standard error” entry of the summary(mdl) output:\n\nsummary(mdl)\n\n\nCall:\nlm(formula = wellbeing ~ 1 + social_int, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.5628  -3.2741  -0.7908   3.3703  20.4706 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 32.40771    1.17532  27.573  &lt; 2e-16 ***\nsocial_int   0.32220    0.09243   3.486 0.000605 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.247 on 198 degrees of freedom\nMultiple R-squared:  0.05781,   Adjusted R-squared:  0.05306 \nF-statistic: 12.15 on 1 and 198 DF,  p-value: 0.0006045\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe term “Residual standard error” is a misnomer, as the help page for sigma says (check ?sigma). However, it’s hard to get rid of this bad name as it has been used in too many books showing R output.\n\n\n\n\n\n\n\n\n\n\n\nThe estimated standard deviation of the errors is \\(\\hat \\sigma = 5.25\\).\n\n\n\n\n\n\n\n\nQuestion 6\n\n\nInterpret the estimated intercept, slope, and standard deviation of the errors in the context of the research question.\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo interpret the estimated standard deviation of the errors we can use the fact that about 95% of values from a normal distribution fall within two standard deviations of the center.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nIntercept\nSlope\nStandard deviation of the errors\n\n\n\nThe estimated wellbeing score associated with zero weekly social interactions is 32.41.\n\n\nThe estimated increase in wellbeing associated with one additional weekly social interaction is 0.32.\n\n\nFor any particular number of weekly social interactions, participants’ wellbeing scores should be distributed above and below the regression line with standard deviation estimated to be \\(\\hat \\sigma = 5.25\\). Since \\(2 \\hat \\sigma = 10.49\\), we expect most (about 95%) of the participants’ wellbeing scores to be within about 11 points from the regression line.\n\n\n\n\n\n\n\n\nQuestion 7\n\n\nPlot the data and the fitted regression line. To do so:\n\nExtract the estimated regression coefficients e.g., via betas &lt;- coef(mdl)\n\nExtract the first entry of betas (i.e., the intercept) via betas[1]\n\nExtract the second entry of betas (i.e., the slope) via betas[2]\n\nProvide the intercept and slope to the function\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nExtracting values\nThe function coef(mdl) returns a vector (a sequence of numbers all of the same type). To get the first element of the sequence you append [1], and [2] for the second.\nPlotting\nIn your ggplot(), you will need to specify geom_abline(). This might help get you started:\n\n geom_abline(intercept = intercept, slope = slope) \n\n\n\n\n\n\n\n\n Solution \n\n\nFirst extract the values required:\n\nbetas &lt;- coef(mdl)\nintercept &lt;- betas[1]\nslope &lt;- betas[2]\n\nWe can plot the model as follows:\n\nggplot(data = mwdata, aes(x = social_int, y = wellbeing)) +\n  geom_point() +\n  geom_abline(intercept = intercept, slope = slope, color = 'blue') + \n  labs(x = \"Social Interactions (Number per Week)\", y = \"Wellbeing (WEMWBS) Scores\")"
  },
  {
    "objectID": "1_01_slr.html#predicted-values-residuals",
    "href": "1_01_slr.html#predicted-values-residuals",
    "title": "Simple Linear Regression",
    "section": "Predicted Values & Residuals",
    "text": "Predicted Values & Residuals\n\nPredicted Values (\\(\\hat y_i\\))\nModel predicted values for sample data:\nWe can get out the model predicted values for \\(y\\), the “y hats” (\\(\\hat y\\)), for the data in the sample using various functions:\n\npredict(&lt;fitted model&gt;)\nfitted(&lt;fitted model&gt;)\nfitted.values(&lt;fitted model&gt;)\nmdl$fitted.values\n\nFor example, this will give us the estimated wellbeing score (point on our regression line) for each observed value of social interactions for each of our 200 participants.\n\npredict(mdl)\n\nFor space saving purposes (i.e., we don’t need to see all 200 values for this demonstration!), we can return the first six predicted values via head():\n\nhead(predict(mdl))\n\n       1        2        3        4        5        6 \n36.59625 37.24064 35.95186 37.24064 38.20723 36.59625 \n\n\nModel predicted values for other (unobserved) data:\nTo compute the model-predicted values for unobserved data (i.e., data not contained in the sample), we can use the following function:\n\npredict(&lt;fitted model&gt;, newdata = &lt;dataframe&gt;)\n\nFor this example, we first need to remember that the model predicts wellbeing using the independent variable social_int. Hence, if we want predictions for new (unobserved) data, we first need to create a tibble with a column called social_int containing the number of weekly social interactions for which we want the prediction, and store this as a dataframe.\n\n#Create dataframe 'newdata' containing 2, 25, and 28 weekly social interactions\nnewdata &lt;- tibble(social_int = c(2, 25, 28))\nnewdata\n\n# A tibble: 3 × 1\n  social_int\n       &lt;dbl&gt;\n1          2\n2         25\n3         28\n\n\nThen we take newdata and add a new column called wellbeing_hat, computed as the prediction from the fitted mdl using the newdata above:\n\nnewdata &lt;- newdata %&gt;%\n  mutate(\n    wellbeing_hat = predict(mdl, newdata = newdata)\n  )\nnewdata\n\n# A tibble: 3 × 2\n  social_int wellbeing_hat\n       &lt;dbl&gt;         &lt;dbl&gt;\n1          2          33.1\n2         25          40.5\n3         28          41.4\n\n\nResiduals (\\(\\hat \\epsilon_i\\))\nThe residuals represent the deviations between the actual responses and the predicted responses and can be obtained either as\n\nmdl$residuals\nresid(mdl)\nresiduals(mdl)\ncomputing them as the difference between the response (\\(y_i\\)) and the predicted response (\\(\\hat y_i\\))\n\n\n\n\nQuestion 8\n\n\nUse predict(mdl) to compute the fitted values and residuals. Mutate the mwdata dataframe to include the fitted values and residuals as extra columns.\nAssign to the following symbols the corresponding numerical values:\n\n\n\\(y_{3}\\) (response variable for unit \\(i = 3\\) in the sample data)\n\n\\(\\hat y_{3}\\) (fitted value for the third unit)\n\n\\(\\hat \\epsilon_{5}\\) (the residual corresponding to the 5th unit, i.e., \\(y_{5} - \\hat y_{5}\\))\n\n\n\n\n\n Solution \n\n\n\nmwdata_fitted &lt;- mwdata %&gt;%\n  mutate(\n    wellbeing_hat = predict(mdl),\n    resid = wellbeing - wellbeing_hat\n  )\n\nhead(mwdata_fitted)\n\n# A tibble: 6 × 9\n    age outdoor_time social_int routine wellbeing location steps_k wellbeing_hat\n  &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;         &lt;dbl&gt;\n1    28           12         13       1        36 rural       21.6          36.6\n2    56            5         15       1        41 rural       12.3          37.2\n3    25           19         11       1        35 rural       49.8          36.0\n4    60           25         15       0        35 rural       NA            37.2\n5    19            9         18       1        32 rural       48.1          38.2\n6    34           18         13       1        34 rural       67.3          36.6\n# ℹ 1 more variable: resid &lt;dbl&gt;\n\n\n\n\n\\(y_{3}\\) = 35 (see row 3, column 5)\n\n\\(\\hat y_{3}\\) = 35.95 (see row 3, column 8)\n\n\\(\\hat \\epsilon_{5} = y_{5} - \\hat y_{5}\\) = 32 - 38.21 = -6.21 (see row 5, columns 5 and 8)"
  },
  {
    "objectID": "1_01_slr.html#writing-up-presenting-results",
    "href": "1_01_slr.html#writing-up-presenting-results",
    "title": "Simple Linear Regression",
    "section": "Writing Up & Presenting Results",
    "text": "Writing Up & Presenting Results\n\nQuestion 9\n\n\nProvide key model results in a formatted table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse tab_model() from the sjPlot package.\nYou can rename your DV and IV labels by specifying dv.labels and pred.labels. To do so, specify your variable name on the left, and what you would like this to be named in the table on the right.\n\n\n\n\n\n\n\n Solution \n\n\n\ntab_model(mdl,\n          dv.labels = \"Wellbeing (WEMWBS) Scores\",\n          pred.labels = c(\"social_int\" = \"Social Interactions (Number per Week)\"),\n          title = \"Regression Table for Wellbeing Model\")\n\n\n\nTable 3: Regression Table for Wellbeing Model\n\n\n\n\n\n\n\n\n \nWellbeing (WEMWBS) Scores\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n32.41\n30.09 – 34.73\n&lt;0.001\n\n\nSocial Interactions\n(Number per Week)\n0.32\n0.14 – 0.50\n0.001\n\n\nObservations\n200\n\n\nR2 / R2 adjusted\n0.058 / 0.053\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nDescribe the design of the study (see Study Overview codebook), and the analyses that you undertook. Interpret your results in the context of the research question and report your model results in full.\nMake reference to your descriptive plots and/or statistics and regression table.\n\n\n\n\n Solution \n\n\n\n\n\n\n\n\nThe mwdata dataset contained information on 200 hypothetical participants who lived in Edinburgh & Lothians area. Using a between-subjects design, the researchers collected information on participants’ wellbeing (measured via WEMWBS), outdoor time (hours per week), social interactions (number per week), routine (whether or not one was followed), location of residence (City, Suburb, or Rural), average weekly steps (in thousands), and age (in years).\nTo visualise the marginal distributions of wellbeing and social interactions, density plots were used. To understand the strength of association between the two variables, the correlation coefficient was estimated. To investigate whether the number of weekly social interactions influences wellbeing (WEMWBS) scores, the following simple linear regression model was used:\n\\[\n\\text{Wellbeing} = \\beta_0 + \\beta_1 \\cdot \\text{Social Interactions}\n\\] From Figure 1 and Figure 2, we can see that both wellbeing \\((M = 36.3, SD = 5.39)\\) and social interactions \\((M = 12.06, SD = 4.02)\\) followed unimodal distributions. There was a weak, positive, linear association between WEMWBS scores and the weekly number of social interactions for the participants in the sample \\((r = .24)\\).\nFull regression results are displayed in Table 3. There was a significant association between wellbeing scores and social interactions \\((\\beta = 0.32, SE = 0.09, p &lt; .001)\\). The estimated wellbeing score with no social interactions per week was 32.41. Each additional social interaction was associated with a 0.32 point increase in wellbeing scores."
  },
  {
    "objectID": "1_02_mlr.html",
    "href": "1_02_mlr.html",
    "title": "Multiple Linear Regression",
    "section": "",
    "text": "At the end of this lab, you will:\n\nExtend the ideas of single linear regression to consider regression models with two or more predictors\nUnderstand and interpret the coefficients in multiple linear regression models\n\n\nBe up to date with lectures\nHave completed Week 1 lab exercises\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\npatchwork\nsjPlot\nkableExtra\n\nAll results should be presented following APA guidelines.If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/wellbeing_rural.csv"
  },
  {
    "objectID": "1_02_mlr.html#study-analysis-plan-overview",
    "href": "1_02_mlr.html#study-analysis-plan-overview",
    "title": "Multiple Linear Regression",
    "section": "Study & Analysis Plan Overview",
    "text": "Study & Analysis Plan Overview\n\nQuestion 1\n\n\nProvide a brief overview of the study design and data, before detailing your analysis plan to address the research question.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nGive the reader some background on the context of the study (you might be able to re-use some of the content you wrote for Lab 1 here)\nState what type of analysis you will conduct in order to address the research question\nSpecify the model to be fitted to address the research question\nSpecify your chosen significance (\\(\\alpha\\)) level\nState your hypotheses\n\nMuch of the information required can be found in the Study Overview codebook.\n\n\n\n\n\n\n\n Solution \n\n\nThe mwdata dataset contained information on 200 hypothetical participants who lived in Edinburgh & Lothians area. Using a between-subjects design, the researchers collected information on participants’ wellbeing (measured via WEMWBS), outdoor time (hours per week), social interactions (number per week), routine (whether or not one was followed), location of residence (City, Suburb, or Rural), average weekly steps (in thousands), and age (in years).\nDensity plots and boxplots will be used to visualise the marginal distributions of wellbeing, social interactions, and outdoor time. To understand the strength of association among the variables, we will estimate the the correlation coefficients. To address the research question of whether there is an association between wellbeing and time spent outdoors after taking into account the association between wellbeing and social interactions, we are going to fit the following multiple linear regression model:\n\\[\n\\text{Wellbeing} = \\beta_0 + \\beta_1 \\cdot Social~Interactions + \\beta_2 \\cdot Outdoor~Time + \\epsilon\n\\]\nEffects will be considered statistically significant at \\(\\alpha=.05\\).\nOur hypotheses are:\n\\(H_0: \\beta_2 = 0\\): There is no association between wellbeing and time spent outdoors after taking into account the association between wellbeing and social interactions\n\\(H_1: \\beta_2 \\neq 0\\): There is an association between wellbeing and time spent outdoors after taking into account the association between wellbeing and social interactions"
  },
  {
    "objectID": "1_02_mlr.html#descriptive-statistics-visualisations",
    "href": "1_02_mlr.html#descriptive-statistics-visualisations",
    "title": "Multiple Linear Regression",
    "section": "Descriptive Statistics & Visualisations",
    "text": "Descriptive Statistics & Visualisations\n\nQuestion 2\n\n\nAlongside descriptive statistics, visualize the marginal distributions of the wellbeing, outdoor_time, and social_int variables.\n\n\n\n\n\n\nHint\n\n\n\n\n\nCode for tables & plots - You might be able to re-use some of the code you wrote for Lab 1 here, and remember that you can refer back to the DAPR1 materials too\nPlot interpretation\n- The shape, center and spread of the distribution\n- Whether the distribution is symmetric or skewed\n- Whether the distribution is unimodal or bimodal\nPlotting tips\n- Use \\n to wrap text in your titles and or axis labels\n- The patchwork package allows us to arrange multiple plots in two ways - | arranges the plots adjacent to one another, and / arranges the plots on top of one another\nTable tips\n- The describe() function from the psych package will produce a table of descriptive statistics. If you would like only a subset of this output (e.g., mean, sd), you can use select() after calling describe() e.g., describe() %&gt;% select(mean, sd)\n- The kableExtra package allows us to produce well formatted tables for our descriptive statistics. To do so, you need to specify the kable() and kable_styling() arguments\n- Review the guidance on the rmd bootcamp, particularly Lesson 4\n\n\n\n\n\n\n\n Solution \n\n\n\n\nNumeric\nVisual\n\n\n\nWe can present our summary statistics for wellbeing, outdoor time, and social interactions as a well formatted table using kable():\n\nmwdata %&gt;% \n  select(wellbeing, outdoor_time, social_int) %&gt;%\n    describe() %&gt;%\n    kable(caption = \"Wellbeing, Social Interactions, and Outdoor Time Descriptive Statistics\", align = \"c\", digits = 2, booktabs = TRUE) %&gt;%\n    kable_styling(full_width = FALSE)\n\n\n\nTable 1: Wellbeing, Social Interactions, and Outdoor Time Descriptive Statistics\n\n\nvars\nn\nmean\nsd\nmedian\ntrimmed\nmad\nmin\nmax\nrange\nskew\nkurtosis\nse\n\n\n\nwellbeing\n1\n200\n36.30\n5.39\n35\n36.07\n4.45\n22\n59\n37\n0.58\n0.92\n0.38\n\n\noutdoor_time\n2\n200\n18.25\n7.10\n18\n18.14\n7.41\n1\n35\n34\n0.06\n-0.62\n0.50\n\n\nsocial_int\n3\n200\n12.06\n4.02\n12\n11.96\n4.45\n3\n24\n21\n0.21\n-0.40\n0.28\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe marginal distribution of scores on the WEMWBS was unimodal with a mean of approximately 36.3. There was variation in WEMWBS scores (SD = 5.39)\n\nThe marginal distribution of weekly hours spent outdoors was unimodal with a mean of approximately 18.25. There was variation in weekly hours spent outdoors (SD = 7.1)\nThe marginal distribution of numbers of social interactions per week was unimodal with a mean of approximately 12.06. There was variation in numbers of social interactions (SD = 4.02)\n\n\n\n\n\n\nYou should be familiar now with how to visualise a marginal distribution. You might choose histograms, density curves, or boxplots, or a combination:\n\nwellbeing_plot &lt;- \n  ggplot(data = mwdata, aes(x = wellbeing)) +\n  geom_density() +\n  geom_boxplot(width = 1/200) +\n  labs(x = \"Score on WEMWBS (range 14-70)\", y = \"Probability\\nDensity\")\n\noutdoortime_plot &lt;- \n  ggplot(data = mwdata, aes(x = outdoor_time)) +\n  geom_density() +\n  geom_boxplot(width = 1/200) +\n  labs(x = \"Time spent outdoors per week (hours)\", y = \"Probability\\nDensity\")\n\nsocial_plot &lt;- \n  ggplot(data = mwdata, aes(x = social_int)) +\n  geom_density() +\n  geom_boxplot(width = 1/200) +\n  labs(x = \"Number of social interactions per week\", y = \"Probability\\nDensity\")\n\n# arrange plots vertically \nwellbeing_plot / outdoortime_plot / social_plot\n\n\n\nFigure 1: Marginal distribution plots of wellbeing sores, weekly hours spent outdoors, and social interactions\n\n\n\n\n\n\n\n\n\n\n\nQuestion 3\n\n\nProduce plots of the associations between the outcome variable (wellbeing) and each of the explanatory variables.\n\n\n\n\n\n\nHint\n\n\n\n\n\nPlot interpretation\n- Direction of association\n- Form of association (can it be summarised well with a straight line?)\n- Strength of association (how closely do points fall to a recognizable pattern such as a line?)\n- Unusual observations that do not fit the pattern of the rest of the observations and which are worth examining in more detail\nPlot tips\n- use \\n to wrap text in your titles and or axis labels\n- consider using geom_smooth() to superimpose the best-fitting line describing the association of interest\n\n\n\n\n\n\n\n Solution \n\n\n\nwellbeing_outdoor &lt;- \n  ggplot(data = mwdata, aes(x = outdoor_time, y = wellbeing)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) + \n  labs(x = \"Time spent outdoors \\nper week (hours)\", y = \"Wellbeing score (WEMWBS)\")\n\nwellbeing_social &lt;- \n  ggplot(data = mwdata, aes(x = social_int, y = wellbeing)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) + \n  labs(x = \"Number of social interactions \\nper week\", y = \"Wellbeing score (WEMWBS)\")\n\n# place plots adjacent to one another\nwellbeing_outdoor | wellbeing_social\n\n\n\nFigure 2: Scatterplots displaying the relationships between scores on the WEMWBS and a) weekly outdoor time (hours), and b) weekly number of social interactions\n\n\n\nBoth scatterplots indicated weak, positive, and linear associations both between wellbeing and outdoor time, and between wellbeing and the number of weekly social interactions.\n\n\n\n\n\nQuestion 4\n\n\nProduce a correlation matrix of the variables which are to be used in the analysis, and write a short paragraph describing the associations.\n\n\n\n\n\n\nHint\n\n\n\n\n\nCorrelation Matrix\nReview Lab 1 Q2 for guidance on how to produce a correlation matrix.\nAPA Format\nMake sure to round your numbers in-line with APA 7th edition guidelines as noted at the start of the lab (see ‘Presenting Results’). The round() function will come in handy here.\n\n\n\n\n\n\n\n Solution \n\n\nWe can either index the dataframe or select the variables of interest:\n\n\nIndex dataframe ([])\nVariable selection (select())\n\n\n\n\n# correlation matrix of the three columns of interest (check which columns we need - in this case, 2,3, and 5)\nround(cor(mwdata[,c(5,3,2)]), digits = 2)\n\n             wellbeing social_int outdoor_time\nwellbeing         1.00       0.24         0.25\nsocial_int        0.24       1.00        -0.04\noutdoor_time      0.25      -0.04         1.00\n\n\n\n\n\n# select only the columns we want by variable name, and pass this to cor()\nmwdata %&gt;% \n  select(wellbeing, social_int, outdoor_time) %&gt;%\n  cor() %&gt;%\n  round(digits = 2)\n\n             wellbeing social_int outdoor_time\nwellbeing         1.00       0.24         0.25\nsocial_int        0.24       1.00        -0.04\noutdoor_time      0.25      -0.04         1.00\n\n\n\n\n\n\n\n\n\n\n\n\nThere was a weak, positive, linear association between WEMWBS scores and weekly outdoor time for the participants in the sample (\\(r\\) = .25). Higher number of hours spent outdoors each week was associated, on average, with higher wellbeing scores\n\nThere was a weak, positive, linear association between WEMWBS scores and the weekly number of social interactions for the participants in the sample (\\(r\\) = .24). More social interactions were associated, on average, with higher wellbeing scores\nThere was a negligible negative correlation between weekly outdoor time and the weekly number of social interactions (\\(r\\) = -.04)"
  },
  {
    "objectID": "1_02_mlr.html#model-fitting-interpretation",
    "href": "1_02_mlr.html#model-fitting-interpretation",
    "title": "Multiple Linear Regression",
    "section": "Model Fitting & Interpretation",
    "text": "Model Fitting & Interpretation\n\nQuestion 5\n\n\nRecall the model specified in Q1, and:\n\nState the parameters of the model. How do we denote parameter estimates?\n\nFit the linear model in using lm(), assigning the output to an object called mdl1.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nAs we did for simple linear regression, we can fit our multiple regression model using the lm() function. We can add as many explanatory (i.e., independent) variables as we like, separating them with a +.\n model name &lt;- lm(dependent variable ~ independent variable 1 + independent variable 2 + …, data = dataframe) \n\n\n\n\n\n\n\n Solution \n\n\nA model for the association between \\(x_1\\) = weekly numbers of social interactions, \\(x_2\\) = weekly outdoor time, and \\(y\\) = scores on the WEMWBS can be given by: \\[\ny = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\epsilon \\\\ \\quad \\\\\n\\text{where} \\quad \\epsilon \\sim N(0, \\sigma) \\text{ independently}\n\\]\nIn the model specified above,\n\n\n\\(\\mu_{y|x_1, x_2} = \\beta_0 + \\beta_1 x + \\beta_2 x_2\\) represents the systematic part of the model giving the mean of \\(y\\) at each combination of values of \\(x_1\\) and \\(x_2\\);\n\n\\(\\epsilon\\) represents the error (deviation) from that mean, and the errors are independent from one another.\n\nThe parameters of our model are:\n\n\n\\(\\beta_0\\) (The intercept);\n\n\\(\\beta_1\\) (The slope across values of \\(x_1\\));\n\n\\(\\beta_2\\) (The slope across values of \\(x_2\\));\n\n\n\\(\\sigma\\) (The standard deviation of the errors).\n\nWhen we estimate these parameters from the available data, we have a fitted model (recall that the h\\(\\hat{\\textrm{a}}\\)ts are used to distinguish our estimates from the true unknown parameters):\n\\[\n\\widehat{Wellbeing} = \\hat \\beta_0 + \\hat \\beta_1 \\cdot Social~Interactions + \\hat \\beta_2 \\cdot Outdoor~Time\n\\] And we have residuals \\(\\hat \\epsilon = y - \\hat y\\) which are the deviations from the observed values and our model-predicted responses.\nFitting the model in R:\n\nmdl1 &lt;- lm(wellbeing ~ social_int + outdoor_time, data = mwdata)\n\n\n\n\n\n\nVisual\nNote that for simple linear regression we talked about our model as a line in 2 dimensions: the systematic part \\(\\beta_0 + \\beta_1 x\\) defined a line for \\(\\mu_y\\) across the possible values of \\(x\\), with \\(\\epsilon\\) as the random deviations from that line. But in multiple regression we have more than two variables making up our model.\nIn this particular case of three variables (one outcome + two explanatory), we can think of our model as a regression surface (see Figure 3). The systematic part of our model defines the surface across a range of possible values of both \\(x_1\\) and \\(x_2\\). Deviations from the surface are determined by the random error component, \\(\\hat \\epsilon\\).\n\n\n\n\nFigure 3: Regression surface for wellbeing ~ social_int + outdoor_time, from two different angles\n\n\n\nDon’t worry about trying to figure out how to visualise it if we had any more explanatory variables! We can only concieve of 3 spatial dimensions. One could imagine this surface changing over time, which would bring in a 4th dimension, but beyond that, it’s not worth trying!\n\n\n\nQuestion 6\n\n\nUsing any of:\n\nmdl1\nmdl1$coefficients\ncoef(mdl1)\ncoefficients(mdl1)\nsummary(mdl1)\n\nWrite out the estimated parameter values of:\n\n\n\\(\\hat \\beta_0\\), the estimated average wellbeing score associated with zero hours of outdoor time and zero social interactions per week.\n\n\n\\(\\hat \\beta_1\\), the estimated increase in average wellbeing score associated with an additional social interaction per week (an increase of one), holding weekly outdoor time constant.\n\n\n\\(\\hat \\beta_2\\), the estimated increase in average wellbeing score associated with one hour increase in weekly outdoor time, holding the number of social interactions constant\n\n\n\n\n\n\n\n\nWhat do we mean by hold constant / controlling for / partialling out / residualizing for?\n\n\n\nWhen the remaining explanatory variables are held at the same value or are fixed.\n\n\n\n\n\n\n Solution \n\n\n\n\nmdl1$coefficients\ncoef(mdl1)\ncoefficients(mdl1)\nsummary(mdl1)\n\n\n\n\nmdl1$coefficients\n\n (Intercept)   social_int outdoor_time \n  28.6201808    0.3348821    0.1990943 \n\n\n\n\n\ncoef(mdl1)\n\n (Intercept)   social_int outdoor_time \n  28.6201808    0.3348821    0.1990943 \n\n\n\n\n\ncoefficients(mdl1)\n\n (Intercept)   social_int outdoor_time \n  28.6201808    0.3348821    0.1990943 \n\n\n\n\nLook under the “Estimate” column:\n\nsummary(mdl1)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7611  -3.1308  -0.4213   3.3126  18.8406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.62018    1.48786  19.236  &lt; 2e-16 ***\nsocial_int    0.33488    0.08929   3.751 0.000232 ***\noutdoor_time  0.19909    0.05060   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.065 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\n\n\n\n\n\n\n\\(\\hat \\beta_0\\) = 28.62\n\n\n\\(\\hat \\beta_1\\) = 0.33\n\n\n\\(\\hat \\beta_2\\) = 0.2\n\n\n\n\n\n\nQuestion 7\n\n\nWithin what distance from the model predicted values (the regression line) would we expect 95% of WEMWBS wellbeing scores to be?\n\n\n\n\n\n\nHint\n\n\n\n\n\nEither sigma() or part of the output from summary() will help you here (see Lab 1 Q5 for a detailed explanation of \\(\\hat \\sigma\\)).\n\n\n\n\n\n\n\n Solution \n\n\n\n\nsigma(mdl1)\nsummary(mdl1)\n\n\n\n\nsigma(mdl1)\n\n[1] 5.065003\n\n\n\n\nLook at the “Residual standard error” entry of the summary(mdl) output:\n\nsummary(mdl1)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7611  -3.1308  -0.4213   3.3126  18.8406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.62018    1.48786  19.236  &lt; 2e-16 ***\nsocial_int    0.33488    0.08929   3.751 0.000232 ***\noutdoor_time  0.19909    0.05060   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.065 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\n\n\n\n\nThe estimated standard deviation of the errors is \\(\\hat \\sigma\\) = 5.07. We would expect 95% of wellbeing scores to be within about 10.13 (\\(2 \\hat \\sigma\\)) from the model fit.\n\n\n\n\n\nQuestion 8\n\n\nBased on the model, predict the wellbeing scores for the following individuals who were not included in the original sample:\n\nLeah: Social Interactions = 25; Outdoor Time = 3\nSean: Social Interactions = 19; Outdoor Time = 36\nMike: Social Interactions = 15; Outdoor Time = 20\nDonna: Social Interactions = 7; Outdoor Time = 1\n\nWho has the highest predicted wellbeing score, and who has the lowest?\n\n\n\n\n\n\nHint\n\n\n\n\n\nIt might be helpful to review the ’Model predicted values for other (unobserved data) from the Predicted Values & Residuals of Lab 1.\n\n\n\n\n\n\n\n Solution \n\n\nFirst we need to pass the data into R:\n\nwellbeing_query &lt;- tibble(social_int = c(25, 19, 15, 7),\n                          outdoor_time = c(3, 36, 20, 1))\n\nAnd next use predict() to get their estimated wellbeing scores:\n\npredict(mdl1, newdata = wellbeing_query)\n\n       1        2        3        4 \n37.58952 42.15034 37.62530 31.16345 \n\n\nSean has the highest predicted wellbeing score (42.15), and Donna the lowest (31.16)."
  },
  {
    "objectID": "1_02_mlr.html#writing-up-presenting-results",
    "href": "1_02_mlr.html#writing-up-presenting-results",
    "title": "Multiple Linear Regression",
    "section": "Writing Up & Presenting Results",
    "text": "Writing Up & Presenting Results\n\nQuestion 9\n\n\nProvide key model results in a formatted table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse tab_model() from the sjPlot package.\nYou can rename your DV and IV labels by specifying dv.labels and pred.labels. To do so, specify your variable name on the left, and what you would like this to be named in the table on the right.\n\n\n\n\n\n\n\n Solution \n\n\n\ntab_model(mdl1,\n          dv.labels = \"Wellbeing (WEMWBS Scores)\",\n          pred.labels = c(\"social_int\" = \"Social Interactions (number per week)\",\n                          \"outdoor_time\" = \"Outdoor Time (hours per week)\"),\n          title = \"Regression Table for Wellbeing Model\")\n\n\n\nTable 2: Regression Table for Wellbeing Model\n\n\n\n\n\n\n\n\n \nWellbeing (WEMWBS Scores)\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n28.62\n25.69 – 31.55\n&lt;0.001\n\n\nSocial Interactions\n(number per week)\n0.33\n0.16 – 0.51\n&lt;0.001\n\n\nOutdoor Time (hours per\nweek)\n0.20\n0.10 – 0.30\n&lt;0.001\n\n\nObservations\n200\n\n\nR2 / R2 adjusted\n0.126 / 0.118\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nInterpret your results in the context of the research question.\nMake reference to the your regression table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nMake sure to include a decision in relation to your null hypothesis - based on the evidence, should you reject or fail to reject the null?\n\n\n\n\n\n\n\n Solution \n\n\nFrom Figure 1, we can see that wellbeing \\((M = 36.3, SD = 5.39)\\), social interactions \\((M = 12.06, SD = 4.02)\\), and outdoor time \\((M = 18.25, SD = 7.1)\\) followed unimodal distributions. There were weak, positive, linear associations between WEMWBS scores and the weekly number of social interactions \\((r = .24)\\), and between WEMWBS scores and outdoor time \\((r = .25)\\) in the sample.\nA multiple regression model was used to determine if there was an association between well-being and time spent outdoors after taking into account the association between well-being and social interactions. As presented in Table 2, outdoor time was significantly associated with wellbeing scores \\((\\beta = 0.20, SE = 0.05, p &lt; .001)\\) after controlling for the number of weekly social interactions. Results suggested that, holding constant social interactions, for every additional hour spent outdoors each week, wellbeing scores increased by 0.20 points. Therefore, we should reject the null hypothesis since \\(p &lt; .05\\)."
  },
  {
    "objectID": "1_03_mlr_stz.html",
    "href": "1_03_mlr_stz.html",
    "title": "Multiple Linear Regression & Standardization",
    "section": "",
    "text": "At the end of this lab, you will:\n\nExtend the ideas of single linear regression to consider regression models with two or more predictors\nUnderstand how to interpret significance tests for \\(\\beta\\) coefficients\nUnderstand how to standardize model coefficients and when this is appropriate to do\nUnderstand how to interpret standardized model coefficients in multiple linear regression models\n\n\nBe up to date with lectures\nHave completed Week 1 and Week 2 lab exercises\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npatchwork\nsjPlot\nppcor\nkableExtra\n\nAll results should be presented following APA guidelines.If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/wellbeing_rural.csv."
  },
  {
    "objectID": "1_03_mlr_stz.html#lab-2-recap",
    "href": "1_03_mlr_stz.html#lab-2-recap",
    "title": "Multiple Linear Regression & Standardization",
    "section": "Lab 2 Recap",
    "text": "Lab 2 Recap\n\nQuestion 1\n\n\nFit the following multiple linear regression model, and assign the output to an object called mdl, and examine the summary output.\n\\[\n\\text{Wellbeing} = \\beta_0 + \\beta_1 \\cdot Social~Interactions + \\beta_2 \\cdot Outdoor~Time + \\epsilon\n\\]\n\n\n\n\n Solution \n\n\n\nmdl &lt;- lm(wellbeing ~ social_int + outdoor_time, data = mwdata)\nsummary(mdl)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7611  -3.1308  -0.4213   3.3126  18.8406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.62018    1.48786  19.236  &lt; 2e-16 ***\nsocial_int    0.33488    0.08929   3.751 0.000232 ***\noutdoor_time  0.19909    0.05060   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.065 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06"
  },
  {
    "objectID": "1_03_mlr_stz.html#significance-tests-for-beta-coefficients",
    "href": "1_03_mlr_stz.html#significance-tests-for-beta-coefficients",
    "title": "Multiple Linear Regression & Standardization",
    "section": "Significance Tests for \\(\\beta\\) Coefficients",
    "text": "Significance Tests for \\(\\beta\\) Coefficients\n\nQuestion 2\n\n\nTest the hypothesis that the population slope for outdoor time is zero — that is, that there is no linear association between wellbeing and outdoor time (after controlling for the number of social interactions) in the population.\n\n\n\n\n\n\nHint\n\n\n\n\n\nRecall the formula for obtaining a test statistic:\nA test statistic for the null hypothesis \\(H_0: \\beta_j = 0\\) is \\[\nt = \\frac{\\hat \\beta_j - 0}{SE(\\hat \\beta_j)}\n\\] which follows a \\(t\\)-distribution with \\(n-k-1\\) degrees of freedom (where \\(k\\) = number of predictors and \\(n\\) = sample size).\n\n\n\n\n\n\n\n Solution \n\n\n\n\nManually\nR Function\n\n\n\nWe calculate the test statistic for \\(\\beta_2\\) as:\n\\[\nt = \\frac{\\hat \\beta_2 - 0}{SE(\\hat \\beta_2)} = \\frac{0.19909 - 0}{0.05060} = 3.934585\n\\]\nand compare it with the 5% critical value from a \\(t\\)-distribution with \\(n-3\\) degrees of freedom (since \\(k = 2\\), we have \\(n-2-1\\)), which is:\n\nn &lt;- nrow(mwdata)\nk &lt;- 2\ntstar &lt;- qt(0.975, df = n - k - 1)\ntstar\n\n[1] 1.972079\n\n#tstar = 1.972079\n\nAs \\(|t|\\) (\\(|t|\\) = 3.93) is much larger than \\(t^*\\) (\\(t^*\\) = 1.97), we can reject the null hypothesis as we have strong evidence against it.\nThe \\(p\\)-value, shown below, also confirms this conclusion.\n\n2 * (1 - pt(3.934585, n - 3))\n\n[1] 0.0001154709\n\n\n\n\nPlease note that the same information was already contained in the row corresponding to the variable “outdoor_time” in the output of summary(mdl), which reported the \\(t\\)-statistic under t value and the \\(p\\)-value under Pr(&gt;|t|):\n\nsummary(mdl)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7611  -3.1308  -0.4213   3.3126  18.8406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.62018    1.48786  19.236  &lt; 2e-16 ***\nsocial_int    0.33488    0.08929   3.751 0.000232 ***\noutdoor_time  0.19909    0.05060   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.065 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\n\nThe result is exactly the same (up to rounding errors) as calculating manually.\nBefore we interpret the results, note that sometimes \\(p\\)-values will be reported to \\(e^X\\). For example, look in the Pr(&gt;|t|) column for “(Intercept)”. The value \\(2e^{-16}\\) simply means \\(2 \\times 10^{-16}\\). This is a very small value (i.e., 0.0000000000000002), hence we would simply report it as &lt;.001 following the APA guidelines.\n\n\n\n\n\n\n\n\n\nWe performed a \\(t\\)-test against the null hypothesis that outdoor time was not associated with wellbeing scores after controlling for social interactions. A significant association was found between outdoor time (hours per week) and wellbeing (WEMWBS scores) \\(t(197) = 3.94,\\ p &lt; .001\\), two-sided. Thus, we have evidence to reject the null hypothesis.\n\n\n\n\n\n\n\n\nQuestion 3\n\n\nObtain 95% confidence intervals for the regression coefficients, and write a sentence about each one.\n\n\n\n\n\n\nHint\n\n\n\n\n\nRecall the formula for obtaining a confidence interval:\nA confidence interval for the population slope is \\[\n\\hat \\beta_j \\pm t^* \\cdot SE(\\hat \\beta_j)\n\\] where \\(t^*\\) denotes the critical value chosen from t-distribution with \\(n-k-1\\) degrees of freedom (where \\(k\\) = number of predictors and \\(n\\) = sample size) for a desired \\(\\alpha\\) level of confidence.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nManually\nR Function\n\n\n\nFor 95% confidence we have \\(t^* = 1.97\\):\n\nn &lt;- nrow(mwdata)\nk &lt;- 2\ntstar &lt;- qt(0.975, df = n - k - 1)\ntstar\n\n[1] 1.972079\n\n\nThe confidence intervals are:\n\ntibble(\n  b0_LowerCI = round(28.62018 - (qt(0.975, n-3) * 1.48786), 3),\n  b0_UpperCI = round(28.62018 + (qt(0.975, n-3)* 1.48786), 3),\n  b1_LowerCI = round(0.33488 - (qt(0.975, n-3) * 0.08929), 3),\n  b1_UpperCI = round(0.33488 + (qt(0.975, n-3)* 0.08929), 3),\n  b2_LowerCI = round(0.19909 - (qt(0.975, n-3) * 0.05060), 3),\n  b2_UpperCI = round(0.19909 + (qt(0.975, n-3)* 0.05060), 3)\n      )\n\n# A tibble: 1 × 6\n  b0_LowerCI b0_UpperCI b1_LowerCI b1_UpperCI b2_LowerCI b2_UpperCI\n       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1       25.7       31.6      0.159      0.511      0.099      0.299\n\n\n\n\nWe can much more easily obtain the confidence intervals for the regression coefficients using the command confint():\n\nconfint(mdl, level = 0.95)\n\n                   2.5 %     97.5 %\n(Intercept)  25.68600170 31.5543598\nsocial_int    0.15880045  0.5109638\noutdoor_time  0.09931273  0.2988759\n\n\nThe result is exactly the same (up to rounding errors) as calculating manually.\n\n\n\n\n\n\n\n\n\n\nThe average wellbeing score for all those with zero hours of outdoor time and zero social interactions per week was between 25.69 and 31.55.\n\nWhen holding weekly outdoor time constant, each increase of one social interaction per week was associated with a difference in wellbeing scores between 0.16 and 0.51, on average.\n\nWhen holding the number of social interactions per week constant, each one hour increase in weekly outdoor time was associated with a difference in wellbeing scores between 0.1 and 0.3, on average."
  },
  {
    "objectID": "1_03_mlr_stz.html#standardization",
    "href": "1_03_mlr_stz.html#standardization",
    "title": "Multiple Linear Regression & Standardization",
    "section": "Standardization",
    "text": "Standardization\n\nQuestion 4\n\n\nFit two regression models using the standardized response and explanatory variables. For demonstration purposes, fit one model using z-scored variables, and the other using the scale() function.\n\n\n\n\n\n\nHint\n\n\n\n\n\nBoth of these methods - z-scoring and scale() - will give us a standardized model.\nZ-Score\nAdd to the “mwdata” dataset three variables called z_wellbeing, z_social_int, and z_outdoor_time representing the standardized welllbeing, social interactions and outdoor time variables, respectively.\nRecall the formula for the \\(z\\)-score: \\[\nz_x = \\frac{x - \\bar{x}}{s_x}, \\qquad z_y = \\frac{y - \\bar{y}}{s_y}\n\\]\nscale()\nUse the scale() function when specifying your lm() statement.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nZ-Score\nscale() function\n\n\n\nz-score variables:\n\nmwdata &lt;- mwdata %&gt;%\n  mutate(\n    z_wellbeing = (wellbeing - mean(wellbeing)) / sd(wellbeing),\n    z_social_int = (social_int - mean(social_int)) / sd(social_int),\n    z_outdoor_time = (outdoor_time - mean(outdoor_time)) / sd(outdoor_time)\n  )\n\nCheck that they are standardized:\n\nmwdata %&gt;%\n  summarise(\n    M_z_wellbeing = round(mean(z_wellbeing),2), SD_z_wellbeing = sd(z_wellbeing), \n    M_z_social_int = round(mean(z_social_int),2), SD_z_social_int = sd(z_social_int),\n    M_z_outdoor_time = round(mean(z_outdoor_time),2), SD_z_outdoor_time = sd(z_outdoor_time)\n  )\n\n# A tibble: 1 × 6\n  M_z_wellbeing SD_z_wellbeing M_z_social_int SD_z_social_int M_z_outdoor_time\n          &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;           &lt;dbl&gt;            &lt;dbl&gt;\n1             0              1              0               1                0\n# ℹ 1 more variable: SD_z_outdoor_time &lt;dbl&gt;\n\n#mean of 0, SD of 1 - all good to go\n\nRun model:\n\nmdl_z &lt;- lm(z_wellbeing ~ z_social_int + z_outdoor_time, data = mwdata)\n\n\n\n\nmdl_s &lt;- lm(scale(wellbeing) ~ scale(social_int) + scale(outdoor_time), data = mwdata)\n\n\n\n\n\n\n\n\n\nQuestion 5\n\n\nExamine the estimates from both standardized models - what do you notice?\n\n\n\n\n Solution \n\n\n\n\nZ-Score\nscale() function\n\n\n\n\nsummary(mdl_z)\n\n\nCall:\nlm(formula = z_wellbeing ~ z_social_int + z_outdoor_time, data = mwdata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9231 -0.5806 -0.0781  0.6144  3.4942 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    -4.168e-16  6.642e-02   0.000 1.000000    \nz_social_int    2.499e-01  6.663e-02   3.751 0.000232 ***\nz_outdoor_time  2.622e-01  6.663e-02   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9394 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\nround(summary(mdl_z)$coefficients, 2)\n\n               Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)        0.00       0.07    0.00        1\nz_social_int       0.25       0.07    3.75        0\nz_outdoor_time     0.26       0.07    3.93        0\n\n\n\n\n\nsummary(mdl_s)\n\n\nCall:\nlm(formula = scale(wellbeing) ~ scale(social_int) + scale(outdoor_time), \n    data = mwdata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9231 -0.5806 -0.0781  0.6144  3.4942 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         -4.106e-16  6.642e-02   0.000 1.000000    \nscale(social_int)    2.499e-01  6.663e-02   3.751 0.000232 ***\nscale(outdoor_time)  2.622e-01  6.663e-02   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9394 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\nround(summary(mdl_s)$coefficients, 2)\n\n                    Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)             0.00       0.07    0.00        1\nscale(social_int)       0.25       0.07    3.75        0\nscale(outdoor_time)     0.26       0.07    3.93        0\n\n\n\n\n\nFrom comparing either the summary() or rounded output, we can see that the estimates are the same under both approaches. That means you can use either approach to standardize the variables in your model.\n\n\n\n\n\nQuestion 6\n\n\nExamine the ‘Coefficients’ section of the summary() output from the standardized and unstandardized models - what do you notice? In other words, what is the same / different?\n\n\n\n\n Solution \n\n\n\n\nUnstandardized\nStandardized\n\n\n\n\nsummary(mdl)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7611  -3.1308  -0.4213   3.3126  18.8406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.62018    1.48786  19.236  &lt; 2e-16 ***\nsocial_int    0.33488    0.08929   3.751 0.000232 ***\noutdoor_time  0.19909    0.05060   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.065 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\nround(summary(mdl)$coefficients, 2)\n\n             Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)     28.62       1.49   19.24        0\nsocial_int       0.33       0.09    3.75        0\noutdoor_time     0.20       0.05    3.93        0\n\n\n\n\n\nsummary(mdl_z)\n\n\nCall:\nlm(formula = z_wellbeing ~ z_social_int + z_outdoor_time, data = mwdata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9231 -0.5806 -0.0781  0.6144  3.4942 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    -4.168e-16  6.642e-02   0.000 1.000000    \nz_social_int    2.499e-01  6.663e-02   3.751 0.000232 ***\nz_outdoor_time  2.622e-01  6.663e-02   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9394 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\nround(summary(mdl_z)$coefficients, 2)\n\n               Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)        0.00       0.07    0.00        1\nz_social_int       0.25       0.07    3.75        0\nz_outdoor_time     0.26       0.07    3.93        0\n\n\n\n\n\nSimilarities\n\nThe \\(t\\) and \\(p\\)-values for the two predictor variables in both models are the same. This is because the significance of these values remains the same for the standardized coefficients as for unstandardized coefficients\n\nDifferences\n\nThe estimates and standard errors for the intercept and both predictor variables are different under the unstandardized and standardized models\n\nThe \\(t\\) and \\(p\\)-values are different in each model for the intercept. This is because:\n\nIn the unstandardized model, the intercept is significantly different from 0 (it is 28.62), and hence has a very small \\(p\\)-value (&lt; .001)\n\nIn the standardized model, the intercept is not significantly different from 0 (it is 0!), and hence has a \\(p\\)-value of 1.\n\n\n\n\n\n\n\n\nQuestion 7\n\n\nHow do these standardized estimates relate to the semi-partial correlation coefficients?\nProduce a visualisation of the association between wellbeing and outdoor time, after accounting for social interactions.\n\n\n\n\n\n\nHint\n\n\n\n\n\nSemi-partial (part) correlation coefficient\nTo calculate semi-partial (part) correlation coefficients, you will need to use the spcor.test() from the ppcor package.\nRecall that you can look at the estimates from either ‘mdl_s’ or ‘mdl_z’ - they contain the same standardized model estimates.\nPlotting\nTo visualise just one association, you need to specify the terms argument in plot_model(). Don’t forget you can look up the documentation by typing ?plot_model in the console.\nSince using plot_model(), We need to use ‘mdl_z’ here not ‘mdl_s’ - it won’t work with a model that’s used the scale() function.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nSemi-partial (part) correlation coefficient\nVisualisation\n\n\n\nFirst, lets recall the estimates from our standardized model (rounding to 2 decimal places):\n\nround(mdl_z$coefficients, 2)\n\n   (Intercept)   z_social_int z_outdoor_time \n          0.00           0.25           0.26 \n\n\nNext, lets calculate the semi-partial correlation coefficients:\n\n#semi-partial (part) correlation between wellbeing & social interactions\nwb_soc &lt;- spcor.test(mwdata$wellbeing, mwdata$social_int, mwdata$outdoor_time,  method=\"pearson\")\n#round correlation coefficient estimate to 2 decimal places\nround(wb_soc$estimate, 2)\n\n[1] 0.25\n\n#semi-partial (part) correlation between wellbeing & outdoor time\nwb_out &lt;- spcor.test(mwdata$wellbeing, mwdata$outdoor_time, mwdata$social_int, method=\"pearson\")\n#round correlation coefficient estimate to 2 decimal places\nround(wb_out$estimate, 2)\n\n[1] 0.26\n\n\nWe can see that the slope estimates from the standardized model are equivalent to the semi-partial (part) correlation coefficients.\n\n\n\nplot_model(mdl_z, type = \"eff\",\n           terms = c(\"z_outdoor_time\"), \n           show.data = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 8\n\n\nPlot the data and the fitted regression line from both the unstandardized and standardized models. To do so, for each model:\n\nExtract the estimated regression coefficients e.g., via betas &lt;- coef(mdl)\n\nExtract the first entry of betas (i.e., the intercept) via betas[1]\n\nExtract the second entry of betas (i.e., the slope) via betas[2]\n\nProvide the intercept and slope to the function\n\nNote down what you observe from the plots - what is the same / different?\n\n\n\n\n\n\nHint\n\n\n\n\n\nThis is very similar to Lab 1 Q7.\nExtracting values\nThe function coef() returns a vector (a sequence of numbers all of the same type). To get the first element of the sequence you append [1], and [2] for the second.\nPlotting\nIn your ggplot(), you will need to specify geom_abline(). This might help get you started:\n\n geom_abline(intercept = intercept, slope = slope) \n\nYou may also want to plot these side by side to more easily compare, so consider using | from patchwork.\n\n\n\n\n\n\n\n Solution \n\n\nFirst extract the values required for both non-standardized and standardized models:\n\n#non-standardized (from 'mdl')\nbetas &lt;- coef(mdl)\nintercept &lt;- betas[1]\nslope &lt;- betas[2]\n\n#standardized (from 'mdl_z')\nbetas_z &lt;- coef(mdl_z)\nintercept_z &lt;- betas_z[1]\nslope_z &lt;- betas_z[2]\n\nWe can plot the models as follows:\n\np1 &lt;- ggplot(data = mwdata, aes(x = social_int, y = wellbeing)) +\n  geom_point() +\n  geom_abline(intercept = intercept, slope = slope, color = 'blue') + \n  labs(x = \"Social Interactions \\n(Number per Week)\", y = \"Wellbeing (WEMWBS) Scores\")\n\np2 &lt;- ggplot(data = mwdata, aes(x = z_social_int, y = z_wellbeing)) +\n  geom_point() +\n  geom_abline(intercept = intercept_z, slope = slope_z, color = 'red') + \n  labs(x = \"Social Interactions \\n(Number per Week; Z-Scored)\", y = \"Wellbeing (WEMWBS) Scores; Z-Scored\")\n\np1 | p2\n\n\n\n\n\n\n\nSimilarities\n\nThe data points are distributed in the same pattern\n\nThe slope of the line follows the same gradient\n\nDifferences\n\nThe x- and y-axis scales are different for each plot. This is because:\n\nThe unstandardized is in the original units where we interpret the slope as the change in \\(y\\) units for a unit change in \\(x\\)\n\nThe standardized is in SD units where we interpret the slope as the SD change in \\(y\\) for 1 SD change in \\(x\\)"
  },
  {
    "objectID": "1_03_mlr_stz.html#writing-up-presenting-results",
    "href": "1_03_mlr_stz.html#writing-up-presenting-results",
    "title": "Multiple Linear Regression & Standardization",
    "section": "Writing Up & Presenting Results",
    "text": "Writing Up & Presenting Results\n\nQuestion 9\n\n\nProvide key model results from the standardized model in a formatted table.\n\n\n\n\n Solution \n\n\n\ntab_model(mdl_z,\n          dv.labels = \"Wellbeing (WEMWBS Scores)\",\n          pred.labels = c(\"z_social_int\" = \"Social Interactions (number per week)\",\n                          \"z_outdoor_time\" = \"Outdoor Time (hours per week)\"),\n          title = \"Regression Results for Wellbeing Model (both DV and IVs z-scored)\")\n\n\n\nTable 1: Regression Results for Wellbeing Model (both DV and IVs z-scored)\n\n\n\n\n\n\n\n\n \nWellbeing (WEMWBS Scores)\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n-0.00\n-0.13 – 0.13\n1.000\n\n\nSocial Interactions\n(number per week)\n0.25\n0.12 – 0.38\n&lt;0.001\n\n\nOutdoor Time (hours per\nweek)\n0.26\n0.13 – 0.39\n&lt;0.001\n\n\nObservations\n200\n\n\nR2 / R2 adjusted\n0.126 / 0.118\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nInterpret the results from the standardized model the context of the research question.\nMake reference to the your regression table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nRemember to inform the reader of the scale of your variables.\n\n\n\n\n\n\n\n Solution \n\n\nA multiple regression model was used to determine if there was an association between well-being and time spent outdoors after taking into account the association between well-being and social interactions. All variables (wellbeing, social interactions, and outdoor time) were \\(z\\)-scored. As presented in Table 1, outdoor time was significantly associated with wellbeing scores \\((\\beta = 0.26, SE = 0.07, p &lt; .001)\\) after controlling for the number of weekly social interactions. Results suggested that, holding constant social interactions, for every standard deviation increase in outdoor time, wellbeing scores increased on average by 0.26 standard deviations. Therefore, we should reject the null hypothesis since \\(p &lt; .05\\)."
  },
  {
    "objectID": "1_04_model_fit_comp.html",
    "href": "1_04_model_fit_comp.html",
    "title": "Model Fit and Comparisons",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand how to calculate the interpret \\(R^2\\) and adjusted-\\(R^2\\) as a measure of model quality.\nUnderstand the calculation and interpretation of the \\(F\\)-test of model utility.\nUnderstand measures of model fit using F.\n\nUnderstand the principles of model selection and how to compare models via F tests.\nUnderstand AIC and BIC.\n\n\nBe up to date with lectures\nHave completed previous lab exercises from Week 1, Week 2, and Week 3\n\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\nsjPlot\nkableExtra\n\nAll results should be presented following APA guidelines. If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/wellbeing_rural.csv."
  },
  {
    "objectID": "1_04_model_fit_comp.html#section-i-model-fit",
    "href": "1_04_model_fit_comp.html#section-i-model-fit",
    "title": "Model Fit and Comparisons",
    "section": "Section I: Model Fit",
    "text": "Section I: Model Fit\nIn the first section of this lab, you will focus on the statistics contained within the highlighted sections of the summary() output below. You will be both calculating these by hand and deriving via R before interpreting these values in the context of the research question.\n\n\n\n\n\n\n\n\n\n\nQuestion 1\n\n\nFit the following multiple linear regression model, and assign the output to an object called mdl, and examine the summary output.\n\\[\n\\text{Wellbeing} = \\beta_0 + \\beta_1 \\cdot Social~Interactions + \\beta_2 \\cdot Outdoor~Time + \\epsilon\n\\]\n\n\n\n\n Solution \n\n\n\nmdl &lt;- lm(wellbeing ~ social_int + outdoor_time, data = mwdata)\nsummary(mdl)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7611  -3.1308  -0.4213   3.3126  18.8406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.62018    1.48786  19.236  &lt; 2e-16 ***\nsocial_int    0.33488    0.08929   3.751 0.000232 ***\noutdoor_time  0.19909    0.05060   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.065 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\n\n\n\n\n\n\nQuestion 2\n\n\nWhat is the proportion of the total variability in wellbeing scores explained by the model?\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe proportion of the total variability explained is given by \\(R^2\\). Since the model includes 2 predictors, you should report the Adjusted-\\(R^2\\).\nThe \\(R^2\\) coefficient is defined as:\n\\[\nR^2 = \\frac{SS_{Model}}{SS_{Total}} = 1 - \\frac{SS_{Residual}}{SS_{Total}}\n\\]\nThe Adjusted-\\(R^2\\) coefficient is defined as:\n\\[\n\\hat R^2 = 1 - \\frac{(1 - R^2)(n-1)}{n-k-1}\n\\quad \\\\  \n\\]\n\\[\n\\begin{align}\n& \\text{Where:} \\\\\n& n = \\text{sample size} \\\\\n& k = \\text{number of explanatory variables} \\\\\n\\end{align}\n\\]\n\n\n\n\n\n\n\n Solution \n\n\n\n\nManually\nR function\n\n\n\nIn R we can write:\n\n#Define n & k\nn &lt;- nrow(mwdata)\nk &lt;- 2\n\n#Predicted scores\nwellbeing_fitted &lt;- mwdata %&gt;%\n  mutate(\n    wellbeing_pred = predict(mdl),\n    wellbeing_resid = wellbeing - wellbeing_pred)\n\n# Sums of Squares, and R / Adjusted R Squared\nwellbeing_fitted %&gt;%\n  summarise(\n    SSModel = sum((wellbeing_pred - mean(wellbeing))^2),\n    SSTotal = sum((wellbeing - mean(wellbeing))^2),\n    SSResid = sum(wellbeing_resid^2)\n  ) %&gt;% \n  summarise(\n    RSquared = SSModel / SSTotal,\n    AdjRSquared = 1-((1-(RSquared))*(n-1)/(n-k-1))\n  )\n\n# A tibble: 1 × 2\n  RSquared AdjRSquared\n     &lt;dbl&gt;       &lt;dbl&gt;\n1    0.126       0.118\n\n\nThe output displays the Adjusted \\(R\\)-squared value in the following column:\nAdjRSquared\n &lt;dbl&gt;\n 0.118\n\n\n\n#look in second bottom row - Multiple R Squared and Adjusted R Squared both reported here\nsummary(mdl)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7611  -3.1308  -0.4213   3.3126  18.8406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.62018    1.48786  19.236  &lt; 2e-16 ***\nsocial_int    0.33488    0.08929   3.751 0.000232 ***\noutdoor_time  0.19909    0.05060   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.065 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\n\nThe output of summary() displays the Adjusted \\(R\\)-squared value in the following line:\nAdjusted R-squared:  0.1176 \n\n\n\n\n\n\n\n\n\nApproximately 12% of the total variability in wellbeing scores is accounted for by social interactions and outdoor time.\n\n\n\n\n\n\n\n\nQuestion 3\n\n\nWhat do you notice about the unadjusted and adjusted R-squared values?\n\n\n\n\n\n\nHint\n\n\n\n\n\nAre they similar or quite different? Why might this be?\n\n\n\n\n\n\n\n Solution \n\n\nThe values of the unadjusted (0.1265) and adjusted R-squared (0.1176) values are quite similar. This is because the sample size is quite large \\((n = 200)\\), and the number of predictors \\((k = 2)\\) is small.\n\n\n\n\n\nQuestion 4\n\n\nPerform a model utility test at the 5% significance level and report your results.\nIn other words, conduct an \\(F\\)-test against the null hypothesis that the model is ineffective at predicting wellbeing scores using social interactions and outdoor time by computing the \\(F\\)-statistic using its definition.\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe \\(F\\)-ratio is used to test the null hypothesis that all regression slopes are zero.\nIt is called the \\(F\\)-ratio because it is the ratio of the how much of the variation is explained by the model (per parameter) versus how much of the variation is left unexplained in the residuals (per remaining degrees of freedom).\n\\[\nF_{df_{model},df_{residual}} = \\frac{MS_{Model}}{MS_{Residual}} = \\frac{SS_{Model}/df_{Model}}{SS_{Residual}/df_{Residual}} \\\\\n\\quad \\\\  \n\\]\n\\[\n\\begin{align}\n& \\text{Where:} \\\\\n& df_{model} = k \\\\\n& df_{residual} = n-k-1 \\\\\n& n = \\text{sample size} \\\\\n& k  = \\text{number of explanatory variables} \\\\\n\\end{align}\n\\]\n\n\n\n\n\n\n\n Solution \n\n\n\n\nManually\nR function\n\n\n\n\n#df(model) = k \ndf1 &lt;- 2\n\n#df(residual) = n - k - 1\ndf2 &lt;- nrow(mwdata) - 2 - 1\n\nf_star &lt;- qf(0.95, df1, df2)\n\n#check value\nf_star\n\n[1] 3.041753\n\n\n\nmodel_utility &lt;- wellbeing_fitted %&gt;%\n  summarise(\n    SSModel = sum((wellbeing_pred - mean(wellbeing))^2),\n    SSResid = sum(wellbeing_resid^2),\n    MSModel = SSModel / df1,\n    MSResid = SSResid / df2,\n    FObs = MSModel / MSResid\n  )\nmodel_utility\n\n# A tibble: 1 × 5\n  SSModel SSResid MSModel MSResid  FObs\n    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1    732.   5054.    366.    25.7  14.3\n\n\nWe can also compute the p-value:\n\npvalue &lt;- 1 - pf(model_utility$FObs, df1, df2)\npvalue\n\n[1] 1.643779e-06\n\n\nThe value 1.643779e-06 simply means \\(1.6 \\times 10^{-6}\\), so it’s a really small number (i.e., 0.000001643779).\n\n\n\n#look in bottom row\nsummary(mdl)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7611  -3.1308  -0.4213   3.3126  18.8406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.62018    1.48786  19.236  &lt; 2e-16 ***\nsocial_int    0.33488    0.08929   3.751 0.000232 ***\noutdoor_time  0.19909    0.05060   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.065 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\n\nThe relevant row is the following:\n\nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\n\n\n\n\n\n\n\n\n\nWe performed an \\(F\\)-test of model utility at the 5% significance level, where \\(F(2,197) = 14.26, p &lt;.001\\).\nThe large \\(F\\)-statistic and small \\(p\\)-value \\((p &lt;.001)\\) suggested that we have very strong evidence against the null hypothesis.\nIn other words, the data provide strong evidence that the number of social interactions and outdoor time are predictors of wellbeing scores."
  },
  {
    "objectID": "1_04_model_fit_comp.html#section-ii-model-comparisons",
    "href": "1_04_model_fit_comp.html#section-ii-model-comparisons",
    "title": "Model Fit and Comparisons",
    "section": "Section II: Model Comparisons",
    "text": "Section II: Model Comparisons\nIn the second section of this lab, you will focus on model comparison where you will formally test a number of research questions:\n\n\nRQ1: Is the number of weekly social interactions a useful predictor of wellbeing scores?\nRQ2: Does weekly outdoor time explain a significant amount of variance in wellbeing scores over and above the number of weekly social interactions?\n\n\n\n\nQuestion 5\n\n\nFit the below 3 models required to address the 2 research questions stated above. Note down which model(s) will be used to address each research question, and examine the results of each model.\nName the models as follows: “wb_mdl0”, “wb_mdl1”, “wb_mdl2”\n\\[\n\\text{Wellbeing} = \\beta_0  + \\epsilon\n\\]\n\n\\[\n\\text{Wellbeing} = \\beta_0  + \\beta_1 \\cdot Social~Interactions + \\epsilon\n\\]\n\n\\[\n\\text{Wellbeing} = \\beta_0  + \\beta_1 \\cdot Social~Interactions + \\beta_2 \\cdot Outdoor~Time + \\epsilon\n\\] \n\n\n\n\n\n\nHint\n\n\n\n\n\nThe summary() function will be useful to examine the model output.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nwb_mdl0\nwb_mdl1\nwb_mdl2\n\n\n\n\n#null/intercept only model\nwb_mdl0 &lt;- lm(wellbeing ~ 1, data = mwdata)\nsummary(wb_mdl0)\n\n\nCall:\nlm(formula = wellbeing ~ 1, data = mwdata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-14.295  -3.295  -1.295   3.705  22.705 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  36.2950     0.3813   95.19   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.392 on 199 degrees of freedom\n\n\n\n\n\n#model with social interactions\nwb_mdl1 &lt;- lm(wellbeing ~ social_int, data = mwdata)\nsummary(wb_mdl1)\n\n\nCall:\nlm(formula = wellbeing ~ social_int, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.5628  -3.2741  -0.7908   3.3703  20.4706 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 32.40771    1.17532  27.573  &lt; 2e-16 ***\nsocial_int   0.32220    0.09243   3.486 0.000605 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.247 on 198 degrees of freedom\nMultiple R-squared:  0.05781,   Adjusted R-squared:  0.05306 \nF-statistic: 12.15 on 1 and 198 DF,  p-value: 0.0006045\n\n\n\n\n\n#model with social interactions and outdoor time\nwb_mdl2 &lt;- lm(wellbeing ~ social_int + outdoor_time, data = mwdata)\nsummary(wb_mdl2)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7611  -3.1308  -0.4213   3.3126  18.8406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.62018    1.48786  19.236  &lt; 2e-16 ***\nsocial_int    0.33488    0.08929   3.751 0.000232 ***\noutdoor_time  0.19909    0.05060   3.935 0.000115 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.065 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\n\n\n\n\nThe models required to address each research question (RQ) are:\n\nRQ1: Models wb_mdl0 and wb_mdl1\nRQ2: Models wb_mdl1 and wb_mdl2\n\n\n\n\n\n\nQuestion 6\n\n\nRQ1: Is the number of weekly social interactions a useful predictor of wellbeing scores?\nCheck that the \\(F\\)-statistic and the \\(p\\)-value are the the same from the model comparison as that which are given at the bottom of summary(wb_mdl1).\nProvide the key model results from the two models in a single formatted table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the anova() function to perform a model comparison between your model with social interactions (wb_mdl1) to the null model (wb_mdl0). Remember that the null model tests the null hypothesis that all beta coefficients are zero. By comparing wb_mdl0 to wb_mdl1, we can test whether we should include the IV of ‘social_int’.\nYou can use KableExtra to present your model comparison results in a well formatted table.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nModel Comparison\nComparing summary() and anova() Outputs\nTable of Model Results\n\n\n\nRun model comparison via anova(), and present results in well formatted table:\n\nanova(wb_mdl0, wb_mdl1) %&gt;%\n    kable(caption = \"Model Comparison - wb_mdl0 vs wb_mdl1\", align = \"c\", digits = c(2,2,2,2,2,4)) %&gt;%\n    kable_styling(full_width = FALSE)\n\n\n\nTable 1: Model Comparison - wb_mdl0 vs wb_mdl1\n\nRes.Df\nRSS\nDf\nSum of Sq\nF\nPr(&gt;F)\n\n\n\n199\n5785.6\nNA\nNA\nNA\nNA\n\n\n198\n5451.1\n1\n334.49\n12.15\n6e-04\n\n\n\n\n\n\n\n\n\n\nThe output of anova(wb_mdl0, wb_mdl1) displays the \\(F\\)-statistic and the \\(p\\)-value in the following line:\n  Res.Df    RSS Df Sum of Sq     F    Pr(&gt;F)  \n2    198 5451.1  1    334.49 12.15 0.0006045 ***\nWe can check that the \\(F\\)-statistic and the \\(p\\)-value are the the same as that which is given at the bottom of summary(wb_mdl1):\nF-statistic: 12.15 on 1 and 198 DF,  p-value: 0.0006045\nThe \\(F\\)-statistic and the \\(p\\)-value from anova(wb_mdl0, wb_mdl1) and summary(wb_mdl1) both match! This is because the \\(F\\)-test from a model with a single predictor (i.e, ‘wb_mdl1’) is really just a comparison against the null model (i.e, ‘wb_mdl0’).\n\n\n\ntab_model(wb_mdl0, wb_mdl1,\n          dv.labels = c(\"Wellbeing (WEMWBS Scores)\", \"Wellbeing (WEMWBS Scores)\"),\n          pred.labels = c(\"social_int\" = \"Social Interactions (number per week)\"),\n          title = \"Regression Table for Wellbeing Models wb0 and wb1\")\n\n\n\nTable 2: Regression Table for Wellbeing Models wb0 and wb1\n\n\n\n\n\n\n\n\n\n\n\n \nWellbeing (WEMWBS Scores)\nWellbeing (WEMWBS Scores)\n\n\nPredictors\nEstimates\nCI\np\nEstimates\nCI\np\n\n\n(Intercept)\n36.29\n35.54 – 37.05\n&lt;0.001\n32.41\n30.09 – 34.73\n&lt;0.001\n\n\nSocial Interactions\n(number per week)\n\n\n\n0.32\n0.14 – 0.50\n0.001\n\n\nObservations\n200\n200\n\n\nR2 / R2 adjusted\n0.000 / 0.000\n0.058 / 0.053\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe number of social interactions was found to explain a significant amount of variance in wellbeing scores (\\(F\\)(1 ,198) = 12.15, \\(p\\)&lt;.001). The model with social interactions was significantly better fitting than the intercept-only model, and thus social interactions is a useful predictor of wellbeing scores. Full regression results are presented in Table 2.\n\n\n\n\n\n\n\n\nQuestion 7\n\n\nLook at the amount of variation in wellbeing scores explained by models “wb_mdl1” and “wb_mdl2”.\nFrom this, can we answer the second research question of whether weekly outdoor time explains a significant amount of variance in wellbeing scores over and above social interactions?\nProvide justification/rationale for your answer.\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou will need to review the R-Squared and Adjusted R-Squared values.\n\n\n\n\n\n\n\n Solution \n\n\nLet’s look at the amount of variance explained by each model:\n\nsummary(wb_mdl1)$r.squared\n\n[1] 0.0578147\n\nsummary(wb_mdl2)$adj.r.squared\n\n[1] 0.1176021\n\n\nThe model with weekly outdoor time as a predictor explains 12% of the variance, and the model without explains 6%. But, from only looking at the proportion of variance accounted for in each model, we cannot determine which model is statistically a better fit.\nTo answer the question ‘Does including weekly outdoor time as a predictor provide a significantly better fit of the data?’ we need to statistically compare wb_mdl1 to wb_mdl2.\n\n\n\n\n\nQuestion 8\n\n\nDoes weekly outdoor time explain a significant amount of variance in wellbeing scores over and above social interactions?\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo address RQ2, you need to statistically compare “wb_mdl1” and “wb_mdl2”.\nYou can use KableExtra to present your model comparison results in a well formatted table.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nModel Comparison\nTable of Model Results\n\n\n\nTo statistically compare models, we could use an incremental \\(F\\)-test to compare the models since the models are nested and from the same dataset:\n\nanova(wb_mdl1, wb_mdl2) %&gt;%\n    kable(caption = \"Model Comparison - wb_mdl1 vs wb_mdl2\", align = \"c\", digits = c(2,2,2,2,2,4)) %&gt;%\n    kable_styling(full_width = FALSE)\n\n\n\nTable 3: Model Comparison - wb_mdl1 vs wb_mdl2\n\nRes.Df\nRSS\nDf\nSum of Sq\nF\nPr(&gt;F)\n\n\n\n198\n5451.10\nNA\nNA\nNA\nNA\n\n\n197\n5053.89\n1\n397.21\n15.48\n1e-04\n\n\n\n\n\n\n\n\n\n\nPresent results from both models:\n\ntab_model(wb_mdl1, wb_mdl2,\n          dv.labels = c(\"Wellbeing (WEMWBS Scores)\", \"Wellbeing (WEMWBS Scores)\"),\n          pred.labels = c(\"social_int\" = \"Social Interactions (number per week)\",\n                          \"outdoor_time\" = \"Outdoor Time (hours per week)\"),\n          title = \"Regression Table for Wellbeing Models wb1 and wb2\")\n\n\n\nTable 4: Regression Table for Wellbeing Models wb1 and wb2\n\n\n\n\n\n\n\n\n\n\n\n \nWellbeing (WEMWBS Scores)\nWellbeing (WEMWBS Scores)\n\n\nPredictors\nEstimates\nCI\np\nEstimates\nCI\np\n\n\n(Intercept)\n32.41\n30.09 – 34.73\n&lt;0.001\n28.62\n25.69 – 31.55\n&lt;0.001\n\n\nSocial Interactions\n(number per week)\n0.32\n0.14 – 0.50\n0.001\n0.33\n0.16 – 0.51\n&lt;0.001\n\n\nOutdoor Time (hours per\nweek)\n\n\n\n0.20\n0.10 – 0.30\n&lt;0.001\n\n\nObservations\n200\n200\n\n\nR2 / R2 adjusted\n0.058 / 0.053\n0.126 / 0.118\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs presented in Table 3, weekly outdoor time was found to explain a significant amount of variance in wellbeing scores over and above weekly social interactions (\\(F\\)(1 ,197) = 15.48, \\(p\\)&lt;.001).\n\n\n\n\n\n\n\n\nQuestion 9\n\n\nCompare the two following models, each looking at the associations of Wellbeing scores and different predictor variables.\n\\(\\text{Wellbeing} = \\beta_0 + \\beta_1 \\cdot \\text{Social~Interactions} + \\beta_2 \\cdot \\text{Age} + \\epsilon\\)\n\\(\\text{Wellbeing} = \\beta_0 + \\beta_1 \\cdot \\text{Outdoor~Time} + \\epsilon\\)\nReport which model you think best fits the data, and justify your answer.\n\n\n\n\n\n\nHint\n\n\n\n\n\nCompare using AIC() and BIC() since the models are non-nested.\n\n\n\n\n\n\n\n Solution \n\n\n\n#fit models\nwb_socint_age &lt;- lm(wellbeing ~ social_int + age, data = mwdata)\nwb_outdoor &lt;- lm(wellbeing ~ outdoor_time, data = mwdata)\n\n\n#AIC values\nAIC(wb_socint_age, wb_outdoor)\n\n              df      AIC\nwb_socint_age  4 1236.575\nwb_outdoor     3 1233.289\n\n#BIC values\nBIC(wb_socint_age, wb_outdoor)\n\n              df      BIC\nwb_socint_age  4 1249.769\nwb_outdoor     3 1243.184\n\n\n\n\n\n\n\n\nWe used AIC and BIC model selection to distinguish between two possible models describing the association between several personal factors and wellbeing scores. The model with outdoor time included as a single predictor was better fitting (AIC = 1233.29) than the alternative model with weekly number of social interactions and age (AIC = 1236.58) included. Based on the BIC value of the former model (BIC = 1243.18), we concluded that it was better fitting than the alternative, latter model (BIC = 1249.77).\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nThe code below fits 6 different models based on our mwdata:\n\nmodel1 &lt;- lm(wellbeing ~ social_int, data = mwdata)\nmodel2 &lt;- lm(wellbeing ~ social_int + outdoor_time, data = mwdata)\nmodel3 &lt;- lm(wellbeing ~ social_int + age, data = mwdata)\nmodel4 &lt;- lm(wellbeing ~ social_int + outdoor_time + age, data = mwdata)\nmodel5 &lt;- lm(wellbeing ~ social_int + outdoor_time + age + steps_k, data = mwdata)\nmodel6 &lt;- lm(wellbeing ~ social_int + outdoor_time, data = wb_data)\n\nFor each of the below pairs of models, what methods are/are not available for us to use for comparison and why?\n\n\nmodel1 vs model2\n\n\nmodel2 vs model3\n\n\nmodel1 vs model4\n\n\nmodel3 vs model5\n\n\nmodel2 vs model6\n\n\nThis flowchart might help you to reach your decision:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou may need to examine the dataset, and check for accuracy (e.g., are there any impossible / out of range values?) and completeness (e.g., are there any missing values?).\n\n\n\n\n\n\n\n Solution \n\n\n\n\nmodel1 vs model2\nmodel2 vs model3\nmodel1 vs model4\nmodel3 vs model5\nmodel2 vs model6\n\n\n\n\nThese models are nested - model2 contains all the variables of model1 and they are fitted on the same dataset.\n\nWe can therefore use an \\(F\\)-test or AIC and BIC.\n\n\n\n\nThese models are not nested, but they are fitted on the same dataset.\n\nWe can therefore use AIC or BIC, but we cannot use an \\(F\\)-test.\n\n\n\n\nThese models are nested - model4 contains all the variables of model1 and they are fitted on the same dataset.\n\nWe can therefore use an \\(F\\)-test or AIC and BIC.\n\n\n\n\nThese models are not nested, and they are not fitted on the same dataset. The “steps_k” variable contains missing values (over 30% of the data is missing for this variable), and so these whole rows are excluded from model5 (but they are included in model3).\nWe cannot compare these models.\n\n\n\n\nThese models are nested, but they are not fitted on the same dataset: model2 uses the ‘mwdata’ dataset, whilst model6 uses the ‘wb_data’ dataset.\nWe cannot compare these models."
  },
  {
    "objectID": "1_05_writeup_recap.html",
    "href": "1_05_writeup_recap.html",
    "title": "Write Up & Block 1 Recap",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand how to write-up and provide interpretation of linear models with single and multiple predictors.\n\n\nBe up to date with lectures\nHave completed Labs 1 - 4\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\npatchwork\nsjPlot\nkableExtra\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/FOMOdataset.csv."
  },
  {
    "objectID": "1_05_writeup_recap.html#study-overview",
    "href": "1_05_writeup_recap.html#study-overview",
    "title": "Write Up & Block 1 Recap",
    "section": "Study Overview",
    "text": "Study Overview\n\nResearch Aim\nExplore the associations among Fear of Missing Out (FoMO), age, social media networks, and the Big Five personality traits.\nResearch Questions\n\nRQ1: Does age predict FoMO?\nRQ2: Does the number of Instagram followers explain a significant amount of variance in FoMO over and above age?\nRQ3: Does personality predict FoMO?\n\n\n\n FoMO data codebook.\n\n\nDescription\nThe data used for this write-up exercise are simulated, drawing on recent work on Fear of Missing Out (FoMO), socio-demographic factors, and the Big Five personality traits. The simulated data are based on the findings of this work, and acted to expand upon the methods and results reported in the following paper:\nRozgonjuk, D., Sindermann, C., Elhai, J. D., & Montag, C. (2021). Individual differences in Fear of Missing Out (FoMO): Age, gender, and the Big Five personality trait domains, facets, and items. Personality and Individual Differences, 171, 110546. https://doi.org/10.1016/j.paid.2020.110546\nIn the current study, participants were invited to an online study investigating the associations among FoMO, socio-demographic factors, and personality. The final sample comprised 3370 people. Participants completed a FOMO scale and a personality inventory. The 10-item FOMO scale measured the extent of experiencing apprehension regarding missing out on interesting events of others on a 5-point scale (1 = “not at all true of me” to 5 = “extremely true of me”), producing a possible range of scores between 10 and 50. The Big Five Inventory (BFI) is a 45-item personality assessment questionnaire (note that only 43 items were used to match the study above) that uses a five-point response scale (1 = “very inapplicable” to 5 = “very applicable”). The BFI consists of five domains: Neuroticism (8 items; possible range of scores 8-40), Extraversion (8 items; possible range of scores 8-40), Openness to Experience (10 items; possible range of scores 10-50), Agreeableness (8 items; possible range of scores 8-40), and Conscientiousness (9 items; possible range of scores 9-45). We extended the aforementioned study to include an extra socio-demographic variable - a measure of popularity on social media based on the number of followers. Unlike the original study, we do not have measures of gender, education level, or specific country of residence.\nData Dictionary\nThe data in FOMOdataset.csv contain eight attributes collected from a simulated sample of \\(n=3370\\) hypothetical individuals across the UK, and include:\n\n\n\n\n\n\n\nVariable\n      Description\n    \n\n\nFOMO\nFoMO Score (as measured by the 10-item FoMO scale)\n\n\nAge\nAge (in years)\n\n\nN\nScore on personality items assessing Neuroticism from the Big Five Inventory (BFI)\n\n\nE\nScore on personality items assessing Extraversion from the Big Five Inventory (BFI)\n\n\nO\nScore on personality items assessing Openness from the Big Five Inventory (BFI)\n\n\nA\nScore on personality items assessing Agreeableness from the Big Five Inventory (BFI)\n\n\nC\nScore on personality items assessing Conscientiousness from the Big Five Inventory (BFI)\n\n\nTotalFollowers\nTotal Number of Instagram Followers\n\n\n\n\n\n\nPreview\nThe first six rows of the data are:\n\n\n\n\n\n\n\nFOMO\n      Age\n      N\n      E\n      O\n      A\n      C\n      TotalFollowers\n    \n\n\n28\n38\n26\n30\n32\n27\n38\n98\n\n\n26\n30\n23\n27\n33\n32\n30\n192\n\n\n23\n33\n14\n30\n36\n27\n24\n177\n\n\n18\n44\n26\n21\n37\n28\n34\n119\n\n\n19\n43\n32\n21\n41\n35\n40\n278\n\n\n24\n43\n22\n25\n31\n30\n24\n184\n\n\n\n\n\n\n\n\n\n\n\n\nSetup\n\nSetup\n\n\n\nCreate a new RMarkdown file\nLoad the required package(s)\nRead the FOMO dataset into R, assigning it to an object named fomo\n\n\n\n\n\n\n Solution \n\n\n\n#Loading the required package(s)\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(sjPlot)\nlibrary(kableExtra)\nlibrary(psych)\n\n#Reading in fomo data and storing in object named 'fomo'\nfomo &lt;- read_csv(\"https://uoepsy.github.io/data/FOMOdataset.csv\")\n\n#check first six rows\nhead(fomo)\n\n# A tibble: 6 × 8\n   FOMO   Age     N     E     O     A     C TotalFollowers\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;          &lt;dbl&gt;\n1    28    38    26    30    32    27    38             98\n2    26    30    23    27    33    32    30            192\n3    23    33    14    30    36    27    24            177\n4    18    44    26    21    37    28    34            119\n5    19    43    32    21    41    35    40            278\n6    24    43    22    25    31    30    24            184\n\n\n\n\n\n\nProvided Analysis Code\nBelow you will find the code required to conduct the analysis to address the research questions. This should look similar (in most areas) to what you worked through in lecture.\n\n Provided Analysis Code"
  },
  {
    "objectID": "1_05_writeup_recap.html#data-management",
    "href": "1_05_writeup_recap.html#data-management",
    "title": "Write Up & Block 1 Recap",
    "section": "Data Management",
    "text": "Data Management\n\nlibrary(tidyverse) # for all things!\nlibrary(psych) # good for descriptive stats\nlibrary(patchwork) # grouping plots together\nlibrary(kableExtra) # useful for creating nice tables\nlibrary(sjPlot) #regression tables & plots\n\nfomo &lt;- read_csv(\"https://uoepsy.github.io/data/FOMOdataset.csv\")\n\n# standardise FoMO & personality scores for RQ3\nfomo &lt;- \n  fomo %&gt;% \n    mutate(\n      FOMOz = (FOMO-mean(FOMO))/sd(FOMO),\n      Oz = (O-mean(O))/sd(O),\n      Cz = (C-mean(C))/sd(C),\n      Ez = (E-mean(E))/sd(E),\n      Az = (A-mean(A))/sd(A),      \n      Nz = (N-mean(N))/sd(N))\n#alternatively, you could do FOMOz = scale(FOMO, center = TRUE, scale = TRUE)"
  },
  {
    "objectID": "1_05_writeup_recap.html#overall",
    "href": "1_05_writeup_recap.html#overall",
    "title": "Write Up & Block 1 Recap",
    "section": "Overall",
    "text": "Overall\n\n#######\n#Descriptive Stats\n#######\n\n\n# the describe() function is from the psych package, and kable() from kableExtra which is used to make a nice table where the values are rounded to 2 decimal places using digits = 2. \n# We are first renaming our variables to give more appropriate / informative names.\n#Next we are selecting columns 2, 3, 4, 8, and 9 from the describe output (n, mean, sd, min, max)\n\nfomo %&gt;% \n    select(FOMO, Age, TotalFollowers, N, E, O, C, A) %&gt;%\n    rename(\"Fear of Missing Out\" = FOMO, \"Age (in years)\" = Age, \"Number of Instagram Followers\" = TotalFollowers, \"Neuroticism\" = N, \"Extraversion\" = E, \"Openness\" = O, \"Conscientiousness\" = C, \"Agreeableness\" = A) %&gt;%\n    describe() %&gt;%\n    select(2:4, 8:9) %&gt;%\n    rename(\"N\" = n, \"Mean\" = mean, \"SD\" = sd, \"Minimum\" = min, \"Maximum\" = max) %&gt;%\n        kable(., caption = \"FoMO, Socio-Demographic Factors, and Personality Traits Descriptive Statistics\", digits = 2) %&gt;%\n        kable_styling()   \n\n\nFoMO, Socio-Demographic Factors, and Personality Traits Descriptive Statistics\n\n\nN\nMean\nSD\nMinimum\nMaximum\n\n\n\nFear of Missing Out\n3370\n24.63\n6.42\n10\n46\n\n\nAge (in years)\n3370\n33.61\n10.42\n12\n75\n\n\nNumber of Instagram Followers\n3370\n203.25\n93.42\n1\n594\n\n\nNeuroticism\n3370\n22.92\n5.77\n8\n40\n\n\nExtraversion\n3370\n25.88\n5.94\n8\n40\n\n\nOpenness\n3370\n37.61\n5.80\n14\n50\n\n\nConscientiousness\n3370\n31.04\n5.49\n13\n45\n\n\nAgreeableness\n3370\n30.89\n4.93\n13\n43\n\n\n\n\n#from above, no missing values and scores within range (look at min and max values)\n\n\n# scatterplot matrix, hist, and corr of FoMO, Socio-Demographic Factors, and Personality Traits Descriptive Statistics\npairs.panels(fomo %&gt;%\n    select(-FOMOz, -Oz, -Cz, -Ez, -Az, -Nz))"
  },
  {
    "objectID": "1_05_writeup_recap.html#rq1",
    "href": "1_05_writeup_recap.html#rq1",
    "title": "Write Up & Block 1 Recap",
    "section": "RQ1",
    "text": "RQ1\n\n#######\n#Descriptive Stats\n#######\n\nfomo %&gt;% \n    select(FOMO, Age) %&gt;%\n    rename(\"Fear of Missing Out\" = FOMO, \"Age (in years)\" = Age) %&gt;%\n    describe() %&gt;%\n    select(2:4, 8:9) %&gt;%\n    rename(\"N\" = n, \"Mean\" = mean, \"SD\" = sd, \"Minimum\" = min, \"Maximum\" = max) %&gt;%    \n        kable(., caption = \"FoMO and Age Descriptive Statistics\", digits = 2) %&gt;%\n        kable_styling()    \n\n\nFoMO and Age Descriptive Statistics\n\n\nN\nMean\nSD\nMinimum\nMaximum\n\n\n\nFear of Missing Out\n3370\n24.63\n6.42\n10\n46\n\n\nAge (in years)\n3370\n33.61\n10.42\n12\n75\n\n\n\n\n# scatterplot\np1 &lt;- ggplot(data = fomo, aes(x = Age, y = FOMO)) + \n    geom_point() + \n  geom_smooth(method = 'lm', se = FALSE, colour = 'red', linewidth=2) +\n  labs(x = \"(a) Age (in years)\", y = \"Fear of Missing Out\")\np1\n\n\n\n\n\n\n\n\n#######\n#Model Building\n#######\n\nfomo_mdl1 &lt;- lm(FOMO ~ Age, data = fomo)\nsummary(fomo_mdl1)\n\n\nCall:\nlm(formula = FOMO ~ Age, data = fomo)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-17.1028  -4.2129  -0.1602   4.0551  22.2321 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 31.22239    0.35408   88.18   &lt;2e-16 ***\nAge         -0.19617    0.01006  -19.50   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.084 on 3368 degrees of freedom\nMultiple R-squared:  0.1014,    Adjusted R-squared:  0.1011 \nF-statistic: 380.1 on 1 and 3368 DF,  p-value: &lt; 2.2e-16\n\nconfint(fomo_mdl1)\n\n                 2.5 %     97.5 %\n(Intercept) 30.5281496 31.9166293\nAge         -0.2158992 -0.1764425\n\n\n\n#######\n#Table for Results\n#######\n\ntab_model(fomo_mdl1,\n          dv.labels = \"FoMO\",\n          pred.labels = c(\"Age\" = \"Age (in years)\"), \n          title = \"RQ1: Regression Table for FoMO Model\")\n\n\nRQ1: Regression Table for FoMO Model\n\n\n \nFoMO\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n31.22\n30.53 – 31.92\n&lt;0.001\n\n\nAge (in years)\n-0.20\n-0.22 – -0.18\n&lt;0.001\n\n\nObservations\n3370\n\n\nR2 / R2 adjusted\n0.101 / 0.101"
  },
  {
    "objectID": "1_05_writeup_recap.html#rq2",
    "href": "1_05_writeup_recap.html#rq2",
    "title": "Write Up & Block 1 Recap",
    "section": "RQ2",
    "text": "RQ2\n\n#######\n#Descriptive Stats\n#######\n\nfomo %&gt;% \n    select(FOMO, Age, TotalFollowers) %&gt;%\n    rename(\"Fear of Missing Out\" = FOMO, \"Age (in years)\" = Age, \"Number of Instagram Followers\" = TotalFollowers) %&gt;%\n    describe() %&gt;%\n    select(2:4, 8:9) %&gt;%\n    rename(\"N\" = n, \"Mean\" = mean, \"SD\" = sd, \"Minimum\" = min, \"Maximum\" = max) %&gt;%    \n        kable(., caption = \"FoMO and Socio-Demographic Factors Descriptive Statistics\", digits = 2) %&gt;%\n        kable_styling()    \n\n\nFoMO and Socio-Demographic Factors Descriptive Statistics\n\n\nN\nMean\nSD\nMinimum\nMaximum\n\n\n\nFear of Missing Out\n3370\n24.63\n6.42\n10\n46\n\n\nAge (in years)\n3370\n33.61\n10.42\n12\n75\n\n\nNumber of Instagram Followers\n3370\n203.25\n93.42\n1\n594\n\n\n\n\n# scatterplots\np2 &lt;- ggplot(data = fomo, aes(x = TotalFollowers, y = FOMO)) + \n    geom_point() + \n  geom_smooth(method = 'lm', se = FALSE, colour = 'purple', linewidth=2) +\n  labs(x = \"(b) Total Number of \\nInstagram Followers\", y = \"Fear of Missing Out\")\n\np2\n\n\n\n\n\n\n\n\n#######\n#Model Building\n#######\n\nfomo_mdl2 &lt;- lm(FOMO ~ Age + TotalFollowers, data = fomo)\nsummary(fomo_mdl2)\n\n\nCall:\nlm(formula = FOMO ~ Age + TotalFollowers, data = fomo)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-17.273  -4.066  -0.071   3.841  21.705 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    26.521966   0.446021   59.46   &lt;2e-16 ***\nAge            -0.165111   0.009871  -16.73   &lt;2e-16 ***\nTotalFollowers  0.017989   0.001101   16.34   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.857 on 3367 degrees of freedom\nMultiple R-squared:  0.1674,    Adjusted R-squared:  0.1669 \nF-statistic: 338.6 on 2 and 3367 DF,  p-value: &lt; 2.2e-16\n\nconfint(fomo_mdl2)\n\n                     2.5 %      97.5 %\n(Intercept)    25.64746694 27.39646570\nAge            -0.18446526 -0.14575589\nTotalFollowers  0.01583102  0.02014788\n\n\n\n#######\n#Model Comparison\n#######\n\nanova(fomo_mdl1 ,fomo_mdl2) %&gt;%\n    kable(caption = \"Model Comparison - fomo_mdl1 vs fomo_mdl2\", align = \"c\", digits = c(2,2,2,2,2,60)) %&gt;%\n    kable_styling(full_width = FALSE)\n\n\nModel Comparison - fomo_mdl1 vs fomo_mdl2\n\nRes.Df\nRSS\nDf\nSum of Sq\nF\nPr(&gt;F)\n\n\n\n3368\n124676.4\nNA\nNA\nNA\nNA\n\n\n3367\n115515.0\n1\n9161.44\n267.04\n7.98e-58\n\n\n\n\n\n\n#######\n#Table for Results\n#######\n\ntab_model(fomo_mdl1 ,fomo_mdl2,\n          dv.labels = c(\"FoMO\",\"FoMO\"),\n          pred.labels = c(\"Age\" = \"Age (in years)\",\n                          \"TotalFollowers\" = \"Number of Instagram Followers\"), \n          title = \"RQ2 - Regression Table for FoMO Model\")\n\n\nRQ2 - Regression Table for FoMO Model\n\n\n\n\n\n\n\n\n\n\n\n \nFoMO\nFoMO\n\n\nPredictors\nEstimates\nCI\np\nEstimates\nCI\np\n\n\n(Intercept)\n31.22\n30.53 – 31.92\n&lt;0.001\n26.52\n25.65 – 27.40\n&lt;0.001\n\n\nAge (in years)\n-0.20\n-0.22 – -0.18\n&lt;0.001\n-0.17\n-0.18 – -0.15\n&lt;0.001\n\n\nNumber of Instagram\nFollowers\n\n\n\n0.02\n0.02 – 0.02\n&lt;0.001\n\n\nObservations\n3370\n3370\n\n\nR2 / R2 adjusted\n0.101 / 0.101\n0.167 / 0.167"
  },
  {
    "objectID": "1_05_writeup_recap.html#rq3",
    "href": "1_05_writeup_recap.html#rq3",
    "title": "Write Up & Block 1 Recap",
    "section": "RQ3",
    "text": "RQ3\n\n#######\n#Descriptive Stats\n#######\n\nfomo %&gt;% \n    select(FOMO, N, E, O, C, A) %&gt;%\n    rename(\"Fear of Missing Out\" = FOMO, \"Neuroticism\" = N, \"Extraversion\" = E, \"Openness\" = O, \"Conscientiousness\" = C, \"Agreeableness\" = A) %&gt;%\n    describe() %&gt;%\n    select(2:4, 8:9) %&gt;%\n    rename(\"N\" = n, \"Mean\" = mean, \"SD\" = sd, \"Minimum\" = min, \"Maximum\" = max) %&gt;%    \n        kable(., caption = \"FoMO and Personality Descriptive Statistics\", digits = 2) %&gt;%\n        kable_styling()  \n\n\nFoMO and Personality Descriptive Statistics\n\n\nN\nMean\nSD\nMinimum\nMaximum\n\n\n\nFear of Missing Out\n3370\n24.63\n6.42\n10\n46\n\n\nNeuroticism\n3370\n22.92\n5.77\n8\n40\n\n\nExtraversion\n3370\n25.88\n5.94\n8\n40\n\n\nOpenness\n3370\n37.61\n5.80\n14\n50\n\n\nConscientiousness\n3370\n31.04\n5.49\n13\n45\n\n\nAgreeableness\n3370\n30.89\n4.93\n13\n43\n\n\n\n\n\n\n#######\n#Model Building\n#######\n\nfomo_mdl3 &lt;- lm(FOMOz ~ Nz + Ez + Oz + Cz + Az, data = fomo)\nsummary(fomo_mdl3)\n\n\nCall:\nlm(formula = FOMOz ~ Nz + Ez + Oz + Cz + Az, data = fomo)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.74061 -0.60648 -0.01036  0.59506  3.13402 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -1.453e-17  1.527e-02   0.000    1.000    \nNz           4.266e-01  1.643e-02  25.971  &lt; 2e-16 ***\nEz           1.744e-02  1.570e-02   1.111    0.267    \nOz           1.117e-02  1.550e-02   0.721    0.471    \nCz          -3.079e-01  1.596e-02 -19.289  &lt; 2e-16 ***\nAz          -8.508e-02  1.544e-02  -5.511 3.83e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8865 on 3364 degrees of freedom\nMultiple R-squared:  0.2152,    Adjusted R-squared:  0.2141 \nF-statistic: 184.5 on 5 and 3364 DF,  p-value: &lt; 2.2e-16\n\nconfint(fomo_mdl3)\n\n                  2.5 %      97.5 %\n(Intercept) -0.02994194  0.02994194\nNz           0.39441959  0.45883445\nEz          -0.01334388  0.04823358\nOz          -0.01921470  0.04155523\nCz          -0.33916065 -0.27657348\nAz          -0.11535145 -0.05481487\n\n\n\n#plot model examining significant personality predictors\nN_plot &lt;- plot_model(fomo_mdl3, type = \"eff\",\n           terms = c(\"Nz\"),\n           show.data = TRUE,\n           axis.title = c(\"Neuroticsm \\n(z-scored)\",\"FoMO Score (z-scored)\"),\n           title = \"FoMO & N\")\n\nC_plot &lt;- plot_model(fomo_mdl3, type = \"eff\",\n           terms = c(\"Cz\"),\n           show.data = TRUE,\n           axis.title = c(\"Conscientiousness \\n(z-scored)\",\"FoMO Score (z-scored)\"),\n           title = \"FoMO & C\")\n\nA_plot &lt;- plot_model(fomo_mdl3, type = \"eff\",\n           terms = c(\"Az\"),\n           show.data = TRUE,\n           axis.title = c(\"Agreeableness \\n(z-scored)\",\"FoMO Score (z-scored)\"),\n           title = \"FoMO & A\")\n\nN_plot | C_plot | A_plot\n\n\n\n\n\n\n\n\n#create table for results - RQ3\ntab_model(fomo_mdl3,\n          dv.labels = \"FoMO (Z-Scored)\",\n          pred.labels = c(\"Nz\" = \"Neuroticism (Z-Scored)\",\n                          \"Ez\" = \"Extraversion (Z-Scored)\",\n                          \"Oz\" = \"Openness (Z-Scored)\",\n                          \"Az\" = \"Agreeableness (Z-Scored)\",\n                          \"Cz\" = \"Conscientiousness (Z-Scored)\"),\n          title = \"RQ3 - Regression Table for FoMO Model\")\n\n\nRQ3 - Regression Table for FoMO Model\n\n\n\n\n\n\n\n\n \nFoMO (Z-Scored)\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n-0.00\n-0.03 – 0.03\n1.000\n\n\nNeuroticism (Z-Scored)\n0.43\n0.39 – 0.46\n&lt;0.001\n\n\nExtraversion (Z-Scored)\n0.02\n-0.01 – 0.05\n0.267\n\n\nOpenness (Z-Scored)\n0.01\n-0.02 – 0.04\n0.471\n\n\nConscientiousness\n(Z-Scored)\n-0.31\n-0.34 – -0.28\n&lt;0.001\n\n\nAgreeableness (Z-Scored)\n-0.09\n-0.12 – -0.05\n&lt;0.001\n\n\nObservations\n3370\n\n\nR2 / R2 adjusted\n0.215 / 0.214"
  },
  {
    "objectID": "1_06_dummy.html",
    "href": "1_06_dummy.html",
    "title": "Dummy Coding",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand how to specify a new baseline/reference level for categorical variables\nUnderstand how to specify dummy coding\nInterpret the output from a model using dummy coding\nUnderstand how to specify contracts to test specific effects\n\n\nBe up to date with lectures\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\nkableExtra\nemmeans\n\nAll results should be presented following APA guidelines. If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/caffeinedrink.csv"
  },
  {
    "objectID": "1_06_dummy.html#study-analysis-plan-overview",
    "href": "1_06_dummy.html#study-analysis-plan-overview",
    "title": "Dummy Coding",
    "section": "Study & Analysis Plan Overview",
    "text": "Study & Analysis Plan Overview\n\nQuestion 1\n\n\nExamine the dataset, and perform any necessary and appropriate data management steps.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nConvert categorical variables to factors\nLabel appropriately factors to aid with your model interpretations if required\nIf needed, provide better variable names\n\n\n\n\n\n\n\n\n Solution \n\n\nLet’s have a look at the data to see what we’re working with:\n\n#first look at dataset structure\nstr(caffeine)\n\nspc_tbl_ [40 × 2] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ treatment: chr [1:40] \"control\" \"control\" \"control\" \"control\" ...\n $ wpm      : num [1:40] 109 114 113 110 116 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   treatment = col_character(),\n  ..   wpm = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n#now lets look at top 6 rows (or the head) of the dataset\nhead(caffeine)\n\n# A tibble: 6 × 2\n  treatment   wpm\n  &lt;chr&gt;     &lt;dbl&gt;\n1 control    109.\n2 control    114.\n3 control    113.\n4 control    110.\n5 control    116.\n6 control    113.\n\n#check for NAs - there are none - all FALSE\ntable(is.na(caffeine))\n\n\nFALSE \n   80 \n\n\nLet’s start with the ‘treatment’ condition variable. This should be coded as factor (&lt;fctr&gt;), but can see from above it is currently coded as a character (&lt;chr&gt;). Let’s correct this.\n\n#Code treatment as a factor\ncaffeine &lt;- caffeine %&gt;%\n  mutate(treatment = as_factor(treatment))\n\nNext, let’s look at the ‘wpm’ variable. Here we want to check for impossible values - i.e., cannot have a negative WPM.\n\n# all looks ok - min and max both positive values\ndescribe(caffeine$wpm)\n\n   vars  n   mean   sd median trimmed  mad    min    max range skew kurtosis\nX1    1 40 113.59 2.92 113.06  113.51 3.62 107.94 120.24  12.3 0.22    -0.84\n     se\nX1 0.46\n\n\n\n\n\n\n\n\nAll participant data was complete (no missing values), with WPM scores within possible ranges. Treatment was coded as a factor with four levels (control (water), coffee, red bull, and mint tea).\n\n\n\n\n\n\n\n\nQuestion 2\n\n\nChoose an appropriate reference level for the Treatment condition.\n\n\n\n\n Solution \n\n\nThe Treatment factor has a group coded ‘Control (Water)’ which lends itself naturally to be the reference category.\n\n#set 'Control' caffeine treatment condition as our reference group \ncaffeine$treatment &lt;- relevel(caffeine$treatment, \"control\")\n\n#check levels - control should be first in the list\nlevels(caffeine$treatment)\n\n[1] \"control\"  \"coffee\"   \"red_bull\" \"mint_tea\"\n\n\n\n\n\n\n\nQuestion 3\n\n\nProvide a brief overview of the study design and data, before detailing your analysis plan to address the research question.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nGive the reader some background on the context of the study\nState what type of analysis you will conduct in order to address the research question\nSpecify the model to be fitted to address the research question (note that you will need to specify the reference level of your categorical variable)\nSpecify your chosen significance (\\(\\alpha\\)) level\nState your hypotheses\n\nMuch of the information required can be found in the Study Overview codebook.\n\n\n\n\n\n\n\n Solution \n\n\nThe caffeine dataset contained information on 40 hypothetical participants who took part in an experiment examining whether the number of words typed per minute (WPM) differed among caffeine treatment conditions. Using a between-subjects design, the researchers collected information on participants’ WPM (average number of words typed per minute), and which one of four treatment conditions they were randomly assigned to (Control (Water), Coffee, Mint Tea, or Red Bull).\nBoxplots will be used to visualise the associations among WPM and caffeine treatment conditions. To address the research question of whether WPM differs by caffeine treatment condition, we first need to define the dummy variables for Treatment:\n\\[\nTreatment_\\text{Coffee} = \\begin{cases}  \n1 & \\text{if Treatment is Coffee} \\\\  \n0 & \\text{otherwise}  \n\\end{cases}  \n\\quad    \n\\]\n\\[\nTreatment_\\text{Red Bull} = \\begin{cases}  \n1 & \\text{if Treatment is Red Bull} \\\\  \n0 & \\text{otherwise}  \n\\\\  \n\\end{cases}  \n\\quad  \n\\]\n\\[\nTreatment_\\text{Mint Tea} = \\begin{cases}  \n1 & \\text{if Treatment is Mint Tea} \\\\  \n0 & \\text{otherwise}  \n\\end{cases}  \n\\quad  \n\\]\n\\[\n(\\text{Control (Water) is base level})  \n\\]\nBased on the above dummy coding, we are going to fit the following regression model:\n\\[\n\\begin{align}\n\\text{WPM} = \\beta_0 + \\beta_1 \\cdot \\text{Treatment(Coffee)} \\\\    \n+ \\beta_2 \\cdot \\text{Treatment(Red Bull)} + \\beta_3 \\cdot \\text{Treatment(Mint Tea)} + \\epsilon\n\\end{align}\n\\]\nEffects will be considered statistically significant at \\(\\alpha=.05\\)\nOur hypotheses are:\n\\(H_0:\\) All \\(\\beta_j = 0\\) (for \\(j = 1, 2, 3\\))\nThere are no differences in WPM based on caffeine treatment conditions.\n\\(H_1:\\) At least one \\(\\beta_j \\neq 0\\) (for \\(j = 1, 2, 3\\))\nThere are differences in WPM based on caffeine treatment conditions."
  },
  {
    "objectID": "1_06_dummy.html#descriptive-statistics-visualisations",
    "href": "1_06_dummy.html#descriptive-statistics-visualisations",
    "title": "Dummy Coding",
    "section": "Descriptive Statistics & Visualisations",
    "text": "Descriptive Statistics & Visualisations\n\nQuestion 4\n\n\nProvide a table of descriptive statistics and visualise your data.\nRemember to interpret your plot in the context of the study (i.e., comment on any observed differences among treatment groups).\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nFor your table of descriptive statistics, both the group_by() and summarise() functions will come in handy here.\nRecall that when visualising categorical variables, geom_boxplot() may be most appropriate to use.\nMake sure to comment on any observed differences among the sample means of the four treatment conditions.\n\n\n\n\n\n\n\n\n Solution \n\n\n\n\nNumeric\nVisual\n\n\n\nDescriptive statistics presented in a well formatted table:\n\ncaf_desc &lt;- caffeine %&gt;%\n  group_by(treatment) %&gt;%\n  summarise(n = n(), \n            Mean = mean(wpm), \n            SD = sd(wpm),\n            Minimum = min(wpm),\n            Maximum = max(wpm)) %&gt;%\n    kable(caption = \"Descriptive Statistics\", digits = 2) %&gt;%\n    kable_styling()\n\ncaf_desc\n\n\n\nTable 1: Descriptive Statistics\n\ntreatment\nn\nMean\nSD\nMinimum\nMaximum\n\n\n\ncontrol\n10\n112.15\n1.98\n109.43\n116.23\n\n\ncoffee\n10\n114.48\n1.82\n112.07\n117.16\n\n\nred_bull\n10\n116.65\n2.15\n113.00\n120.24\n\n\nmint_tea\n10\n111.09\n2.13\n107.94\n115.82\n\n\n\n\n\n\n\n\n\n\nSince we have a continuous outcome and a categorical predictor - a boxplot would be most appropriate for visualisations:\n\ncaf_plt &lt;- ggplot(data = caffeine, aes(x = treatment, y = wpm, fill = treatment)) +\n  geom_boxplot() +\n  labs(x = 'Treatment Condition', y = 'WPM')\n\ncaf_plt\n\n\n\nFigure 1: Association between Treatment Conditions and WPM\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom the boxplots, it seems that those in the Red Bull condition, on average, typed the most WPM, whilst those in the Mint Tea condition the fewest.\nOverall, the average WPM appears to be lower for those in the non-caffeine conditions (i.e., control - water / mint tea) in comparison to those in the caffeine drinks condition (red bull / coffee)."
  },
  {
    "objectID": "1_06_dummy.html#model-fitting-interpretation",
    "href": "1_06_dummy.html#model-fitting-interpretation",
    "title": "Dummy Coding",
    "section": "Model Fitting & Interpretation",
    "text": "Model Fitting & Interpretation\n\nQuestion 5\n\n\nFit the specified model, and assign it the name “caf_mdl1”.\nInterpret your coefficients in the context of the study.\n\n\n\n\n\n\nHow do we specify dummy coding in R?\n\n\n\nFortunately, R computes the dummy variables for us! Thus, each row in the summary() output of the model will correspond to one of the estimated \\(\\beta\\)’s in the equation above.\n\n\n\n\n\n\n Solution \n\n\n\n#fit model\ncaf_mdl1 &lt;- lm(wpm ~ treatment, data=caffeine)\n\n\n#check model output\nsummary(caf_mdl1)\n\n\nCall:\nlm(formula = wpm ~ treatment, data = caffeine)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.652 -1.362 -0.151  1.125  4.729 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       112.1460     0.6402 175.179  &lt; 2e-16 ***\ntreatmentcoffee     2.3350     0.9053   2.579   0.0141 *  \ntreatmentred_bull   4.5060     0.9053   4.977 1.61e-05 ***\ntreatmentmint_tea  -1.0550     0.9053  -1.165   0.2516    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.024 on 36 degrees of freedom\nMultiple R-squared:  0.5563,    Adjusted R-squared:  0.5194 \nF-statistic: 15.05 on 3 and 36 DF,  p-value: 1.651e-06\n\n\nLet’s first map our coefficients and estimates:\n\n\n\n\n\n\n\nCoefficient\nEstimate\nCorresponds to\n\n\n\n(Intercept)\n112.1460\n\\(\\beta_0 = \\hat \\mu_1\\)\n\n\ntreatmentcoffee\n2.3350\n\\(\\beta_0 + \\beta_1 = \\hat \\mu_2\\)\n\n\ntreatmentred_bull\n4.5060\n\\(\\beta_0 + \\beta_2 = \\hat \\mu_3\\)\n\n\ntreatmentmint_tea\n-1.0550\n\\(\\beta_0 + \\beta_3 = \\hat \\mu_4\\)\n\n\n\n\n\n\n\n\n\n\nThe estimate corresponding to (Intercept) contains \\(\\hat \\beta_0 = \\hat \\mu_1 = 112.15\\). The estimated average WPM for those in the control condition (water) was approximately 112.15.\nThe next estimate corresponds to treatmentcoffee and was \\(\\hat \\beta_1 = 2.34\\). The difference in mean WPM between Control and Coffee was estimated to be \\(2.34\\). Thus, \\(\\hat \\mu_2 = 112.15 + 2.34 = 114.49\\). In other words, people who have had coffee typed approximately 114.49 words, which was 2.34 words per minute more than those who have had water. This difference was statistically significant \\((p = .01)\\).\nThe estimate corresponding to treatmentred_bull was \\(\\hat \\beta_2 = 4.51\\). This was the estimated difference in mean WPM between Control and Red Bull, estimated to be \\(4.51\\). Thus, \\(\\hat \\mu_3 = 112.15 + 4.51 = 116.66\\). In other words, people who had red bull typed approximately 116.66 words, 4.51 words per minute more than those who had water. This difference was statistically significant \\((p &lt; .001)\\).\nThe estimate corresponding to treatmentmint_tea was \\(\\hat \\beta_3 = -1.06\\). This was the estimated difference in mean WPM between Control and Mint Tea, estimated to be \\(-1.06\\). Thus, \\(\\hat \\mu_4 = 112.15 + (-1.06) = 111.09\\). In other words, people who had mint tea typed approximately 111.09 words, 1.06 words per minute less than those who had water. This difference was not statistically significant \\((p = .25)\\)."
  },
  {
    "objectID": "1_06_dummy.html#planned-comparisons-contrasts",
    "href": "1_06_dummy.html#planned-comparisons-contrasts",
    "title": "Dummy Coding",
    "section": "Planned Comparisons / Contrasts",
    "text": "Planned Comparisons / Contrasts\n\nQuestion 6\n\n\nFormally state the two planned comparisons that the researchers were interested in as testable hypotheses.\n\n\n\n\n Solution \n\n\nRecall that the researchers were also interested in addressing these two questions:\n\nWhether having some kind of caffeine (i.e., red bull or coffee), rather than no caffeine (i.e., control - water or mint tea), resulted in a difference in average WPM\nWhether there was a difference in average WPM between those with hot drinks (i.e., mint tea / coffee) in comparison to those with cold drinks (control - water / red bull)\n\nWe can specify the two hypotheses as follows:\n\n\nCaffeine vs No Caffeine\nHot vs Cold\n\n\n\n\\[\n\\begin{aligned}\n1. \\quad H_0 &: \\mu_\\text{No Caffeine} = \\mu_\\text{Caffeine} \\\\\n    \\quad H_0 &: \\frac{1}{2} (\\mu_\\text{Control} + \\mu_\\text{Mint Tea}) = \\frac{1}{2} (\\mu_\\text{Coffee} + \\mu_\\text{Red Bull}) \\\\\n\\\\\n    \\quad H_1 &: \\mu_\\text{No Caffeine} \\neq \\mu_\\text{Caffeine} \\\\\n    \\quad H_1 &: \\frac{1}{2} (\\mu_\\text{Control} + \\mu_\\text{Mint Tea}) \\neq \\frac{1}{2} (\\mu_\\text{Coffee} + \\mu_\\text{Red Bull}) \\\\\n\\\\\n\\end{aligned}\n\\]\n\n\n\\[\n\\begin{aligned}\n2. \\quad H_0 &: \\mu_\\text{Hot Drink} = \\mu_\\text{Cold Drink} \\\\\n    \\quad H_0 &: \\frac{1}{2} (\\mu_\\text{Coffee} + \\mu_\\text{Mint Tea}) = \\frac{1}{2} (\\mu_\\text{Control} + \\mu_\\text{Red Bull})\n\\\\\n\\\\\n    \\quad H_1 &: \\mu_\\text{Hot Drink} \\neq \\mu_\\text{Cold Drink} \\\\\n    \\quad H_1 &: \\frac{1}{2} (\\mu_\\text{Coffee} + \\mu_\\text{Mint Tea}) \\neq \\frac{1}{2} (\\mu_\\text{Control} + \\mu_\\text{Red Bull})\n    \\\\\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\nQuestion 7\n\n\nAfter checking the levels of the factor treatment, use emmeans() to obtain the estimated treatment means and uncertainties for your factor.\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse plot() to visualise this.\n\n\n\n\n\n\n\n Solution \n\n\n\nlevels(caffeine$treatment)\n\n[1] \"control\"  \"coffee\"   \"red_bull\" \"mint_tea\"\n\n\nUse the emmeans() to get the estimated means of our groups:\n\ntreatment_mean &lt;- emmeans(caf_mdl1, ~ treatment)\ntreatment_mean\n\n treatment emmean   SE df lower.CL upper.CL\n control      112 0.64 36      111      113\n coffee       114 0.64 36      113      116\n red_bull     117 0.64 36      115      118\n mint_tea     111 0.64 36      110      112\n\nConfidence level used: 0.95 \n\nplot(treatment_mean)\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 8\n\n\nSpecify the coefficients of the comparisons and run the contrast analysis, obtaining 95% confidence intervals.\n\n\n\n\n\n\nHint\n\n\n\n\n\nOrdering matters here - look again at the output of levels(caffeine$treatment) as this will help you when assigning your weights.\n\n\n\n\n\n\n\n Solution \n\n\nAs shown above via levels(), the ordering of the treatment factor is:\n\nControl (no caffeine / cold drink)\nCoffee (caffeine / hot drink)\nRed Bull (caffeine / cold drink)\nMint Tea (no caffeine / hot drink)\n\nFrom this ordering, we can specify our weights - based on the hypothesis, lets assign positive values to the no caffeine and hot drink conditions:\n\ntreatment_comp &lt;- list(\"No Caffeine - Caffeine\" = c(1/2, -1/2, -1/2, 1/2),\n             \"Hot Drink - Cold Drink\" = c(-1/2, 1/2, -1/2, 1/2)\n             )\n\nNow lets run our contrast analysis and get confidence intervals - to do so we use the contrast() function from emmeans():\n\n#run contrast analysis\ntreatment_comp_test &lt;- contrast(treatment_mean, method = treatment_comp)\n\n#examine output\ntreatment_comp_test\n\n contrast               estimate   SE df t.ratio p.value\n No Caffeine - Caffeine    -3.95 0.64 36  -6.167  &lt;.0001\n Hot Drink - Cold Drink    -1.61 0.64 36  -2.520  0.0163\n\n#obtain confidence intervals\nconfint(treatment_comp_test)\n\n contrast               estimate   SE df lower.CL upper.CL\n No Caffeine - Caffeine    -3.95 0.64 36    -5.25   -2.650\n Hot Drink - Cold Drink    -1.61 0.64 36    -2.91   -0.315\n\nConfidence level used: 0.95 \n\n\n\n\n\n\n\nQuestion 9\n\n\nInterpret the results of the contrast analysis in the context of the researchers hypotheses.\n\n\n\n\n Solution \n\n\n\n\nHypothesis 1: Caffeine vs No Caffeine\nHypothesis 2: Hot vs Cold\n\n\n\nWe performed a test against \\(H_0: \\frac{1}{2}(\\mu_1 + \\mu_4) - \\frac{1}{2}(\\mu_2 + \\mu_3) = 0\\). At the 5% significance level, there was evidence that the mean WPM for those who were in the no caffeine condition was significantly different from those in a caffeine condition \\((t(36) = -6.17, p &lt; .001, \\text{two-sided})\\), and this difference was estimated to be -3.95. We are 95% confident that those who consumed no caffeine typed, on average, between 2.7 and 5.3 words less per minute than those who consumed some form of caffeine \\(CI_{95}[-5.25, -2.65]\\).\n\n\nWe performed a test against \\(H_0: \\frac{1}{2}(\\mu_2 + \\mu_4) - \\frac{1}{2}(\\mu_1 + \\mu_3) = 0\\). At the 5% significance level, there was evidence that the average WPM for those in the hot drink condition significantly differed from those in the cold drink condition \\((t(36) = -2.52, p = .02, \\text{two-sided})\\), and this difference was estimated to be -1.61. We are 95% confident that those who consumed a hot drink typed, on average, between 0.3 and 2.9 words less per minute than those who consumed a cold drink \\(CI_{95}[-2.91, -0.32]\\)."
  },
  {
    "objectID": "1_06_dummy.html#study-design",
    "href": "1_06_dummy.html#study-design",
    "title": "Dummy Coding",
    "section": "Study Design",
    "text": "Study Design\n\nQuestion 10\n\n\nFor each of the below experiment descriptions, note (1) the design, (2) number of variables of interest, (3) levels of categorical variables, (4) what you think the reference group should be and why.\n\n\nExperiment 1\nExperiment 2\nExperiment 3\n\n\n\nA group of researchers were interested in whether sleep deprivation influenced reaction time. They hypothesised that sleep deprived individuals would have slower reaction times than non-sleep deprived individuals.\nTo test this, they recruited 60 participants who were matched on a number of demographic variables including age and sex. One member of each pair (e.g., female aged 18) was placed into a different sleep condition - ‘Sleep Deprived’ (4 hours per night) or ‘Non-Sleep Deprived’ (8 hours per night).\n\n\nA group of researchers were interested in replicating an experiment testing the Stroop Effect.\nThey recruited 50 participants who took part in Task A (word colour and meaning are congruent) and Task B (word colour and meaning are incongruent) where they were asked to name the color of the ink instead of reading the word. The order of presentation was counterbalanced across participants. The researchers hypothesised that participants would take significantly more time (‘response time’ measured in seconds) to complete Task B than Task A.\nYou can test yourself here for fun: Stroop Task\n\n\nA group of researchers wanted to test a hypothesised theory according to which patients with amnesia will have a deficit in explicit memory but not implicit memory. Huntingtons patients, on the other hand, will display the opposite: they will have no deficit in explicit memory, but will have a deficit in implicit memory.\nTo test this, researchers designed a study that included two variables: ‘Diagnosis’ (Amnesic, Huntingtons, Control) and ‘Task’ (Grammar, Classification, Recognition) where participants were randomly assigned to a Task condition. The first two tasks (Grammar and Classification) are known to reflect implicit memory processes, whereas the Recognition task is known to reflect explicit memory processes.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nExperiment 1\nExperiment 2\nExperiment 3\n\n\n\n\nDesign = Between-person: Matched pairs\nNo of variables of interest = 2 - Sleep Condition and Reaction Time\nLevels of variables = Sleep Condition has 2 levels - Sleep Deprived and Non-Sleep Deprived; Reaction Time is a continuous measure, so has no associated levels\nReference Group = Sleep Condition - Non-Sleep Deprived because the research question stated that the researchers were interested in how the sleep deprived group differed from the non-sleep deprived group.\n\n\n\n\nDesign = Within-person: repeated measures\nNo of variables of interest = 2 - Task and Response Time\nLevels of variables = Task has 2 levels - A and B; Response Time is a continuous measure, so has no associated levels\nReference Group = Task - A because the research question stated that the researchers were interested in how response time in Task B differed from the response time in Task A.\n\n\n\n\nDesign = Between-person: 3×3 factorial design\nNo of variables of interest = 2 - Diagnosis and Task\nLevels of variables = Diagnosis has 3 levels - Amnesic, Huntingtons, and Control; Task has 3 levels - Grammar, Classification, and Recognition\nReference Groups = Diagnosis - Control; Task - Recognition. We have chosen Control since the other two groups have some form of cognitive impairment; and the Recognition task since it measures explicit memory whilst the other two task types implicit."
  },
  {
    "objectID": "1_07_effects.html",
    "href": "1_07_effects.html",
    "title": "Effects Coding",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand how to specify sum-to-zero coding\nInterpret the output from a model using sum-to-zero coding\nUnderstand how to specify contracts to test specific effects\n\n\nBe up to date with lectures\nHave completed Week 7 lab exercises\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\nkableExtra\nemmeans\n\nAll results should be presented following APA guidelines. If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/RestaurantSpending.csv"
  },
  {
    "objectID": "1_07_effects.html#study-analysis-plan-overview",
    "href": "1_07_effects.html#study-analysis-plan-overview",
    "title": "Effects Coding",
    "section": "Study & Analysis Plan Overview",
    "text": "Study & Analysis Plan Overview\n\nQuestion 1\n\n\nExamine the dataset, and perform any necessary and appropriate data management steps.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nConvert categorical variables to factors\nCheck for missing values\nLabel appropriately factors to aid with your model interpretations if required\nIf needed, provide better variable names\n\n\n\n\n\n\n\n\n Solution \n\n\nLet’s have a look at the data to see what we’re working with:\n\n#first look at dataset structure\nstr(rest_spend)\n\nspc_tbl_ [360 × 3] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ id    : num [1:360] 1 2 3 4 5 6 7 8 9 10 ...\n $ type  : chr [1:360] \"No Music\" \"Pop Music\" \"Pop Music\" \"Pop Music\" ...\n $ amount: num [1:360] 23.1 20.6 19.2 16.7 25.9 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   id = col_double(),\n  ..   type = col_character(),\n  ..   amount = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n#now lets look at top 6 rows (or the head) of the dataset\nhead(rest_spend)\n\n# A tibble: 6 × 3\n     id type            amount\n  &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n1     1 No Music          23.1\n2     2 Pop Music         20.6\n3     3 Pop Music         19.2\n4     4 Pop Music         16.7\n5     5 Classical Music   25.9\n6     6 Pop Music         19.3\n\n#check for NAs - there are none - all FALSE\ntable(is.na(rest_spend))\n\n\nFALSE \n 1080 \n\n\nLet’s start with the music ‘type’ variable. This should be coded as factor (&lt;fctr&gt;), but can see from above it is currently coded as a character (&lt;chr&gt;). Let’s fix this, and rename ‘type’ to ‘music’ and remove the word ‘music’ form the labels of the levels of the factor to avoid repetition whilst we’re at it:\n\nrest_spend &lt;- rest_spend %&gt;%\n    mutate(\n        type = factor(type, \n                           levels = c(\"No Music\", \"Pop Music\", \"Classical Music\"),\n                           labels = c(\"None\", \"Pop\", \"Classical\"))) %&gt;%\n        rename(music = type)\n\nNext, let’s look at the ‘amount’ variable. Here we want to check for impossible values - i.e., cannot have a negative £ per head.\n\n# all looks ok - min and max both positive values\ndescribe(rest_spend$amount)\n\n   vars   n  mean   sd median trimmed  mad   min   max range  skew kurtosis\nX1    1 360 22.74 3.01  22.88   22.81 3.06 13.71 33.43 19.72 -0.19      0.2\n     se\nX1 0.16\n\n\n\n\n\n\n\n\nAll participant data was complete (no missing values), with restaurant spending per person within possible ranges. Music type was coded as a factor with three levels (none, pop, and classical).\n\n\n\n\n\n\n\n\nQuestion 2\n\n\nProvide a brief overview of the study design and data, before detailing your analysis plan to address the research question.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nGive the reader some background on the context of the study\nState what type of analysis you will conduct in order to address the research question\nSpecify the model to be fitted to address the research question (note that you will need to specify the reference level of your categorical variable)\nSpecify your chosen significance (\\(\\alpha\\)) level\nState your hypotheses\n\nMuch of the information required can be found in the Study Overview codebook.\n\n\n\n\n\n\n\n Solution \n\n\nThe rest_spend dataset contained information on 360 hypothetical participants who took part in an experiment examining the effect of music on customer spending in a restaurant setting. Using a between-subjects design, the researchers had one of three types of music - classical, pop, or silence - played in a restaurant over 18 successive evenings. As well as recording the type of music played during the meal, the researchers also recorded the average spend per person (in £).\nAll participant data was complete (no missing values), with restaurant spending per person within possible ranges. Music type was coded as a factor with three levels (none, pop, and classical).\nBoxplots will be used to visualise the associations among spend per person and background music conditions. To address the research question of whether spend per person differs by background music condition, we can specify our model and coding scheme as follows:\n\\[\n\\text{Restaurant Spending} = \\beta_0 + \\beta_1 \\cdot \\text{EffectLevel1} + \\beta_2 \\cdot \\text{EffectLevel2} + \\epsilon\n\\]\nwhere:\n\\[\n\\text{EffectLevel1} = \\begin{cases}\n1  & \\text{if observation is from category 1} \\\\\n0  & \\text{if observation is from category 2} \\\\\n-1 & \\text{otherwise}\n\\end{cases}\n\\]\n\\[\n\\text{EffectLevel2} = \\begin{cases}\n0  & \\text{if observation is from category 1} \\\\\n1  & \\text{if observation is from category 2} \\\\\n-1 & \\text{otherwise}\n\\end{cases}\n\\]\nSchematically:\n\\[\n\\begin{matrix}\n\\textbf{Level}           & \\textbf{EffectLevel1} & \\textbf{EffectLevel2} \\\\\n\\hline\n\\text{None}              & 1   & 0    \\\\\n\\text{Pop}               & 0   & 1    \\\\\n\\text{Classical}         & -1  & -1\n\\end{matrix}\n\\]\nEffects will be considered statistically significant at \\(\\alpha=.05\\)\nOur hypotheses are:\n\\(H_0:\\) All \\(\\beta_j = 0\\) (for \\(j = 1, 2\\))\nThere are no differences in average spend per person based on background music conditions.\n\\(H_1:\\) At least one \\(\\beta_j \\neq 0\\) (for \\(j = 1, 2\\))\nThere are differences in average spend per person based on background music conditions."
  },
  {
    "objectID": "1_07_effects.html#descriptive-statistics-visualisations",
    "href": "1_07_effects.html#descriptive-statistics-visualisations",
    "title": "Effects Coding",
    "section": "Descriptive Statistics & Visualisations",
    "text": "Descriptive Statistics & Visualisations\n\nQuestion 3\n\n\nProvide a table of descriptive statistics and visualise your data.\nRemember to interpret your plot in the context of the study (i.e., comment on any observed differences among treatment groups).\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nFor your table of descriptive statistics, both the group_by() and summarise() functions will come in handy here.\nRecall that when visualising categorical variables, geom_boxplot() may be most appropriate to use.\nIt might be helpful to add a line representing the grand mean (the mean of all the observations). You can do this by specifying geom_hline(). Within this argument, you will need to specify where the horizontal line should cut the y-axis via yintercept =. You might want to specify line: type (via lty =), width (via lwd =), and colour (via colour =).\nMake sure to comment on any observed differences among the sample means of the four treatment conditions.\n\n\n\n\n\n\n\n\n Solution \n\n\n\n\nNumeric\nVisual\n\n\n\n\nrest_spend %&gt;% \n            group_by(music) %&gt;%\n            summarise(n = n(),\n                      Mean = mean(amount),\n                      SD = sd(amount),\n                      Min = min(amount),\n                      Max = max(amount)) %&gt;% \n            kable(caption = \"Restaurant Spending & Music Type Descriptive Statistics\", digits = 2) %&gt;%\n            kable_styling()\n\n\n\nTable 1: Restaurant Spending & Music Type Descriptive Statistics\n\nmusic\nn\nMean\nSD\nMin\nMax\n\n\n\nNone\n120\n22.14\n3.44\n13.71\n33.43\n\n\nPop\n120\n21.90\n2.97\n15.60\n28.94\n\n\nClassical\n120\n24.17\n1.89\n19.05\n28.02\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = rest_spend, aes(x = music, y = amount, fill = music)) +\n  geom_boxplot() +\n    geom_hline(yintercept = mean(rest_spend$amount), lty = 2, lwd = 1, colour = \"darkgrey\") +\n  labs(x = 'Background Music Type', y = 'Restaurant Spending (in GBP)')\n\n\n\nFigure 1: Associations between Restaurant Spending and Music Type\n\n\n\n\n\n\n\n\n\n\n\n\n\nThere are three types of music groups (\\(g = 3\\)), where there is one group for each music type: “Classical,” “None,” “Pop”. Each group has 120 observations.\nIt seems that customers in the None and Pop music conditions had a similar average restaurant spending\nThe average restaurant spending seems to be higher for those who had in the Classical music condition in comparison to customers in both the None and Pop music type conditions."
  },
  {
    "objectID": "1_07_effects.html#model-fitting-interpretation",
    "href": "1_07_effects.html#model-fitting-interpretation",
    "title": "Effects Coding",
    "section": "Model Fitting & Interpretation",
    "text": "Model Fitting & Interpretation\n\nQuestion 4\n\n\nSet the sum to zero constraint for the factor of background music.\nFit the specified model, and assign it the name “mdl_stz”.\n\n\n\n\n\n\nHint\n\n\n\n\n\nWe can switch between side-constraints using the following code:\n\n#use dummy coding\ncontrasts(rest_spend$music) &lt;- \"contr.treatment\"\n\n#use sum-to-zero coding\ncontrasts(rest_spend$music) &lt;- \"contr.sum\"\n\n\n\n\n\n\n\n\n Solution \n\n\n\n\nSum to Zero Constraint\nFit Model\n\n\n\n\ncontrasts(rest_spend$music) &lt;- \"contr.sum\"\n\n#check coding matches our table above:\ncontrasts(rest_spend$music)\n\n          [,1] [,2]\nNone         1    0\nPop          0    1\nClassical   -1   -1\n\n\n\n\n\nmdl_stz &lt;- lm(amount ~ music, data = rest_spend)\n\n#check summary\nsummary(mdl_stz)\n\n\nCall:\nlm(formula = amount ~ music, data = rest_spend)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-8.433 -1.886  0.127  1.755 11.285 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  22.7382     0.1497 151.856  &lt; 2e-16 ***\nmusic1       -0.5968     0.2118  -2.818   0.0051 ** \nmusic2       -0.8392     0.2118  -3.963 8.94e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.841 on 357 degrees of freedom\nMultiple R-squared:  0.1151,    Adjusted R-squared:  0.1101 \nF-statistic: 23.21 on 2 and 357 DF,  p-value: 3.335e-10\n\n\n\n\n\n\n\n\n\n\nQuestion 5\n\n\nInterpret your coefficients in the context of the study.\n\n\n\n\n\n\nHint\n\n\n\n\n\nRecall that under this constraint the interpretation of the coefficients becomes:\n\n\n\\(\\beta_0\\) represents the grand mean\n\n\\(\\beta_i\\) the effect due to group \\(i\\) — that is, the mean response in group \\(i\\) minus the grand mean\n\n\n\n\n\n\n\n\n Solution \n\n\nLet’s first map our coefficients and estimates:\n\n\n\n\n\n\n\nCoefficient\nEstimate\nCorresponds to\n\n\n\n(Intercept)\n22.7382\n\\(\\beta_0 = \\frac{\\mu_1 + \\mu_2 + \\mu_3}{3} = \\mu\\)\n\n\nmusic1\n-0.5968\n\\(\\beta_1 = \\mu_1 - \\mu\\)\n\n\nmusic2\n-0.8392\n\\(\\beta_2 = \\mu_2 - \\mu\\)\n\n\n\n\n\n\n\n\n\n\nThe estimate corresponding to (Intercept) contains \\(\\beta_0 = \\mu = 22.7382\\). This value represents the grand mean of the data. The estimated average spending for customers across background music conditions is approximately £22.74.\nThe next estimate corresponds to music1 and is \\(\\hat \\beta_1 = -0.5968\\). The difference in mean spending between None \\((\\hat \\mu_1)\\) and the grand mean \\((\\hat \\mu_0)\\) was estimated to be \\(-0.5968\\). In other words, people with no music playing in the background seem to spend approximately £0.60 less than average, and spent \\(22.7382 + (-0.5968) = £22.14\\) in total.\nThe estimate corresponding to music2 is \\(\\hat \\beta_2 = -0.8392\\). The difference in mean spending between Pop \\((\\hat \\mu_2)\\) and the grand mean \\((\\hat \\mu_0)\\) was estimated to be \\(-0.8392\\). In other words, customers with Pop music playing in the background seem to spend approximately £0.84 less than average, and spent \\(22.7382 + (-0.8392) = £21.90\\) in total.\nThe estimate for music3, representing the difference of “Classical” to the grand mean is not shown by summary(). Because of the side-constraint, we know that \\(\\mu_3 = \\beta_0 - (\\beta_1 + \\beta_2)\\). The difference in mean spending between Classical and the grand mean was estimated to be \\(-(-0.5968 + -0.8392) = 1.436\\). In other words, customers with Classical music playing in the background seem to spend approximately £1.44 more than average, and spent \\(22.7382 - (-0.5968 + -0.8392) = £24.17\\) in total.\n\n\n\n\n\n\n\n\n\nQuestion 6\n\n\nObtain the estimated (or predicted) group means for the “None,” “Pop,” and “Classical” background music conditions by using the predict() function.\n\n\n\n\n\n\nHint\n\n\n\n\n\nStep 1: Define a data frame via tibble() with a column having the same name as the factor in the fitted model (i.e., music). Then, specify all the groups (i.e., levels) for which you would like the predicted mean.\nStep 2: Pass the data frame to the predict function using the newdata = argument. The predict() function will match the column named type with the predictor called type in the fitted model ‘mdl_stz’.\n\n\n\n\n\n\n\n Solution \n\n\nStep 1:\n\nquery_groups &lt;- tibble(music = c(\"None\", \"Pop\", \"Classical\"))\nquery_groups\n\n# A tibble: 3 × 1\n  music    \n  &lt;chr&gt;    \n1 None     \n2 Pop      \n3 Classical\n\n\nStep 2:\n\npredict(mdl_stz, newdata = query_groups)\n\n       1        2        3 \n22.14139 21.89894 24.17414 \n\n\n\nPredicted mean of “None” = \\(\\hat \\mu_\\text{None}\\) = 22.14\nPredicted mean of “Pop” = \\(\\hat \\mu_\\text{Pop}\\) = 21.90\nPredicted mean of “Classical” = \\(\\hat \\mu_\\text{Classical}\\) = 24.17\n\nWe can see that these predicted means match our model estimates in Q5."
  },
  {
    "objectID": "1_07_effects.html#planned-comparisons-contrasts",
    "href": "1_07_effects.html#planned-comparisons-contrasts",
    "title": "Effects Coding",
    "section": "Planned Comparisons / Contrasts",
    "text": "Planned Comparisons / Contrasts\n\nQuestion 7\n\n\nFormally state the planned comparison that the researchers were interested in as a testable hypothesis.\n\n\n\n\n Solution \n\n\nRecall that the researchers were also interested in addressing the following question:\n\nWhether having some kind of music playing (i.e., pop or classical), rather than no music (i.e., none), resulted in a difference in spending\n\nWe can specify the hypothesis as follows:\n\\[\n\\begin{aligned}\n    \\quad H_0 &: \\mu_\\text{No Music} = \\mu_\\text{Music} \\\\\n    \\quad H_0 &: \\mu_\\text{None} = \\frac{1}{2} (\\mu_\\text{Pop} + \\mu_\\text{Classical}) \\\\\n\\\\\n    \\quad H_1 &: \\mu_\\text{No Music} \\neq \\mu_\\text{Music} \\\\\n    \\quad H_1 &: \\mu_\\text{No Music} \\neq \\frac{1}{2} (\\mu_\\text{Pop} + \\mu_\\text{Classical}) \\\\\n\\\\\n\\end{aligned}\n\\]\n\n\n\n\n\nQuestion 8\n\n\nAfter checking the levels of the factor music, use emmeans() to obtain the estimated treatment means and uncertainties for your factor.\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse plot() to visualise this.\n\n\n\n\n\n\n\n Solution \n\n\n\nlevels(rest_spend$music)\n\n[1] \"None\"      \"Pop\"       \"Classical\"\n\n\nUse the emmeans() to get the estimated means of our groups:\n\nmusic_mean &lt;- emmeans(mdl_stz, ~ music)\nmusic_mean\n\n music     emmean    SE  df lower.CL upper.CL\n None        22.1 0.259 357     21.6     22.7\n Pop         21.9 0.259 357     21.4     22.4\n Classical   24.2 0.259 357     23.7     24.7\n\nConfidence level used: 0.95 \n\nplot(music_mean)\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 9\n\n\nSpecify the coefficients of the comparisons and run the contrast analysis, obtaining 95% confidence intervals.\n\n\n\n\n\n\nHint\n\n\n\n\n\nOrdering matters here - look again at the output of levels(rest_spend$music) as this will help you when assigning your weights.\n\n\n\n\n\n\n\n Solution \n\n\nAs shown above via levels(), the ordering of the treatment factor is:\n\nNone (no music)\nPop (music)\nClassical (music)\n\nFrom this ordering, we can specify our weights - based on the hypothesis, lets assign positive values to the music conditions:\n\nmusic_comp &lt;- list(\"No Music - Music\" = c(-1, 1/2, 1/2))\n\nNow lets run our contrast analysis and get confidence intervals:\n\n#run contrast analysis\nmusic_comp_test &lt;- contrast(music_mean, method = music_comp)\n\n#examine output\nmusic_comp_test\n\n contrast         estimate    SE  df t.ratio p.value\n No Music - Music    0.895 0.318 357   2.818  0.0051\n\n#obtain confidence intervals\nconfint(music_comp_test)\n\n contrast         estimate    SE  df lower.CL upper.CL\n No Music - Music    0.895 0.318 357     0.27     1.52\n\nConfidence level used: 0.95 \n\n\n\n\n\n\n\nQuestion 10\n\n\nInterpret the results of the contrast analysis in the context of the researchers hypotheses.\n\n\n\n\n Solution \n\n\n\n\n\n\n\n\nWe performed a test against \\(H_0: \\mu_1 - \\frac{1}{2}(\\mu_2 + \\mu_3) = 0\\). At the 5% significance level, there was evidence that restaurant spending per person for those who were in the no music condition was significantly different from those in a music condition (\\(t(357) = 2.82, p = .005, \\text{two-sided})\\), and this difference was estimated to be 0.90. We are 95% confident that those who heard some form of background music spent on average, between £0.27 and £1.52 more per person on their meal than those who heard no background music \\((CI_{95}[0.27, 1.52])\\)."
  },
  {
    "objectID": "1_08_assump_diag.html",
    "href": "1_08_assump_diag.html",
    "title": "Assumptions and Diagnostics",
    "section": "",
    "text": "At the end of this lab, you will:\n\nBe able to state the assumptions underlying a linear model\nSpecify the assumptions underlying a linear model with multiple predictors\nAssess if a fitted model satisfies the assumptions of your model\nAssess the effect of influential cases on linear model coefficients and overall model evaluations\n\n\nBe up to date with lectures\nHave completed Week 2 lab exercises\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\ncar\nsee\nperformance\nkableExtra\nsjPlot\n\nAll results should be presented following APA guidelines. If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/wellbeing_rural.csv"
  },
  {
    "objectID": "1_08_assump_diag.html#assumptions",
    "href": "1_08_assump_diag.html#assumptions",
    "title": "Assumptions and Diagnostics",
    "section": "Assumptions",
    "text": "Assumptions\n\nQuestion 1\n\n\nLet’s start by using check_model() for our wb_mdl1 model - we can refer to these plots as a guide as we work through the assumptions questions of the lab.\n\n\n\n\n\n\nThese plots cannot be used in your reports - they are to be used as a guide only.\n\n\n\n\n\n\n\n Solution \n\n\n\ncheck_model(wb_mdl1)\n\n\n\n\n\n\n\nThe check_model() function is a useful way to check the assumptions of models, as it also returns some useful notes to aid your interpretation. There does appear to be evidence that some assumptions may have been violated, but to be sure we need to check each assumption individually with plots that are more suitable for a statistics report.\n\n\n\n\n\nQuestion 2\n\n\nCheck if the fitted model satisfies the linearity assumption for wb_mdl1.\nWrite a sentence summarising whether or not you consider the assumption to have been met. Justify your answer with reference to the plots.\n\n\n\n\n\n\nHint\n\n\n\n\n\nHow you check this assumption depends on the number of predictors in your model:\n\nSingle predictor: Use either residual vs fitted values plot (plot(model, which = 1)), and/or a scatterplot with loess lines\n\nFor interpretation - in the former, you want the residuals appear to be randomly scattered around zero, without showing any pattern with respect to the fitted values; in the latter, the loess line should closely follow the data.\n\n\nMultiple predictors: Use component-residual plots (also known as partial-residual plots) to check the assumption of linearity.\n\nFor interpretation - you are looking for the pink line to follow a linear relationship (i.e., follow the blue line).\n\n\n\n\n\n\n\n\n\n\n Solution \n\n\n\ncrPlots(wb_mdl1)\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe smoother (the pink line) follows quite closely to a linear relationship (the dashed blue line), though there was some deviation. Overall, the evidence suggested that the linearity assumption was met.\n\n\n\n\n\n\n\n\nQuestion 3\n\n\nCheck if the fitted model wb_mdl1 satisfy the equal variance (homoscedasticity) assumption.\nWrite a sentence summarising whether or not you consider the assumption to have been met. Justify your answer with reference to the plot.\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse residualPlots() to plot residuals against the predictor. Since we are only interested in visually assessing our assumption checks, we can suppress the curvature test output by specifying tests = FALSE.\nFor interpretation - if the assumption is met, you should see a random scatter of \\((x, y)\\) points with constant mean and variance functions i.e., the vertical spread of the residuals should roughly be the same everywhere.\n\nQuick Tip if plotting using plot(model)\nAs the residuals can be positive or negative, we can make it easier to assess equal spread by improving the ‘resolution’ of the points.\nWe can make all residuals positive by discarding the sign (take the absolute value), and then take the square root to make them closer to each other.\nA plot of \\(\\sqrt{|\\text{Standardized residuals}|}\\) against the fitted values can be obtained via plot(model, which = 3).\n\n\n\n\n\n\n\n\n Solution \n\n\nWe can visually assess by plotting the Pearson residuals against the fitted values:\n\nresidualPlots(wb_mdl1, tests = FALSE)\n\n\n\n\n\n\n\nOr by plotting the \\(\\sqrt{|\\text{Standardized residuals}|}\\) against the fitted values:\n\nplot(wb_mdl1, which = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nPartial residual plots did show non-linear trends between residuals and predictors, hence there is evidence of non-constant variance i.e., heteroscedasticity. Thus, the data did not meet the assumption of equal variance, as the spread of the standardized residuals did not appear to be constant (for the most part) as the fitted values varied.\nIn the second plot, all points are above 0, but the majority of the points are not very close to each other. The line does not appear to be relatively flat, and so this also suggested that the error variance does change across the fitted values.\n\n\n\n\n\n\n\n\nQuestion 4\n\n\nAssess whether there is autocorrelation in the error terms.\nWrite a sentence summarising whether or not you consider the assumption of independence to have been met (you may have to assume certain aspects of the study design).\n\n\n\n\n Solution \n\n\n\n\n\n\n\n\nSince our data were collected from a between-persons study design, we can assume (i.e., based on design, we believe) the errors to be independent.\n\n\n\n\n\n\n\n\nQuestion 5\n\n\nCheck if the fitted model wb_mdl1 satisfies the normality assumption.\nWrite a sentence summarising whether or not you consider the assumption to have been met. Justify your answer with reference to the plots.\n\n\n\n\n\n\nHint\n\n\n\n\n\nWe can get the QQplot from plot(model, which = 2), and you can plot the frequency distribution of the residuals via ggplot(data = ???, aes(x = model$residuals)) + geom_histogram().\nFor interpretation - remember that departures from a linear trend in QQ plots indicate a lack of normality.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nHistogram\nQQ Plot\n\n\n\n\nggplot(data = mwdata, aes(x = wb_mdl1$residuals)) +\n    geom_histogram() \n\n\n\n\n\n\n\n\n\n\n\n\n\nThe histogram indicated that the residuals (the differences between observed and predicted values) followed close to a normal distribution.\n\n\n\n\n\n\nplot(wb_mdl1, which = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe QQplot indicated that the residuals followed close to a normal distribution, as the points followed a linear pattern and there was no substantial skew or departure from normality. There was some evidence of heavier tails, and we may want to examine some observations more closely (i.e., 16, 78, 109)."
  },
  {
    "objectID": "1_08_assump_diag.html#multicollinearity",
    "href": "1_08_assump_diag.html#multicollinearity",
    "title": "Assumptions and Diagnostics",
    "section": "Multicollinearity",
    "text": "Multicollinearity\n\nQuestion 6\n\n\nFor wb_mdl1, calculate the variance inflation factor (VIF) for the predictors in the model.\nWrite a sentence summarising whether or not you consider multicollinearity to be a problem here.\n\n\n\n\n\n\nHint\n\n\n\n\n\nWe can loosely interpret VIF values &gt;5 as indicative of moderate multicollinearity, and values &gt;10 as indicative of severe multicollinearity.\n\n\n\n\n\n\n\n Solution \n\n\n\nvif(wb_mdl1)\n\noutdoor_time   social_int \n    1.001306     1.001306 \n\n\n\n\n\n\n\n\nThe VIF values for all predictors are &lt;5, indicating that multicollinearity is not adversely affecting model estimates."
  },
  {
    "objectID": "1_08_assump_diag.html#diagnostics",
    "href": "1_08_assump_diag.html#diagnostics",
    "title": "Assumptions and Diagnostics",
    "section": "Diagnostics",
    "text": "Diagnostics\n\nQuestion 7\n\n\nCreate a new tibble which contains:\n\nThe original variables from the model (Hint, what does wb_mdl1$model give you?)\nThe fitted values from the model \\(\\hat y\\)\n\nThe residuals \\(\\hat \\epsilon\\)\n\nThe studentised residuals\nThe hat values\nThe Cook’s Distance values\n\n\n\n\n\n Solution \n\n\n\nmdl_diagnost &lt;- \n  tibble(\n  wb_mdl1$model,\n  fitted = fitted(wb_mdl1),\n  resid = residuals(wb_mdl1),\n  studres = rstudent(wb_mdl1),\n  hats = hatvalues(wb_mdl1),\n  cooksd = cooks.distance(wb_mdl1)\n)\n\n\n\n\n\n\nQuestion 8\n\n\nFrom the tibble above, comment on the following:\n\nLooking at the studentised residuals, are there any outliers?\nLooking at the hat values, are there any observations with high leverage?\nLooking at the Cook’s Distance values, are there any highly influential points?\n\n\n\n\n\n Solution \n\n\n\n\nOutliers\nHigh Leverage\nInfluential Points\n\n\n\nIn a standard normal distribution, 95% of the values are roughly between -2 and 2. Because of this, studentised residuals of \\(&gt;2\\) or \\(&lt; -2\\) indicate potential outlyingness.\nWe can ask R how many of the absolute values (by specifying abs()) are \\(&gt;2\\):\n\ntable(abs(mdl_diagnost$studres) &gt; 2)\n\n\nFALSE  TRUE \n  189    11 \n\n\nWe have 11 TRUE observations, which tells us that they have |studentised residuals| \\(&gt;2\\).\nWe can identify which of our observations have these values:\n\nwhich(abs(mdl_diagnost$studres) &gt; 2)\n\n 16  50  53  58  62  76  78 109 126 151 163 \n 16  50  53  58  62  76  78 109 126 151 163 \n\n\nSo we know that observations (or rows) 16, 50, 53, 58, 62, 76, 78, 109, 126, 151, and 163 have absolute values that have studentised residuals of \\(&gt;2\\) or \\(&lt; -2\\).\nWe could also filter our newly created tibble to these observations to examine the values further:\n\nmwdata %&gt;%\n    mutate(\n    studres = rstudent(wb_mdl1)) %&gt;%\n  dplyr::filter(., studres &gt; 2 | studres &lt; -2) %&gt;%\n  arrange(., desc(studres)) %&gt;%\n  kable(.)  %&gt;%   \n    kable_styling(., full_width = F)\n\n\n\nage\noutdoor_time\nsocial_int\nroutine\nwellbeing\nlocation\nsteps_k\nstudres\n\n\n\n23\n26\n19\n1\n59\ncity\nNA\n3.904186\n\n\n34\n29\n11\n1\n50\nsuburb\n61.1\n2.402389\n\n\n39\n28\n11\n1\n49\nsuburb\n65.6\n2.234367\n\n\n22\n22\n11\n1\n47\ncity\n80.1\n2.060351\n\n\n58\n31\n16\n1\n30\nrural\n46.6\n-2.047644\n\n\n46\n19\n19\n1\n28\nrural\n34.8\n-2.167219\n\n\n44\n25\n11\n0\n26\nrural\n66.6\n-2.261542\n\n\n47\n24\n15\n0\n27\nrural\n53.5\n-2.292089\n\n\n35\n19\n17\n0\n26\nrural\n66.1\n-2.433253\n\n\n19\n23\n17\n0\n26\nrural\n60.0\n-2.602129\n\n\n36\n19\n16\n0\n22\nrural\n51.6\n-3.199777\n\n\n\n\n\n\n\n\n\n\n\nThere were 11 observations identified as potential outliers.\n\n\n\n\n\nHat values of more than \\(2 \\bar{h}\\) (2 times the average hat value) are considered high leverage. The average hat value, \\(\\bar{h}\\) is calculated as \\(\\frac{k + 1}{n}\\), where \\(k\\) is the number of predictors, and \\(n\\) is the sample size.\nFor our model: \\[\n\\bar h = \\frac{k+1}{n} = \\frac{2+1}{200} = \\frac{3}{200} = 0.015\n\\] We can ask whether any of observations have hat values which are greater than \\(2 \\bar h\\):\n\ntable(mdl_diagnost$hats &gt; (2*0.015))\n\n\nFALSE  TRUE \n  184    16 \n\n\nWe have 16 TRUE observations, which tells us that they have high leverage.\nWe can identify which of our observations have these values:\n\nwhich(mdl_diagnost$hats &gt; (2*0.015))\n\n 25  56  59  60  72  73  75  79 127 131 149 159 165 169 176 197 \n 25  56  59  60  72  73  75  79 127 131 149 159 165 169 176 197 \n\n\nSo we know that observations (or rows) 25, 56, 59, 60, 72, 73, 75, 79, 127, 131, 149, 159, 165, 169, 176, and 197 have hat values which are greater than \\(2 \\bar h\\).\nWe could also filter our newly created tibble to these observations to examine the values further:\n\nmwdata %&gt;%\n    mutate(\n    hats = hatvalues(wb_mdl1)) %&gt;%\n  dplyr::filter(., hats &gt; (2*0.015)) %&gt;%\n  arrange(., desc(hats)) %&gt;%\n  kable(.)  %&gt;%   \n    kable_styling(., full_width = F)\n\n\n\nage\noutdoor_time\nsocial_int\nroutine\nwellbeing\nlocation\nsteps_k\nhats\n\n\n\n21\n9\n24\n1\n35\nsuburb\nNA\n0.0564084\n\n\n62\n31\n3\n1\n37\ncity\n49.2\n0.0452765\n\n\n69\n2\n19\n0\n39\nrural\n5.9\n0.0448793\n\n\n19\n7\n21\n0\n39\nrural\n40.0\n0.0411712\n\n\n63\n10\n21\n1\n41\nrural\n24.3\n0.0356713\n\n\n27\n1\n11\n1\n38\nrural\nNA\n0.0352975\n\n\n53\n35\n14\n1\n35\nrural\n24.4\n0.0345566\n\n\n21\n7\n5\n1\n30\nsuburb\n3.3\n0.0341635\n\n\n18\n28\n4\n0\n32\ncity\n71.6\n0.0336901\n\n\n30\n10\n4\n1\n36\nrural\n29.7\n0.0328599\n\n\n44\n5\n7\n1\n35\nrural\n15.1\n0.0313589\n\n\n69\n11\n4\n0\n31\nsuburb\n15.6\n0.0312095\n\n\n23\n29\n5\n1\n36\nrural\nNA\n0.0310672\n\n\n56\n32\n7\n1\n41\ncity\n58.6\n0.0309399\n\n\n35\n10\n20\n1\n46\ncity\nNA\n0.0305338\n\n\n21\n34\n13\n1\n48\nsuburb\n35.1\n0.0301977\n\n\n\n\n\n\n\n\n\n\n\nThere were 16 observations that had high leverage (&gt; \\(2 \\bar h\\)).\n\n\n\n\n\nWe are using a Cook’s Distance cut-off of \\(\\frac{4}{n-k-1}\\), where \\(k\\) is the number of predictors, and \\(n\\) is the sample size.\nFor our model: \\[\nD_{cutoff} = \\frac{4}{n-k-1} = \\frac{4}{200 - 2 - 1} = \\frac{4}{197} = 0.020\n\\]\nWe can ask whether any of observations have a high influence on our model estimates:\n\ntable(mdl_diagnost$cooksd &gt; 0.020)\n\n\nFALSE  TRUE \n  189    11 \n\n\nYes, we have 11 TRUE observations, which tells us that they are above the \\(D_{cutoff} = 0.020\\).\nWe can identify which of our observations have these values:\n\nwhich(mdl_diagnost$cooksd &gt; 0.020)\n\n 16  53  58  76  78 109 125 126 149 151 169 \n 16  53  58  76  78 109 125 126 149 151 169 \n\n\nSo we know that observations (or rows) 16, 53, 58, 76, 78, 109, 125, 126, 149, 151, and 169 have \\(D &gt; 0.020\\).\nWe could also filter our newly created tibble to these observations to examine the values further:\n\nmwdata %&gt;%\n    mutate(\n    cooksd = cooks.distance(wb_mdl1)) %&gt;%\n  dplyr::filter(., cooksd &gt; 4/(200-2-1)) %&gt;%\n  arrange(., desc(cooksd)) %&gt;%\n  kable(.)  %&gt;%   \n    kable_styling(., full_width = F)\n\n\n\nage\noutdoor_time\nsocial_int\nroutine\nwellbeing\nlocation\nsteps_k\ncooksd\n\n\n\n23\n26\n19\n1\n59\ncity\nNA\n0.1295568\n\n\n58\n31\n16\n1\n30\nrural\n46.6\n0.0376693\n\n\n19\n23\n17\n0\n26\nrural\n60.0\n0.0336478\n\n\n36\n19\n16\n0\n22\nrural\n51.6\n0.0326114\n\n\n34\n29\n11\n1\n50\nsuburb\n61.1\n0.0319559\n\n\n35\n10\n20\n1\n46\ncity\nNA\n0.0318858\n\n\n46\n19\n19\n1\n28\nrural\n34.8\n0.0314694\n\n\n21\n34\n13\n1\n48\nsuburb\n35.1\n0.0284437\n\n\n35\n19\n17\n0\n26\nrural\n66.1\n0.0247096\n\n\n39\n28\n11\n1\n49\nsuburb\n65.6\n0.0243298\n\n\n\n\n\nYou can also display the Cook’s Distance values themselves using plot(model, which = 4), and add a horizontal line at the \\(D_{cutoff} = 0.020\\) using abline(h = ???):\n\nplot(wb_mdl1, which = 4, abline(h=0.020, col=\"blue\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nThere were 11 observations that had a high influence on our model estimates.\n\n\n\n\n\n\n\n\n\n\n\nQuestion 9\n\n\nUse the function influence.measures() to extract these delete-1 measures1 of influence.\nChoose a couple of these measures to focus on, exploring in more detail (you may want to examine values or even try plotting distributions).\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe function influence.measures() returns an infl-type object. To plot this, we need to find a way to extract the actual numbers from it.\nWhat do you think names(influence.measures(wb_mdl1)) shows you? How can we use influence.measures(wb_mdl1)$&lt;insert name here&gt; to extract the matrix of numbers?\n\n\n\n\n\n\n\n Solution \n\n\n\n\nExtracting influence.measures()\nExamine DFBETA values\nPlotting COVRATIO statistics\n\n\n\n\n#extract measures\ninf_mes &lt;- influence.measures(wb_mdl1)\n\n#examine top ten rows, and round to 3 decimal places\nround(inf_mes$infmat[1:10,], 3)\n\n   dfb.1_ dfb.otd_ dfb.scl_  dffit cov.r cook.d   hat\n1   0.006   -0.008    0.002  0.012 1.024  0.000 0.009\n2   0.083   -0.168    0.061  0.203 1.016  0.014 0.025\n3  -0.006   -0.001    0.004 -0.016 1.020  0.000 0.005\n4   0.047   -0.050   -0.039 -0.081 1.020  0.002 0.012\n5   0.001    0.080   -0.091 -0.138 1.028  0.006 0.024\n6  -0.003    0.001   -0.008 -0.037 1.017  0.000 0.005\n7  -0.008   -0.001    0.015  0.018 1.036  0.000 0.020\n8   0.106   -0.119   -0.006  0.166 0.985  0.009 0.010\n9  -0.003    0.004   -0.001 -0.007 1.025  0.000 0.009\n10  0.002   -0.008    0.008  0.015 1.026  0.000 0.010\n\n\n\n\nDFbeta represents the difference in the beta coefficients when a case is excluded from the model versus when it’s included. A large DFbeta value would suggest that a case has a substantial impact on the estimated coefficients, and thus a high influence on the model results; a small DFbeta value would suggest that the case has less influence on the estimated coefficients.\nA commonly used cut-off or threshold to compare \\(|DFBETA|\\) values (absolute values) against is \\(\\frac{2}{\\sqrt{n}}\\) (see Belsley et al., (1980) p. 28 for more info)2.\nFor our model:\n\\[\n|DFBETA_{cutoff}| \\quad = \\quad \\frac{2}{\\sqrt{n}} \\quad = \\quad  \\frac{2}{\\sqrt{200}}  = 0.141\n\\]\nIn order to extract these in order to arrange in descending order, we need to save our delete-1 measures of influence as a dataframe (via as.data.frame()). Then we can then arrange our DFBETA values in descending order (via arrange(desc(???))). To avoid returning 200 rows of output (i.e., the length of the dataframe), we can ask for the first 15 rows via (head(., 15)):\n\n#save as a dataframe\ninf_mes1 &lt;- as.data.frame(inf_mes$infmat)\n\n#arrange dfbeta values in descending order using the absolute value, and show first 10 rows\ninf_mes1 %&gt;%\n    arrange(desc(abs(dfb.1_))) %&gt;%\n    head(., 15)\n\n        dfb.1_    dfb.otd_    dfb.scl_      dffit     cov.r      cook.d\n109 -0.4918246  0.32363373  0.49483157  0.6455776 0.8332377 0.129556799\n53   0.2430892 -0.26944443 -0.15351312 -0.3388798 0.9790122 0.037669317\n16   0.2060412 -0.13252138 -0.23259175 -0.3223359 0.9310954 0.033647762\n101 -0.1947109  0.09412063  0.15487642 -0.2046876 1.0063119 0.013897196\n179  0.1902832 -0.07096434 -0.16598552  0.2085435 0.9990240 0.014401828\n76   0.1730591 -0.02595756 -0.26823452 -0.3101290 0.9651183 0.031469445\n85  -0.1646134  0.10294561  0.11084731 -0.1711913 1.0143158 0.009748336\n149 -0.1638458  0.26658339  0.03742045  0.2934205 1.0039126 0.028443695\n56   0.1604565 -0.19478940 -0.02813891  0.2114811 1.0330872 0.014891276\n173 -0.1561237  0.10614219  0.15969174  0.2161367 1.0033339 0.015479111\n75   0.1457701 -0.07234892 -0.11988282  0.1497178 1.0393526 0.007484738\n50   0.1353661 -0.13659118 -0.12403587 -0.2437762 0.9485325 0.019390273\n26   0.1300856 -0.08559983 -0.13088097 -0.1707527 1.0263050 0.009715555\n58   0.1291280 -0.02591707 -0.21369424 -0.2756455 0.9405759 0.024709605\n78   0.1272542 -0.03198691 -0.22393152 -0.3200349 0.8802619 0.032611416\n            hat\n109 0.026614646\n53  0.026659223\n16  0.015112834\n101 0.020817727\n179 0.018565852\n76  0.020066684\n85  0.020304231\n149 0.030197659\n56  0.035297538\n173 0.020995260\n75  0.032859874\n50  0.011184976\n26  0.026614646\n58  0.012670376\n78  0.009904492\n\n\nWe can see that we have 11 \\(|DFBETA|\\) values &gt; \\(\\frac{2}{\\sqrt{200}}\\), from observations (or rows) 16, 53, 56, 75, 76, 85, 101, 109, 149, 173, and 179 that we may want to examine further:\n\nwhich(abs(inf_mes1$dfb.1_) &gt; (2/sqrt(200)))\n\n [1]  16  53  56  75  76  85 101 109 149 173 179\n\n\n\n\nValues which are \\(&gt;1+\\frac{3(k+1)}{n}\\) or \\(&lt;1-\\frac{3(k+1)}{n}\\) are considered as having strong influence.\nFor our model, this is: \\[\n1 \\pm \\frac{3(k+1)}{n} \\quad = \\quad 1 \\pm\\frac{3(2+1)}{200} \\quad = \\quad 1\\pm \\frac{9}{200} \\quad = \\quad 1\\pm0.045\n\\]\nThe “infmat” bit of an infl-type object contains the numbers, as we can see from out output above. To use it with ggplot(), we will need to turn it into a dataframe (as.data.frame()), or a tibble (as_tibble()):\n\ninfdata &lt;- inf_mes$infmat %&gt;%\n  as_tibble()\n\nNow we can build our plot. It would be useful to add vertical lines at the values \\(\\quad 1\\pm0.045\\). To do so, we can use the geom_vline() function:\n\nggplot(data = infdata, aes(x = cov.r)) + \n  geom_histogram() +\n  geom_vline(aes(xintercept = c(1-0.045), col = \"blue\")) +\n  geom_vline(aes(xintercept = c(1+0.045), col = \"red\")) + \n  theme(legend.position = \"none\")  #remove legend\n\n\n\n\n\n\n\nIt looks like a few observations may be having quite a strong influence on the standard errors here. We can check specifically how many observations are potentially having a having strong influence using the cut off \\(1\\pm0.045\\):\n\ntable(infdata$cov.r &lt; 1 - 0.045 | infdata$cov.r &gt; 1 + 0.045)\n\n\nFALSE  TRUE \n  185    15 \n\n\nWe can identify these 15 observations to investigate further:\n\nwhich(infdata$cov.r &lt; 1 - 0.045 | infdata$cov.r &gt; 1 + 0.045)\n\n [1]  16  25  50  58  62  72  73  78  79 109 127 151 159 165 176\n\n\nWe know that observations (or rows) 16, 25, 50, 58, 62, 72, 73, 78, 79, 109, 127, 151, 159, 165, and 176 have \\(\\text{COVRATIO  } 1\\pm0.045\\).\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nWhat approaches would be appropriate to take given the issues highlighted above with the violations of assumptions and case diagnostic results?\n\n\n\n\n Solution \n\n\nThere are lots of different options available, and there is no one right answer. Assuming that we have no issues with model specification (i.e., are not missing variables, have modeled appropriately), then we may want to consider one of the below approaches (note: this is not an exhaustive list!)\n\n\nInvestigate Observations\nSensitivity Analysis\nBootstrapping\nOLS vs WLS Regression\nData Transformations\nUsing Non-Linear Models\nRemoving Observations\n\n\n\nThe first step is to re-examine your data. It is important to be familiar with your dataset, as you need to know what values are typical, normal, and possible. Could it be the case that you have missed some impossible values (e.g., a negative value of a persons height), values outwith the possible range (e.g., a score of 55 on a survey where scores can only range 10-50), values that don’t make any sense (e.g., an age of 200), or maybe there are even typos / data entry errors (e.g., forgetting to put a decimal point, so having a height of 152m instead of 1.52m)!\nIf there is a simple error in the data, it could be that you can fix the typo. If that is not possible (maybe you didn’t collect the data, so are unsure of what the value(s) should/could be), you will need to delete the value (i.e., set as an NA), because you know that it is incorrect.\nWe should aim to never change a legitimate value where possible (and remember that if you have a large dataset, a small number of extreme values will be unlikely to have a strong influence on your results).\nIf there is an extreme, but legitimate value that you have determined is adversely influencing your model (i.e., by examining the assumptions and diagnostics as outlined above), you may want to consider ways to reduce this influence (e.g., winsorizing - which essentially truncates or caps the identified extreme values to a specified percentile, in turn reducing their influence on the model without completely eliminating the observation(s). For example, you could replace values below the 5th percentile with the 5th percentile value, and values above the 95th percentile with the 95th percentile value).\nIf after re-examining your data you cannot identify any atypical, non-normal, or impossible values, you may need to select a different approach as outlined below.\n\n\nThis allows us to assess the sensitivity of our results (i.e., parameter estimates, p-values, confidence intervals) to changes in our modelling approach (i.e., the removal of observations).\nWe can re-fit our model after excluding our identified outliers and potentially influential observations, and compare these results to the original model.\n\n\n\n\n\n\nProcess of Removing Observations\n\n\n\n\n\nThe current example involves removing all identified outliers and potentially influential observations at the same time. Ideally, and to ensure a more thorough sensitivity analysis, you would remove each of these observations one at a time, assess the effects on the model by comparing to your original, reassessing the remaining pre-identified observations, and repeating the process if necessary.\n\n\n\n\n\nOriginal Model\nModel with Observations Removed\nCompare summary() output\n\n\n\n\n## wellbeing model\nwb_mdl1 &lt;- lm(wellbeing ~ outdoor_time + social_int, data = mwdata) \nsummary(wb_mdl1)\n\n\nCall:\nlm(formula = wellbeing ~ outdoor_time + social_int, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7611  -3.1308  -0.4213   3.3126  18.8406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  28.62018    1.48786  19.236  &lt; 2e-16 ***\noutdoor_time  0.19909    0.05060   3.935 0.000115 ***\nsocial_int    0.33488    0.08929   3.751 0.000232 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.065 on 197 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n\n\n\n\n\n## wellbeing model\nwb_mdl2 &lt;- lm(wellbeing ~ outdoor_time + social_int, data = mwdata[-c(16, 25, 50, 53, 56, 58, 59, 60, 62, 72, 73, 75, 76, 78, 79, 85, 101, 109, 125, 126, 127, 131, 149, 151, 159, 163, 165, 169, 173, 176, 179, 197), ])\nsummary(wb_mdl2)\n\n\nCall:\nlm(formula = wellbeing ~ outdoor_time + social_int, data = mwdata[-c(16, \n    25, 50, 53, 56, 58, 59, 60, 62, 72, 73, 75, 76, 78, 79, 85, \n    101, 109, 125, 126, 127, 131, 149, 151, 159, 163, 165, 169, \n    173, 176, 179, 197), ])\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.7700 -2.6445 -0.6073  2.8586  9.6605 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  27.91311    1.42612  19.573  &lt; 2e-16 ***\noutdoor_time  0.19356    0.04901   3.950 0.000116 ***\nsocial_int    0.39830    0.08964   4.443 1.62e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.044 on 165 degrees of freedom\nMultiple R-squared:  0.1774,    Adjusted R-squared:  0.1675 \nF-statistic:  17.8 on 2 and 165 DF,  p-value: 1.004e-07\n\n\n\n\n\ntab_model(wb_mdl1, wb_mdl2,\n          dv.labels = c(\"Wellbeing (WEMWBS Scores)\", \"Wellbeing (WEMWBS Scores)\"),\n          pred.labels = c(\"outdoor_time\" = \"Outdoor Time (hours per week)\",\n                          \"social_int\" = \"Social Interactions (number per week)\"),\n          title = \"Regression Table for Wellbeing Models wb1 and wb2\")\n\n\nRegression Table for Wellbeing Models wb1 and wb2\n\n\n\n\n\n\n\n\n\n\n\n \nWellbeing (WEMWBS Scores)\nWellbeing (WEMWBS Scores)\n\n\nPredictors\nEstimates\nCI\np\nEstimates\nCI\np\n\n\n(Intercept)\n28.62\n25.69 – 31.55\n&lt;0.001\n27.91\n25.10 – 30.73\n&lt;0.001\n\n\nOutdoor Time (hours per\nweek)\n0.20\n0.10 – 0.30\n&lt;0.001\n0.19\n0.10 – 0.29\n&lt;0.001\n\n\nSocial Interactions\n(number per week)\n0.33\n0.16 – 0.51\n&lt;0.001\n0.40\n0.22 – 0.58\n&lt;0.001\n\n\nObservations\n200\n168\n\n\nR2 / R2 adjusted\n0.126 / 0.118\n0.177 / 0.167\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe conducted a sensitivity analysis to assess how robust our conclusions were regarding outdoor time and the weekly number of social interactions in the presence of previously identified outliers and potentially influential observations. We re-fit the model, excluding these 28 observations (14% of our original sample), and compared these model results (wb_mdl2) to those of our original model (wb_mdl1).\nThere was little difference in the estimates from wb_mdl1 and wb_mdl2, and so we can conclude that after conducting a sensitivity analysis, there were no meaningful differences in our results, and hence our conclusions from our original model hold. Specifically:\n\nThe direction of all model estimates are the same in wb_mdl1 and wb_mdl2 (i.e., all positive)\nThere is no difference in statistical significance, and the p-values were of a similar magnitude (i.e., all &lt; .001)\nThe estimate and confidence intervals for outdoor_time are very similar\nThere are some quantitative differences in the estimate and confidence intervals for social_int. The estimate differs slightly in magnitude by 0.07), but given that this remains positive and significant, we do not need to be too concerned about this.\n\n\n\n\n\n\nThe bootstrap method is an alternative non-parametric method of constructing a standard error. Instead of having to rely on calculating the standard error with a formula and potentially applying fancy mathematical corrections, bootstrapping involves mimicking the idea of “repeatedly sampling from the population”. It does so by repeatedly resampling with replacement from our original sample.\nWhat this means is that we don’t have to rely on any assumptions about our model residuals, because we actually generate an actual distribution that we can take as an approximation of our sampling distribution, meaning that we can actually look at where 95% of the distribution falls, without having to rely on any summing of squared deviations.\nNote, the bootstrap may provide us with an alternative way of conducting inference, but our model may still be mis-specified. It is also very important to remember that bootstrapping is entirely reliant on utilising our original sample to pretend that it is a population (and mimic sampling from that population). If our original sample is not representative of the population that we’re interested in, bootstrapping doesn’t help us at all.\nMore on how bootstrapping works next week!\n\n\nThe method of ordinary least squares regression (OLS: i.e., the type of regression model you have been fitting on the course) assumes that there is constant variance in the errors (homoscedasticity). The method of weighted least squares (WLS) can be used when the ordinary least squares assumption of constant variance in the errors is violated (i.e., you have evidence of heteroscedasticity, like we do in Q3 of this lab).\nIf we have some specific belief that your non-constant variance is due to differences in the variances of the outcome between various groups, then it might be better to use Weighted Least Squares.\nAs an example, imagine we are looking at weight of different dog breeds (Figure 1). The weights of chihuahuas are all quite close together (between 2 to 5kg), but the weight of, for example, spaniels is anywhere from 8 to 25kg - a much bigger variance.\n\n\n\n\nFigure 1: The weights of 49 dogs, of 7 breeds\n\n\n\nRecall that the default way that lm() deals with categorical predictors such as dog breed, is to compare each one to a reference level. In this case, that reference level is “beagle” (first in the alphabet). Looking at Figure 1 above, which comparison do you feel more confident in?\n\n\nA: Beagles (14kg) vs Pugs (9.1kg). A difference of 4.9kg.\n\n\nB: Beagles (14kg) vs Spaniels (19kg). A difference of 5kg.\n\nHopefully, your intuition is that A looks like a clearer difference than B because there’s less overlap between Beagles and Pugs than between Beagles and Spaniels. Our standard linear model, however, assumes the standard errors are identical for each comparison:\n\n\n\nCall:\nlm(formula = weight ~ breed, data = dogdf)\n...\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             13.996      1.649   8.489 1.17e-10 ***\nbreedpug                -4.858      2.332  -2.084   0.0433 *  \nbreedspaniel             5.052      2.332   2.167   0.0360 *  \nbreedchihuahua         -10.078      2.332  -4.322 9.28e-05 ***\nbreedboxer              20.625      2.332   8.846 3.82e-11 ***\nbreedgolden retriever   17.923      2.332   7.687 1.54e-09 ***\nbreedlurcher             5.905      2.332   2.533   0.0151 *  \n---\n\n\nFurthermore, we can see that we have heteroscedasticity in our residuals - the variance is not constant across the model:\n\nplot(dogmodel, which=3)\n\n\n\n\n\n\n\nWeighted least squares is a method that allows us to apply weights to each observation, where the size of the weight indicates the precision of the information contained in that observation.\nWe can, in our dog-breeds example, allocate different weights to each breed. Accordingly, the Chihuahuas are given higher weights (and so Chihuahua comparisons result in a smaller SE), and Spaniels and Retrievers are given lower weights.\n\nlibrary(nlme)\nload(url(\"https://uoepsy.github.io/data/dogweight.RData\"))\ndogmod_wls = gls(weight ~ breed, data = dogdf, \n                 weights = varIdent(form = ~ 1 | breed))\nsummary(dogmod_wls)\n\n\n\nCoefficients:\n                           Value Std.Error   t-value p-value\n(Intercept)            13.995640  1.044722 13.396516  0.0000\nbreedpug               -4.858097  1.271562 -3.820576  0.0004\nbreedspaniel            5.051696  2.763611  1.827933  0.0747\nbreedchihuahua        -10.077615  1.095964 -9.195207  0.0000\nbreedboxer             20.625429  1.820370 11.330351  0.0000\nbreedgolden retriever  17.922779  2.976253  6.021927  0.0000\nbreedlurcher            5.905261  1.362367  4.334559  0.0001\n\n\nWe can also apply weights that change according to continuous predictors (e.g. observations with a smaller value of \\(x\\) are given more weight than observations with larger values).\n\n\nA data transformation involves the replacement of a variable (e.g., \\(y\\)) by a function of that variable in order to change the shape of a distribution or association (e.g., to help reduce skew). We can transform the outcome variable prior to fitting the model, using something such as log(y) or sqrt(y). This will sometimes allow us to estimate a model for which our assumptions are satisfied.\nSome of the most common (not an exhaustive list) transformations are:\n\n\nLog (log(y)): Often used for reducing right skewness. Note, this transformation cannot be applied to zero or negative values (make sure to check your data!)\n\nSquare root (sqrt(y)): Also often used for reducing right skewness. This transformation can be applied to zero values (but not negative), and is commonly applied to count data\n\n\n\n\n\nFigure 2: A model of a transformed outcome variable can sometimes avoid violations of assumptions that arise when modeling the outcome variable directly. Data from https://uoepsy.github.io/data/trouble1.csv\n\n\n\nThe major downside of this is that we are no longer modelling \\(y\\), but some transformation \\(f(y)\\) (\\(y\\) with some function \\(f\\) applied to it). Interpretation of the coefficients changes accordingly, such that we are no longer talking in terms of changes in y, but changes in \\(f(y)\\). When the transformation function used is non-linear (see the Right-Hand of Figure 3) a change in \\(f(y)\\) is not the same for every \\(y\\).\n\n\n\n\nFigure 3: The log transformation is non-linear\n\n\n\nFor certain transformations, we can re-express coefficients to be interpretable with respect to \\(y\\) itself. For instance, the model using a log transform \\(ln(y) = b_0 + b_1(x)\\) gives us a coefficient that represents statement A below. We can re-express this by taking the opposite function to logarithm, the exponent, exp(). Similar to how this works in logistic regression, the exponentiated coefficients obtained from exp(coef(model)) are multiplicative, meaning we can say something such as statement B\n\n\n\nA: “a 1 unit change in \\(x\\) is associated with a \\(b\\) unit change in \\(ln(y)\\)”.\n\n\nB: “a 1 unit change in \\(x\\) is associated with \\(e^b\\) percent change in \\(y\\).”\n\n\nFinding the optimal transformation to use can be difficult, but there are methods out there to help you. One such method is the BoxCox transformation, which can be conducted using BoxCox(variable, lambda=\"auto\"), from the forecast package.3\n\n\n\n\nGeneralized Linear Models\nHigher Order Terms\n\n\n\nGeneralized Linear Models (GLMs) can appropriately deal with data that do not follow a normal distribution (which is a requirement for traditional linear models). They can accommodate various types of distributions, including the Poisson, binomial, and gamma distributions. This makes them suitable for modelling count data (e.g., number of sunny days Edinburgh has per year - yes, count data can include 0!), binary data (where there are only two possible values e.g., doesn’t wear glasses vs wear glasses, smoker vs non-smoker, i.e., values that are yes/no or 0/1), and other types of non-normal data.\nWe will explore some GLMs later in the course (Semester 2 Block 4), where we will work with logistic regression models.\n\n\nHigher order regression terms refer to the inclusion of polynomial terms of degree higher than one in a regression model. In a linear regression model, the association between the dependent variable (\\(Y\\)) and the independent variable (\\(X\\)) is assumed to be linear, which means the association can be represented by a straight line. However, in many real-world scenarios, associations between variables are not strictly linear, and including higher order regression terms can help capture more complex relationships. Higher order terms that you could incorporate include quadratic, cubic, or higher degree polynomial terms.\nFor example, in a quadratic regression model, the relationship between \\(Y\\) and \\(X\\) can be represented as:\n\\[\nY = \\beta_0 + \\beta_1 \\cdot X + \\beta_2 \\cdot X^2 + \\epsilon\n\\] \\[\n\\begin{align}\n& \\text{Where:} \\\\\n& Y = \\text{Dependent Variable} \\\\\n& X = \\text{Independent Variable} \\\\\n\\end{align}\n\\]\nAs in our models we’ve seen so far, \\(\\beta_0\\), \\(\\beta_1\\), and \\(\\beta_2\\) are the coefficients to be estimated in the above model. What is different from what we’ve seen in DAPR2 is the term \\(\\beta_2 \\cdot X^2\\), and this represents the quadratic term. This allows for a curved as opposed to straight line to represent the association between \\(Y\\) and \\(X\\), and hence can allow us to capture more complex relationships. For example, we can model the association between height and age:\n\n\n\n\nFigure 4: Two linear models, one with a quadratic term (right)\n\n\n\nPlease note that these types of models are beyond the scope of the DAPR2 course, but if you want to know more, please do read up on these in your own time.\n\n\n\n\n\nRemoving outliers and potentially influential observations should be a last resort - not all outliers are inherently ‘bad’ - we do expect natural variation in our population(s) of interest. Outliers can be informative about the topic under investigation, and this is why you need to be very careful about excluding outliers due only to their ‘extremeness’. In doing so, you can distort your results by removing variability - i.e., by forcing the data to be more normal and less variable than it actually is, and reduce statistical power by reducing the size of your sample.\nIf you do decide to remove observations, you will need to document what specific data points you excluded, and provide an explanation as to why these were excluded.\nTo set specific values to NA in our dataset (and save this updated dataset in a new object named mwdata2), we could use the following code. For the purpose of this demonstration, lets say that we wanted to set any age values of &lt;20 as NA. In the original dataset mwdata, we had 3 individuals aged 18, and 6 aged 19, so we should end up with 9 NA values in mwdata2 column age:\n\n#specify age column in original dataset, where age is &lt; 20, for values to be set to NA and save to new object named mwdata2 to avoid overwriting original data\nmwdata2 &lt;-  mwdata %&gt;% \n    mutate(age = replace(age, age &lt; 20, NA))\n\n#check how many NA values we have - there should be 9 (so 9 TRUEs):\ntable(is.na(mwdata2$age))\n\n\nFALSE  TRUE \n  191     9 \n\n\nIf we wanted to remove a full row from the datset, we could use the following code. For the purpose of this demonstration, lets say that we wanted to remove all rows that were highlighted in the above assumption and diagnostic checks as potentially having an adverse influence on our model estimates:\n\n# create new dataset 'mwdata3' without (by specifying -) identified outliers and potentially influential observations\nmwdata3 &lt;- mwdata[-c(16, 25, 50, 53, 56, 58, 59, 60, 62, 72, 73, 75, 76, 78, 79, 85, 101, 109, 125, 126, 127, 131, 149, 151, 159, 163, 165, 169, 173, 176, 179, 197), ]\n\n# check dimensions - should now have 32 rows less than original dataset 200 - 32 = 168\ndim(mwdata3)\n\n[1] 168   7"
  },
  {
    "objectID": "1_08_assump_diag.html#footnotes",
    "href": "1_08_assump_diag.html#footnotes",
    "title": "Assumptions and Diagnostics",
    "section": "Footnotes",
    "text": "Footnotes\n\nleave-one-out deletion diagnostics↩︎\nBelsley, D. A., Kuh, E., & Welsch, R. E. (2005). Regression diagnostics: Identifying influential data and sources of collinearity. John Wiley & Sons. DOI: 10.1002/0471725153↩︎\nThis method finds an appropriate value for \\(\\lambda\\) such that the transformation \\((sign(x) |x|^{\\lambda}-1)/\\lambda\\) results in a close to normal distribution.↩︎"
  },
  {
    "objectID": "1_09_bootstrap.html",
    "href": "1_09_bootstrap.html",
    "title": "Bootstraping",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand the principles of bootstrapping\nApply the bootstrap confidence interval to inference in linear models\n\n\nBe up to date with lectures\nHave completed previous lab exercises from Week X and Week X\n\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\npatchwork\nsjPlot\nkableExtra\ncar\n\nAll results should be presented following APA guidelines. If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\nThe example write-up sections included as part of the solutions are not perfect - they instead should give you a good example of what information you should include and how to structure this. Note that you must not copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more here.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/science-faith-attitude.csv."
  },
  {
    "objectID": "1_09_bootstrap.html#study-overview-data-management",
    "href": "1_09_bootstrap.html#study-overview-data-management",
    "title": "Bootstraping",
    "section": "Study Overview & Data Management",
    "text": "Study Overview & Data Management\n\nQuestion 1\n\n\nExamine the dataset, and perform any necessary and appropriate data management steps.\nNote, to address the research question, we only need to refer to the kstot, age, and toomuchscience variables. Subset the data to only have those 3 columns.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nCheck for missing data\nIf needed, provide better variable names\n\n\n\n\n\n\n\n\n Solution \n\n\n\n# Inspect top 6 rows\nhead(ebsurvey)\n\n# A tibble: 6 × 7\n     v5    v6 kstot   age  male toomuchscience solveprob\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;          &lt;dbl&gt;     &lt;dbl&gt;\n1     1     2    12    35     1              2         0\n2     2     2    11    34     0              1         1\n3     3     2     7    40     0             NA        NA\n4     4     2     9    32     0              3         0\n5     5     2     6    35     0              3         1\n6     6     2    11    67     1             NA        NA\n\n# Check data dimensions\ndim(ebsurvey)\n\n[1] 21886     7\n\n\nThere are 21886 observations on 7 variables.\nHowever, today we will be only using the kstot, age, and toomuchscience variables, and so we subset the data to only include these:\n\nebsurvey &lt;- ebsurvey %&gt;%\n    select(kstot, age, toomuchscience)\n\nAre there any NA values in the data?\n\n#check for NAs\nanyNA(ebsurvey)\n\n[1] TRUE\n\n#how many NAs?\ntable(is.na(ebsurvey))\n\n\nFALSE  TRUE \n54268 11390 \n\n#11390 NAs in data set \n\n#Omit the NAs\nebsurvey &lt;- na.omit(ebsurvey)\n\n# Check new data dimensions\ndim(ebsurvey)\n\n[1] 10503     3\n\n\nGive the variables more meaningful names. Rename kstot to science_knowledge and rename toomuchscience to attitude:\n\nebsurvey &lt;- ebsurvey %&gt;%\n    rename(science_knowledge = kstot,\n           attitude = toomuchscience)\nhead(ebsurvey)\n\n# A tibble: 6 × 3\n  science_knowledge   age attitude\n              &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1                12    35        2\n2                11    34        1\n3                 9    32        3\n4                 6    35        3\n5                 9    37        1\n6                 5    63        2\n\n\n\n\n\n\n\nQuestion 2\n\n\nProvide a brief overview of the study design and data, before detailing your analysis plan to address the research question.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nGive the reader some background on the context of the study\nState what type of analysis you will conduct in order to address the research question\nSpecify the model to be fitted to address the research question (note that you will need to specify the reference level of your categorical variable)\nSpecify your chosen significance (\\(\\alpha\\)) level\nState your hypotheses\n\nMuch of the information required can be found in the Study Overview codebook.\n\n\n\n\n\n\n\n Solution \n\n\nThe ebsurvey dataset, excluding missing values, included 10,503 individual respondents who were measured on 3 different attributes: (1) score on a science “quiz” composed of 13 true/false items; (2) attitudes towards science and faith (question wording: “We rely too much on science and not enough on faith” with responses recorded on a 5-point scale from strongly disagree to strongly agree); and (3) their age (in years).\nHistograms will be used to visualise the marginal distributions of attitudes towards science and faith, scientific knowledge, and age. To understand the strength of association among the variables, we will estimate the the correlation coefficients. To address the research question of whether there is an association between people’s scientific knowledge and their attitudes towards science and faith after accounting for their age, we are going to fit the following multiple linear regression model:\n\\[\n\\text{Attitude} = \\beta_0  + \\beta_1 \\cdot \\text{Science Knowledge} + \\beta_2 \\cdot \\text{Age} + \\epsilon\n\\] Effects will be considered statistically significant at \\(\\alpha = .05\\).\nOur hypotheses are:\n\\(H_0: \\beta_1 = 0\\): There is no association between people’s scientific knowledge and their attitudes towards science and faith after accounting for their age\n\\(H_1: \\beta_1 \\neq 0\\): There is an association between people’s scientific knowledge and their attitudes towards science and faith after accounting for their age"
  },
  {
    "objectID": "1_09_bootstrap.html#descriptive-statistics-visualisations",
    "href": "1_09_bootstrap.html#descriptive-statistics-visualisations",
    "title": "Bootstraping",
    "section": "Descriptive Statistics & Visualisations",
    "text": "Descriptive Statistics & Visualisations\n\nQuestion 3\n\n\nAlongside descriptive statistics, visualize the marginal distributions of the attitude, science_knowledge, and age variables.\n\n\n\n\n\n\nHint\n\n\n\n\n\nCode for tables & plots - You might be able to re-use some of the code you wrote for Lab 1 here, and remember that you can refer back to the DAPR1 materials too\nPlot interpretation\n- The shape, center and spread of the distribution\n- Whether the distribution is symmetric or skewed\n- Whether the distribution is unimodal or bimodal\nPlotting tips\n- Use \\n to wrap text in your titles and or axis labels\n- The patchwork package allows us to arrange multiple plots in two ways - | arranges the plots adjacent to one another, and / arranges the plots on top of one another\nTable tips\n- The describe() function from the psych package will produce a table of descriptive statistics. If you would like only a subset of this output (e.g., mean, sd), you can use select() after calling describe() e.g., describe() %&gt;% select(mean, sd)\n- The kableExtra package allows us to produce well formatted tables for our descriptive statistics. To do so, you need to specify the kable() and kable_styling() arguments\n- Review the guidance on the rmd bootcamp, particularly Lesson 4\n\n\n\n\n\n\n\n Solution \n\n\n\n\nNumeric\nVisual\n\n\n\n\nebsurvey %&gt;% \n    describe() %&gt;%\n    kable(caption = \"Attitude, Scientfic Knowledge, and Age Descriptive Statistics\", align = \"c\", digits = 2) %&gt;%\n    kable_styling(full_width = FALSE)\n\n\n\nTable 1: Attitude, Scientfic Knowledge, and Age Descriptive Statistics\n\n\nvars\nn\nmean\nsd\nmedian\ntrimmed\nmad\nmin\nmax\nrange\nskew\nkurtosis\nse\n\n\n\nscience_knowledge\n1\n10503\n8.68\n2.61\n9\n8.81\n2.97\n0\n13\n13\n-0.42\n-0.38\n0.03\n\n\nage\n2\n10503\n44.93\n17.32\n44\n44.51\n20.76\n15\n93\n78\n0.18\n-0.88\n0.17\n\n\nattitude\n3\n10503\n2.20\n1.22\n2\n2.25\n1.48\n0\n4\n4\n-0.25\n-0.87\n0.01\n\n\n\n\n\n\n\n\n\n\n\n\nAge\nScience Knowledge\nAttitude Towards Science & Faith\n\n\n\nYou may wish to consider using helpful bin sizes, see the bindwidth argument, but this is subjective and optional.\n\nggplot(ebsurvey, aes(x = age)) +\n    geom_histogram() +\n    labs(x = 'Age (years)', \n         y = 'Frequency')\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe mean age in the sample is about 45 years with a standard deviation of just over 17 years. The distribution looks approximately normal, with a slight positive skew.\n\n\n\n\n\n\nggplot(ebsurvey, aes(x = science_knowledge)) +\n    geom_histogram() +\n    labs(x = 'Science Knowledge Quiz Scores', \n         y = 'Frequency')\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe histogram shows that the majority of values on the science knowledge quiz score cluster between about 5 and 11. There is a slight negative skew to the distribution. Overall there is little reason for concern as to the appropriateness of the variable for inclusion.\n\n\n\n\n\n\nggplot(ebsurvey, aes(x = attitude)) +\n    geom_histogram() +\n    labs(x = 'We Rely too Much on Science and not Enough on Faith', \n         y = 'Frequency')\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe mean score on the science and faith attitude variable is just over 2. There are only 5 discrete values possible in the distribution, based on the response options available, but the distribution looks approximately normal, with a slight negative skew.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 4\n\n\nProduce plots of the associations between the outcome variable (attitude) and each of the explanatory variables.\n\n\n\n\n\n\nHint\n\n\n\n\n\nPlot interpretation\n- Direction of association\n- Form of association (can it be summarised well with a straight line?)\n- Strength of association (how closely do points fall to a recognizable pattern such as a line?)\n- Unusual observations that do not fit the pattern of the rest of the observations and which are worth examining in more detail\nPlot tips\n- use \\n to wrap text in your titles and or axis labels\n- consider using geom_smooth() to superimpose the best-fitting line describing the association of interest\n\n\n\n\n\n\n\n Solution \n\n\n\np1 &lt;- ggplot(data = ebsurvey, aes(x = age, y = attitude)) +\n    geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) + \n    labs(x = 'Age (in years)', y = \"Attitude towards Science and Faith\")\n\np2 &lt;- ggplot(data = ebsurvey, aes(x = science_knowledge, y = attitude)) +\n    geom_point()  +\n  geom_smooth(method = \"lm\", se = FALSE) + \n    labs(x = \"Science Knowledge Quiz Scores\", y = \"Attitude towards Science and Faith\")\n\np1 | p2 \n\n\n\nFigure 1: Scatterplots displaying the associations between Attitude towards Science and Faith and a) Age, and b) Science Knowledge\n\n\n\nFrom the pairwise scatterplots, it does not seem like there is a strong linear dependence of attitude to science and faith on a person’s age and science knowledge.\n\n\n\n\n\nQuestion 5\n\n\nProduce a correlation matrix of the variables which are to be used in the analysis, and write a short paragraph describing the associations.\n\n\n\n\n\n\nHint\n\n\n\n\n\nCorrelation Matrix\nReview Lab 1 Q2 for guidance on how to produce a correlation matrix.\nAPA Format\nMake sure to round your numbers in-line with APA 7th edition guidelines as noted at the start of the lab (see ‘Presenting Results’). The round() function will come in handy here.\n\n\n\n\n\n\n\n Solution \n\n\nWe can either index the dataframe or select the variables of interest:\n\n\nIndex dataframe ([])\nVariable selection (select())\n\n\n\n\n# correlation matrix of the three columns of interest (check which columns we need - in this case, 1,2,3)\nround(cor(ebsurvey[,c(1:3)]), digits = 2)\n\n                  science_knowledge   age attitude\nscience_knowledge              1.00 -0.12    -0.18\nage                           -0.12  1.00     0.05\nattitude                      -0.18  0.05     1.00\n\n\n\n\n\n# select only the columns we want by variable name, and pass this to cor()\nebsurvey %&gt;% \n  select(attitude, science_knowledge, age) %&gt;%\n  cor() %&gt;%\n  round(digits = 2)\n\n                  attitude science_knowledge   age\nattitude              1.00             -0.18  0.05\nscience_knowledge    -0.18              1.00 -0.12\nage                   0.05             -0.12  1.00\n\n\n\n\n\n\n\n\n\n\n\n\nThere was a weak, positive, linear association between attitude towards science and faith and age for the participants in the sample \\((r = .05)\\)\n\nThere was a weak, negative, linear association between attitude towards science and faith and scientific knowledge for the participants in the sample \\((r = -.18)\\)\n\nThere was a weak, negative, linear association between scientific knowledge and age for the participants in the sample \\((r = -.12)\\). The correlation is relatively small in absolute terms, and we therefore have little concern about multicollinearity influencing this regression analysis\nOverall, there were very weak linear associations among the variables of interest"
  },
  {
    "objectID": "1_09_bootstrap.html#model-fitting-interpretation",
    "href": "1_09_bootstrap.html#model-fitting-interpretation",
    "title": "Bootstraping",
    "section": "Model Fitting & Interpretation",
    "text": "Model Fitting & Interpretation\n\nQuestion 6\n\n\nFit the specified model, and assign it the name “att_mdl”.\n\\[\n\\text{Attitude} = \\beta_0  + \\beta_1 \\cdot \\text{Science Knowledge} + \\beta_2 \\cdot \\text{Age} + \\epsilon\n\\]\n\n\n\n\n Solution \n\n\n\natt_mdl &lt;- lm(attitude ~ science_knowledge + age, data = ebsurvey)\n\n\n\n\n\n\nQuestion 7\n\n\nCheck the assumptions of your model. Note any violations of the model assumptions.\n\n\n\n\n Solution \n\n\n\npar(mfrow = c(2,2)) # set 2 by 2 panels\nplot(att_mdl)\n\n\n\n\n\n\npar(mfrow = c(1,1)) # go back to 1 by 1 panels\n\nBased on the visual inspection of the plots, the assumptions appear to be violated.\n\n\n\n\n\nQuestion 8\n\n\nBootstrap your model.\nInterpret your coefficients in the context of the study.\n\n\n\n\n Solution \n\n\n\n#Run model\nboot_mdl &lt;- Boot(att_mdl, R = 1000)\n\n\n#check summary\nsummary(boot_mdl)\n\n\nNumber of bootstrap replications R = 1000 \n                    original    bootBias    bootSE    bootMed\n(Intercept)        2.7882487  1.7947e-03 0.0533413  2.7903803\nscience_knowledge -0.0802763 -5.0405e-05 0.0044263 -0.0802919\nage                0.0023794 -2.5284e-05 0.0006813  0.0023295\n\n\n\n\nIntercept\nScience knowledge\nAge\n\n\n\nThe results in Table @ref(tab:tbl-boot) report an estimate of the intercept (or constant) as equal to approximately 2.79. The constant of a multiple regression model can be interpreted as the average expected value of the dependent variable when all of the independent variables equal zero. In this case, the independent variable science knowledge has only a handful of respondents that score zero, and no one is aged zero, so the constant by itself does not tell us much. Researchers do not often have predictions based on the intercept, so it often receives little attention. A better choice would be to mean centre age, and refit the model with a mean centred age variable!\n\n\nThe estimated value for the slope coefficient linking knowledge to attitude is estimated to be approximately -0.08. This represents the average marginal effect of knowledge on attitude, and can be interpreted as the expected change in the dependent variable on average for a one-unit increase in the independent variable, controlling for age. In this example, every increase in quiz score by one point is associated with a decrease in attitude score of about –0.08, adjusted for age. Bearing in mind the valence of the question wording, this means that those who are more knowledgeable tend to be more favourable towards science – i.e. disagreeing with the statement.\n\n\nThe slope coefficient linking age to attitude is estimated to be approximately 0.002. This represents the average marginal effect of each additional year on attitude, and can be interpreted as the expected change in the dependent variable on average for a one-unit increase in the independent variable, controlling for science knowledge. For this example, that means that for every year older a person is, their attitude score is expected to increase by 0.002, controlling for science knowledge. This may seem like a very small effect, but remember that this is the effect of only one additional year. Bearing in mind the valence of the question wording, this means that older people tend to be less favourable towards science – i.e. agreeing with the statement.\n\n\n\n\n\n\n\n\nQuestion 9\n\n\nObtain confidence intervals for your bootstrapped model estimates.\n\n\n\n\n Solution \n\n\nYou can use your preferred confidence level here, but by default this is 95%:\n\nConfint(boot_mdl, level = 0.95, type = \"perc\")\n\nBootstrap percent confidence intervals\n\n                      Estimate         2.5 %       97.5 %\n(Intercept)        2.788248712  2.6877669516  2.888953606\nscience_knowledge -0.080276256 -0.0887889092 -0.071671501\nage                0.002379446  0.0009551896  0.003710649\n\n\nThe type = \"perc\" argument tells R to return the values that comprise 95% of all values in between them, i.e. the value with 2.5% of observations below it and the value with 2.5% of observations above it and 97.5% of observations below it.\nIf you want to make it into a nice table:\n\nConfint(boot_mdl, type = \"perc\") %&gt;%\n    kable(digits = 3, caption = 'Bootstrap 95% CIs') %&gt;%\n    kable_styling(full_width = FALSE)\n\n\nTable 2: ?(caption)\n\n\n\n\n(a) Bootstrap 95% CIs\n\n\nEstimate\n2.5 %\n97.5 %\n\n\n\n(Intercept)\n2.788\n2.688\n2.889\n\n\nscience_knowledge\n-0.080\n-0.089\n-0.072\n\n\nage\n0.002\n0.001\n0.004\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe are 95% confident that the population intercept is between 2.68 and 2.90\n\nWe are 95% confident that the population slope for science knowledge is between -0.09 and -0.07\n\nWe are 95% confident that the population slope for age is between 0.001 and 0.004\n\nThe bootstrap confidence intervals table containing the 95% confidence intervals for both slope estimates do not include 0. This leads us to reject both null hypotheses at the 5% significance level, and conclude that there appear to be associations between both attitude to science and faith and age, and for attitude to science and faith with science knowledge."
  },
  {
    "objectID": "1_09_bootstrap.html#writing-up-presenting-results",
    "href": "1_09_bootstrap.html#writing-up-presenting-results",
    "title": "Bootstraping",
    "section": "Writing Up & Presenting Results",
    "text": "Writing Up & Presenting Results\n\nQuestion 10\n\n\nInterpret the results from your bootstrapped model in the context of the research question.\nProvide key model results in a formatted table, and refer to this in your write-up.\n\n\n\n\n\n\nHint\n\n\n\n\n\nMake sure to include a decision in relation to your null hypothesis - based on the evidence, should you reject or fail to reject the null?\n\n\n\n\n\n\n\n Solution \n\n\nWe used a subset of data from the 2005 Eurobarometer 63.1 survey to investigate whether:\n\nThere is a significant linear relationship between people’s age and their attitudes to science and faith after accounting for their scientific knowledge.\nThere is a significant linear relationship between people’s scientific knowledge and their attitudes to science and faith after accounting for their age.\n\nFigure @ref(fig:res-descr-plot) displays the scatterplots of the pairwise relationships between the 3 variables. From the plot and the correlation matrix, displyed in Table @ref(tab:res-descr-cor), it appears that there is a weak negative linear association between attitude and science knowledge, and nearly no linear association between attitude and age.\n\n\n\n\nPairwise scatterplots of the variables.\n\n\n\n\n\n\nCorrelation matrix\n\n\nscience_knowledge\nage\nattitude\n\n\n\nscience_knowledge\n1.000\n-0.122\n-0.176\n\n\nage\n-0.122\n1.000\n0.055\n\n\nattitude\n-0.176\n0.055\n1.000\n\n\n\n\n\nTo answer the research hypotheses, we fitted the following regression model: \\[\n\\text{Attitude} = \\beta_0 + \\beta_1 \\cdot \\text{Science Knowledge} + \\beta_2 \\cdot \\text{Age} + \\epsilon\n\\]\nWhich resulted in the following estimated regression coefficients for the original sample: \\[\n\\widehat{\\text{Attitude}} = 2.8 -0.08 \\cdot \\text{Science Knowledge} + 0.0024 \\cdot \\text{Age}\n\\]\nThe model does not satisfy the regression assumptions, see Figure @ref(fig:res-diag-plots), and for this reason we will assess statistical significance using the boostrap approach with \\(R = 1000\\) resamples.\n\n\n\n\nDiagnostic plots\n\n\n\n\n\n\nBootstrap 95% CIs\n\n\nEstimate\n2.5 %\n97.5 %\n\n\n\n(Intercept)\n2.788\n2.688\n2.889\n\n\nscience_knowledge\n-0.080\n-0.089\n-0.072\n\n\nage\n0.002\n0.001\n0.004\n\n\n\n\n\nThe 95% bootstrap confidence intervals are provided in Table @ref(tab:resboottable). These results displayed suggest that there is a negative and statistically significant relationship between knowledge of science and attitude to science and faith. Specifically, the results show that for every additional correct quiz answer people give, we would expect the attitude score to be lower by about 0.08. For age, the effect is in the opposite direction. For every additional year older a person is, they are expected to score .002 more on the attitude scale. The R-squared for the model is 0.032, which means that approximately 3% of the variance in attitude is explained by science knowledge and age. This leaves the majority of variation in attitudes unexplained by our model. Thus we conclude that respondents with greater knowledge about science also tend to be more positive about it, regardless of their age, while older people are slightly less positive, irrespective of their level of knowledge."
  },
  {
    "objectID": "2_01_int1_nc.html",
    "href": "2_01_int1_nc.html",
    "title": "Interactions I: Num x Cat",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand the concept of an interaction.\nBe able to interpret the meaning of a numeric \\(\\times\\) categorical interaction.\nVisualize and probe interactions.\n\n\nBe up to date with lectures\nHave completed all labs from Semester 1\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\npatchwork\nsandwich\ninteractions\n\nAll results should be presented following APA guidelines. If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/wellbeing_rural.csv."
  },
  {
    "objectID": "2_01_int1_nc.html#study-analysis-plan-overview",
    "href": "2_01_int1_nc.html#study-analysis-plan-overview",
    "title": "Interactions I: Num x Cat",
    "section": "Study & Analysis Plan Overview",
    "text": "Study & Analysis Plan Overview\n\nQuestion 1\n\n\nProvide a brief overview of the study design and data, before detailing your analysis plan to address the research question.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nState what type of analysis you will conduct in order to address the research question\nSpecify the model to be fitted to address the research question (note that you will need to specify the reference level of your categorical variable)\nSpecify your chosen significance (\\(\\alpha\\)) level\nState your hypotheses\n\nMuch of the information required can be found in the Study Overview codebook.\n\n\n\n\n\n“Except in special circumstances, a model including a product term for interaction between two explanatory variables should also include terms with each of the explanatory variables individually, even though their coefficients may not be significantly different from zero. Following this rule avoids the logical inconsistency of saying that the effect of \\(X_1\\) depends on the level of \\(X_2\\) but that there is no effect of \\(X_1\\).”\n— Ramsey and Schafer (2012)\n\n\n\n\n\n\n Solution \n\n\nThe mwdata dataset contained information on 200 hypothetical participants who lived in Edinburgh & Lothians area. Using a between-subjects design, the researchers collected information on participants’ wellbeing (measured via WEMWBS), outdoor time (hours per week), social interactions (number per week), routine (whether or not one was followed), location of residence (City, Suburb, or Rural), average weekly steps (in thousands), and age (in years).\nDensity plots and histograms will be used to visualise the marginal distributions of wellbeing and social interactions, and the strength of association between the two variables estimated via the correlation coefficient. To understand how these associations differ between rural and non-rural locations, scatterplots will be used.\nTo address the research question of whether the association between the number of social interactions and wellbeing differs between rural and non-rural residents, we are going to fit the following interaction model, where \\(y\\) = wellbeing; \\(x_1\\) = social interactions; and \\(x_2\\) = whether or not the respondent lives in a rural location (where not rural will be specified as the reference group).\n\\[\ny = \\beta_0 + \\beta_1  x_1 + \\beta_2  x_2 + \\beta_3 (x_1 \\cdot x_2) + \\epsilon \\\\\n\\quad\n\\\\\n\\text{where} \\quad \\epsilon \\sim N(0, \\sigma) \\quad \\text{independently}\n\\]\n\nOR\n\n\\[\n\\begin{split}\n\\text{Wellbeing} = \\beta_0 + \\beta_1 \\cdot Social~Interactions + \\beta_2 \\cdot Location_{Rural} \\\\+ \\beta_3 \\cdot (Social~Interactions \\cdot Location_{Rural}) + \\epsilon \\\\\n\\end{split}\n\\]\nEffects will be considered statistically significant at \\(\\alpha=.05\\)\nOur hypotheses are:\n\\(H_0: \\beta_3 = 0\\)\nThe association between wellbeing and social interactions is not moderated by whether or not a person lives in a rural area.\n\\(H_1: \\beta_3 \\neq 0\\)\nThe association between wellbeing and social interactions is moderated by whether or not a person lives in a rural area.\n\n\n\n\n\nQuestion 2\n\n\nCheck coding of variables (e.g., that categorical variables are coded as factors).\nNote that the “location” variable currently has three levels (Rural/Suburb/City). In order to address the research question, we only want two (Rural/Not Rural) locations - you will need to fix this.\nAs specified in Q1, we want ‘not rural’ as the reference group, so make sure to specify this.\n\n\n\n\n\n\nHint\n\n\n\n\n\nOne way to do this would be to use ifelse() to define a variable which takes one value (“Rural”) if the observation meets from some condition, or another value (“Not Rural”) if it does not. Type ?ifelse in the console if you want to see the help function. You can use it to add a new variable either inside mutate(), or using data$new_variable_name &lt;- ifelse(test, x, y) syntax.\n\n\n\n\n\n\n\n Solution \n\n\nCreate a new variable for Rural/Not Rural:\n\n#if location is rural, assign name 'rural'. If another value (i.e., city or suburb) assign name 'not rural'.\n# In other words, if location = rural assign name rural; if location != rural then assign name not rural.\nmwdata &lt;- mwdata %&gt;% \n  mutate(\n    isRural = ifelse(location == \"rural\", \"rural\", \"not rural\")\n  )\n\nCheck coding of variables within mwdata and ensure isRural is a factor with two levels, ‘rural’ and ‘not rural’:\n\n# check structure of dataset (alternatively run is.factor() for specific variable)\nstr(mwdata) \n\ntibble [200 × 8] (S3: tbl_df/tbl/data.frame)\n $ age         : num [1:200] 28 56 25 60 19 34 41 41 35 53 ...\n $ outdoor_time: num [1:200] 12 5 19 25 9 18 17 11 12 13 ...\n $ social_int  : num [1:200] 13 15 11 15 18 13 19 12 13 15 ...\n $ routine     : num [1:200] 1 1 1 0 1 1 1 1 0 1 ...\n $ wellbeing   : num [1:200] 36 41 35 35 32 34 39 43 35 37 ...\n $ location    : chr [1:200] \"rural\" \"rural\" \"rural\" \"rural\" ...\n $ steps_k     : num [1:200] 21.6 12.3 49.8 NA 48.1 67.3 1.9 50.9 NA 35.5 ...\n $ isRural     : chr [1:200] \"rural\" \"rural\" \"rural\" \"rural\" ...\n\n#assign isRural as a factor\nmwdata$isRural &lt;- as_factor(mwdata$isRural)\n\n#check that isRural is now a factor\nis.factor(mwdata$isRural) \n\n[1] TRUE\n\n\n\n#specify 'not rural' as reference group\nmwdata$isRural &lt;- relevel(mwdata$isRural, 'not rural')"
  },
  {
    "objectID": "2_01_int1_nc.html#descriptive-statistics-visualisations",
    "href": "2_01_int1_nc.html#descriptive-statistics-visualisations",
    "title": "Interactions I: Num x Cat",
    "section": "Descriptive Statistics & Visualisations",
    "text": "Descriptive Statistics & Visualisations\n\nQuestion 3\n\n\nProvide a table of descriptive statistics and visualise your data.\nIn particular:\n\nExplore the associations among the variables included in your analysis\nProduce a visualisation of the association between weekly number of social interactions and well-being, with separate facets for rural vs non-rural respondents OR with different colours for each level of the isRural variable.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nThe pairs.panels() function from the psych package can plot all variables in a dataset against one another. This will save you the time you would have spent creating individual plots, but is only useful for continuous variables.\n\nTo include facets, within your ggplot() argument you will need to specify + facet_wrap() in order to produce facets for each location. It would also be useful to specify geom_smooth(method=\"lm\")\n\n\n\n\n\n\n\n\n\n Solution \n\n\n\n\nNumeric\nVisual\n\n\n\nFor a quick overview of several summary statistics at once for all columns of our dataframe, but separately for each level of location (i.e.,rural and non-rural), you can use describeBy() from the psych package (but note that this is not an APA style table):\n\ndescribeBy(mwdata, mwdata$isRural)\n\n\n Descriptive statistics by group \ngroup: not rural\n             vars   n  mean    sd median trimmed   mad  min   max range  skew\nage             1 100 43.01 14.95   41.5   42.74 18.53 18.0  70.0  52.0  0.13\noutdoor_time    2 100 18.72  6.91   18.0   18.61  7.41  6.0  34.0  28.0  0.08\nsocial_int      3 100 11.67  3.95   12.0   11.51  3.71  3.0  24.0  21.0  0.37\nroutine         4 100  0.54  0.50    1.0    0.55  0.00  0.0   1.0   1.0 -0.16\nwellbeing       5 100 38.57  5.66   39.0   38.36  5.93 26.0  59.0  33.0  0.44\nlocation*       6 100  1.43  0.50    1.0    1.41  0.00  1.0   2.0   1.0  0.28\nsteps_k         7  68 51.03 26.14   49.6   50.56 31.58  2.9 111.3 108.4  0.15\nisRural*        8 100  1.00  0.00    1.0    1.00  0.00  1.0   1.0   0.0   NaN\n             kurtosis   se\nage             -1.13 1.49\noutdoor_time    -0.87 0.69\nsocial_int       0.13 0.39\nroutine         -1.99 0.05\nwellbeing        0.38 0.57\nlocation*       -1.94 0.05\nsteps_k         -0.94 3.17\nisRural*          NaN 0.00\n------------------------------------------------------------ \ngroup: rural\n             vars   n  mean    sd median trimmed   mad min   max range  skew\nage             1 100 41.59 14.85  42.00   41.38 17.79  18  69.0  51.0  0.09\noutdoor_time    2 100 17.79  7.29  18.00   17.68  7.41   1  35.0  34.0  0.06\nsocial_int      3 100 12.46  4.08  12.00   12.41  4.45   4  21.0  17.0  0.05\nroutine         4 100  0.59  0.49   1.00    0.61  0.00   0   1.0   1.0 -0.36\nwellbeing       5 100 34.02  3.99  34.00   34.08  2.97  22  45.0  23.0 -0.07\nlocation*       6 100  1.00  0.00   1.00    1.00  0.00   1   1.0   0.0   NaN\nsteps_k         7  66 38.63 26.64  35.15   37.00 30.62   0 110.6 110.6  0.45\nisRural*        8 100  2.00  0.00   2.00    2.00  0.00   2   2.0   0.0   NaN\n             kurtosis   se\nage             -1.18 1.49\noutdoor_time    -0.49 0.73\nsocial_int      -0.82 0.41\nroutine         -1.89 0.05\nwellbeing        0.40 0.40\nlocation*         NaN 0.00\nsteps_k         -0.59 3.28\nisRural*          NaN 0.00\n\n\nWe can present our summary statistics for wellbeing and social interactions grouped by location in a well formatted table using kable():\n\nmwdata %&gt;%\n    select(isRural, wellbeing, social_int) %&gt;%\n    group_by(isRural) %&gt;%\n    summarise(Wellbeing_M = mean(wellbeing),\n              Wellbeing_SD = sd(wellbeing),\n              SocialInt_M = mean(social_int),\n              SocialInt_SD = sd(social_int)) %&gt;%\n    kable(caption = \"Wellbeing, Social Interactions, and Location Descriptive Statistics\", align = \"c\", digits = 2, booktabs = TRUE) %&gt;%\n    kable_styling(full_width = FALSE)\n\n\n\nTable 1: Wellbeing, Social Interactions, and Location Descriptive Statistics\n\nisRural\nWellbeing_M\nWellbeing_SD\nSocialInt_M\nSocialInt_SD\n\n\n\nnot rural\n38.57\n5.66\n11.67\n3.95\n\n\nrural\n34.02\n3.99\n12.46\n4.08\n\n\n\n\n\n\n\n\n\n\nLet’s first plot the continuous variables included within our model (note that we could use this for the whole dataset, but we don’t want to include irrelevant- / non-continuous variables):\n\nmwdata %&gt;% \n  select(wellbeing, social_int) %&gt;%\n  pairs.panels()\n\n\n\n\n\n\n\n\n\n\n\n\n\nWellbeing and social interactions appear to follow unimodal distributions. There was a weak, positive association between wellbeing and social interactions (\\(r\\) = .24).\n\n\n\nNow lets look at wellbeing scores by location:\n\nggplot(data = mwdata, aes(x = isRural, y = wellbeing)) +\n  geom_boxplot() + \n  labs(x = \"Location\", y = \"Wellbeing (WEMWBS Scores)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nThose in rural locations appear to have lower wellbeing scores in comparison to those in non-rural locations.\n\n\n\nNext, lets produce our plots with a facet for rural vs non-rural residents:\n\nggplot(data = mwdata, aes(x = social_int, y = wellbeing)) +\n  geom_point() +\n  geom_smooth(method=\"lm\", se=FALSE) +\n  facet_wrap(~isRural, labeller = \"label_both\") + \n  labs(x = \"Social Interactions (number per week)\", y = \"Wellbeing (WEMWBS Scores)\")\n\n\n\n\n\n\n\nOr instead of facets, we could use different colours for each location (rural vs non-rural):\n\nggplot(data = mwdata, aes(x = social_int, y = wellbeing, colour = isRural)) +\n  geom_point() + \n  geom_smooth(method=\"lm\", se=FALSE) +\n    scale_colour_discrete(\n    name =\"Location\",\n    labels=c(\"Not Rural\", \"Rural\")) + \n    labs(x = \"Social Interactions (number per week)\", y = \"Wellbeing (WEMWBS Scores)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nThose in non-rural locations appear to have higher wellbeing scores across almost all levels of social interactions. The slopes appear to be different for each location, where the greatest difference in wellbeing scores by location is most visible the highest number of social interactions. This suggests that there may be an interaction.\n\n\n\n\n\n\n\n\n\nHow do we know there might be an interaction?\n\n\n\n\n\nThe lines in the two plots above are not running in parallel - this suggests the presence of an interaction. Specifically in our example, the non-parallel lines suggest an interaction effect based on location, as the number of social interactions does not appear to have the same influence on rural and non-rural residents’ wellbeing scores. However, the only way we can determine whether there is actually an interaction is by including an interaction term in our model, and testing this."
  },
  {
    "objectID": "2_01_int1_nc.html#model-fitting-interpretation",
    "href": "2_01_int1_nc.html#model-fitting-interpretation",
    "title": "Interactions I: Num x Cat",
    "section": "Model Fitting & Interpretation",
    "text": "Model Fitting & Interpretation\n\nQuestion 4\n\n\nFit your model using lm(), and assign it as an object with the name “rural_mod”.\n\n\n\n\n\n\nHint\n\n\n\n\n\nWhen fitting a regression model in R with two explanatory variables A and B, and their interaction, these three are equivalent:\n\ny ~ A + B + A:B\ny ~ A + B + A*B\ny ~ A*B\n\n\n\n\n\n\n\n\n Solution \n\n\n\n#fit model including interaction between social_int and isRural\nrural_mod &lt;- lm(wellbeing ~  social_int * isRural, data = mwdata)\n\n#check model output\nsummary(rural_mod)\n\n\nCall:\nlm(formula = wellbeing ~ social_int * isRural, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12.4845  -2.7975   0.0155   2.4539  15.6743 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              30.9986     1.4284  21.702  &lt; 2e-16 ***\nsocial_int                0.6488     0.1160   5.593 7.42e-08 ***\nisRuralrural              1.3866     2.0510   0.676  0.49981    \nsocial_int:isRuralrural  -0.5176     0.1615  -3.206  0.00157 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.558 on 196 degrees of freedom\nMultiple R-squared:  0.2962,    Adjusted R-squared:  0.2854 \nF-statistic: 27.49 on 3 and 196 DF,  p-value: 6.97e-15\n\n\n\n\n\n\n\nQuestion 5\n\n\nLook at the parameter estimates from your model, and write a description of what each one corresponds to on the plot shown in Figure 1 (it may help to sketch out the plot yourself and annotate it).\n\n\n\n\nFigure 1: Multiple regression model: Wellbeing ~ Social Interactions * is Rural\n\n\n\n\n Options\n\n\nHere are some options to choose from:\n\nThe point at which the red line cuts the y-axis (where social_int = 0)\nThe point at which the blue line cuts the y-axis (where social_int = 0)\nThe vertical distance from the red to the blue line at the y-axis (where social_int = 0)\nThe vertical distance from the blue to the red line at the y-axis (where social_int = 0)\nThe vertical distance from the blue to the red line at the center of the plot\n\nThe vertical distance from the red to the blue line at the center of the plot\n\nThe slope (vertical increase on the y-axis associated with a 1 unit increase on the x-axis) of the red line\nThe slope (vertical increase on the y-axis associated with a 1 unit increase on the x-axis) of the blue line\nHow the slope of the line changes when you move from the red to the blue line\n\n\n\n\n\n\n\n\n Solution \n\n\nRecall that we can obtain our parameter estimates using various functions such as summary(),coef(), coefficients(), etc.\n\ncoefficients(rural_mod)\n\n            (Intercept)              social_int            isRuralrural \n             30.9985688               0.6487945               1.3865688 \nsocial_int:isRuralrural \n             -0.5175856 \n\n\n\n\n\\(\\beta_0\\) = (Intercept) = 31\n\nOn plot: The point at which the red line cuts the y-axis\nInterpretation: The intercept, or predicted wellbeing score when the number of social interactions per week is 0, and when location is not rural.\n\n\n\n\\(\\beta_1\\) = social_int = 0.65\n\nOn plot: The slope (vertical increase on the y-axis associated with a 1 unit increase on the x-axis) of the red line.\nInterpretation: The simple slope of social interactions (number per week) for location reference group (not rural).\n\n\n\n\\(\\beta_2\\) = isRuralrural = 1.39\n\nOn plot: The vertical distance from the red to the blue line at the y-axis (where social_int = 0).\n\nInterpretation: The simple effect of location (or the difference in wellbeing scores between rural and non rural residents) when number of social interactions is 0.\n\n\n\n\\(\\beta_3\\) social_int:isRuralrural = -0.52\n\nOn plot: How the slope of the line differs when you move from the red to the blue line.\nInterpretation: The interaction between social interactions (number per week) and location (rural/not rural). This is the estimated difference in simple slopes of social interactions for rural vs non-rural residents.\n\n\n\n\n\n\n\n\nQuestion 6\n\n\nMean center the continuous IV(s), and re-run your model with mean centered variable(s).\n\n\n\n\n Solution \n\n\nCreate mean centered variable for ‘social_int’, named ‘mc_social_int’:\n\nmwdata &lt;-\n mwdata %&gt;%\n  mutate(\n   mc_social_int = social_int - mean(social_int)\n    )\n\nRe-run model with ‘mc_social_int’:\n\n#fit model including interaction between social_int and isRural\nrural_mod1 &lt;- lm(wellbeing ~  mc_social_int * isRural, data = mwdata)\n\n#check model output\nsummary(rural_mod1)\n\n\nCall:\nlm(formula = wellbeing ~ mc_social_int * isRural, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12.4845  -2.7975   0.0155   2.4539  15.6743 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                 38.8263     0.4581  84.754  &lt; 2e-16 ***\nmc_social_int                0.6488     0.1160   5.593 7.42e-08 ***\nisRuralrural                -4.8581     0.6478  -7.500 2.17e-12 ***\nmc_social_int:isRuralrural  -0.5176     0.1615  -3.206  0.00157 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.558 on 196 degrees of freedom\nMultiple R-squared:  0.2962,    Adjusted R-squared:  0.2854 \nF-statistic: 27.49 on 3 and 196 DF,  p-value: 6.97e-15\n\n\n\n\n\n\n\nQuestion 7\n\n\nNote any differences between the summary() output between the “rural_mod” and “rural_mod1” models. Pay particular attention to your coefficients and their significance values. Why do you think these differences have been observed?\n\n\n\n\n\n\nHint\n\n\n\n\n\nThese plots illustrate the difference between the “rural_mod” and “rural_mod1” models.\n\n\n\n\nFigure 2: Difference when social interactions is not vs is mean centered.Note that the lines without SE intervals on the left plot represent predicted values below the minimum observed number of social interactions, to ensure that zero on the x-axis is visible\n\n\n\n\n\n\n\n\n\n\n Solution \n\n\nRecall that when there is an interaction A\\(\\times\\)B, the coefficients A and B are no longer main effects. Instead, they are conditional effects upon the other being zero.\nIn our “rural_mod”, the isRural coefficient is the difference in rural vs non-rural when social interactions is 0. In our “rural_mod1”, this difference is when social interactions is the mean (12.06).\nWhilst the difference in rural vs non-rural may not be significantly different when social interactions is zero, there is a significant difference at the average number of social interactions (as you can see from the plot below - note that this is the same plot as in the hint).\n\n\n\n\nFigure 3: Difference when social interactions is not vs is mean centered"
  },
  {
    "objectID": "2_01_int1_nc.html#visualise-interaction-model",
    "href": "2_01_int1_nc.html#visualise-interaction-model",
    "title": "Interactions I: Num x Cat",
    "section": "Visualise Interaction Model",
    "text": "Visualise Interaction Model\n\nQuestion 8\n\n\nUsing the probe_interaction() function from the interactions package, visualise the interaction effects from your model.\nTry to summarise the interaction effects in a short and concise sentence.\n\n\n\n\n\n\nHint\n\n\n\n\n\nMake sure to give your plot informative titles/labels. You, for example, likely want to give your plot:\n\na clear and concise title (specify main.title =)\naxis labels with units or scale included (specify x.label = and y.label =)\na legend title (specify legend.main =)\n\n\n\n\n\n\n\n\n Solution \n\n\n\nplt_rural_mod &lt;- probe_interaction(model = rural_mod1, \n                  pred = mc_social_int, \n                  modx = isRural, \n                  interval = T,\n                  main.title = \"Predicted Wellbeing Scores across \\n Social Interactions by Location\",\n                  x.label = \"Number of Social Interactions per Week (Mean Centred)\",\n                  y.label = \"Wellbeing (WEMWBS Scores)\",\n                  legend.main = \"Location\")\n\nLet’s look at our plot:\n\nplt_rural_mod$interactplot\n\n\n\nFigure 4: Predicted Wellbeing Scores across Social Interactions by Location\n\n\n\n\n\n\n\n\n\nThis suggested that for individuals living in non-rural locations, wellbeing scores increased at a steeper rate across the number of social interactions in comparison to those in rural locations."
  },
  {
    "objectID": "2_01_int1_nc.html#writing-up-presenting-results",
    "href": "2_01_int1_nc.html#writing-up-presenting-results",
    "title": "Interactions I: Num x Cat",
    "section": "Writing Up & Presenting Results",
    "text": "Writing Up & Presenting Results\n\nQuestion 9\n\n\nProvide key model results (from ‘mc_social_int’) in a formatted table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse tab_model() from the sjPlot package.\nYou can rename your DV and IV labels by specifying dv.labels and pred.labels. To do so, specify your variable name on the left, and what you would like this to be named in the table on the right.\n\n\n\n\n\n\n\n Solution \n\n\n\n#create table for results\ntab_model(rural_mod1,\n          dv.labels = \"Wellbeing (WEMWBS Scores)\",\n          pred.labels = c(\"mc_social_int\" = \"Social Interactions (number per week; mean centred)\",\n                          \"isRuralrural\" = \"Location - Rural\",\n                          \"mc_social_int:isRuralrural\" = \"Social Interactions (number per week; mean centred) * Location - Rural\"),\n          title = \"Regression Table for Wellbeing Model\")\n\n\n\nTable 2: Regression Table for Wellbeing Model\n\n\n\n\n\n\n\n\n \nWellbeing (WEMWBS Scores)\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n38.83\n37.92 – 39.73\n&lt;0.001\n\n\nSocial Interactions\n(number per week; mean\ncentred)\n0.65\n0.42 – 0.88\n&lt;0.001\n\n\nLocation - Rural\n-4.86\n-6.14 – -3.58\n&lt;0.001\n\n\nSocial Interactions\n(number per week; mean\ncentred) * Location -\nRural\n-0.52\n-0.84 – -0.20\n0.002\n\n\nObservations\n200\n\n\nR2 / R2 adjusted\n0.296 / 0.285\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nInterpret your results (from ‘mc_social_int’) in the context of the research question and report your model in full.\nMake reference to the interaction plot and regression table.\n\n\n“The best method of communicating findings about the presence of a significant interaction may be to present a table or graph of the estimated means at various combinations of the interacting variables.”\n— Ramsey and Schafer (2012)\n\n\n\n\n\n\n Solution \n\n\n\n\n\n\n\n\nFull regression results including 95% Confidence Intervals are shown in Table 2. The \\(F\\)-test for model utility was significant \\((F(3,196) = 27.49, p &lt; .001)\\), and the model explained approximately 28.54% of the variability in wellbeing scores.\nThere was a significant conditional association between wellbeing (WEMWBS Scores) and social interactions \\((\\beta = 0.65, SE = 0.12, p &lt; .001)\\), which suggested that for those living in non-rural locations, wellbeing scores increased by 0.65 for every additional social interaction per week. A significant conditional association was also evident between wellbeing and location \\((\\beta = -4.86, SE = 0.65, p &lt; .001)\\), which suggested that for those with the average number of social interactions per week \\((M = 12.06)\\), wellbeing scores were 4.86 points lower for those in rural areas in comparison to those in non-rural.\nThe association between wellbeing (WEMWBS Scores) and social interactions was found to be dependent upon location (rural/non-rural), and this was significant \\((\\beta = -0.52, SE = 0.16, p = .002)\\). The expected increase in wellbeing (WEMWBS Scores) for every additional social interaction per week was 0.52 points less for those living in rural locations in comparison to those in non-rural. This interaction is visually presented in Figure 4. Therefore, we have evidence to reject the null hypothesis (that the association between wellbeing and social interactions is not moderated by whether or not a person lives in a rural area)."
  },
  {
    "objectID": "2_02_int2_nn.html",
    "href": "2_02_int2_nn.html",
    "title": "Interactions II: Num x Num",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand the concept of an interaction.\nBe able to interpret the meaning of a numeric \\(\\times\\) numeric interaction.\nUnderstand the principle of marginality and why this impacts modelling choices with interactions.\nVisualize and probe interactions.\n\n\nBe up to date with lectures\nHave completed previous lab exercises from Week 7\n\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\nsjPlot\nkableExtra\nsandwich\ninteractions\n\nAll results should be presented following APA guidelines. If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/scs_study.csv."
  },
  {
    "objectID": "2_02_int2_nn.html#study-analysis-plan-overview",
    "href": "2_02_int2_nn.html#study-analysis-plan-overview",
    "title": "Interactions II: Num x Num",
    "section": "Study & Analysis Plan Overview",
    "text": "Study & Analysis Plan Overview\n\nQuestion 1\n\n\nProvide a brief overview of the study design and data, before detailing your analysis plan to address the research question.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nGive the reader some background on the context of the study\nState what type of analysis you will conduct in order to address the research question\nSpecify the model to be fitted to address the research question (note that you will need to specify the reference level of your categorical variables)\nSpecify your chosen significance (\\(\\alpha\\)) level\nState your hypotheses\n\nMuch of the information required can be found in the Study Overview codebook.\n\n\n\n\n\n\n\n Solution \n\n\nThe scs_study dataset contained information on 656 participants, including \\(z\\)-scores on 5 personality traits assessed by the Big-Five Aspects Scale (BFAS; Openness, Conscientiousness, Extraversion, Agreeableness and Neuroticism). Participants were also assessed on the Social Comparison Scale (SCS), which is an 11-item scale measuring self-perception (relative to others) of social rank, attractiveness and belonging, and the Depression Anxiety and Stress Scale (DASS-21) - a 21 item measure with higher scores indicating higher severity of symptoms. For both of these measures, only total scores were available. Items in the SCS were measured on a 5-point scale, giving minimum and maximum possible scores of 11 and 55 respectively. Items in the DASS-21 were measured on a 4-point scale, meaning that scores could range from 21 to 84.\nDensity plots and histograms will be used to visualise the marginal distributions of DASS-21 Scores, SCS Scores, and Neuroticism. To understand the strength of association among the variables, we will estimate the the correlation coefficients; and to visualise these associations scatterplots will be used. To address the research question of whether Neuroticism moderated the effect of social comparison on depression and anxiety, we are going to fit the following interaction model:\n\\[\n\\begin{split}\n{DASS-21~Score} = \\beta_0 + \\beta_1 \\cdot SCS~Score + \\beta_2 \\cdot Neuroticism  \\\\+ \\beta_3 \\cdot (SCS~Score \\cdot Neuroticism) + \\epsilon\n\\end{split}\n\\] Effects will be considered statistically significant at \\(\\alpha=.05\\)\nOur hypotheses are:\n\\(H_0: \\beta_3 = 0\\)\nThe effect of social comparison on symptoms of depression, anxiety and stress does not vary depending on level of Neuroticism\n\\(H_1: \\beta_3 \\neq 0\\)\nThe effect of social comparison on symptoms of depression, anxiety and stress does vary depending on level of Neuroticism"
  },
  {
    "objectID": "2_02_int2_nn.html#descriptive-statistics-visualisations",
    "href": "2_02_int2_nn.html#descriptive-statistics-visualisations",
    "title": "Interactions II: Num x Num",
    "section": "Descriptive Statistics & Visualisations",
    "text": "Descriptive Statistics & Visualisations\n\nQuestion 2\n\n\nProvide a table of descriptive statistics and visualise your data.\nRemember to interpret these in the context of the study.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nThe describe() function is from the psych package; and kable() and kable_styling() (which are used to make a nice table) from kableExtra would be useful to present your descriptive statistics.\nThe pairs.panels() function from the psych package will plot all variables in a dataset against one another. This will save you the time you would have spent creating individual plots.\n\n\n\n\n\n\n\n\n Solution \n\n\n\n\nNumeric\nVisual\n\n\n\nDescriptive statistics presented in a well formatted table:\n\n# note that we are selecting only our three variables of interest (dass, scs, zn)\n\ndescribe(scs_study %&gt;% \n             select(dass, scs, zn)) %&gt;% \n             kable(caption = \"Descriptive Statistics - DASS-21, SCS, and Neuroticism (Z-Scored)\", digits = 2) %&gt;%\n             kable_styling()\n\n\n\nTable 1: Descriptive Statistics - DASS-21, SCS, and Neuroticism (Z-Scored)\n\n\nvars\nn\nmean\nsd\nmedian\ntrimmed\nmad\nmin\nmax\nrange\nskew\nkurtosis\nse\n\n\n\ndass\n1\n656\n44.72\n6.76\n44.00\n44.62\n5.93\n23.00\n68.00\n45.0\n0.18\n0.33\n0.26\n\n\nscs\n2\n656\n35.77\n3.53\n35.00\n35.59\n2.97\n27.00\n54.00\n27.0\n0.60\n0.96\n0.14\n\n\nzn\n3\n656\n0.00\n1.00\n-0.21\n-0.10\n1.00\n-1.45\n3.35\n4.8\n0.80\n0.04\n0.04\n\n\n\n\n\n\n\n\n\n\nVisualise associations among variables of interest:\n\nscs_study %&gt;% \n  select(dass, scs, zn) %&gt;%\n  pairs.panels()\n\n\n\n\n\n\n\n\n\n\nDescription of individual variables:\n\n\n\n\n\n\n\nThe marginal distribution of scores on the Depression, Anxiety and Stress Scale (DASS-21) was unimodal with a mean of 44.72 and a standard deviation of 6.76.\nThe marginal distribution of score on the Social Comparison Scale (SCS) was unimodal with a mean of 35.77 and a standard deviation of 3.53.\nThe marginal distribution of Neuroticism (Z-scored) was positively skewed.\n\n\n\n\nDescription of correlations:\n\n\n\n\n\n\n\nThere was a weak, negative association between scores on the Depression Anxiety and Stress Scale and scores on the Social Comparison Scale for the participants in the sample \\((r = -.23)\\)\n\nSeverity of symptoms measured on the DASS-21 were lower, on average, for those who more favorably perceived their social rank\n\n\n\nThere was a weak, positive association between DASS-21 Scores and levels of Neuroticism \\((r = .20)\\)\n\nParticipants who were more neurotic tended to, on average, display a higher severity of symptoms of depression, anxiety and stress\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 3\n\n\nRun the two code chunks below. It takes the dataset, and uses the cut() function to add a new variable called “zn_group”, which is the “zn” variable split into 4 groups.\n\nscs_study &lt;-\n  scs_study %&gt;%\n  mutate(\n    zn_group = cut(zn, 4)\n  )\n\nWe can see how it has split the “zn” variable by plotting the two against one another (note that the levels of the new variable are named according to the cut-points):\n\nggplot(data = scs_study, aes(x = zn_group, y = zn)) + \n  geom_point()\n\n\n\n\n\n\n\nPlot the association between scores on the SCS and scores on the DASS-21, for each group of the variable we just created.\nHow does the pattern differ across groups? Does it suggest an interaction?\n\n\n\n\n\n\nHint\n\n\n\n\n\nRather than creating four separate plots, you might want to map some feature of the plot to the variable we created in the data, or make use of facet_wrap() / facet_grid().\nRemember that you can specify geom_smooth() to add a trend line.\n\n\n\n\n\n\n\n Solution \n\n\n\nggplot(data = scs_study, aes(x = scs, y = dass, col = zn_group)) + \n  geom_point() + \n  geom_smooth(method='lm', se = FALSE) +\n  facet_grid(~zn_group) +\n  labs(x = \"SCS Scores \", y = \"DASS-21 Scores\") +\n  theme(legend.position = \"none\") # removes the legend\n\n\n\n\n\n\n\nThe association between DASS-21 scores and SCS scores appears to be different across these groups. For those with a relatively high Neuroticism score, the association seems stronger, while for those with a low Neuroticism score there is almost no discernible association.\nThis does suggest an interaction - the association of DASS-21 ~ SCS differs across the values of Neuroticism.\n\n\n\n\n\nVisualising Interaction Terms\nCutting one of the explanatory variables up into groups essentially turns a numeric variable into a categorical one. We did this just to make it easier to visualise how an association differs across the values of another variable, because we can imagine a separate line for the association between SCS and DASS-21 scores for each of the groups of Neuroticism. However, in grouping a numeric variable like this we lose information. Neuroticism is measured on a continuous scale, and we want to capture how the association between SCS and DASS-21 differs across that continuum (rather than cutting it into chunks).\nWe could imagine cutting it into more and more chunks (see Figure 1), until what we end up with is an infinite number of lines - i.e., a three-dimensional plane/surface (recall that in for a multiple regression model with 2 explanatory variables, we can think of the model as having three-dimensions). The inclusion of the interaction term simply results in this surface no longer being necessarily flat. You can see this in Figure 2).\n\n\n\n\nFigure 1: Separate regression lines DASS ~ SCS for Neuroticism when cut into 4 (left) or 6 (center) or 12 (right) groups.\n\n\n\n\n\n\nFigure 2: 3D plot of regression surface with interaction. You can explore the plot in the figure below from different angles by moving it around with your mouse."
  },
  {
    "objectID": "2_02_int2_nn.html#model-fitting-interpretation",
    "href": "2_02_int2_nn.html#model-fitting-interpretation",
    "title": "Interactions II: Num x Num",
    "section": "Model Fitting & Interpretation",
    "text": "Model Fitting & Interpretation\n\nQuestion 4\n\n\nConsider that Neuroticism has already been \\(z\\)-scored, but scs has not. To ensure that we can compare the effects of our estimates (and so they are both on meaningful scales), standardize the scs variable.\n\n\n\n\n\n\nHint\n\n\n\n\n\nRecall the formula for the \\(z\\)-score: \\[\nz_x = \\frac{x - \\bar{x}}{s_x}, \\qquad z_y = \\frac{y - \\bar{y}}{s_y}\n\\]\n\n\n\n\n\n\n\n Solution \n\n\n\n# standardize scs score\nscs_study &lt;- \n  scs_study %&gt;% \n    mutate(\n      zscs = (scs-mean(scs))/sd(scs)\n    )\n\n\n\n\n\n\nQuestion 5\n\n\nFit your model (including the standardized predictor variables) using lm(), and assign it as an object with the name “dass_mdl”.\n\n\n\n\n\n\nHint\n\n\n\n\n\nWhen fitting a regression model in R with two explanatory variables A and B, and their interaction, these three are equivalent:\n\ny ~ A + B + A:B\ny ~ A + B + A*B\ny ~ A*B\n\n\n\n\n\n\n\n\n Solution \n\n\n\n#fit interaction model\ndass_mdl &lt;- lm(dass ~  zscs*zn, data = scs_study)\n\n#check model output\nsummary(dass_mdl)\n\n\nCall:\nlm(formula = dass ~ zscs * zn, data = scs_study)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-16.301  -3.825  -0.173   3.733  45.777 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  44.9324     0.2405 186.807  &lt; 2e-16 ***\nzscs         -1.5691     0.2416  -6.495 1.64e-10 ***\nzn            1.5798     0.2409   6.559 1.11e-10 ***\nzscs:zn      -1.8332     0.2316  -7.915 1.06e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.123 on 652 degrees of freedom\nMultiple R-squared:  0.1825,    Adjusted R-squared:  0.1787 \nF-statistic:  48.5 on 3 and 652 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\nQuestion 6\n\n\nInterpret your coefficients in the context of the study.\n\n\n\n\n Solution \n\n\nRecall that we can obtain our parameter estimates using various functions such as summary(),coef(), coefficients(), etc.\n\ncoefficients(dass_mdl)\n\n(Intercept)        zscs          zn     zscs:zn \n  44.932448   -1.569097    1.579769   -1.833169 \n\n\n\n\n\\(\\beta_0\\) = (Intercept) = 44.93\n\nThe intercept, or predicted DASS-21 score for an SCS score of 0 (\\(Z\\)-scored) and Neuroticism score of 0 (\\(Z\\)-scored).\n\n\n\n\\(\\beta_1\\) = zscs = -1.57\n\nThe simple slope of SCS scores when Neuroticism scores are 0 (\\(Z\\)-scored).\nFor an individual with a Neuroticism level of 0, DASS-21 scores decreased by 1.57 for every 1 standard deviation increase in SCS scores.\n\n\n\n\\(\\beta_2\\) = zn = 1.58\n\nThe simple slope of Neuroticism when SCS scores are 0 (\\(Z\\)-scored).\nFor those with SCS scores of 0, DASS-21 scored increased by 1.58 for every 1 standard deviation increase in Neuroticism.\n\n\n\n\\(\\beta_3\\) zscs:zn = -1.83\n\nThe interaction between SCS score and Neuroticism on DASS-21 Scores\nThe change in the slope of Neuroticism as a function of SCS Scores\nFor every 1 standard deviation increase in SCS scores, when Neuroticism scores increase by 1 SD, the slope with DASS-21 scores is adjusted -1.83."
  },
  {
    "objectID": "2_02_int2_nn.html#visualise-interaction-model",
    "href": "2_02_int2_nn.html#visualise-interaction-model",
    "title": "Interactions II: Num x Num",
    "section": "Visualise Interaction Model",
    "text": "Visualise Interaction Model\n\nQuestion 7\n\n\nUsing the probe_interaction() function from the interactions package, visualise the interaction effects from your model.\nTry to summarise the interaction effects in a short and concise sentence.\n\n\n\n\n\n\nHint\n\n\n\n\n\nBecause we are looking at a numeric x numeric interaction, we want to specify jnplot = T (see this weeks lecture, slides 17-21 for a worked example).\nRemember to give your plot informative titles/labels. You, for example, likely want to give your plot:\n\na clear and concise title (specify main.title =)\naxis labels with units or scale included (specify x.label = and y.label =)\na legend title (specify legend.main =)\n\n\n\n\n\n\n\n\n Solution \n\n\n\nplt_dass_mdl &lt;- probe_interaction(model = dass_mdl, \n                  pred = zscs, \n                  modx = zn, \n                  cond.int = T,\n                  interval = T, \n                  jnplot = T,\n                  main.title = \"Neuroticism moderating the effect of\\nsocial comparison on depression and anxiety\",\n                  x.label = \"Social Comparison Scale (Z-scored)\",\n                  y.label = \"DASS-21 Scores\",\n                  legend.main = \"Neuroticism (Z-scored)\")\n\nLet’s look at the plot - to do so you need to call interactplot from your object plt_dass_mdl:\n\nplt_dass_mdl$interactplot\n\n\n\nFigure 3: Simple Sloes for +/- 1 SD and Mean Neuroticism Scores\n\n\n\n\n\n\n\n\n\n\nFor individuals 1 SD below the sample mean on Neuroticism, as their SCS Score increases, it appears that their wellbeing increases\nFor individuals with average levels of Neuroticism, as their SCS Score increases, it appears that their wellbeing decreases\nFor individuals 1 SD above the sample mean on Neuroticism, as their SCS Score increases, it appears that their wellbeing decreases at an increased rate\n\n\n\n\n\n\n\n\n\nQuestion 8\n\n\nConduct a simple slopes analysis.\n\n\n\n\n\n\nHint\n\n\n\n\n\nIf you wanted to see only the simple slopes or only the Johnson-Neyman plot, you could call $simslopes$slopes or simslopes$jnplot respectively from your object plt_dass_mdl.\n\n\n\n\n\n\n\n Solution \n\n\n\nplt_dass_mdl$simslopes\n\nJOHNSON-NEYMAN INTERVAL \n\nWhen zn is OUTSIDE the interval [-1.28, -0.55], the slope of zscs is p &lt;\n.05.\n\nNote: The range of observed values of zn is [-1.45, 3.35]\n\n\nSIMPLE SLOPES ANALYSIS \n\nWhen zn = -1.000000e+00 (- 1 SD): \n\n                               Est.   S.E.   t val.      p\n--------------------------- ------- ------ -------- ------\nSlope of zscs                  0.26   0.35     0.76   0.45\nConditional intercept         43.35   0.34   127.47   0.00\n\nWhen zn = -8.610271e-16 (Mean): \n\n                               Est.   S.E.   t val.      p\n--------------------------- ------- ------ -------- ------\nSlope of zscs                 -1.57   0.24    -6.50   0.00\nConditional intercept         44.93   0.24   186.81   0.00\n\nWhen zn =  1.000000e+00 (+ 1 SD): \n\n                               Est.   S.E.   t val.      p\n--------------------------- ------- ------ -------- ------\nSlope of zscs                 -3.40   0.32   -10.59   0.00\nConditional intercept         46.51   0.34   136.52   0.00\n\n\n\n\nFigure 4: Johnson-Neyman Plot\n\n\n\n\n\n\n\n\n\nThe Johnson-Neyman technique indicated that the association between DASS-21 scores and SCS was significant when Neuroticism scores were less than 1.28 standard deviations below the mean or more than -0.55 standard deviations above the mean."
  },
  {
    "objectID": "2_02_int2_nn.html#writing-up-presenting-results",
    "href": "2_02_int2_nn.html#writing-up-presenting-results",
    "title": "Interactions II: Num x Num",
    "section": "Writing Up & Presenting Results",
    "text": "Writing Up & Presenting Results\n\nQuestion 9\n\n\nProvide key model results in a formatted table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse tab_model() from the sjPlot package.\nRemember that you can rename your DV and IV labels by specifying dv.labels and pred.labels.\n\n\n\n\n\n\n\n Solution \n\n\n\n#create table for results\ntab_model(dass_mdl,\n          dv.labels = \"DASS-21 Scores\",\n          pred.labels = c(\"zscs\" = \"Social Comparison Scale (Z-scored)\",\n                          \"zn\" = \"Neuroticism (Z-scored)\",\n                          \"zscs:zn\" = \"Social Comparison Scale (Z-scored): Neutoricism (Z-scored)\"),\n          title = \"Regression table for DASS-21 model\")\n\n\n\nTable 2: Regression table for DASS-21 model\n\n\n\n\n\n\n\n\n \nDASS-21 Scores\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n44.93\n44.46 – 45.40\n&lt;0.001\n\n\nSocial Comparison Scale\n(Z-scored)\n-1.57\n-2.04 – -1.09\n&lt;0.001\n\n\nNeuroticism (Z-scored)\n1.58\n1.11 – 2.05\n&lt;0.001\n\n\nSocial Comparison Scale\n(Z-scored): Neutoricism\n(Z-scored)\n-1.83\n-2.29 – -1.38\n&lt;0.001\n\n\nObservations\n656\n\n\nR2 / R2 adjusted\n0.182 / 0.179\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nInterpret your results in the context of the research question and report your model in full.\nMake reference to the interaction plot and regression table.\n\n\n\n\n Solution \n\n\n\n\n\n\n\n\nFull regression results including 95% confidence intervals (\\95% CIs) are shown in Table 2. The \\(F\\)-test for model utility was significant \\((F(3,652) = 48.50, p&lt;.001)\\), and the model explained approximately 17.87% of the variability in DASS-21 scores.\nThere was a significant conditional association between DASS-21 Scores and SCS scores (\\(Z\\)-scored) \\((\\beta = -1.57, SE = 0.24, p &lt; .001)\\), suggesting that for those with Neuroticism scores of 0, DASS-21 scores decreased by 1.57 for every 1 standard deviation increase in SCS scores.\nA significant conditional association was also evident between DASS-21 Scores and Neuroticism (\\(Z\\)-scored) \\((\\beta = 1.58, SE = 0.24, p &lt;.001)\\), suggesting that for those with SCS scores of 0, DASS-21 scores increased by 1.58 for every 1 standard deviation increase in Neuroticism.\nThe association between symptoms of depression and anxiety (DASS-21 scores) and social comparison was found to be dependent upon the level of Neuroticism, with a greater negative association between the two for those with higher levels of Neuroticism \\((\\beta = -1.83, SE = 0.23, p &lt;.001)\\). For every standard deviation increase in SCS Scores, the change in DASS-21 scores associated with an increase of 1 SD in Neuroticism was adjusted by -1.83. This buffering interaction is displayed in Figure 3. We further used the Johnson-Neyman technique to probe the interaction, and to identify regions of significance. We identified that Neuroticism values (z-scored) outside the range of -1.28 to -0.55 were significant (see Figure 4).\nTherefore, we have evidence to reject the null hypothesis (that the effect of social comparison on symptoms of depression, anxiety and stress does not vary depending on level of Neuroticism)."
  },
  {
    "objectID": "2_03_int3_cc.html",
    "href": "2_03_int3_cc.html",
    "title": "Interactions III: Cat x Cat",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand the concept of an interaction.\nBe able to interpret a categorical \\(\\times\\) categorical interaction.\nVisualize and probe interactions.\n\n\nBe up to date with lectures\nHave completed previous lab exercises from Week 7 and Week 8\n\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\nsjPlot\nkableExtra\nsandwich\ninteractions\n\nAll results should be presented following APA guidelines. If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/cognitive_experiment_3_by_2.csv"
  },
  {
    "objectID": "2_03_int3_cc.html#study-analysis-plan-overview",
    "href": "2_03_int3_cc.html#study-analysis-plan-overview",
    "title": "Interactions III: Cat x Cat",
    "section": "Study & Analysis Plan Overview",
    "text": "Study & Analysis Plan Overview\n\nQuestion 1\n\n\nExamine the dataset, and perform any necessary and appropriate data management steps.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nConvert categorical variables to factors\nLabel appropriately factors to aid with your model interpretations\nIf needed, provide better variable names\n\nNote that all of these steps can be done in combination - the mutate() and factor() functions will likely be useful here.\n\n\n\n\n\n\n\n Solution \n\n\nLet’s have a look at the data to see what we’re working with:\n\n#first look at dataset structure\nstr(cog)\n\nspc_tbl_ [30 × 3] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Diagnosis: num [1:30] 1 1 1 1 1 1 1 1 1 1 ...\n $ Task     : num [1:30] 1 1 1 1 1 2 2 2 2 2 ...\n $ Y        : num [1:30] 44 63 76 72 45 70 51 82 66 56 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Diagnosis = col_double(),\n  ..   Task = col_double(),\n  ..   Y = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n#now lets look at top 6 rows (or the head) of the dataset\nhead(cog)\n\n# A tibble: 6 × 3\n  Diagnosis  Task     Y\n      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1         1     1    44\n2         1     1    63\n3         1     1    76\n4         1     1    72\n5         1     1    45\n6         1     2    70\n\n\nThe columns Diagnosis and Task should be coded into factors with better labels, as currently, without making reference to the codebook, it is not clear what “1” and “2” represent. It is also unclear what the Y column represents - this should be renamed.\n\n#We can make all of the changes noted above in one (long) command. \n#First we can use the function `factor()` by specifying the current levels and what labels each level should map to. \n#We can also simply rename the Y column to score. \n\ncog &lt;- cog %&gt;%\n    mutate(\n        Diagnosis = factor(Diagnosis, \n                           levels = c(1, 2, 3),\n                           labels = c('Amnesic', 'Huntingtons', 'Control')),\n        Task = factor(Task, \n                      levels = c(1, 2),\n                      labels = c('Grammar', 'Recognition'))) %&gt;%\n    rename(Score = Y)\n\n#Use head() function to check renaming\nhead(cog)\n\n# A tibble: 6 × 3\n  Diagnosis Task        Score\n  &lt;fct&gt;     &lt;fct&gt;       &lt;dbl&gt;\n1 Amnesic   Grammar        44\n2 Amnesic   Grammar        63\n3 Amnesic   Grammar        76\n4 Amnesic   Grammar        72\n5 Amnesic   Grammar        45\n6 Amnesic   Recognition    70\n\n\n\n\n\n\n\nQuestion 2\n\n\nChoose appropriate reference levels for the Diagnosis and Task variables.\n\n\n\n\n\n\nHint\n\n\n\n\n\nRead the Study Overview codebook carefully.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nDiagnosis\nTask\n\n\n\nThe Diagnosis factor has a group coded ‘Control’ which lends itself naturally to be the reference category, since it is the only group of participants with no known neurological disorder.\n\ncog$Diagnosis &lt;- relevel(cog$Diagnosis, 'Control')\n\nlevels(cog$Diagnosis)\n\n[1] \"Control\"     \"Amnesic\"     \"Huntingtons\"\n\n\n\n\nThere is no natural reference category for the Task factor, so we will leave it unaltered. However, if you are of a different opinion, please note that there is no absolute correct answer. As long as you describe and interpret the model correctly, you will reach to the same conclusions as someone that has chosen a different baseline category.\nWe can see what the reference group is below (first in list):\n\nlevels(cog$Task)\n\n[1] \"Grammar\"     \"Recognition\"\n\n\n\n\n\n\n\n\n\n\nQuestion 3\n\n\nProvide a brief overview of the study design and data, before detailing your analysis plan to address the research question.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nGive the reader some background on the context of the study\nState what type of analysis you will conduct in order to address the research question\nSpecify the model to be fitted to address the research question (note that you will need to specify the reference level of your categorical variables)\nSpecify your chosen significance (\\(\\alpha\\)) level\nState your hypotheses\n\nMuch of the information required can be found in the Study Overview codebook.\n\n\n\n\n\n\n\n Solution \n\n\nThe cog dataset contained information on 30 hypothetical participants from a between-subjects study. Participants belonged to one of three ‘Diagnosis’ groups, which had 10 participants in each - Control, Amnesic, or Huntingtons. Participants from each of the Diagnosis groups were randomly assigned to one of two ‘Tasks’ to measure different memory processes - Grammar or Recognition. For the purpose of this analysis, ‘Control’ was designated as the reference group for Diagnosis, since it was the only group of participants with no known neurological disorder, and as there is no natural reference group for Diagnosis, we chose to leave this as ‘Grammar’.\nBoxplots will be used to visualise the associations among Diagnosis and Task conditions. To address the research question of whether the difference in performance between explicit and implicit memory tasks will be greatest for Huntington patients in comparison to controls, we first need to define the dummy variables for Diagnosis:\n\\[\nD_\\text{Amnesic} = \\begin{cases}\n1 & \\text{if Diagnosis is Amnesic} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\quad  \n\\\\  \nD_\\text{Huntingtons} = \\begin{cases}\n1 & \\text{if Diagnosis is Huntingtons} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\quad  \n\\\\  \n\\\\  \n(\\text{Control is base level})\n\\]\nAnd for Task:\n\\[\nT_\\text{Recognition} = \\begin{cases}\n1 & \\text{if Task is Recognition} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\quad\n\\\\\n\\\\\n(\\text{Grammar is base level})\n\\] Based on the above dummy coding, we are going to fit the following interaction model:\n\\[\n\\begin{aligned}\nScore &= \\beta_0 \\\\\n      &+ \\beta_1 D_\\text{Amnesic} + \\beta_2 D_\\text{Huntingtons}  \\\\\n      &+ \\beta_3 T_\\text{Recognition}  \\\\\n      &+ \\beta_4 (D_\\text{Amnesic} * T_\\text{Recognition}) + \\beta_5 (D_\\text{Huntingtons} * T_\\text{Recognition})  \\\\\n      &+ \\epsilon\n\\end{aligned}\n\\] Effects will be considered statistically significant at \\(\\alpha=.05\\)\nOur hypotheses are:\n\\(H_0: \\beta_5 = 0\\)\nThe difference in performance between explicit and implicit memory tasks does not significantly differ between patients with Huntingtons in comparison to Controls.\n\\(H_1: \\beta_5 \\neq 0\\)\nThe difference in performance between explicit and implicit memory tasks does significantly differ between patients with Huntingtons in comparison to Controls."
  },
  {
    "objectID": "2_03_int3_cc.html#descriptive-statistics-visualisations",
    "href": "2_03_int3_cc.html#descriptive-statistics-visualisations",
    "title": "Interactions III: Cat x Cat",
    "section": "Descriptive Statistics & Visualisations",
    "text": "Descriptive Statistics & Visualisations\n\nQuestion 4\n\n\nProvide a table of descriptive statistics and visualise your data.\nRemember to interpret your plot in the context of the study.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nFor your table of descriptive statistics, both the group_by() and summarise() functions will come in handy here.\nRecall that when visualising categorical variables, geom_boxplot() may be most appropriate to use.\n\n\n\n\n\n\n\n\n Solution \n\n\n\n\nNumeric\nVisual\n\n\n\nDescriptive statistics presented in a well formatted table:\n\ncog_desc &lt;- cog %&gt;% \n            group_by(Diagnosis, Task) %&gt;%\n            summarise(Mean = mean(Score),\n                      SD = sd(Score),\n                      Min = min(Score),\n                      Max = max(Score)) %&gt;% \n            kable(caption = \"Descriptive Statistics\", digits = 2) %&gt;%\n            kable_styling()\n\ncog_desc\n\n\n\nTable 1: Descriptive Statistics\n\nDiagnosis\nTask\nMean\nSD\nMin\nMax\n\n\n\nControl\nGrammar\n80\n11.68\n70\n98\n\n\nControl\nRecognition\n95\n12.98\n80\n107\n\n\nAmnesic\nGrammar\n60\n14.92\n44\n76\n\n\nAmnesic\nRecognition\n65\n12.17\n51\n82\n\n\nHuntingtons\nGrammar\n40\n13.25\n24\n55\n\n\nHuntingtons\nRecognition\n95\n13.38\n80\n108\n\n\n\n\n\n\n\n\n\n\nVisualise associations among variables of interest:\n\ncog_plt &lt;- ggplot(cog, aes(x = Diagnosis, y = Score, fill = Task)) + \n  geom_boxplot() \ncog_plt\n\n\n\nFigure 1: Associations among Score, Diagnosis, and Task\n\n\n\n\n\n\n\n\n\n\n\n\n\nScores on Recognition tasks appear to be higher than those on Grammar across Diagnosis conditions\n\nParticipants with Amnesia do not appear to differ in Score for Recognition or Grammar tasks\n\nIn comparison to Controls, Amnesic patients score lower on both tasks, but not considerably so\n\nParticipants with Huntingtons do differ in Score for Recognition and Grammar tasks, with higher scores on Recognition tasks\n\nIn comparison to Controls, Huntingtons patients score similarly on Recognition tasks, but considerably lower on Grammar tasks"
  },
  {
    "objectID": "2_03_int3_cc.html#model-fitting-interpretation",
    "href": "2_03_int3_cc.html#model-fitting-interpretation",
    "title": "Interactions III: Cat x Cat",
    "section": "Model Fitting & Interpretation",
    "text": "Model Fitting & Interpretation\n\nQuestion 5\n\n\nFit the specified model using lm(), and store the model in an object named “cog_mdl”.\n\n\n\n\n\n\nHow do we specify dummy coding in R?\n\n\n\nFortunately, R computes the dummy variables for us! Thus, each row in the summary() output of the model will correspond to one of the estimated \\(\\beta\\)’s in the equation above.\n\n\n\n\n\n\n Solution \n\n\n\n#fit interaction model\ncog_mdl &lt;- lm(Score ~ Diagnosis * Task, data = cog)\n\n#check model output\nsummary(cog_mdl)\n\n\nCall:\nlm(formula = Score ~ Diagnosis * Task, data = cog)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-16.00 -12.25   2.00  11.75  18.00 \n\nCoefficients:\n                                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                            80.000      5.859  13.653 8.27e-13 ***\nDiagnosisAmnesic                      -20.000      8.287  -2.414  0.02379 *  \nDiagnosisHuntingtons                  -40.000      8.287  -4.827 6.45e-05 ***\nTaskRecognition                        15.000      8.287   1.810  0.08281 .  \nDiagnosisAmnesic:TaskRecognition      -10.000     11.719  -0.853  0.40192    \nDiagnosisHuntingtons:TaskRecognition   40.000     11.719   3.413  0.00228 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 13.1 on 24 degrees of freedom\nMultiple R-squared:  0.7394,    Adjusted R-squared:  0.6851 \nF-statistic: 13.62 on 5 and 24 DF,  p-value: 2.359e-06\n\n\n\n\n\n\n\nQuestion 6\n\n\nRecall your table of descriptive statistics - map each coefficient from the summary() output from “cog_mdl” to the group means.\n\n\n\n\n Solution \n\n\n\ncog_desc\n\n\nDescriptive Statistics\n\nDiagnosis\nTask\nMean\nSD\nMin\nMax\n\n\n\nControl\nGrammar\n80\n11.68\n70\n98\n\n\nControl\nRecognition\n95\n12.98\n80\n107\n\n\nAmnesic\nGrammar\n60\n14.92\n44\n76\n\n\nAmnesic\nRecognition\n65\n12.17\n51\n82\n\n\nHuntingtons\nGrammar\n40\n13.25\n24\n55\n\n\nHuntingtons\nRecognition\n95\n13.38\n80\n108\n\n\n\n\n\n\n\\(\\hat{\\beta}_0\\) = 80\n= Mean(Control, Grammar)\n\\(\\hat{\\beta}_1\\) = -20\n= Mean(Amnesic, Grammar) - Mean(Control, Grammar)\n= 60 - 80\n\\(\\hat{\\beta}_2\\) = -40\n= Mean(Huntingtons, Grammar) - Mean(Control, Grammar)\n= 40 - 80\n\\(\\hat{\\beta}_3\\) = 15\n= Mean(Control, Recognition) - Mean(Control, Grammar)\n= 95 - 80\n\\(\\hat{\\beta}_4\\) = -10\n= [Mean(Amnesic, Recognition) - Mean(Amnesic, Grammar)] -\n[Mean(Control, Recognition) - Mean(Control, Grammar)]\n= [65 - 60] - [95 - 80] = 5 - 15 = -10\n\\(\\hat{\\beta}_5\\) = 40\n= [Mean(Huntingtons, Recognition) - Mean(Huntingtons, Grammar)] -\n[Mean(Control, Recognition) - Mean(Control, Grammar)]\n= [95 - 40] - [95 - 80] = 55 - 15 = 40\n\n\n\n\n\n\nQuestion 7\n\n\nInterpret your coefficients in the context of the study.\n\n\n\n\n Solution \n\n\nRecall that we can obtain our parameter estimates using various functions such as summary(),coef(), coefficients(), etc.\n\ncoefficients(cog_mdl)\n\n                         (Intercept)                     DiagnosisAmnesic \n                                  80                                  -20 \n                DiagnosisHuntingtons                      TaskRecognition \n                                 -40                                   15 \n    DiagnosisAmnesic:TaskRecognition DiagnosisHuntingtons:TaskRecognition \n                                 -10                                   40 \n\n\n\n\n\\(\\beta_0\\) = (Intercept) = 80\n\nThe intercept, or predicted scores for those in the Control diagnosis condition on the Grammar task.\n\n\n\n\\(\\beta_1\\) = DiagnosisAmnesic = -20\n\nThe difference in scores between Amnesic and Control conditions on the Grammar task\nOn the Grammar task, individuals with Amnesia scored 20 points lower than Control participants.\n\n\n\n\\(\\beta_2\\) = DiagnosisHuntingtons = -40\n\nThe difference in score between Huntingtons and Control conditions on the Grammar task\nOn the Grammar task, individuals with Huntingtons scored 40 points lower than Control participants.\n\n\n\n\\(\\beta_3\\) TaskRecognition = 15\n\nThe difference in score between individuals in the Control diagnosis condition completing Recognition and Grammar tasks.\nControl participants scored 15 points higher when completing Recognition tasks in comparison to Grammar tasks.\n\n\n\n\\(\\beta_4\\) DiagnosisAmnesic:TaskRecognition = -10\n\nThe difference between score in Amnesic and Control diagnosis conditions between Recognition and Grammar tasks.\nThe difference between Grammar and Recognition tasks is 10 points lower in the Amnesiac vs Control diagnosis conditions.\n\n\n\n\\(\\beta_5\\) DiagnosisHuntingtons:TaskRecognition = 40\n\nThe difference between score in Huntingtons and Control diagnosis conditions between Recognition and Grammar tasks.\nThe difference between Grammar and Recognition tasks is 40 points higher in the Huntingtons vs Control diagnosis conditions."
  },
  {
    "objectID": "2_03_int3_cc.html#visualise-interaction-model",
    "href": "2_03_int3_cc.html#visualise-interaction-model",
    "title": "Interactions III: Cat x Cat",
    "section": "Visualise Interaction Model",
    "text": "Visualise Interaction Model\n\nQuestion 8\n\n\nUsing the cat_plot() function from the interactions package, visualise the interaction effects from your model.\nTry to summarise the interaction effects in a few short and concise sentences.\n\n\n\n\n Solution \n\n\n\nplt_cog_mdl &lt;- cat_plot(model = cog_mdl, \n                  pred = Diagnosis, \n                  modx = Task, \n                  main.title = \"Scores across Diagnosis and Task\",\n                  x.label = \"Diagnosis\",\n                  y.label = \"Score\",\n                  legend.main = \"Task\")\nplt_cog_mdl\n\n\n\nFigure 2: Interaction Plot\n\n\n\n\n\n\n\n\n\nThe effect of Task on Scores does appear to vary depending on Diagnosis.\nThe difference in score between recognition and grammar tasks for Huntingtons patients is larger than the difference in score between recognition and grammar tasks for the Control patients.\nThe difference in score between recognition and grammar tasks for Amnesic patients however does not appear to be very different (given the overlapping intervals) than the difference in score between recognition and grammar tasks for the Control patients.\n\n\n\n\n\n\n\n\n\nHow do we know there is an interaction?\n\n\n\n\n\nIf you imagine connecting the dots of the same color with a line (you could specify geom = \"line\" in a new line in the code chunk above to do this), you can see that the two virtual lines are not parallel (see below plot), suggesting the presence of an interaction. The difference in score between recognition and grammar tasks for Huntingtons patients (consider the vertical difference) is larger than the difference in score between recognition and grammar tasks for the Control patients. If those vertical differences were the same, there would be no interaction.\n\n\n\n\nFigure 3: Interaction Plot with Connected Lines"
  },
  {
    "objectID": "2_03_int3_cc.html#writing-up-presenting-results",
    "href": "2_03_int3_cc.html#writing-up-presenting-results",
    "title": "Interactions III: Cat x Cat",
    "section": "Writing Up & Presenting Results",
    "text": "Writing Up & Presenting Results\n\nQuestion 9\n\n\nProvide key model results in a formatted table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse tab_model() from the sjPlot package.\nRemember that you can rename your DV and IV labels by specifying dv.labels and pred.labels.\n\n\n\n\n\n\n\n Solution \n\n\n\n#create table for results\ntab_model(cog_mdl, \n          show.stat = TRUE,\n          dv.labels = \"Scores\",\n          title = \"Regression table for Scores model\")\n\n\n\nTable 2: Regression table for Scores model\n\n\n\n\n\n\n\n\n\n \nScores\n\n\nPredictors\nEstimates\nCI\nStatistic\np\n\n\n(Intercept)\n80.00\n67.91 – 92.09\n13.65\n&lt;0.001\n\n\nDiagnosis [Amnesic]\n-20.00\n-37.10 – -2.90\n-2.41\n0.024\n\n\nDiagnosis [Huntingtons]\n-40.00\n-57.10 – -22.90\n-4.83\n&lt;0.001\n\n\nTask [Recognition]\n15.00\n-2.10 – 32.10\n1.81\n0.083\n\n\nDiagnosis [Amnesic] ×\nTask [Recognition]\n-10.00\n-34.19 – 14.19\n-0.85\n0.402\n\n\nDiagnosis [Huntingtons] ×\nTask [Recognition]\n40.00\n15.81 – 64.19\n3.41\n0.002\n\n\nObservations\n30\n\n\nR2 / R2 adjusted\n0.739 / 0.685\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nInterpret your results in the context of the research question and report your model in full.\nMake reference to the interaction plot and regression table.\n\n\n\n\n Solution \n\n\nFull regression results including 95% Confidence Intervals are shown in Table 2. The \\(F\\)-test for model utility was significant \\((F(5,24) = 13.62, p &lt;.001)\\), and the model explained approximately 68.5% of the variability in Scores. The interaction between Task and Diagnosis is visually presented in Figure 2.\nThe difference in scores between the recognition and grammar tasks, respectively measuring explicit and implicit memory, for amnesiac patients in comparison to controls was estimated to be -10 points \\((\\beta = -10, SE = 11.72)\\), though this difference was not significantly different from zero \\((t(24) = -0.85, p = .40)\\).\nThe difference in scores between the recognition and grammar tasks, respectively measuring explicit and implicit memory, for Huntingtons patients in comparison to controls was significant \\((t(24) = 3.41, p = .002)\\), and indicated a difference of 40 points in explicit vs implicit memory performance \\((\\beta = 40, SE = 11.72)\\).\nTherefore, we have evidence to reject the null hypothesis (the difference in performance between explicit and implicit memory tasks does not significantly differ between patients with Huntingtons in comparison to Controls)."
  },
  {
    "objectID": "2_03_int3_cc.html#footnotes",
    "href": "2_03_int3_cc.html#footnotes",
    "title": "Interactions III: Cat x Cat",
    "section": "Footnotes",
    "text": "Footnotes\n\nSome researchers may point out that a design where each person was assessed on both tasks might have been more efficient. However, the task factor in such design would then be within-subjects, meaning that the scores corresponding to the same person would be correlated. To analyse such design we will need a different method which (spoiler alert!) will be discussed next year in DAPR3.↩︎"
  },
  {
    "objectID": "2_04_simp_pair.html",
    "href": "2_04_simp_pair.html",
    "title": "Simple Effects, Pairwise Comparisons, & Corrections",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand how to interpret simple effects for experimental designs\nUnderstand how to conduct pairwise comparisons\nUnderstand how to apply corrections available for multiple comparisons\n\n\nBe up to date with lectures\nHave completed previous lab exercises from Week 1, Week 2, and Week 3\n\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\nkableExtra\nsjPlot\ninteractions\npatchwork\nemmeans\n\nAll results should be presented following APA guidelines. If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/cognitive_experiment.csv. Note, you have already worked with some of this data last week - see Semester 2 Week 3 lab, but we now have a third Task condition - Classification."
  },
  {
    "objectID": "2_04_simp_pair.html#study-analysis-plan-overview",
    "href": "2_04_simp_pair.html#study-analysis-plan-overview",
    "title": "Simple Effects, Pairwise Comparisons, & Corrections",
    "section": "Study & Analysis Plan Overview",
    "text": "Study & Analysis Plan Overview\n\nQuestion 1\n\n\nFirstly, examine the dataset, and perform any necessary and appropriate data management steps.\nNext, consider would be the most appropriate coding constraint to apply in order to best address the research question - i.e., are we interested in whether group X (e.g., Amnesic) differed from group Y (e.g., Huntingtons), or whether group X (e.g., Amnesic) differed from the global/grand mean?\nChoose appropriate reference levels for the Diagnosis and Task variables based on your decision above.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nConvert categorical variables to factors\nLabel appropriately factors to aid with your model interpretations\nIf needed, provide better variable names\n\nNote that all of these steps can be done in combination - the mutate() and factor() functions will likely be useful here.\n\n\n\n\n\n\n\n Solution \n\n\nLet’s have a look at the data to see what we’re working with - str() or head() are a good place to start - and then we should check for any missing data (NA values):\n\n#first look at dataset structure\nstr(cog)\n\nspc_tbl_ [45 × 3] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Diagnosis: num [1:45] 1 1 1 1 1 1 1 1 1 1 ...\n $ Task     : num [1:45] 1 1 1 1 1 2 2 2 2 2 ...\n $ Y        : num [1:45] 44 63 76 72 45 72 66 55 82 75 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Diagnosis = col_double(),\n  ..   Task = col_double(),\n  ..   Y = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n#now lets look at top 6 rows (or the head) of the dataset\nhead(cog)\n\n# A tibble: 6 × 3\n  Diagnosis  Task     Y\n      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1         1     1    44\n2         1     1    63\n3         1     1    76\n4         1     1    72\n5         1     1    45\n6         1     2    72\n\n#check for NAs \ntable(is.na(cog))\n\n\nFALSE \n  135 \n\n# there are none - all FALSE\n\nNext, lets convert Diagnosis and Task into factors, making the labels of each factor level more meaningful. According to the data description, the encoding of the factor Diagnosis is: 1 = amnesic patients, 2 = Huntingtons patients, and 3 are control patients. The encoding for the factor Task is: 1 = grammar task, 2 = classification task, and 3 = recognition task.\n\ncog &lt;- cog %&gt;%\n    mutate(\n        Diagnosis = factor(Diagnosis, \n                           levels = c(1, 2, 3),\n                           labels = c('amnesic', 'huntingtons', 'control'),\n                           ordered = FALSE),\n        Task = factor(Task, \n                      levels = c(1, 2, 3),\n                      labels = c('grammar', 'classification', 'recognition'),\n                      ordered = FALSE)) %&gt;%\n    rename(Score = Y)\n\nSince we are interested in comparing groups, we should use dummy coding. By default, R uses dummy coding, so we do not need to make any changes to the coding constraint.\nHowever, for our reference groups, we’re likely to want it to be the Control group for Diagnosis, and recognition for Task:\n\ncog$Diagnosis &lt;- fct_relevel(cog$Diagnosis, \"control\")\ncog$Task &lt;- fct_relevel(cog$Task, \"recognition\")\n\n\n\n\n\n\nQuestion 2\n\n\nProvide a brief overview of the study design and data, before detailing your analysis plan to address the research question.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nGive the reader some background on the context of the study (you might be able to re-use some of the content you wrote for Semester 2 Week 3 lab here, but note that we now have an extra condition within Task)\nOutline data checks / data cleaning\nState what type of analysis you will conduct in order to address the research question\nSpecify the model to be fitted to address the research question (note that you will need to specify the reference level of your categorical variables. This will be somewhat similar to last week, but with the addition of Classification in Task, our model will contain a different number of parameters)\nSpecify your chosen significance (\\(\\alpha\\)) level\nState your hypotheses\n\nMuch of the information required can be found in the Study Overview codebook.\n\n\n\n\n\n\n\n Solution \n\n\nThe cog dataset contained information on 45 hypothetical participants from a between-subjects study. Participants belonged to one of three ‘Diagnosis’ groups, which had 15 participants in each - Control, Amnesic, or Huntingtons. Participants from each of the Diagnosis groups were equally and randomly assigned to one of three ‘Tasks’ to measure different memory processes - Grammar, Classification, or Recognition - the former two measuring implicit memory and the latter explicit. This resulted in 5 participants from each Diagnosis group in each of the three Task conditions.\nAll participant data was complete, and categorical variables were coded as factors. For the purpose of this analysis, ‘Control’ was designated as the reference group for Diagnosis, since it was the only group of participants with no known neurological disorder. For Task, the recognition task measures explicit memory whereas the other two measure implicit memory, so this was specified as the reference group.\nBoxplots will be used to visualise the associations among Diagnosis and Task conditions. To address the research question of whether the difference in performance between explicit and implicit memory tasks will be greatest for Huntington patients in comparison to controls, we first need to define the dummy variables:\nFor Diagnosis:\n\\[\nD_\\text{Amnesic} = \\begin{cases}\n1 & \\text{if Diagnosis is Amnesic} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\quad  \n\\\\  \nD_\\text{Huntingtons} = \\begin{cases}\n1 & \\text{if Diagnosis is Huntingtons} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\quad  \n\\\\  \n\\\\  \n(\\text{Control is base level})\n\\]\nAnd for Task:\n\\[\nT_\\text{Grammar} = \\begin{cases}\n1 & \\text{if Task is Grammar} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\quad  \n\\\\  \nT_\\text{Classification} = \\begin{cases}\n1 & \\text{if Task is Classification} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\quad  \n\\\\  \n\\\\  \n(\\text{Recognition is base level})\n\\]\nBased on the above dummy coding, we are going to fit the following interaction model:\n\\[\n\\begin{aligned}\nInteraction Model: Score &= \\beta_0 \\\\\n      &+ \\beta_1 D_\\text{Amnseic} + \\beta_2 D_\\text{Huntingtons}   \\\\\n      &+ \\beta_3 T_\\text{Grammar}  + \\beta_4 T_\\text{Classification} \\\\\n      &+ \\beta_5 (D_\\text{Amnseic} * T_\\text{Grammar}) + \\beta_6 (D_\\text{Huntingtons} * T_\\text{Grammar})  \\\\\n      &+ \\beta_7 (D_\\text{Amnseic} * T_\\text{Classification}) + \\beta_8 (D_\\text{Huntingtons} * T_\\text{Classification})  \\\\\n      &+ \\epsilon\n\\end{aligned}\n\\]\nEffects will be considered statistically significant at \\(\\alpha = .05\\)\nOur hypotheses are:\n\\(H_0:\\) All \\(\\beta_j = 0\\) (for \\(j = 5, 6, 7, 8\\))\nThere are no significant differences in performance between explicit and implicit memory tasks for patients with different cognitive impairment(s).\n\\(H_1:\\) At least one \\(\\beta_j \\neq 0\\) (for \\(j = 5, 6, 7, 8\\))\nThere are significant differences in performance between explicit and implicit memory tasks for patients with different cognitive impairment(s)."
  },
  {
    "objectID": "2_04_simp_pair.html#descriptive-statistics-visualisations",
    "href": "2_04_simp_pair.html#descriptive-statistics-visualisations",
    "title": "Simple Effects, Pairwise Comparisons, & Corrections",
    "section": "Descriptive Statistics & Visualisations",
    "text": "Descriptive Statistics & Visualisations\n\nQuestion 3\n\n\nProvide a table of descriptive statistics and visualise your data.\nInterpret the descriptive statistics and visualisations in the context of the study (i.e., comment on any observed differences among treatment groups).\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nFor your table of descriptive statistics, both the group_by() and summarise() functions will come in handy here\n\nRecall that when visualising a continuous outcome across several groups, geom_boxplot() may be most appropriate to use\n\nMake sure to comment on any observed differences among the sample means of the four treatment conditions\n\n\n\n\n\n\n\n\n Solution \n\n\n\n\nNumeric\nVisual\n\n\n\nDescriptive statistics presented in a well formatted table:\n\ncog_stats &lt;- cog %&gt;% \n    group_by(Diagnosis, Task) %&gt;%\n    summarise(\n        Mean = mean(Score), \n        SD = sd(Score),\n        SE = sd(Score) / sqrt(n()),\n        Min = min(Score),\n        Max = max(Score)) %&gt;%\n    kable(caption = \"Descriptive Statistics of Score\", digits = 2) %&gt;%\n    kable_styling()\n\ncog_stats\n\n\n\nTable 1: Descriptive Statistics\n\nDiagnosis\nTask\nMean\nSD\nSE\nMin\nMax\n\n\n\ncontrol\nrecognition\n95\n12.98\n5.81\n80\n107\n\n\ncontrol\ngrammar\n80\n11.68\n5.22\n70\n98\n\n\ncontrol\nclassification\n80\n12.98\n5.81\n65\n92\n\n\namnesic\nrecognition\n65\n12.17\n5.44\n51\n82\n\n\namnesic\ngrammar\n60\n14.92\n6.67\n44\n76\n\n\namnesic\nclassification\n70\n10.17\n4.55\n55\n82\n\n\nhuntingtons\nrecognition\n95\n13.38\n5.98\n80\n108\n\n\nhuntingtons\ngrammar\n40\n13.25\n5.92\n24\n55\n\n\nhuntingtons\nclassification\n45\n10.86\n4.86\n33\n59\n\n\n\n\n\n\n\n\n\n\nSince we have a continuous outcome and 2 categorical predictors - a boxplot would be most appropriate for visualisations:\n\ncog_plt &lt;- ggplot(data = cog, aes(x = Diagnosis, y = Score, color = Task)) +\n  geom_boxplot() +\n  labs(x = 'Diagnosis', y = 'Score')\ncog_plt\n\n\n\nFigure 1: Association between Task Condition, Diagnosis, and Score\n\n\n\n\n\n\n\n\n\n\n\n\n\nControl patients consistently perform best across all tasks. They don’t seem to differ substantially in their scores between grammar and classification tasks, but they clearly perform better in the recognition task than the grammar and classification ones.\nAmnesic patients appear to perform better than Huntingtons patients in grammar an classification tasks (reflecting intrinsic memory processes), and perform worse than Huntingtons patients in the recognition task (reflecting extrinsic memory processes)."
  },
  {
    "objectID": "2_04_simp_pair.html#model-fitting-interpretation",
    "href": "2_04_simp_pair.html#model-fitting-interpretation",
    "title": "Simple Effects, Pairwise Comparisons, & Corrections",
    "section": "Model Fitting & Interpretation",
    "text": "Model Fitting & Interpretation\n\nQuestion 4\n\n\nFit the specified model using lm(), and store the model in an object named “mdl_int”.\nProvide key model results in a formatted table and plot the interaction model before reporting in-text the overall model fit.\n\n\n\n\n\n\nHint\n\n\n\n\n\nTable tips - Use tab_model() from the sjPlot package. Remember that you can rename your DV and IV labels by specifying dv.labels and pred.labels.\nPlotting tips - Using the cat_plot() function from the interactions package, visualise the interaction effects from your model.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nBuild & Check Model\nResults Table\nInteraction Plot\n\n\n\nFit model & check summary:\n\n#fit interaction model\nmdl_int &lt;- lm(Score ~ Diagnosis * Task, data = cog)\n\n#check model output\nsummary(mdl_int)\n\n\nCall:\nlm(formula = Score ~ Diagnosis * Task, data = cog)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n   -16    -12      2     11     18 \n\nCoefficients:\n                                          Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)                              9.500e+01  5.617e+00  16.912  &lt; 2e-16\nDiagnosisamnesic                        -3.000e+01  7.944e+00  -3.776 0.000576\nDiagnosishuntingtons                     2.960e-14  7.944e+00   0.000 1.000000\nTaskgrammar                             -1.500e+01  7.944e+00  -1.888 0.067085\nTaskclassification                      -1.500e+01  7.944e+00  -1.888 0.067085\nDiagnosisamnesic:Taskgrammar             1.000e+01  1.123e+01   0.890 0.379329\nDiagnosishuntingtons:Taskgrammar        -4.000e+01  1.123e+01  -3.560 0.001063\nDiagnosisamnesic:Taskclassification      2.000e+01  1.123e+01   1.780 0.083490\nDiagnosishuntingtons:Taskclassification -3.500e+01  1.123e+01  -3.115 0.003597\n                                           \n(Intercept)                             ***\nDiagnosisamnesic                        ***\nDiagnosishuntingtons                       \nTaskgrammar                             .  \nTaskclassification                      .  \nDiagnosisamnesic:Taskgrammar               \nDiagnosishuntingtons:Taskgrammar        ** \nDiagnosisamnesic:Taskclassification     .  \nDiagnosishuntingtons:Taskclassification ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.56 on 36 degrees of freedom\nMultiple R-squared:  0.7318,    Adjusted R-squared:  0.6722 \nF-statistic: 12.28 on 8 and 36 DF,  p-value: 2.844e-08\n\n\n\n\nTable containing the results from model:\n\ntab_model(mdl_int,\n          dv.labels = \"Scores\",\n          pred.labels = c(\"Diagnosisamnesic\" = \"Diagnosis - Amnesic\",\n                          \"Diagnosishuntingtons\" = \"Diagnosis - Huntingtons\",\n                          \"Taskgrammar\" = \"Task - Grammar\",\n                          \"Taskclassification\" = \"Task - Classification\",\n                          \"Diagnosisamnesic:Taskgrammar\" = \"Diagnosis - Amnesic : Task - Grammar\",\n                          \"Diagnosishuntingtons:Taskgrammar\" = \"Diagnosis - Huntingtons : Task - Grammar\",\n                          \"Diagnosisamnesic:Taskclassification\" = \"Diagnosis - Amnesic : Task - Classification\",\n                          \"Diagnosishuntingtons:Taskclassification\" = \"Diagnosis - Huntingtons : Task - Classification\"),\n          title = \"Regression Table for Scores Model\")\n\n\n\nTable 2: Regression Table for Scores Model\n\n\n\n\n\n\n\n\n \nScores\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n95.00\n83.61 – 106.39\n&lt;0.001\n\n\nDiagnosis - Amnesic\n-30.00\n-46.11 – -13.89\n0.001\n\n\nDiagnosis - Huntingtons\n0.00\n-16.11 – 16.11\n1.000\n\n\nTask - Grammar\n-15.00\n-31.11 – 1.11\n0.067\n\n\nTask - Classification\n-15.00\n-31.11 – 1.11\n0.067\n\n\nDiagnosis - Amnesic :\nTask - Grammar\n10.00\n-12.79 – 32.79\n0.379\n\n\nDiagnosis - Huntingtons :\nTask - Grammar\n-40.00\n-62.79 – -17.21\n0.001\n\n\nDiagnosis - Amnesic :\nTask - Classification\n20.00\n-2.79 – 42.79\n0.083\n\n\nDiagnosis - Huntingtons :\nTask - Classification\n-35.00\n-57.79 – -12.21\n0.004\n\n\nObservations\n45\n\n\nR2 / R2 adjusted\n0.732 / 0.672\n\n\n\n\n\n\n\n\n\n\nPlot interaction model:\n\nplt_cog_mdl &lt;- cat_plot(model = mdl_int, \n                  pred = Diagnosis, \n                  modx = Task, \n                  main.title = \"Scores across Diagnosis and Task\",\n                  x.label = \"Diagnosis\",\n                  y.label = \"Score\",\n                  legend.main = \"Task\")\nplt_cog_mdl\n\n\n\nFigure 2: Interaction Plot\n\n\n\n\n\n\n\n\n\n\n\n\nFull regression results including 95% Confidence Intervals are shown in Table 2, and the interaction model is visually presented in Figure 2. The \\(F\\)-test for model utility was significant \\((F(8, 36) = 12.28, p &lt; .001)\\), and the model explained approximately 67% of the variability in Scores."
  },
  {
    "objectID": "2_04_simp_pair.html#contrast-analysis",
    "href": "2_04_simp_pair.html#contrast-analysis",
    "title": "Simple Effects, Pairwise Comparisons, & Corrections",
    "section": "Contrast Analysis",
    "text": "Contrast Analysis\nWe will now begin by looking at each factor separately.\n\nQuestion 5\n\n\nIn terms of the diagnostic groups, we want to compare the individuals with amnesia to those with Huntingtons. This corresponds to a contrast with coefficients of 0, 1, and −1, for control, amnesic, and Huntingtons, respectively.\nSimilarly, in terms of the tasks, we want to compare the average of the two implicit memory tasks with the explicit memory task. This corresponds to a contrast with coefficients of 0.5, 0.5, and −1 for the three tasks.\nWhen we are in presence of a significant interaction, the coefficients for a contrast between the means are found by multiplying each row coefficient with all column coefficients as shown below:\n\n\n\n\n\n\n\n\nSpecify the contrast weights in R, and state the null hypothesis of your contrast analysis.\n\n\n\n\n Solution \n\n\nThis can be done in R using:\n\n\nOption 1\nOption 2\n\n\n\n\ndiag_coef  &lt;- c('control' = 0, 'amnesic' = 1, 'huntingtons' = -1)\ntask_coef  &lt;- c('grammar' = 0.5, 'classification' = 0.5, 'recognition' = -1)\ncontr_coef &lt;- outer(diag_coef, task_coef)\ncontr_coef\n\n            grammar classification recognition\ncontrol         0.0            0.0           0\namnesic         0.5            0.5          -1\nhuntingtons    -0.5           -0.5           1\n\n\n\n\n\ndiag_coef  &lt;- c('control' = 0, 'amnesic' = 1, 'huntingtons' = -1)\ntask_coef  &lt;- c('grammar' = 0.5, 'classification' = 0.5, 'recognition' = -1)\ncontr_coef &lt;- diag_coef %o% task_coef\ncontr_coef\n\n            grammar classification recognition\ncontrol         0.0            0.0           0\namnesic         0.5            0.5          -1\nhuntingtons    -0.5           -0.5           1\n\n\n\n\n\nThe above coefficients correspond to testing the null hypothesis\n\\[\nH_0 : \\frac{\\mu_{2,1} + \\mu_{2,2}}{2} - \\mu_{2,3} - \\left( \\frac{\\mu_{3,1} + \\mu_{3,2}}{2} - \\mu_{3,3} \\right) = 0\n\\]\n\nwhich can be equivalently specified as\n\n\\[\nH_0 : \\frac{\\mu_{2,1} + \\mu_{2,2}}{2} - \\mu_{2,3} = \\frac{\\mu_{3,1} + \\mu_{3,2}}{2} - \\mu_{3,3}\n\\]\nboth statements state that, in the population, the difference between the mean implicit memory and the explicit memory score is the same for individuals with amnesia and Huntingtons.\nNote that the scores for the grammar and classification tasks have been averaged to obtain a single measure of ‘implicit memory’ score.\n\n\n\n\n\nQuestion 6\n\n\nRun the contrast analysis, and interpret your output in the context of the research question.\n\n\n\n\n Solution \n\n\nNow that we have the coefficients, let’s firstly call the emmeans function (this is helpful to look at the ordering of the groups):\n\nemm &lt;- emmeans(mdl_int, ~ Diagnosis*Task)\nemm\n\n Diagnosis   Task           emmean   SE df lower.CL upper.CL\n control     recognition        95 5.62 36     83.6    106.4\n amnesic     recognition        65 5.62 36     53.6     76.4\n huntingtons recognition        95 5.62 36     83.6    106.4\n control     grammar            80 5.62 36     68.6     91.4\n amnesic     grammar            60 5.62 36     48.6     71.4\n huntingtons grammar            40 5.62 36     28.6     51.4\n control     classification     80 5.62 36     68.6     91.4\n amnesic     classification     70 5.62 36     58.6     81.4\n huntingtons classification     45 5.62 36     33.6     56.4\n\nConfidence level used: 0.95 \n\n\nNext, from contr_coef, insert the coefficients following the order specified by the rows of emm above. That is, the first one should be for control recognition and have a value of 0, the second for amnesic recognition with a value of -1, and so on…\nWe also give a name to this contrast, such as ‘Research Hyp’.\n\ncomp_res &lt;- contrast(emm, \n                     method = list('Research Hyp' = c(0, -1, 1, 0, 0.5, -0.5, 0, 0.5, -0.5))\n                     )\n\nNext, let’s look at the output via one of two ways:\n\n\nOption 1\nOption 2\n\n\n\n\ncomp_res\n\n contrast     estimate   SE df t.ratio p.value\n Research Hyp     52.5 9.73 36   5.396  &lt;.0001\n\nconfint(comp_res)\n\n contrast     estimate   SE df lower.CL upper.CL\n Research Hyp     52.5 9.73 36     32.8     72.2\n\nConfidence level used: 0.95 \n\n\n\n\n\nsummary(comp_res, infer = TRUE)\n\n contrast     estimate   SE df lower.CL upper.CL t.ratio p.value\n Research Hyp     52.5 9.73 36     32.8     72.2   5.396  &lt;.0001\n\nConfidence level used: 0.95 \n\n\n\n\n\n\n\n\n\n\n\nThere was evidence that the contrast was not zero in the population \\(t(36) = 5.40, p &lt; .001\\). Individuals with amnesia and Huntingtons did differ in the difference between implicit and explicit memory tasks, and this difference was estimated to be 52.50. We are 95% confident that the difference in implicit and explicit memory scores between individuals with amnesia and Huntingtons was between 32.80 to 72.20 points. Therefore, we can reject the null hypothesis that the difference in differences is equal to zero."
  },
  {
    "objectID": "2_04_simp_pair.html#simple-effects",
    "href": "2_04_simp_pair.html#simple-effects",
    "title": "Simple Effects, Pairwise Comparisons, & Corrections",
    "section": "Simple Effects",
    "text": "Simple Effects\nBy considering the simple effects1, we can identify at which levels of the interacting condition we see different effects.\n\nQuestion 7\n\n\nExamine the simple effects for Task at each level of Diagnosis; and then the simple effects for Diagnosis at each level of Task.\n\n\n\n\n Solution \n\n\n\n\nSimple Effects of Task\nSimple Effects of Diagnosis\n\n\n\nFrom mdl_int_simple1 we can see the differences between between tasks for each diagnosis group:\n\nmdl_int_simple1 &lt;- pairs(emm, simple = \"Task\")\nmdl_int_simple1\n\nDiagnosis = control:\n contrast                     estimate   SE df t.ratio p.value\n recognition - grammar              15 7.94 36   1.888  0.1567\n recognition - classification       15 7.94 36   1.888  0.1567\n grammar - classification            0 7.94 36   0.000  1.0000\n\nDiagnosis = amnesic:\n contrast                     estimate   SE df t.ratio p.value\n recognition - grammar               5 7.94 36   0.629  0.8050\n recognition - classification       -5 7.94 36  -0.629  0.8050\n grammar - classification          -10 7.94 36  -1.259  0.4273\n\nDiagnosis = huntingtons:\n contrast                     estimate   SE df t.ratio p.value\n recognition - grammar              55 7.94 36   6.923  &lt;.0001\n recognition - classification       50 7.94 36   6.294  &lt;.0001\n grammar - classification           -5 7.94 36  -0.629  0.8050\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\n\n\nLet’s look at the simple effects of Diagnosis, and store these in an object named mdl_int_simple2. From mdl_int_simple2 we can see the differences between diagnoses for each task group:\n\nmdl_int_simple2 &lt;- pairs(emm, simple = \"Diagnosis\")\nmdl_int_simple2\n\nTask = recognition:\n contrast              estimate   SE df t.ratio p.value\n control - amnesic           30 7.94 36   3.776  0.0016\n control - huntingtons        0 7.94 36   0.000  1.0000\n amnesic - huntingtons      -30 7.94 36  -3.776  0.0016\n\nTask = grammar:\n contrast              estimate   SE df t.ratio p.value\n control - amnesic           20 7.94 36   2.518  0.0424\n control - huntingtons       40 7.94 36   5.035  &lt;.0001\n amnesic - huntingtons       20 7.94 36   2.518  0.0424\n\nTask = classification:\n contrast              estimate   SE df t.ratio p.value\n control - amnesic           10 7.94 36   1.259  0.4273\n control - huntingtons       35 7.94 36   4.406  0.0003\n amnesic - huntingtons       25 7.94 36   3.147  0.0091\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\n\n\n\n\n\n\n\n\nQuestion 8\n\n\nVisualise the interaction, displaying two plots - one with Diagnosis on the x-axis, and the other with Task on the x-axis.\nConsidering the simple effects that you noted above, identify the significant effects and match them to the corresponding points of your interaction plot.\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo visualise the interaction, you can use emmip().\nRecall that the patchwork package allows us to arrange multiple plots using either / or | or +\n\n\n\n\n\n\n\n Solution \n\n\n\n\nSimple Effects of Task\nSimple Effects of Diagnosis\n\n\n\n\nplt_1 &lt;- emmip(mdl_int, Diagnosis ~ Task, CIs = TRUE)\nplt_1\n\n\n\n\n\n\n\nFor the simple effects of task (see plt_1), we saw the significant differences (those for which \\(p&lt;.05\\)):\n\nOnly in the Huntingtons group, between recognition & grammar and recognition & classification tasks\n\nleft-most blue point compared to the middle blue point, and then compared to the right-most blue point\n\n\n\n\n\n\nplt_2 &lt;- emmip(mdl_int, Task ~ Diagnosis, CIs = TRUE)\nplt_2\n\n\n\n\n\n\n\nFor the simple effects of Diagnosis (see plt_2), we saw significant differences (those for which \\(p&lt;.05\\)):\n\nin the recognition task, between control & amnesic\n\nleft-most red point to middle red point\n\n\nin the recognition task, between amnesic & huntingtons\n\nmiddle red-point to right-most red point\n\n\nin the grammar task, between control & amnesic\n\nleft-most green point to middle green point\n\n\nin the grammar task, between control & huntingtons\n\nleft-most green point to right-most green point\n\n\nin the grammar task, between amnesic & huntingtons\n\nmiddle green point to right-most green point\n\n\nin the classification task, between control & huntingtons\n\nleft-most blue point to right-most blue point\n\n\nin the classification task, between amnesic & huntingtons\n\nmiddle blue point to right-most blue point"
  },
  {
    "objectID": "2_04_simp_pair.html#pairwise-comparisons-multiple-corrections",
    "href": "2_04_simp_pair.html#pairwise-comparisons-multiple-corrections",
    "title": "Simple Effects, Pairwise Comparisons, & Corrections",
    "section": "Pairwise Comparisons & Multiple Corrections",
    "text": "Pairwise Comparisons & Multiple Corrections\n\nQuestion 9\n\n\nConduct exploratory pairwise comparisons to compare all levels of Diagnosis with all levels of Task, applying no correction (note that Tukey will be automatically applied since we are comparing groups of means, so you will need to overwrite this).\nWithout adjusting our \\(\\alpha\\) (or \\(p\\)-value), why might any inferences drawn from your output be problematic?\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can specify the adjustment using adjust = \". Possible options include:\n\nadjust = \"none\"\nadjust =  \"bonferroni\"\nadjust = \"sidak\"\nadjust = \"Tukey\"\nadjust = scheffe\"\n\n\n\n\n\n\n\n\n Solution \n\n\n\npairs_res &lt;- pairs(emm, adjust = \"none\")\npairs_res\n\n contrast                                             estimate   SE df t.ratio\n control recognition - amnesic recognition                  30 7.94 36   3.776\n control recognition - huntingtons recognition               0 7.94 36   0.000\n control recognition - control grammar                      15 7.94 36   1.888\n control recognition - amnesic grammar                      35 7.94 36   4.406\n control recognition - huntingtons grammar                  55 7.94 36   6.923\n control recognition - control classification               15 7.94 36   1.888\n control recognition - amnesic classification               25 7.94 36   3.147\n control recognition - huntingtons classification           50 7.94 36   6.294\n amnesic recognition - huntingtons recognition             -30 7.94 36  -3.776\n amnesic recognition - control grammar                     -15 7.94 36  -1.888\n amnesic recognition - amnesic grammar                       5 7.94 36   0.629\n amnesic recognition - huntingtons grammar                  25 7.94 36   3.147\n amnesic recognition - control classification              -15 7.94 36  -1.888\n amnesic recognition - amnesic classification               -5 7.94 36  -0.629\n amnesic recognition - huntingtons classification           20 7.94 36   2.518\n huntingtons recognition - control grammar                  15 7.94 36   1.888\n huntingtons recognition - amnesic grammar                  35 7.94 36   4.406\n huntingtons recognition - huntingtons grammar              55 7.94 36   6.923\n huntingtons recognition - control classification           15 7.94 36   1.888\n huntingtons recognition - amnesic classification           25 7.94 36   3.147\n huntingtons recognition - huntingtons classification       50 7.94 36   6.294\n control grammar - amnesic grammar                          20 7.94 36   2.518\n control grammar - huntingtons grammar                      40 7.94 36   5.035\n control grammar - control classification                    0 7.94 36   0.000\n control grammar - amnesic classification                   10 7.94 36   1.259\n control grammar - huntingtons classification               35 7.94 36   4.406\n amnesic grammar - huntingtons grammar                      20 7.94 36   2.518\n amnesic grammar - control classification                  -20 7.94 36  -2.518\n amnesic grammar - amnesic classification                  -10 7.94 36  -1.259\n amnesic grammar - huntingtons classification               15 7.94 36   1.888\n huntingtons grammar - control classification              -40 7.94 36  -5.035\n huntingtons grammar - amnesic classification              -30 7.94 36  -3.776\n huntingtons grammar - huntingtons classification           -5 7.94 36  -0.629\n control classification - amnesic classification            10 7.94 36   1.259\n control classification - huntingtons classification        35 7.94 36   4.406\n amnesic classification - huntingtons classification        25 7.94 36   3.147\n p.value\n  0.0006\n  1.0000\n  0.0671\n  0.0001\n  &lt;.0001\n  0.0671\n  0.0033\n  &lt;.0001\n  0.0006\n  0.0671\n  0.5331\n  0.0033\n  0.0671\n  0.5331\n  0.0164\n  0.0671\n  0.0001\n  &lt;.0001\n  0.0671\n  0.0033\n  &lt;.0001\n  0.0164\n  &lt;.0001\n  1.0000\n  0.2162\n  0.0001\n  0.0164\n  0.0164\n  0.2162\n  0.0671\n  &lt;.0001\n  0.0006\n  0.5331\n  0.2162\n  0.0001\n  0.0033\n\n#can also plot if you'd like:\nplot(pairs_res)\n\n\n\n\n\n\n\nFrom the above, we can see comparisons for all different possible pairs of diagnosis-task combinations.\nIn total, there are 9 different estimates, but comparing them all means that we have 36 comparisons being tested! By not adjusting our \\(p\\)-value, we are increasing the experimentwise Type I error rate - we could wrongly reject the null hypothesis at a much higher rate than 5/100 (or 1/20 as is assumed when \\(\\alpha = .05\\)). To overcome this, we might adjust and determine a result to be statistically significant if \\(p &lt; .005\\), as opposed to \\(p &lt; .05\\), depending on how many tests are in our family of tests).\n\n\n\n\n\nQuestion 10\n\n\nSelect an appropriate method to adjust for multiple comparisons, and then obtain confidence intervals.\nComment on how these \\(p\\)-values differ from your raw (i.e., unadjusted) \\(p\\)-values.\n\n\n\n\n Solution \n\n\nNote what the functions in R do is adjust the \\(p\\)-value, rather than the \\(\\alpha\\).\nSince we’re interested in all pairwise comparisons of means, the Tukey adjustment might be a sensible approach. However, we’ll also show the Bonferroni to show how it differs (note, in practice you would only apply one correction and justify this choice based on your design - we are only applying two to note how they differ!)\n\n\nTukey\nBonferroni\n\n\n\n\ncontrast(emm, method = \"pairwise\", adjust=\"Tukey\")\n\n contrast                                             estimate   SE df t.ratio\n control recognition - amnesic recognition                  30 7.94 36   3.776\n control recognition - huntingtons recognition               0 7.94 36   0.000\n control recognition - control grammar                      15 7.94 36   1.888\n control recognition - amnesic grammar                      35 7.94 36   4.406\n control recognition - huntingtons grammar                  55 7.94 36   6.923\n control recognition - control classification               15 7.94 36   1.888\n control recognition - amnesic classification               25 7.94 36   3.147\n control recognition - huntingtons classification           50 7.94 36   6.294\n amnesic recognition - huntingtons recognition             -30 7.94 36  -3.776\n amnesic recognition - control grammar                     -15 7.94 36  -1.888\n amnesic recognition - amnesic grammar                       5 7.94 36   0.629\n amnesic recognition - huntingtons grammar                  25 7.94 36   3.147\n amnesic recognition - control classification              -15 7.94 36  -1.888\n amnesic recognition - amnesic classification               -5 7.94 36  -0.629\n amnesic recognition - huntingtons classification           20 7.94 36   2.518\n huntingtons recognition - control grammar                  15 7.94 36   1.888\n huntingtons recognition - amnesic grammar                  35 7.94 36   4.406\n huntingtons recognition - huntingtons grammar              55 7.94 36   6.923\n huntingtons recognition - control classification           15 7.94 36   1.888\n huntingtons recognition - amnesic classification           25 7.94 36   3.147\n huntingtons recognition - huntingtons classification       50 7.94 36   6.294\n control grammar - amnesic grammar                          20 7.94 36   2.518\n control grammar - huntingtons grammar                      40 7.94 36   5.035\n control grammar - control classification                    0 7.94 36   0.000\n control grammar - amnesic classification                   10 7.94 36   1.259\n control grammar - huntingtons classification               35 7.94 36   4.406\n amnesic grammar - huntingtons grammar                      20 7.94 36   2.518\n amnesic grammar - control classification                  -20 7.94 36  -2.518\n amnesic grammar - amnesic classification                  -10 7.94 36  -1.259\n amnesic grammar - huntingtons classification               15 7.94 36   1.888\n huntingtons grammar - control classification              -40 7.94 36  -5.035\n huntingtons grammar - amnesic classification              -30 7.94 36  -3.776\n huntingtons grammar - huntingtons classification           -5 7.94 36  -0.629\n control classification - amnesic classification            10 7.94 36   1.259\n control classification - huntingtons classification        35 7.94 36   4.406\n amnesic classification - huntingtons classification        25 7.94 36   3.147\n p.value\n  0.0149\n  1.0000\n  0.6257\n  0.0026\n  &lt;.0001\n  0.6257\n  0.0711\n  &lt;.0001\n  0.0149\n  0.6257\n  0.9993\n  0.0711\n  0.6257\n  0.9993\n  0.2575\n  0.6257\n  0.0026\n  &lt;.0001\n  0.6257\n  0.0711\n  &lt;.0001\n  0.2575\n  0.0004\n  1.0000\n  0.9367\n  0.0026\n  0.2575\n  0.2575\n  0.9367\n  0.6257\n  0.0004\n  0.0149\n  0.9993\n  0.9367\n  0.0026\n  0.0711\n\nP value adjustment: tukey method for comparing a family of 9 estimates \n\n\nNote that 8 of the comparisons are no longer significant when using Tukey’s adjustment, suggesting that these might have been (when using no adjustment) Type I errors!\n\n\n\ncontrast(emm, method = \"pairwise\", adjust=\"bonferroni\")\n\n contrast                                             estimate   SE df t.ratio\n control recognition - amnesic recognition                  30 7.94 36   3.776\n control recognition - huntingtons recognition               0 7.94 36   0.000\n control recognition - control grammar                      15 7.94 36   1.888\n control recognition - amnesic grammar                      35 7.94 36   4.406\n control recognition - huntingtons grammar                  55 7.94 36   6.923\n control recognition - control classification               15 7.94 36   1.888\n control recognition - amnesic classification               25 7.94 36   3.147\n control recognition - huntingtons classification           50 7.94 36   6.294\n amnesic recognition - huntingtons recognition             -30 7.94 36  -3.776\n amnesic recognition - control grammar                     -15 7.94 36  -1.888\n amnesic recognition - amnesic grammar                       5 7.94 36   0.629\n amnesic recognition - huntingtons grammar                  25 7.94 36   3.147\n amnesic recognition - control classification              -15 7.94 36  -1.888\n amnesic recognition - amnesic classification               -5 7.94 36  -0.629\n amnesic recognition - huntingtons classification           20 7.94 36   2.518\n huntingtons recognition - control grammar                  15 7.94 36   1.888\n huntingtons recognition - amnesic grammar                  35 7.94 36   4.406\n huntingtons recognition - huntingtons grammar              55 7.94 36   6.923\n huntingtons recognition - control classification           15 7.94 36   1.888\n huntingtons recognition - amnesic classification           25 7.94 36   3.147\n huntingtons recognition - huntingtons classification       50 7.94 36   6.294\n control grammar - amnesic grammar                          20 7.94 36   2.518\n control grammar - huntingtons grammar                      40 7.94 36   5.035\n control grammar - control classification                    0 7.94 36   0.000\n control grammar - amnesic classification                   10 7.94 36   1.259\n control grammar - huntingtons classification               35 7.94 36   4.406\n amnesic grammar - huntingtons grammar                      20 7.94 36   2.518\n amnesic grammar - control classification                  -20 7.94 36  -2.518\n amnesic grammar - amnesic classification                  -10 7.94 36  -1.259\n amnesic grammar - huntingtons classification               15 7.94 36   1.888\n huntingtons grammar - control classification              -40 7.94 36  -5.035\n huntingtons grammar - amnesic classification              -30 7.94 36  -3.776\n huntingtons grammar - huntingtons classification           -5 7.94 36  -0.629\n control classification - amnesic classification            10 7.94 36   1.259\n control classification - huntingtons classification        35 7.94 36   4.406\n amnesic classification - huntingtons classification        25 7.94 36   3.147\n p.value\n  0.0207\n  1.0000\n  1.0000\n  0.0033\n  &lt;.0001\n  1.0000\n  0.1190\n  &lt;.0001\n  0.0207\n  1.0000\n  1.0000\n  0.1190\n  1.0000\n  1.0000\n  0.5907\n  1.0000\n  0.0033\n  &lt;.0001\n  1.0000\n  0.1190\n  &lt;.0001\n  0.5907\n  0.0005\n  1.0000\n  1.0000\n  0.0033\n  0.5907\n  0.5907\n  1.0000\n  1.0000\n  0.0005\n  0.0207\n  1.0000\n  1.0000\n  0.0033\n  0.1190\n\nP value adjustment: bonferroni method for 36 tests \n\n\nThe first Bonferroni adjusted \\(p\\)-value is 0.0207.\nThe raw (unadjusted) \\(p\\)-value from the previous question was 0.0005759265.\nThe Bonferroni method simply multiplies the ‘raw’ \\(p\\)-value by the number of the tests, which we know is 36.\n\n0.0005759265 * 36\n\n[1] 0.02073335\n\n\nIn terms of differences in Bonferroni to raw \\(p\\)-values, they are thus 36 times the size.\nOne benefit of Bonferroni is that it can be applied to any set of \\(p\\)-values, whereas Tukey only applies when comparing the means of levels of a factor. The downside, however, is that it may be overly conservative (i.e. reduce our power to detect an effect that is truly there)."
  },
  {
    "objectID": "2_04_simp_pair.html#footnotes",
    "href": "2_04_simp_pair.html#footnotes",
    "title": "Simple Effects, Pairwise Comparisons, & Corrections",
    "section": "Footnotes",
    "text": "Footnotes\n\nsimple effects are the effects of one variable at a specific level of another variable↩︎"
  },
  {
    "objectID": "2_06_glm1.html",
    "href": "2_06_glm1.html",
    "title": "Binary Logistic Regression",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand when to use a logistic model\nUnderstand how to fit and interpret a logistic model\n\n\nBe up to date with lectures\nHave completed Labs 1-5\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npatchwork\nkableExtra\npsych\nsjPlot\n\nAll results should be presented following APA guidelines. If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/drunkdoor.csv."
  },
  {
    "objectID": "2_06_glm1.html#study-analysis-plan-overview",
    "href": "2_06_glm1.html#study-analysis-plan-overview",
    "title": "Binary Logistic Regression",
    "section": "Study & Analysis Plan Overview",
    "text": "Study & Analysis Plan Overview\n\nQuestion 1\n\n\nFirstly, examine the dataset, and perform any necessary and appropriate data management steps.\nNext, consider the scales that the variables are currently on, with a particular focus on BAC, age, and condition. COnsider:\n\nDo you want BAC on the current scale, or could you transform it somehow? Consider that instead of the coefficient representing the difference when moving from 0% to 1% BAC (1% blood alcohol is fatal!), we might want to have the difference associated with 0% to 0.01% BAC (i.e, a we want to talk about effects in terms of changing 1/100th of a percentage of BAC)\nDo you want age to be centred at 0 years (as it currently is), or could you re-centre to make it more meaningful?\nIn your data management, you will hopefully make condition a factor, but have you considered the reference level? It would likely make most sense for this to be set as “Low”.\n\n\n\n\n\n Solution \n\n\nLet’s examine the data:\n\n#look at structure of data\nstr(drunkdoor)\n\nspc_tbl_ [120 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ id       : chr [1:120] \"ID1\" \"ID2\" \"ID3\" \"ID4\" ...\n $ bac      : num [1:120] 0.06744 0.00331 0.00323 0.07984 0.06676 ...\n $ age      : num [1:120] 43 64 44 67 62 45 50 45 48 61 ...\n $ condition: chr [1:120] \"Low\" \"Low\" \"Low\" \"High\" ...\n $ notice   : num [1:120] 0 0 1 0 0 1 0 1 0 0 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   id = col_character(),\n  ..   bac = col_double(),\n  ..   age = col_double(),\n  ..   condition = col_character(),\n  ..   notice = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n#check for NAs - there are none - all FALSE\ntable(is.na(drunkdoor))\n\n\nFALSE \n  600 \n\n\nNext we need to specify Condition as a factor, and set ‘Low’ as the reference group:\n\n#re-assign categorical IVs as factors\ndrunkdoor$condition &lt;- factor(drunkdoor$condition,\n                              levels = c(\"Low\", \"High\"))\n\n\n#set 'low' as reference group\ndrunkdoor$condition &lt;- fct_relevel(drunkdoor$condition, \"Low\")\n\nIt may be more useful to have blood alcohol (BAC) in terms of 100ths of percentages, rather than percentages, for the reasons noted above. It would also be more useful for interpretation to have age centered on the mean (note that this won’t change anything other than the intercept in our model). Let’s make both these changes:\n\ndrunkdoor &lt;- drunkdoor %&gt;% \n  mutate(\n    bac100 = bac*100,\n    age_mc = age - mean(age)\n  )\n\n\n\n\n\n\nQuestion 2\n\n\nProvide a brief overview of the study design and data, before detailing your analysis plan to address the research question.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nGive the reader some background on the context of the study\nState what type of analysis you will conduct in order to address the research question\nSpecify the model to be fitted to address the research question\nSpecify your chosen significance (\\(\\alpha\\)) level\nState your hypotheses\n\nMuch of the information required can be found in the Study Overview codebook.\n\n\n\n\n\n\n\n Solution \n\n\nThe drunkdoor dataset contained information on 120 hypothetical participants who were approached within the vicinity of a number of establishments with licenses to sell alcohol to be consumed on-premises. Using a between-subjects design experimental design, experimenters manipulated perceptual load in two ways (door appearance and number of papers held by experimenters) to create low- and high-load conditions. In the low-load condition, the door was a standard MDF construction painted in a neutral grey, and the experimenters handled only 2 sheets of paper which had minimal printed text. In the high-load condition, the door was painted with detailed graffiti and had numerous pieces of paper and notices attached to the side facing the participants, and the experimenters held a pile of 30 papers containing drawings and printed text. Experimenters recorded whether or not participants noticed the mid-conversation experimenter swap (no = 0, yes = 1). The researchers also collected information on participants’ blood alcohol level (BAC; percentage of alcohol in an individual’s blood stream) and age (in years).\nTo aid with interpretation, age was mean centered. The BAC measure was also transformed to represent a one-unit change as 0.01%, as opposed to 1%. Low-load was specified as the reference group of the perceptual load condition.\nDensity plots and bar plots will be used to individually visualise the associations between whether the mid-conversation swap was noticed and BAC, age, and condition.\nTo investigate whether the probability of noticing the swap changed as a function of age, BAC, and perceptual load, a binary logistic regression model was used, where the following model was specified:\n\\[\n\\begin{aligned}\n\\ln \\left( \\frac{p}{1 - p}\\right) = \\beta_0 + \\beta_1 \\cdot Age + \\beta_2 \\cdot BAC + \\beta_3 \\cdot Condition_{High}\n\\end{aligned}\n\\\\ \\\n\\\\ \\\n\\begin{aligned}\n\\text{where } {p} &= \\text{probability of noticing the mid-conversation swap}\n\\end{aligned}\n\\]\nOur hypotheses are:\n\\(H_0:\\) All \\(\\beta_j = 0\\) (for \\(j = 1, 2, 3\\))\nSusceptibility to change blindness is not influenced by age, level of alcohol intoxication, or perceptual load.\n\\(H_1:\\) At least one \\(\\beta_j \\neq 0\\) (for \\(j = 1, 2, 3\\))\nSusceptibility to change blindness is influenced by age, level of alcohol intoxication, and perceptual load.\nEffects will be considered statistically significant at \\(\\alpha = .05\\)."
  },
  {
    "objectID": "2_06_glm1.html#descriptive-statistics-visualisations",
    "href": "2_06_glm1.html#descriptive-statistics-visualisations",
    "title": "Binary Logistic Regression",
    "section": "Descriptive Statistics & Visualisations",
    "text": "Descriptive Statistics & Visualisations\n\nQuestion 3\n\n\nProvide a table of descriptive statistics and visualise your data.\nRemember to interpret these in the context of the study.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nFor your table of descriptive statistics, both the group_by() and summarise() functions will come in handy here\nFor your visualisations, you will need to specify as_factor() when plotting the notice variable since this is numeric, but we want it to be treated as a factor only for plotting purposes\nMake sure to comment on your observations\n\n\n\n\n\n\n\n\n Solution \n\n\n\n\nNumeric\nVisual\n\n\n\nLet’s first produce a descriptive statistics table, grouped by whether or not paricipants noticed the swap, and what perceptual load condition they were assigned to:\n\ndoor_stats &lt;- drunkdoor %&gt;% \n    group_by(notice, condition) %&gt;%\n    summarise(\n        Avg_Age = mean(age), \n        SD_Age = sd(age),\n        SE_Age = sd(age) / sqrt(n()),\n        Min_Age = min(age),\n        Max_Age = max(age),        \n        Avg_BAC = mean(bac), \n        SD_BAC = sd(bac),\n        SE_BAC = sd(bac) / sqrt(n()),\n        Min_BAC = min(bac),\n        Max_BAC = max(bac)) %&gt;%\n    kable(caption = \"Descriptive Statistics\", digits = 2) %&gt;%\n    kable_styling()\n\ndoor_stats\n\n\n\nTable 1: Descriptive Statistics\n\nnotice\ncondition\nAvg_Age\nSD_Age\nSE_Age\nMin_Age\nMax_Age\nAvg_BAC\nSD_BAC\nSE_BAC\nMin_BAC\nMax_BAC\n\n\n\n0\nLow\n61.62\n8.09\n1.65\n41\n74\n0.03\n0.02\n0\n0.00\n0.07\n\n\n0\nHigh\n60.21\n7.96\n1.39\n46\n79\n0.04\n0.02\n0\n0.00\n0.08\n\n\n1\nLow\n52.42\n6.78\n1.13\n41\n65\n0.04\n0.03\n0\n0.00\n0.08\n\n\n1\nHigh\n47.93\n7.05\n1.36\n34\n59\n0.05\n0.02\n0\n0.01\n0.08\n\n\n\n\n\n\n\n\n\n\n\n\nNotice\nNotice & Age\nNotice & BAC\nNotice & Task\n\n\n\n\ndoor_plt1 &lt;- ggplot(data = drunkdoor, aes(x=as_factor(notice), fill=as_factor(notice))) +\n  geom_bar() +\n  labs(x = \"Noticed Swap (0 = No, 1 = Yes)\", fill = \"Noticed Swap (0 = No, 1 = Yes)\", y = \"Frequency\")\ndoor_plt1\n\n\n\nFigure 1: Counts of Notice\n\n\n\n\n\n\ndoor_plt2 &lt;- ggplot(data = drunkdoor, aes(x=age, fill=as_factor(notice))) +\n  geom_density() +\n  labs(x = \"Age (in years)\", fill = \"Noticed Swap (0 = No, 1 = Yes)\")\ndoor_plt2 \n\n\n\nFigure 2: Association between Notice and Age\n\n\n\n\n\n\ndoor_plt3 &lt;- ggplot(data = drunkdoor, aes(x=bac, fill=as_factor(notice))) +\n  geom_density() +\n  labs(x = \"BAC\", fill = \"Noticed Swap (0 = No, 1 = Yes)\")\ndoor_plt3\n\n\n\nFigure 3: Association between Notice and BAC\n\n\n\n\n\n\ndoor_plt4 &lt;- ggplot(data = drunkdoor, aes(x=condition, fill=as_factor(notice))) +\n  geom_bar(position = \"dodge\") +\n  labs(fill = \"Noticed Swap (0 = No, 1 = Yes)\", x = \"Condition\")\ndoor_plt4\n\n\n\nFigure 4: Association between Notice and Perceptual Load Condition\n\n\n\n\n\n\nFrom Figure 1, we can see that there are slightly more individuals that noticed the mid-conversation swap than those who did not.\nFrom Figure 2, we can see that there appear to be more older adults who did not notice the mid-conversation swap.\nFrom Figure 3, we can see that higher BAC appears to be positively associated with noticing a mid-conversation swap.\nFrom Figure 4, in the Low perceptual load condition, more participants noticed the swap than did not, whilst the opposite pattern emerged in the High perceptual group.\n\n\n\n\n\n\n\n\nQuestion 4\n\n\nFor the moment, lets just consider the association between notice and age. Visually following the line from the plot produced below, what do you think the predicted model value would be for someone who is aged 30? What does this value mean?\n\n\n\n\n\n\n\n\n\n\n\n\n Solution \n\n\nHopefully you can see that the model predicted value for someone aged 30 is approximately 1.30.\nWhat does 1.30 really mean here? A 30 year old participant will notice 1.30 experimenter-swaps? They have a 130% probability of noticing the swap? That is maybe closer, but we can’t have such a probability - probability is between 0 and 1."
  },
  {
    "objectID": "2_06_glm1.html#model-fitting-interpretation",
    "href": "2_06_glm1.html#model-fitting-interpretation",
    "title": "Binary Logistic Regression",
    "section": "Model Fitting & Interpretation",
    "text": "Model Fitting & Interpretation\n\nQuestion 5\n\n\nFit your model using glm(), and assign it as an object with the name “changeblind_mdl”.\n\n\n\n\n Solution \n\n\n\nchangeblind_mdl &lt;- glm(notice ~ age_mc + bac100 + condition, data = drunkdoor, family = \"binomial\")\nsummary(changeblind_mdl)\n\n\nCall:\nglm(formula = notice ~ age_mc + bac100 + condition, family = \"binomial\", \n    data = drunkdoor)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   -0.51577    0.53536  -0.963  0.33534    \nage_mc        -0.22584    0.04214  -5.359 8.35e-08 ***\nbac100         0.35002    0.11128   3.145  0.00166 ** \nconditionHigh -1.59215    0.54008  -2.948  0.00320 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 166.06  on 119  degrees of freedom\nResidual deviance: 100.99  on 116  degrees of freedom\nAIC: 108.99\n\nNumber of Fisher Scoring iterations: 5\n\n\n\n\n\n\n\nQuestion 6\n\n\nConduct a model comparison of your model above against the null model. Report the results of the model comparison in APA format.\n\n\n\n\n\n\nHint\n\n\n\n\n\nConsider whether or not your models are nested. The flowchart in Question 10 of the Semester 2 Week 1 lab may be helpful to revisit.\n\n\n\n\n\n\n\n Solution \n\n\n\n#fit null model\nchangeblind_mdl_null &lt;- glm(notice ~ 1, data = drunkdoor, family = \"binomial\")\n\n#run model comparison\nanova(changeblind_mdl_null, changeblind_mdl, test= \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: notice ~ 1\nModel 2: notice ~ age_mc + bac100 + condition\n  Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    \n1       119     166.06                          \n2       116     100.99  3   65.065 4.857e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nAt the 5% significance level, the addition of information about the participants’ age, BAC, and perceptual load resulted in a significant decrease in model deviance \\(\\chi^2(3) = 65.07, p &lt; .001\\).\nHence, we have strong evidence that the participants’ age, BAC, and perceptual load condition are helpful predictors of whether or not they were likely to notice a mid-conversation swap.\n\n\n\n\n\n\n\n\nQuestion 7\n\n\nInterpret your coefficients in the context of the study. When doing so, it may be useful to translate the log-odds back into odds.\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe opposite of the natural logarithm is the exponential, and in R these functions are log() and exp().\nRecall that we can obtain our parameter estimates using various functions such as summary(),coef(), coefficients(), etc. Thus, we want to exponentiate the coefficients from our model in order to translate them back from log-odds.\n\n\n\n\n\n\n\n Solution \n\n\n\nexp(coefficients(changeblind_mdl))\n\n  (Intercept)        age_mc        bac100 conditionHigh \n    0.5970388     0.7978495     1.4190910     0.2034874 \n\n\n\n\n\\(\\beta_0\\) = (Intercept) = 0.6\n\nThe odds of noticing a mid-conversation person-switch for a sober person of average age, with Low perceptual load was 0.60.\n\n\n\n\\(\\beta_1\\) = age_mc = 0.8\n\nFor every year older someone was, the odds of noticing a mid-conversation swap reduced by a factor of 0.80, after accounting for differences in blood alcohol levels and perceptual load.\n\n\n\n\\(\\beta_2\\) = bac100 = 1.42\n\nFor every 1/100th of a percentage increase in BAC, the odds of noticing a mid-conversation person switch increased by a factor of 1.42, after accounting for differences in age and perceptual load.\n\n\n\n\\(\\beta_3\\) conditionHigh = 0.2\n\nThe odds of noticing the swap were significantly different depending upon the perceptual load. For those in the High perceptual condition, the odds of noticing a change decreased by a factor of 0.20, after accounting for differences in age and BAC."
  },
  {
    "objectID": "2_06_glm1.html#visualise-model",
    "href": "2_06_glm1.html#visualise-model",
    "title": "Binary Logistic Regression",
    "section": "Visualise Model",
    "text": "Visualise Model\n\nQuestion 8\n\n\nPlot the predicted model estimates.\n\n\n\n\n\n\nHint\n\n\n\n\n\nHere you will need to use plot_model() from the sjPlot package. To get your estimates, you will need to specify type = \"est\".\n\n\n\n\n\n\n\n Solution \n\n\nplot_model() with type = \"est\" gives a nice way of visualising the model odds ratios and confidence intervals:\n\nplot_model(changeblind_mdl,\n           type = \"est\")\n\n\n\nFigure 5: Model Estimates"
  },
  {
    "objectID": "2_06_glm1.html#writing-up-presenting-results",
    "href": "2_06_glm1.html#writing-up-presenting-results",
    "title": "Binary Logistic Regression",
    "section": "Writing Up & Presenting Results",
    "text": "Writing Up & Presenting Results\n\nQuestion 9\n\n\nProvide key model results in a formatted table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse tab_model() from the sjPlot package.\nRemember that you can rename your DV and IV labels by specifying dv.labels and pred.labels.\n\n\n\n\n\n\n\n Solution \n\n\n\n#create table for results\ntab_model(changeblind_mdl,\n          dv.labels = \"Notice\",\n          pred.labels = c(\"age_mc\" = \"Age (in years)\",\n                          \"bac100\" = \"Blood Alcohol Level (BAC)\",\n                          \"conditionHigh\" = \"Condition - High\"),\n          title = \"Regression table for Notice Model\")\n\n\n\nTable 2: Regression table for Notice model\n\n\n \nNotice\n\n\nPredictors\nOdds Ratios\nCI\np\n\n\n(Intercept)\n0.60\n0.20 – 1.69\n0.335\n\n\nAge (in years)\n0.80\n0.73 – 0.86\n&lt;0.001\n\n\nBlood Alcohol Level (BAC)\n1.42\n1.15 – 1.79\n0.002\n\n\nCondition - High\n0.20\n0.07 – 0.56\n0.003\n\n\nObservations\n120\n\n\nR2 Tjur\n0.475\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nInterpret your results in the context of the research question and report your model in full.\nMake reference to the your regression table.\n\n\n\n\n Solution \n\n\n\n\n\n\n\n\nWhether or not participants noticed the swap mid-conversation (binary 0 vs 1) was modeled using logistic regression, with blood alcohol content (BAC; measured in 100th of percentages blood content), perceptual load condition (low load vs high load, with low as the reference level), and age (in years). See Table 2 for full model results, and Figure 5 for a visualisation of the model estimates and confidence intervals.\nAge was found to be associated with susceptibility to change-blindness, as indicated by decreased odds of noting the mid-conversation swap (\\(OR = 0.8,\\,\\, 95\\%\\, CI\\, [0.73, 0.86]\\)), after accounting for differences in blood alcohol levels and perceptual load.\nIn contrary to what might have been expected, change-blindness appeared to decrease with higher alcohol intoxication, with the odds of noticing the swap increasing 1.42 times (\\(95\\%\\, CI\\,[1.15, 1.79]\\)) for every 1/100th of a percentage increase in blood alcohol content, holding age and perceptual load constant.\nAfter accounting for age and blood alcohol levels, the odds of noticing the swap were significantly different depending upon the perceptual load. For those with a high perceptual load, the odds of noticing a swap decreased by a factor of 0.2 (\\(95\\%\\, CI\\,[0.07, 0.56]\\)).\nIn summary, older age increased the susceptibility to change blindness, high perceptual load was found to decrease the chances of people being blind to change, and increased levels of alcohol intoxication appeared to be associated with a greater chance of noticing change."
  },
  {
    "objectID": "2_07_glm2.html",
    "href": "2_07_glm2.html",
    "title": "More Logistic Regression",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand when to use a logistic model\nUnderstand how to fit and interpret a logistic model\nUnderstand how to evaluate model fit\n\n\nBe up to date with lectures\nHave completed previous lab exercises from Week 6\n\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npatchwork\nkableExtra\npsych\nsjPlot\n\nAll results should be presented following APA guidelines. If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/QuitAttempts.csv."
  },
  {
    "objectID": "2_07_glm2.html#study-analysis-plan-overview",
    "href": "2_07_glm2.html#study-analysis-plan-overview",
    "title": "More Logistic Regression",
    "section": "Study & Analysis Plan Overview",
    "text": "Study & Analysis Plan Overview\n\nQuestion 1\n\n\nExamine the dataset, and perform any necessary and appropriate data management steps.\n\n\n\n\n Solution \n\n\n\n#look at structure of data:\nstr(smoke)\n\nspc_tbl_ [62 × 3] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ S: num [1:62] 1 2 3 4 5 6 7 8 9 10 ...\n $ Q: num [1:62] 0 1 1 0 1 1 1 0 1 0 ...\n $ I: num [1:62] 1 3 2 1 2 2 3 3 3 2 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   S = col_double(),\n  ..   Q = col_double(),\n  ..   I = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n#check for NAs - there are none - all FALSE:\ntable(is.na(smoke))\n\n\nFALSE \n  186 \n\n#re-name variables to improve clarity:\nsmoke &lt;- smoke %&gt;%\n    rename(PID = S,\n           Quit_Attempt = Q,\n           Intention = I)\n\n#re-assign categorical IVs as factors, and give more appropriate labels to each level:\nsmoke$Intention &lt;- factor(smoke$Intention,\n                              levels = c(1,2,3,4),\n                              labels = c(\"Never\", \"Maybe (not in next 6 months)\", \"Yes (within next 6 months)\", \"Yes (within next 30 days)\"))"
  },
  {
    "objectID": "2_07_glm2.html#descriptive-statistics-visualisations",
    "href": "2_07_glm2.html#descriptive-statistics-visualisations",
    "title": "More Logistic Regression",
    "section": "Descriptive Statistics & Visualisations",
    "text": "Descriptive Statistics & Visualisations\n\nQuestion 2\n\n\nProvide a table of descriptive statistics and visualise your data.\nRemember to interpret these in the context of the study.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nFor your table of descriptive statistics, since we have two categorical variables, the select() and table() functions will come in handy here.\nRecall that when visualising a continuous outcome across several groups, geom_boxplot() may be most appropriate to use.\nFor your visualisations, you will need to specify as_factor() when plotting the Quit_Attempt variable since this is numeric, but we want it to be treated as a factor only for plotting purposes\nMake sure to comment on any observed differences among the sample means of the four treatment conditions.\n\n\n\n\n\n\n\n\n Solution \n\n\n\n\nNumeric\nVisual\n\n\n\nLet’s first produce a descriptive statistics table:\n\nsmoke_stats &lt;- smoke %&gt;%\n    select(Intention, Quit_Attempt) %&gt;%\n    table() %&gt;%\n    kable(caption = \"Descriptive Statistics\") %&gt;%\n    kable_styling()\n\nsmoke_stats\n\n\n\nTable 1: Descriptive Statistics\n\n\n0\n1\n\n\n\nNever\n7\n1\n\n\nMaybe (not in next 6 months)\n9\n17\n\n\nYes (within next 6 months)\n5\n18\n\n\nYes (within next 30 days)\n1\n4\n\n\n\n\n\n\n\n\nOr alternatively we could view as proportions:\n\nsmoke_prop &lt;- smoke %&gt;%\n  group_by(Intention, Quit_Attempt) %&gt;%\n  summarise(\n    n = n()) %&gt;%\n  mutate(\n    Prop = round(n/sum(n),2)\n  ) %&gt;%\n    kable(caption = \"Proportions\") %&gt;%\n    kable_styling()\n\nsmoke_prop \n\n\n\nTable 2: Proportions\n\nIntention\nQuit_Attempt\nn\nProp\n\n\n\nNever\n0\n7\n0.88\n\n\nNever\n1\n1\n0.12\n\n\nMaybe (not in next 6 months)\n0\n9\n0.35\n\n\nMaybe (not in next 6 months)\n1\n17\n0.65\n\n\nYes (within next 6 months)\n0\n5\n0.22\n\n\nYes (within next 6 months)\n1\n18\n0.78\n\n\nYes (within next 30 days)\n0\n1\n0.20\n\n\nYes (within next 30 days)\n1\n4\n0.80\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBased on the proportions presented in Table 2, we can see for those who had some intention to quit (i.e., maybe - not in next 6 months, yes - within next 6 months, or yes - within 30 days), there was a larger proportion of individuals who attempted to quit using tobacco products.\n\n\n\n\n\nWe can visually explore the association between the two categorical variables as follows:\n\nsmoke_plt1 &lt;- ggplot(data = smoke, aes(x=as_factor(Quit_Attempt), fill=Intention)) +\n  geom_bar(position = \"dodge\") +\n  labs(fill = 'Intention to Quit', x = \"Attempted Quitting (0 = No, 1 = Yes)\")\nsmoke_plt1\n\n\n\nFigure 1: Association between Intention and Quitting Attempt\n\n\n\n\n\n\n\n\n\nFrom Figure 1, we can see that for those who made an attempt to quit using tobacco products, the majority intended to quit - either in the immediate or distant future. For those who made no attempt to quit using tobacco products, the majority either had no intention of quitting or did not plan to quit in the near future."
  },
  {
    "objectID": "2_07_glm2.html#model-fitting-interpretation",
    "href": "2_07_glm2.html#model-fitting-interpretation",
    "title": "More Logistic Regression",
    "section": "Model Fitting & Interpretation",
    "text": "Model Fitting & Interpretation\n\nQuestion 3\n\n\nFit your model using glm(), and assign it as an object with the name “smoke_mdl1”.\n\n\n\n\n Solution \n\n\n\nsmoke_mdl1 &lt;- glm(Quit_Attempt ~ Intention, data = smoke, family = \"binomial\")\nsummary(smoke_mdl1)\n\n\nCall:\nglm(formula = Quit_Attempt ~ Intention, family = \"binomial\", \n    data = smoke)\n\nCoefficients:\n                                      Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)                             -1.946      1.069  -1.820  0.06872 . \nIntentionMaybe (not in next 6 months)    2.582      1.146   2.253  0.02423 * \nIntentionYes (within next 6 months)      3.227      1.183   2.729  0.00636 **\nIntentionYes (within next 30 days)       3.332      1.547   2.154  0.03123 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 80.648  on 61  degrees of freedom\nResidual deviance: 68.659  on 58  degrees of freedom\nAIC: 76.659\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\n\n\n\nQuestion 4\n\n\nInterpret your coefficients in the context of the study. When doing so, it may be useful to translate the log-odds back into odds.\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe opposite of the natural logarithm is the exponential (see here for more details if you are interested), and in R these functions are log() and exp().\nRecall that we can obtain our parameter estimates using various functions such as summary(),coef(), coefficients(), etc. Thus, we want to exponentiate the coefficients from our model in order to translate them back from log-odds.\n\n\n\n\n\n\n\n Solution \n\n\n\nexp(coefficients(smoke_mdl1))\n\n                          (Intercept) IntentionMaybe (not in next 6 months) \n                            0.1428571                            13.2222222 \n  IntentionYes (within next 6 months)    IntentionYes (within next 30 days) \n                           25.2000000                            28.0000000 \n\n\n\n\n\\(\\beta_0\\) = (Intercept) = 0.14\n\nFor a participant who reported that they “never intend to quit”, the probability that they did attempt quitting was 0.14 times the probability that they did not.\n\n\n\n\\(\\beta_1\\) = Intention Maybe (not in next 6 months) = 13.22\n\nRelative to those who “never intend to quit”, reporting an “intention to quit but not in the next 6 months” meant that an individuals odds of attempting to quit increased by a factor of 13.2.\n\n\n\n\\(\\beta_2\\) = Intention Yes (within next 6 months) = 25.2\n\nRelative to those who “never intend to quit”, reporting an “intention to quit in the next 6 months” increased the odds of attempting to quit by a factor of 25.2.\n\n\n\n\\(\\beta_3\\) Intention Yes (within next 30 days) = 28\n\nRelative to those who “never intend to quit”, reporting an “intention to quit in the next 30 days” was associated with an increase in the odds of attempting to quit by a factor of 28."
  },
  {
    "objectID": "2_07_glm2.html#model-fit",
    "href": "2_07_glm2.html#model-fit",
    "title": "More Logistic Regression",
    "section": "Model Fit",
    "text": "Model Fit\n\nQuestion 5\n\n\nExamine the below plot to determine if the deviance residuals raise concerns about outliers:\n\nplot(rstandard(smoke_mdl1, type = 'deviance'), ylab = 'Standardised Deviance Residuals')\n\n\n\n\n\n\n\nBased on this plot, are there any residuals of concern? Are there any additional plots you could check to determine if there are influential observations?\n\n\n\n\n\n\nHint\n\n\n\n\n\nDeviance Residuals\nBecause logistic regression models don’t have the same expected error distribution (we don’t expect residuals to be normally distributed around the mean, with constant variance), checking the assumptions of logistic regression is a little different.\nTypically, we look at the “deviance residuals”. But we don’t examine plots for patterns, we simply examine them for potentially outlying observations. If we use a standardised residual, it makes it easier to explore extreme values as we expect most residuals to be within -2, 2 or -3, 3 (depending on how strict we feel).\nCook’s Distance\nTo check for influential observations, we can use cooks.distance(), and plot this using plot(). Alternatively, you can specify which = 4 when plotting your fitted model. In logistic regression, we can use the arbitrary cut-offs of 0.5 (moderately influential) or 1 (highly influential) to describe influential points.\n\n\n\n\n\n\n\n Solution \n\n\nIn the plot above, there appears to be 1 residual with a value &gt;|2|, but none with a value &gt;|3|. We will keep this in mind and check if they are also an influential point by plotting Cook’s Distance:\n\n#cooks d - option 1 (only need to use one of these two options)\nplot(cooks.distance(smoke_mdl1), ylab = \"Cook's Distance\")\n\n\n\n\n\n\n#cooks d - option 2 (only need to use one of these two options)\nplot(smoke_mdl1, which = 4)\n\n\n\n\n\n\n\nThere doesn’t appear to be any influential observations based on our Cook’s distance plot, since all values &lt; .50.\n\n\n\n\n\nQuestion 6\n\n\nPerform a Deviance goodness-of-fit test to compare your fitted model to the null.\n\\[\n\\begin{aligned}\nM_0 &: \\qquad \\log \\left( \\frac{p}{1 - p}\\right) = \\beta_0 \\\\\nM_1 &: \\qquad \\log \\left( \\frac{p}{1 - p}\\right) = \\beta_0 + \\beta_1 Intention2 + \\beta_2 Intention3 + \\beta_3 Intention4\n\\end{aligned}\n\\]\nReport which model you think best fits the data.\n\n\n\n\n\n\nHint\n\n\n\n\n\nConsider whether or not your models are nested. The flowchart in Question 10 of the Semester 2 Week 1 lab may be helpful to revisit.\n\n\n\n\n\n\n\n Solution \n\n\nFirst, let’s fit the null model:\n\nsmoke_mdl0 &lt;- glm(Quit_Attempt ~ 1, data = smoke, family = \"binomial\")\nsummary(smoke_mdl0)\n\n\nCall:\nglm(formula = Quit_Attempt ~ 1, family = \"binomial\", data = smoke)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept)   0.5978     0.2654   2.252   0.0243 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 80.648  on 61  degrees of freedom\nResidual deviance: 80.648  on 61  degrees of freedom\nAIC: 82.648\n\nNumber of Fisher Scoring iterations: 4\n\n\nSince our models are nested, we can compare using the likelihood ratio test:\n\nanova(smoke_mdl0, smoke_mdl1, test = 'Chisq')\n\nAnalysis of Deviance Table\n\nModel 1: Quit_Attempt ~ 1\nModel 2: Quit_Attempt ~ Intention\n  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)   \n1        61     80.648                        \n2        58     68.659  3   11.989  0.00742 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nAt the 5% significance level, the addition of information about the participants’ intention to quit resulted in a significant decrease in model deviance \\(\\chi^2(3) = 11.99, p = .007\\).\nHence, we have strong evidence that the model the subjects’ intention to quit is a helpful predictor of whether or not they will attempt quitting in the future.\n\n\n\n\n\n\n\n\nQuestion 7\n\n\nCheck the AIC and BIC values for smoke_mdl0 and smoke_mdl1 - which model should we prefer?\n\n\n\n\n Solution \n\n\n\n#AIC\nAIC(smoke_mdl0, smoke_mdl1)\n\n           df      AIC\nsmoke_mdl0  1 82.64844\nsmoke_mdl1  4 76.65904\n\n#BIC\nBIC(smoke_mdl0, smoke_mdl1)\n\n           df      BIC\nsmoke_mdl0  1 84.77557\nsmoke_mdl1  4 85.16758\n\n\n\n\n\n\n\n\nWe used AIC and BIC model selection to distinguish between two possible models describing the association between attempting to quit and intentions. Our model with with intentions included as a predictor (AIC = 76.66) was better fitting than the null model (AIC = 82.65). However, the BIC values suggested that the model including intentions (BIC = 85.17) was a poorer fit than the null (BIC = 84.77). Based on the weight of evidence from both the Deviance goodness-of-fit test alongside the AIC and BIC values, we would conclude that the model with intentions was better fitting than the null."
  },
  {
    "objectID": "2_07_glm2.html#visualise-model",
    "href": "2_07_glm2.html#visualise-model",
    "title": "More Logistic Regression",
    "section": "Visualise Model",
    "text": "Visualise Model\n\nQuestion 8\n\n\nPlot the following:\n\npredicted model estimates\npredicted probability\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nHere you will need to use plot_model() from the sjPlot package. To get your estimates, you will need to specify type = \"est\", and for predicted probability, type = \"eff\".\n\n\n\n\n\n\n\n Solution \n\n\n\n\nPredicted model estimates\nPredicted probability\n\n\n\nplot_model() with type = \"est\" gives a nice way of visualising the model odds ratios and confidence intervals:\n\nplot_model(smoke_mdl1,\n           type = \"est\")\n\n\n\nFigure 2: Model Estimates\n\n\n\n\n\nplot_model() with type = \"eff\" allows us to visualise the predicted probability based on our model estimates:\n\nplot_model(smoke_mdl1,\n           type = \"eff\")\n\n$Intention\n\n\n\n\nFigure 3: Predicted Probability"
  },
  {
    "objectID": "2_07_glm2.html#writing-up-presenting-results",
    "href": "2_07_glm2.html#writing-up-presenting-results",
    "title": "More Logistic Regression",
    "section": "Writing Up & Presenting Results",
    "text": "Writing Up & Presenting Results\n\nQuestion 9\n\n\nProvide key model results in a formatted table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse tab_model() from the sjPlot package.\nRemember that you can rename your DV and IV labels by specifying dv.labels and pred.labels.\n\n\n\n\n\n\n\n Solution \n\n\n\n#create table for results\ntab_model(smoke_mdl1,\n          dv.labels = \"Attempt to quit using tobacco products\",\n          pred.labels = c(\"Maybe (not in next 6 months)\" = \"Intend to quit but not in the next 6 months\",\n                          \"Yes (within next 6 months)\" = \"Intend to quit in the next 6 months\",\n                          \"Yes (within next 30 days)\" = \"Intend to quit in the next 30 days\"),\n          title = \"Regression table for Smoking Model\")\n\n\n\nTable 3: Regression table for Smoking Model\n\n\n \nAttempt to quit using tobacco products\n\n\nPredictors\nOdds Ratios\nCI\np\n\n\n(Intercept)\n0.14\n0.01 – 0.80\n0.069\n\n\nIntentionMaybe (not in next 6 months)\n13.22\n1.93 – 268.17\n0.024\n\n\nIntentionYes (within next 6 months)\n25.20\n3.42 – 534.12\n0.006\n\n\nIntentionYes (within next 30 days)\n28.00\n1.95 – 1181.69\n0.031\n\n\nObservations\n62\n\n\nR2 Tjur\n0.192\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nInterpret your results in the context of the research question and report your model in full.\n\n\n\n\n Solution \n\n\n\n\n\n\n\n\nWhether or not participants made an attempt to quit using tobacco products (binary 0 vs 1; 0 no attempt to quit, 1 attempted to quit) was modeled using logistic regression, with intention to quit (‘never intend to quit’, ‘may intend to quit but not in the next 6 months’, ‘intend to quit in the next 6 months’, ‘intend to quit in the next 30 days’, with ‘never intend to quit’ as the reference level) as the only predictor. See Table 3 for full model results, and Figure 2 for a visualisation of the model estimates and confidence intervals.\nHaving no intention to quit was found to be associated with attempting to quit (\\(OR = 0.14,\\,\\, 95\\%\\, CI\\, [0.01, 0.8]\\)), where the probability that they did attempt to quit was 0.14 times the probability that they did not.\nRelative to those who never intend to quit, individuals who may intend to quit but not in the next six months had increased odds of attempting to quit (\\(OR = 13.22,\\,\\, 95\\%\\, CI\\, [1.93, 268.17]\\)).\nIn comparison to those with no intention to quit, those who intended to quit in the next six months had their the odds of quitting increased by a factor of 25.2 (\\(95\\%\\, CI\\, [3.42, 534.12]\\))\nFinally, intending to quit in the next 30 days was associated with an increase in the odds of attempting to quit by a factor of 28 (\\(95\\%\\, CI\\, [1.95, 1181.69]\\)) in comparison to those who never intended to quit.\nIn summary, the closer in the future someone intended to quit smoking, the higher their odds of attempting to quit using tobacco products (see Figure 3)."
  },
  {
    "objectID": "2_09_power.html",
    "href": "2_09_power.html",
    "title": "Sample Size and Power Analysis",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand how varying factors can influence power\nBe able to conduct power analyses using the pwr package\n\n\nBe up to date with lectures\nHave completed previous lab exercises from Week X and Week X\n\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\nkableExtra\npwr\n\nAll results should be presented following APA guidelines. If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the rmd bootcamp.\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/recall_med_coast.csv."
  },
  {
    "objectID": "2_09_power.html#study-overview-data-management",
    "href": "2_09_power.html#study-overview-data-management",
    "title": "Sample Size and Power Analysis",
    "section": "Study Overview & Data Management",
    "text": "Study Overview & Data Management\n\nQuestion 1\n\n\nFirst, provide a brief overview of the study design and data.\nNext examine the dataset, and perform any necessary and appropriate data management steps.\n\n\n\n\n Solution \n\n\nSummary of study design and data:\n\n\n\n\n\n\nThe recdata dataset contained information on 100 hypothetical participants who participated in a between-subjects experiment exploring the associations among recall, age, and intervention type. Participants were aged 18-75 years old, and were randomly allocated to one of two intervention groups (exciting - 1-hour long roller-coaster session; or relaxing - 1-hour long meditation session) before completing a free-recall test (% correct).\n\n\n\nNext, data checks & management:\n\n#look at structure of data:\nstr(recdata)\n\nspc_tbl_ [100 × 3] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ perc_recall: num [1:100] 47.4 61.4 50.1 56.4 57 ...\n $ group      : num [1:100] 0 1 0 1 1 0 1 1 1 0 ...\n $ age        : num [1:100] 52 37 46 72 46 69 70 53 41 26 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   perc_recall = col_double(),\n  ..   group = col_double(),\n  ..   age = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n#check for NAs - there are none - all FALSE:\ntable(is.na(recdata))\n\n\nFALSE \n  300 \n\n#Group should be a factor:\nrecdata$group &lt;- factor(recdata$group, \n                        levels = c(0, 1), \n                        labels = c('rollercoaster', 'meditation'))\n\n\n\n\n\n\n\nThe ‘group’ variable denoting which intervention type participants were allocated to was coded as a factor with two levels - ‘rollercoaster’ and ‘meditation’, where ‘rollercoaster’ was designated as the reference group. There were no NAs contained within the dataset, and recall scores were within range (i.e., within possible values of 0-100), as were ages (i.e., all ages ranged from 18-75)."
  },
  {
    "objectID": "2_09_power.html#descriptive-statistics-visualisations",
    "href": "2_09_power.html#descriptive-statistics-visualisations",
    "title": "Sample Size and Power Analysis",
    "section": "Descriptive Statistics & Visualisations",
    "text": "Descriptive Statistics & Visualisations\n\nQuestion 2\n\n\nProvide a table of descriptive statistics and visualise your data.\nRemember to interpret your plot in the context of the study.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nFor your table of descriptive statistics, both the group_by() and summarise() functions will come in handy here.\nRecall that when visualising a continuous outcome across groups, geom_boxplot() may be most appropriate to use.\nMake sure to comment on any observed differences among the sample means of the four treatment conditions.\n\n\n\n\n\n\n\n\n Solution \n\n\nLet’s first produce a descriptive statistics table:\n\nrecall_stats &lt;- recdata %&gt;%\n    group_by(group) %&gt;%\n    summarise(\n       n = n(),\n       Avg_Age = mean(age),\n       Avg_Recall = mean(perc_recall)) %&gt;%\n    kable(caption = \"Descriptive Statistics\", digits = 2) %&gt;%\n    kable_styling()\n\nrecall_stats\n\n\n\nTable 1: Descriptive Statistics\n\ngroup\nn\nAvg_Age\nAvg_Recall\n\n\n\nrollercoaster\n53\n47.85\n50.11\n\n\nmeditation\n47\n46.57\n59.46\n\n\n\n\n\n\n\n\nWe can visually explore the association between Recall and the two predictor variables as follows:\n\nrecall_plt1 &lt;- ggplot(data = recdata, aes(x = group, y = perc_recall, fill = group)) +\n    geom_boxplot() + \n    labs(x = \"Intervention Group\", y = \"Recall (%)\", title = \"Association between Recall and Intervention\")\nrecall_plt1\n\n\n\nFigure 1: Association between Recall and Intervention Group\n\n\n\n\nrecall_plt2 &lt;- ggplot(data = recdata, aes(x = age, y = perc_recall)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", se = FALSE) + \n    labs(x = \"Age (in years)\", y = \"Recall (%)\", title = \"Association between Recall and Age\")\nrecall_plt2\n\n\n\nFigure 2: Association between Recall and Age\n\n\n\nFrom Table 1, Figure 1, and Figure 2 we can see:\n\nthere were more participants in the rollercoaster condition than meditation\nparticipants in the meditation condition had higher recall scores than those in the rollercoaster condition\nthere was less variability in scores in the meditation condition in comparison to the rollercoaster condition\nolder age appeared to be associated with lower recall scores\n\n\n\n\n\n\nQuestion 3\n\n\nUse a scatterplot to visualise the association between recall and age by group.\nIs there any evidence of an interaction between age and group?\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nIt might be useful to specify the color = argument for your grouping variable\nConsider using geom_smooth() to superimpose the best-fitting line describing the association of interest for each intervention group.\n\n\n\n\n\n\n\n\n Solution \n\n\n\nrecall_plt3 &lt;- ggplot(data = recdata, aes(x = age, y = perc_recall, color = group)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", se = FALSE) + \n    labs(x = \"Age (in years)\", y = \"Recall (%)\", title = \"Associations among Recall Score, \\nAge, and Intervention Group\")\nrecall_plt3\n\n\n\nFigure 3: Scatterplot displaying the association between age, intervention group, and recall\n\n\n\nThe slope in Figure 3 appears to be stepper in the roller coaster intervention group than the meditation group - this suggests that there could be an interaction."
  },
  {
    "objectID": "2_09_power.html#sample-size-power",
    "href": "2_09_power.html#sample-size-power",
    "title": "Sample Size and Power Analysis",
    "section": "Sample Size & Power",
    "text": "Sample Size & Power\n\nQuestion 4\n\n\nUsing a significance level (\\(\\alpha\\)) of .05, what sample size (\\(n\\)) would you require to check whether any of the predictors (and interaction) influenced recall scores with a 90% chance?\nBecause you do not know the effect size, assume Cohen’s guideline for linear regression and, to be on the safe side, consider the ‘small’ value.\n\n\n\n\n\n\nHint\n\n\n\n\n\nIn linear regression, the relevant function in R is:\n\npwr.f2.test(u = , v = , f2 = , sig.level = , power = )\n\nWhere:\n\n\nu = numerator degrees of freedom = number predictors in the model (\\(k\\))\n\nv = denominator degrees of freedom = \\(v = n-k-1\\)\n\n\nf2 = effect size. Cohen suggests effect size cut-off values of \\(.02\\) (small), \\(.15\\) (moderate), and \\(.35\\) (large)\n\nsig.level = significance level\n\npower = level of power\n\n\n\n\n\n\n\n\n Solution \n\n\n\nk &lt;- 3\nf2 &lt;- .02\npwr.f2.test(u = k, f2 = f2, sig.level = 0.05, power = 0.9)\n\n\n     Multiple regression power calculation \n\n              u = 3\n              v = 708.495\n             f2 = 0.02\n      sig.level = 0.05\n          power = 0.9\n\n\n\n\n\n\n\n\nA power analysis for a multiple regression model \\((k = 3)\\) was conducted (via the pwr package) to determine the minimum sample size using an \\(\\alpha\\) = .05, power = .90, and small effect size \\((D = .02)\\). The required sample size is \\(n = \\text v + k + 1 = 709 + 3 + 1 = 713\\).\n\n\n\n\n\n\n\n\nQuestion 5\n\n\nUsing the same \\(\\alpha\\) (.05) and power, what would be the sample size if you assumed effect size to be ‘medium’?\n\n\n\n\n\n\nHint\n\n\n\n\n\nIn linear regression, the relevant function in R is:\n\npwr.f2.test(u = , v = , f2 = , sig.level = , power = )\n\nWhere:\n\n\nu = numerator degrees of freedom = number predictors in the model (\\(k\\))\n\nv = denominator degrees of freedom = \\(v = n-k-1\\)\n\n\nf2 = effect size. Cohen suggests effect size cut-off values of \\(.02\\) (small), \\(.15\\) (moderate), and \\(.35\\) (large)\n\nsig.level = significance level\n\npower = level of power\n\n\n\n\n\n\n\n\n Solution \n\n\n\nk &lt;- 3\nf2 &lt;- .15\npwr.f2.test(u = k, f2 = f2, sig.level = 0.05, power = 0.9)\n\n\n     Multiple regression power calculation \n\n              u = 3\n              v = 94.48157\n             f2 = 0.15\n      sig.level = 0.05\n          power = 0.9\n\n\n\n\n\n\n\n\nA power analysis for a multiple regression model \\((k = 3)\\) was conducted (via the pwr package) to determine the minimum sample size using an \\(\\alpha\\) = .05, power = .90, and moderate effect size \\((D = .15)\\). The required sample size is \\(n = \\text v + k + 1 = 95 + 3 + 1 = 99\\).\n\n\n\n\n\n\n\n\nQuestion 6\n\n\nUsing the same \\(\\alpha\\) and power, what would be the sample size if you assumed effect size to be ‘large’?\n\n\n\n\n\n\nHint\n\n\n\n\n\nIn linear regression, the relevant function in R is:\n\npwr.f2.test(u = , v = , f2 = , sig.level = , power = )\n\nWhere:\n\n\nu = numerator degrees of freedom = number predictors in the model (\\(k\\))\n\nv = denominator degrees of freedom = \\(v = n-k-1\\)\n\n\nf2 = effect size. Cohen suggests effect size cut-off values of \\(.02\\) (small), \\(.15\\) (moderate), and \\(.35\\) (large)\n\nsig.level = significance level\n\npower = level of power\n\n\n\n\n\n\n\n\n Solution \n\n\n\nk &lt;- 3\nf2 &lt;- .35\npwr.f2.test(u = k, f2 = f2, sig.level = 0.05, power = 0.9)\n\n\n     Multiple regression power calculation \n\n              u = 3\n              v = 40.61744\n             f2 = 0.35\n      sig.level = 0.05\n          power = 0.9\n\n\n\n\n\n\n\n\nA power analysis for a multiple regression model \\((k = 3)\\) was conducted (via the pwr package) to determine the minimum sample size using an \\(\\alpha\\) = .05, power = .90, and large effect size \\((D = .35)\\). The required sample size is \\(n = \\text v + k + 1 = 41 + 3 + 1 = 45\\).\n\n\n\n\n\n\n\n\nQuestion 7\n\n\nFit the following model using lm(), and assign it as an object with the name “recall_mdl1”.\n\\[\n\\text{Recall} = \\beta_0 + \\beta_1 \\cdot Age  + \\epsilon \\\\\n\\]\nHow much variance in recall scores does the model explain?\n\n\n\n\n Solution \n\n\n\nrecall_mdl1 &lt;- lm(perc_recall ~ age, data = recdata)\nsummary(recall_mdl1)\n\n\nCall:\nlm(formula = perc_recall ~ age, data = recdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.0850  -4.7474   0.7331   4.6758  10.1733 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 62.16336    1.81984  34.159  &lt; 2e-16 ***\nage         -0.16206    0.03672  -4.414 2.61e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.494 on 98 degrees of freedom\nMultiple R-squared:  0.1658,    Adjusted R-squared:  0.1573 \nF-statistic: 19.48 on 1 and 98 DF,  p-value: 2.614e-05\n\n\nWe can see both the R-squared or Adjusted R-squared from the model summary() output. We can use either since we only have a single predictor. To be conservative, we might want to use the adjusted R-squared (0.16).\nThe model, with Age as a single predictor, explained approximately 16% of the variance in recall scores.\n\n\n\n\n\nQuestion 8\n\n\nImagine you found the R-squared that you computed above (Q6) in a paper, and you are using that to base your next study.\nA researcher believes that the inclusion of intervention group and its interaction with age should explain an extra 50% of the variation in recall scores.\nUsing a significance level of 5%, what sample size should you use for your next data collection in order to discover that effect with a power of 0.90?\n\n\n\n\n Solution \n\n\n\n# restricted model m - number of predictors & R-squared\nk &lt;- 1\nR2m &lt;- 0.16\n\n# full model M - number of predictors & R-squared\nK &lt;- 3\nR2M &lt;- 0.16 + 0.5\n\n# effect size - calculate f2\nf2 &lt;- (R2M - R2m) / (1 - R2M)\n\n#run test\npwr.f2.test(u = K - k, f2 = f2, sig.level = 0.05, power = 0.9)\n\n\n     Multiple regression power calculation \n\n              u = 2\n              v = 9.211914\n             f2 = 1.470588\n      sig.level = 0.05\n          power = 0.9\n\n\nThe sample size should be \\(n = \\text v + K + 1 = 10 + 3 + 1 = 14\\).\nWith such a big effect size, don’t be surprised it’s so small. When the effect size is much smaller, that will be harder to detect and you will require a bigger sample size.\n\n\n\n\n\nQuestion 9\n\n\nSuppose that the aforementioned researcher made a mistake, and issues a corrected statement in which they state that the inclusion of intervention group and its interaction with age should explain an extra 5% of the variation in recall scores.\nUsing a significance level of 5%, what sample size should you use for your next data collection in order to discover that effect with a power of 0.90?\n\n\n\n\n Solution \n\n\n\n# restricted model m - number of predictors & R-squared\nk &lt;- 1\nR2m &lt;- 0.16\n\n# full model M - number of predictors & R-squared\nK &lt;- 3\nR2M &lt;- 0.16 + 0.05\n\n# effect size - calculate f2\nf2 &lt;- (R2M - R2m) / (1 - R2M)\n\n# run test\npwr.f2.test(u = K - k, f2 = f2, sig.level = 0.05, power = 0.9)\n\n\n     Multiple regression power calculation \n\n              u = 2\n              v = 199.9608\n             f2 = 0.06329114\n      sig.level = 0.05\n          power = 0.9\n\n\nThe sample size should be \\(n = \\text v + K + 1 = 200 + 3 + 1 = 204\\).\nWith such a small effect size, we need a bigger sample size for us to detect it with high confidence.\n\n\n\n\n\nQuestion 10\n\n\nA colleague produces a visualisation of the joint relationship between sample size and effect size via a power curve (with coloured lines representing large, medium, and small effect sizes).\nBased on this, what feedback/comments might you share with them regarding sample size for their prospective study, and its relation to effect size?\n\n\n\n\nFigure 4: Linear Regression with power = 0.90 and alpha = 0.05\n\n\n\n\n\n\n\n Solution \n\n\nFrom Figure 4, to detect a large effect size (red line), they should aim to recruit ~50 participants, for a medium effect size ~100 (blue line). It is impossible to judge how many participants would be required to detect a small effect size (green line) - we would suggest that they conduct their own power calculation as it is too difficult to judge based on the figure alone.\nGenerally, if they want to be able to detect a medium-large effect with 90% power using \\(\\alpha = .05\\), it appears that there is little gain in recruiting a sample size &gt; ~110. However, if they want to be able to detect a small effect with 90% power using \\(\\alpha = .05\\), they are likely going to require a very large sample size.\nTo summarise the association between effect size and sample size, it appears that the smaller the effect you are trying to detect, the larger the sample size you will require."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Dr Umberto Noe\nDr Josiah King\nDr Emma Waterston\nDepartment of Psychology, The University of Edinburgh"
  },
  {
    "objectID": "about.html#the-team",
    "href": "about.html#the-team",
    "title": "About",
    "section": "",
    "text": "Dr Umberto Noe\nDr Josiah King\nDr Emma Waterston\nDepartment of Psychology, The University of Edinburgh"
  },
  {
    "objectID": "csstests.html",
    "href": "csstests.html",
    "title": "Tests",
    "section": "",
    "text": "learning obj\n\n\nimportant\n\n\nsticky\n\n\n\n\n\nr tips\n\n\nstatbox\n\n\ninterprtation interprtation interprtation\n\n\nQuestion\n\n\nquestion\nwhat is your name?\nwhat is your favourite colour?\n\n\n\n\n Solution \n\n\nsolution\nhello\n\n2+2\n\n[1] 4\n\n\n\n\n\n\n Optional hello my optional friend\n\n\nit’s nice to see you again\n\n\n\n\n\nthis is not a panel\n\n\nthis is a panel\n\n\nthis is a panel"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "Welcome to the Data Analysis for Psychology in R 2 (DAPR2) lab workbook. Using the menu above, you can find lab materials for each week."
  },
  {
    "objectID": "index.html#help-support-feedback",
    "href": "index.html#help-support-feedback",
    "title": "Home",
    "section": "Help, Support & Feedback",
    "text": "Help, Support & Feedback\n\nWithin Lab Workbook\n\nHints, Notes, and Example Write-Up / Interpretation\nHints are shown in a green box, with the title ‘Hint’. If you are unsure what to do, check the collapsible hint provided (note that these are only present for some questions).\n\n\n\n\n\n\nHint\n\n\n\n\n\nThis is an example of a hint.\n\n\n\nNotes are displayed in blue boxes, with the title ‘Note’. These are occasionally used to draw your attention to a specific point.\n\n\n\n\n\n\nNote\n\n\n\nThis is an example of a note.\n\n\nExample write-ups and/or interpretations are shown with a red right border. These are helpful to check your interpretation against, and a useful guide to use in future when interpreting and/or writing up results.\n\n\n\n\n\n\nThis is an example write-up / interpretation block.\n\n\n\n\n\nSolutions\nSolutions are made available immediately below each exercise. To view solutions, click the drop down ‘Solution’ button.\nImportant  Before checking the solution you should attempt the question. You should also avoid copying and pasting code from the solutions. If you do check solutions right away and simply copy the answer, you will struggle to learn from the exercises.\nInstead, you should:\n\nTry to figure out the answer yourself or with your peers (and/or ask for help from a staff member if needed)\nType the code out yourself (and annotate your R code chunks so you know what your code is doing & why - future you will thank you for this).\n\n\n\n\nAsking Questions\n\nDuring labs, if you have a question, please ask one of the tutors for support.\nOutside of labs, we encourage you to use the various support options, details of which can be found on the Course Learn Page."
  },
  {
    "objectID": "index.html#tips-on-googling-statistics-and-r",
    "href": "index.html#tips-on-googling-statistics-and-r",
    "title": "Home",
    "section": "Tips on Googling Statistics and R",
    "text": "Tips on Googling Statistics and R\nSearching online for help with statistics and R can be both a help and a hindrance. If you have an error message in R, copy the error message into Google. The results returned can sometimes just cause more confusion, but sometimes something might jump out at you and help you solve the problem. The same applies with searching the internet for help with statistics - search for “what is a p-value”, and you’ll find many many different articles and forum discussions etc. Some of them you will find too technical, but don’t be scared - the vast majority of people work in statistics will find these too technical too. Some of them you might feel are too simple/not helpful. As a general guide, keep clicking around the search responses, and you may end up finding that someone, somewhere, has provided an explanation at the right level. If you find something during your search which you don’t quite understand, feel free to link it in a post on the discussion forum!"
  },
  {
    "objectID": "index.html#feedback-on-labs",
    "href": "index.html#feedback-on-labs",
    "title": "Home",
    "section": "Feedback on Labs",
    "text": "Feedback on Labs\nIf you wish to make suggestions for improvements to these workbooks (or if you spot any typos!), please email ppls.psych.stats@ed.ac.uk making sure to include the course name in the subject."
  }
]