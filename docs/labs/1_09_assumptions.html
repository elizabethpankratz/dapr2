<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Assumptions &amp; Diagnostics</title>

<script src="site_libs/header-attrs-2.12/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/united.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
<script>
function toggle_visibility(id1, id2) {
var e = document.getElementById(id1);
var f = document.getElementById(id2);
e.style.display = ((e.style.display!='none') ? 'none' : 'block');
if(f.classList.contains('fa-chevron-circle-right')) {
    f.classList.add('fa-chevron-circle-down')
    f.classList.remove('fa-chevron-circle-right')
} else {
    f.classList.add('fa-chevron-circle-right')
    f.classList.remove('fa-chevron-circle-down')
}
}
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>



<style type="text/css">
  code {
    white-space: pre;
  }
  .sourceCode {
    overflow: visible;
  }
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<link rel="stylesheet" href="assets/style-labs.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"><strong>DAPR2</strong></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Intro to Linear Models
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="1_01_models.html">1/1: Functions and models</a>
    </li>
    <li>
      <a href="1_02_slr.html">1/2: Intro to Linear Regression</a>
    </li>
    <li>
      <a href="1_03_slr_model_fit.html">1/3: More Linear Regression</a>
    </li>
    <li>
      <a href="1_04_mlr.html">1/4: Multiple Predictors</a>
    </li>
    <li>
      <a href="1_05_int_nc.html">1/5: Interactions: Num * Cat</a>
    </li>
    <li class="dropdown-header">1/6: Break week</li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    More Linear Models
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="1_07_int_nn.html">1/7: Interactions: Num * Num</a>
    </li>
    <li>
      <a href="1_08_int_cc.html">1/8: Interactions: Cat * Cat</a>
    </li>
    <li>
      <a href="1_09_assumptions.html">1/9: Assumptions &amp; Diagnostics</a>
    </li>
    <li>
      <a href="1_10_bootstrap_reg.html">1/10: Bootstrap &amp; Troubleshooting</a>
    </li>
    <li>
      <a href="1_11_write_up.html">1/11: Writing-up</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Analyzing Experimental Studies
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="2_01_model_comp.html">2/1: Model Comparisons</a>
    </li>
    <li>
      <a href="2_02_coding_factors.html">2/2: Coding Factors</a>
    </li>
    <li>
      <a href="2_03_cont_design_factanova.html">2/3: Contrasts, Study Design, &amp; Factorial ANOVA</a>
    </li>
    <li>
      <a href="2_04_factorial_anova.html">2/4: Two-Way ANOVA</a>
    </li>
    <li>
      <a href="2_05_multi_comp_writeup.html">2/5: Assumptions, Multiple Comparisons, Corrections, &amp; Write-Up Example</a>
    </li>
    <li class="dropdown-header">2/6: Break week</li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Advanced Topics for LM
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="2_07_binary.html">2/7: Binary Logistic Regression</a>
    </li>
    <li>
      <a href="2_08_morelogistic.html">2/8: More Logistic Regression</a>
    </li>
    <li>
      <a href="2_09_exp_vs_conf.html">2/9: Exploratory vs Confirmatory</a>
    </li>
    <li class="dropdown-header">2/10: </li>
    <li class="dropdown-header">2/11: </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Help
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="intro_r_rstudio.html">Getting started with R &amp; RStudio</a>
    </li>
  </ul>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Assumptions &amp; Diagnostics</h1>

</div>


<div class="red">
<p>In this lab, you will be provided with a comprehensive overview of linear regression assumptions and diagnostics. Therefore, whilst the lab might be appear rather lengthy, it will serve as a handy reference for you to use in the future and refer back to when needed.</p>
</div>
<div class="lo">
<p><strong>LEARNING OBJECTIVES</strong></p>
<ol style="list-style-type: decimal">
<li>Be able to state the assumptions underlying a linear model.</li>
<li>Specify the assumptions underlying a linear model with multiple predictors.</li>
<li>Assess if a fitted model satisfies the assumptions of your model.</li>
<li>Assess the effect of influential cases on linear model coefficients and overall model evaluations.</li>
</ol>
</div>
<div id="linear-model-assumptions" class="section level1">
<h1>Linear Model Assumptions</h1>
<p>In the previous labs, we have fitted a number of regression models, including some with multiple predictors. In each case, we first specified the model, then visually explored the marginal distributions and relationships of variables which would be used in the analysis. Finally, we fit the model, and began to examine the fit by studying what the various parameter estimates represented, and the spread of the residuals (the parts of the output inside the red boxes in Figure <a href="#fig:mlroutput">1</a>)</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:mlroutput"></span>
<img src="images/mlroutput.png" alt="Multiple regression output in R, summary.lm(). Residuals and Coefficients highlighted" width="60%" />
<p class="caption">
Figure 1: Multiple regression output in R, summary.lm(). Residuals and Coefficients highlighted
</p>
</div>
<p>But <strong>before</strong> we draw inferences using our model estimates or use our model to make predictions, we need to be satisfied that our model meets a specific set of assumptions. If these assumptions are not satisfied, the results will not hold.</p>
<div class="red">
All of the estimates, intervals and hypothesis tests (see Figure <a href="#fig:mlroutputhyp">2</a>) resulting from a regression analysis <em>assume</em> a certain set of conditions have been met. Meeting these conditions is what allows us to generalise our findings beyond our sample (i.e., to the population).<br />
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:mlroutputhyp"></span>
<img src="images/mlrhyp.png" alt="Multiple regression output in R, summary.lm(). Hypothesis tests highlighted" width="60%" />
<p class="caption">
Figure 2: Multiple regression output in R, summary.lm(). Hypothesis tests highlighted
</p>
</div>
</div>
<p>You can remember the four assumptions by memorising the acronym LINE:</p>
<ul>
<li>L - Linearity</li>
<li>I - Independence</li>
<li>N - Normality</li>
<li>E - Equal variance</li>
</ul>
<p>If at least one of these assumptions does not hold, say N - Normality, you might be reporting a <strong><em>LIE</em></strong>.
Recall the assumptions of the linear model:</p>
<ul>
<li><strong>L</strong>inearity: The relationship between <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span> is linear.</li>
<li><strong>I</strong>ndependence of errors: The error terms should be independent from one another.</li>
<li><strong>N</strong>ormality: The errors <span class="math inline">\(\epsilon\)</span> are normally distributed in the population.</li>
<li><strong>E</strong>qual variances (“Homoscedasticity”): The variability of the errors <span class="math inline">\(\epsilon\)</span> is constant across <span class="math inline">\(x\)</span>.</li>
</ul>
<p>Because we don’t have the data about the entire population, we check the assumptions on the errors by looking at their sample counterpart: the residuals from the fitted model = observed values - fitted values = <span class="math inline">\(y_i - \hat y_i\)</span>.<br />
The residuals <span class="math inline">\(\hat \epsilon_i\)</span> are the sample realisation of the actual, but unknown, true errors <span class="math inline">\(\epsilon_i\)</span> for the entire population. Because these same assumptions hold for a regression model with multiple predictors, we can assess them in a similar way. However, there are a number of important considerations.</p>
<div class="green">
<p>In this lab, we will check the assumptions of two models - one simple linear model, and one with multiple predictors, and assess whether these models meet the assumptions outlined above. We will be working with two different datasets that you have used in previous labs: <code>riverview</code> and <code>wellbeing</code>.</p>
</div>
</div>
<div id="guided-exercises" class="section level1">
<h1>Guided exercises</h1>
<div class="red">
<p>Open a new RMarkdown document.
Copy the code below to load in the tidyverse packages, read in the riverview.csv and wellbeing.csv datasets and fit the following two models:</p>
<p><span class="math display">\[
\begin{aligned}
M1&amp;: \quad \text{Income} = \beta_0 + \beta_1 \cdot \text{Education} + \epsilon \\
M2&amp;: \quad \text{Wellbeing} = \beta_0 + \beta_1 \cdot \text{Outdoor Time} + \beta_2 \cdot \text{Social Interactions} + \epsilon
\end{aligned}
\]</span></p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse) </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># read in the riverview data</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>rvdata <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="at">file =</span> <span class="st">&quot;https://uoepsy.github.io/data/riverview.csv&quot;</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># read in the wellbeing data</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>wbdata <span class="ot">&lt;-</span>  <span class="fu">read_csv</span>(<span class="at">file =</span> <span class="st">&quot;https://uoepsy.github.io/data/wellbeing.csv&quot;</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># fit the linear models: </span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>rv_mdl1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(income <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> education, <span class="at">data =</span> rvdata) <span class="co">#riverview model</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>wb_mdl1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(wellbeing <span class="sc">~</span> outdoor_time <span class="sc">+</span> social_int, <span class="at">data =</span> wbdata) <span class="co">#wellbeing model</span></span></code></pre></div>
<p><strong>Note:</strong> We have have forgone writing the <code>1</code> in <code>lm(y ~ 1 + x...</code>. The 1 just tells R that we want to estimate the Intercept, and it will do this by default even if we leave it out.</p>
</div>
<div id="linearity" class="section level2">
<h2>Linearity</h2>
<div class="frame">
<div id="simple-linear-regression" class="section level3">
<h3>Simple Linear Regression</h3>
<p>In simple linear regression (SLR) with only one explanatory variable, we could assess linearity through a simple scatterplot of the outcome variable against the explanatory. This would allow us to check if the errors have a mean of zero. If this assumption was met, the residuals would appear to be randomly scattered around zero.<br />
The rationale for this is that, once you remove from the data the linear trend, what’s left over in the residuals should not have any trend, i.e. have a mean of zero.</p>
</div>
<div id="multiple-regression" class="section level3">
<h3>Multiple Regression</h3>
<p>In multiple regression, however, it becomes more necessary to rely on diagnostic plots of the model residuals. This is because we need to know whether the relations are linear between the outcome and each predictor <em>after accounting for the other predictors in the model.</em></p>
<p>In order to assess this, we use <strong>partial-residual plots</strong> (also known as ‘component-residual plots’). This is a plot with each explanatory variable <span class="math inline">\(x_j\)</span> on the x-axis, and <strong>partial residuals</strong> on the y-axis.</p>
<p>Partial residuals for a predictor <span class="math inline">\(x_j\)</span> are calculated as:
<span class="math display">\[
\hat \epsilon + \hat \beta_j x_j
\]</span></p>
<p><strong>In R</strong> we can easily create these plots for all predictors in the model by using the <code>crPlots()</code> function from the <strong>car</strong> package.</p>
</div>
</div>
<div class="question-begin">
Question 1
</div>
<div class="question-body">
<p>Check if the fitted model satisfies the linearity assumption for <code>rv_mdl1</code>. Write a sentence summarising whether or not you consider the assumption to have been met. Justify your answer with reference to the plots.</p>
</div>
<p class="question-end">
</p>
<div class="solution-begin">
<span id="sol-start-85" class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-85&#39;, &#39;sol-start-85&#39;)"> Solution </span>
</div>
<div id="sol-body-85" class="solution-body" style="display: none;">
<p>As usual, there are multiple equivalent ways to check this. Below are a couple of possibilities.</p>
<p>Residuals vs fitted values:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(rv_mdl1, <span class="at">which =</span> <span class="dv">1</span>) <span class="co">#here what we need to see is that the red line is approximately horizontal at zero</span></span></code></pre></div>
<p><img src="1_09_assumptions_files/figure-html/unnamed-chunk-2-1.png" width="60%" style="display: block; margin: auto;" /></p>
<p>Some useful quantities:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>riverview_check <span class="ot">&lt;-</span> rvdata <span class="sc">%&gt;%</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">income_hat =</span> <span class="fu">predict</span>(rv_mdl1),</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">resid =</span> income <span class="sc">-</span> income_hat,</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<p>Residuals vs explanatory variable:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(riverview_check, <span class="fu">aes</span>(<span class="at">x =</span> income_hat, <span class="at">y =</span> resid)) <span class="sc">+</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>)</span></code></pre></div>
<p><img src="1_09_assumptions_files/figure-html/unnamed-chunk-4-1.png" width="60%" style="display: block; margin: auto;" />
<br>
Either of the above plots can be used to say:</p>
<div class="int">
<p>The residuals appear to be randomly scattered around zero, without showing any pattern with respect to the fitted values. Hence, there is no sign of violation of the zero-mean assumption.</p>
</div>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question 2
</div>
<div class="question-body">
<p>Create partial-residual plots for the <code>wb_mdl1</code> model.<br />
Remember to load the <strong>car</strong> package first. If it does not load correctly, it might mean that you have need to install it.</p>
<p>Write a sentence summarising whether or not you consider the assumption to have been met. Justify your answer with reference to the plots.</p>
</div>
<p class="question-end">
</p>
<div class="solution-begin">
<span id="sol-start-86" class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-86&#39;, &#39;sol-start-86&#39;)"> Solution </span>
</div>
<div id="sol-body-86" class="solution-body" style="display: none;">
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">crPlots</span>(wb_mdl1)</span></code></pre></div>
<p><img src="1_09_assumptions_files/figure-html/unnamed-chunk-5-1.png" width="85%" style="display: block; margin: auto;" /></p>
<div class="int">
<p>The smoother (the pink line) follows quite closely to a linear relationship (the dashed blue line), suggesting that the linearity assumption is met.</p>
</div>
</div>
<p class="solution-end">
</p>
</div>
<div id="equal-variances-homoscedasticity" class="section level2">
<h2>Equal variances (Homoscedasticity)</h2>
<div class="frame">
<p>The equal variances assumption is that the error variance <span class="math inline">\(\sigma^2\)</span> is constant across values of the predictor(s) <span class="math inline">\(x_1, \dots, x_k\)</span>, and across values of the fitted values <span class="math inline">\(\hat y\)</span>. This sometimes gets termed “Constant” vs “Non-constant” variance. Figures <a href="#fig:ncv1">3</a> &amp; <a href="#fig:ncv2">4</a> shows what these look like visually.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ncv1"></span>
<img src="1_09_assumptions_files/figure-html/ncv1-1.png" alt="Non-constant variance for numeric and categorical x" width="90%" />
<p class="caption">
Figure 3: Non-constant variance for numeric and categorical x
</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ncv2"></span>
<img src="1_09_assumptions_files/figure-html/ncv2-1.png" alt="Constant variance for numeric and categorical x" width="90%" />
<p class="caption">
Figure 4: Constant variance for numeric and categorical x
</p>
</div>
<p><strong>In R</strong> we can create plots of the <em>Pearson residuals</em> against the predicted values <span class="math inline">\(\hat y\)</span> and against the predictors <span class="math inline">\(x_1\)</span>, … <span class="math inline">\(x_k\)</span> by using the <code>residualPlots()</code> function from the <strong>car</strong> package. This function also provides the results of a lack-of-fit test for each of these relationships (note when it is the fitted values <span class="math inline">\(\hat y\)</span> it gets called “Tukey’s test”).</p>
</div>
<div class="question-begin">
Question 3
</div>
<div class="question-body">
<p>Check if the fitted models <code>rv_mdl1</code> and <code>wb_mdl1</code> satisfy the equal variance assumption. Use <code>residualPlots()</code> to plot residuals against the predictor.</p>
<p>Write a sentence summarising whether or not you consider the assumption to have been met for each model. Justify your answer with reference to plots.</p>
</div>
<p class="question-end">
</p>
<div class="solution-begin">
<span id="sol-start-87" class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-87&#39;, &#39;sol-start-87&#39;)"> Solution </span>
</div>
<div id="sol-body-87" class="solution-body" style="display: none;">
<p>Let’s start with our <code>rv_mdl1</code> model. The vertical spread of the residuals should roughly be the same everywhere.</p>
<p>We can visually assess it by plotting the Pearson residuals against the fitted values:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">residualPlots</span>(rv_mdl1)</span></code></pre></div>
<p><img src="1_09_assumptions_files/figure-html/unnamed-chunk-6-1.png" width="90%" style="display: block; margin: auto;" /></p>
<pre><code>##            Test stat Pr(&gt;|Test stat|)
## education    -0.0744           0.9412
## Tukey test   -0.0744           0.9407</code></pre>
<p><strong>Quick Tip:</strong> As the residuals can be positive or negative, we can make it easier to assess equal spread by improving the ‘resolution’ of the points.</p>
<p>We can make all residuals positive by discarding the sign (take the absolute value), and then take the square root to make them closer to each other.</p>
<p>A plot of <span class="math inline">\(\sqrt{|\text{Standardized residuals}|}\)</span> against the fitted values is shown below:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(rv_mdl1, <span class="at">which =</span> <span class="dv">3</span>)</span></code></pre></div>
<p><img src="1_09_assumptions_files/figure-html/unnamed-chunk-7-1.png" width="60%" style="display: block; margin: auto;" /></p>
<p>The plot above has the points closer to each other, and all above 0. The line seems to be relatively flat (as it should be if the spread was constant).</p>
<div class="int">
<p>The spread of the standardized residuals appears to be constant as the fitted values vary.</p>
</div>
<p>Now for our <code>wb_mdl1</code> model:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co">#plot</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="fu">residualPlots</span>(wb_mdl1)</span></code></pre></div>
<p><img src="1_09_assumptions_files/figure-html/unnamed-chunk-8-1.png" width="90%" style="display: block; margin: auto;" /></p>
<pre><code>##              Test stat Pr(&gt;|Test stat|)
## outdoor_time   -0.3478           0.7306
## social_int     -0.1068           0.9157
## Tukey test     -0.4189           0.6753</code></pre>
<div class="int">
<p>Partial residual plots show no clear non-linear trends between residuals and predictors.</p>
<p>Visual inspection of suggested little sign of non-constant variance.</p>
</div>
</div>
<p class="solution-end">
</p>
</div>
<div id="independence" class="section level2">
<h2>Independence</h2>
<div class="frame">
<p>The ‘independence of errors’ assumption is the condition that the errors do not have some underlying relationship which is causing them to influence one another.
<br></p>
<p>There are many sources of possible dependence, and often these are issues of study design. For example, we may have groups of observations in our data which we would expect to be related (e.g., multiple trials from the same participant). Our modelling strategy would need to take this into account.
<br>
One form of dependence is <strong>autocorrelation</strong> - this is when observations influence those adjacent to them. It is common in data for which <em>time</em> is a variable of interest (e.g, the humidity today is dependent upon the rainfall yesterday).</p>
</div>
<div class="question-begin">
Question 4
</div>
<div class="question-body">
<p>For both <code>rv_mdl1</code> and <code>wb_mdl1</code>, visually assess whether there is autocorrelation in the error terms.</p>
<p>Write a sentence summarising whether or not you consider the assumption of independence to have been met for each (you may have to assume certain aspects of the study design).</p>
</div>
<p class="question-end">
</p>
<div class="solution-begin">
<span id="sol-start-88" class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-88&#39;, &#39;sol-start-88&#39;)"> Solution </span>
</div>
<div id="sol-body-88" class="solution-body" style="display: none;">
<p>Lets assess our <code>rv_mdl1</code> first.</p>
<p>To get a single figure made up of 2 by 1 panels, you can use the command <code>par(mfrow = c(1,2))</code>. Then create the plot. Then you need to go back to a single figure made up by a single panel with the command <code>par(mfrow = c(1,1))</code>.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">resid</span>(rv_mdl1))</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">fitted</span>(rv_mdl1), <span class="fu">resid</span>(rv_mdl1))</span></code></pre></div>
<p><img src="1_09_assumptions_files/figure-html/unnamed-chunk-9-1.png" width="60%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span></code></pre></div>
<div class="int">
<p>The plot of the residuals vs their index shows no clear dependence (if they were collected over time, for example, and there was an increasing trend this would highlight a violation). The residuals vs fitted plot shows that there is no association between the errors and the model predictions.</p>
</div>
<p>And now our <code>wb_mdl1</code>:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">resid</span>(wb_mdl1))</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">fitted</span>(wb_mdl1), <span class="fu">resid</span>(wb_mdl1))</span></code></pre></div>
<p><img src="1_09_assumptions_files/figure-html/unnamed-chunk-10-1.png" width="60%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span></code></pre></div>
<div class="int">
<p>Similarly to above, the plot of the residuals vs their index shows no clear dependence, and the residuals vs fitted plot shows that there is no association between the errors and the model predictions.</p>
</div>
</div>
<p class="solution-end">
</p>
</div>
<div id="normality-of-errors" class="section level2">
<h2>Normality of errors</h2>
<div class="frame">
<p>The normality assumption is the condition that the errors <span class="math inline">\(\epsilon\)</span> are normally distributed in the population.</p>
<p>We can visually assess this condition through histograms, density plots, and quantile-quantile plots (QQplots) of our residuals <span class="math inline">\(\hat \epsilon\)</span>.</p>
</div>
<div class="question-begin">
Question 5
</div>
<div class="question-body">
<p>Assess the normality assumption by producing a qqplot of the residuals (either manually or using <code>plot(model, which = ???)</code>) for both <code>rv_mdl1</code> and <code>wb_mdl1</code>.</p>
<p>Write a sentence summarising whether or not you consider the assumption to have been met. Justify your answer with reference to the plots.</p>
</div>
<p class="question-end">
</p>
<div class="solution-begin">
<span id="sol-start-89" class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-89&#39;, &#39;sol-start-89&#39;)"> Solution </span>
</div>
<div id="sol-body-89" class="solution-body" style="display: none;">
<p>We can get the QQplot from one of the <code>plot(model)</code> plot. Remember that departures from a linear trend in QQ plots indicate a lack of normality.</p>
<p>First, lets check our <code>rv_mdl1</code>:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(rv_mdl1, <span class="at">which =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="1_09_assumptions_files/figure-html/unnamed-chunk-11-1.png" width="60%" style="display: block; margin: auto;" /></p>
<div class="int">
<p>The normal quantile plot follows a linear pattern and does not highlight any substantial skew or departure from normality.</p>
</div>
<hr />
<p>Now onto <code>wb_mdl1</code>:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(wb_mdl1, <span class="at">which =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="1_09_assumptions_files/figure-html/unnamed-chunk-12-1.png" width="60%" style="display: block; margin: auto;" /></p>
<div class="int">
<p>The QQplot indicates that the residuals follow close to a normal distribution. Although there is some evidence of heavier tails, given the small sample size (n=32) it is not of concern and we can be more conservative in our visual assessment of the plot.</p>
</div>
</div>
<p class="solution-end">
</p>
</div>
<div id="multicollinearity" class="section level2">
<h2>Multicollinearity</h2>
<div class="frame">
<p>For the linear model with <strong>multiple</strong> explanatory variables, we need to also think about <strong>multicollinearity</strong> - this is when two (or more) of the predictors in our regression model are moderately or highly correlated.<br />
<br>
We can assess multicollinearity using the <strong>variance inflation factor (VIF)</strong>, which for a given predictor <span class="math inline">\(x_j\)</span> is calculated as:<br />
<span class="math display">\[
VIF_j = \frac{1}{1-R_j^2} \\
\]</span>
Suggested cut-offs for VIF are varied. Some suggest 10, others 5. Define what you will consider an acceptable value <em>prior</em> to calculating it. You could loosely interpret VIF values larger than 5 as moderate multicollinearity and values larger than 10 as severe multicollinearity.</p>
<p><strong>In R</strong>, the <code>vif()</code> function from the <strong>car</strong> package will provide VIF values for each predictor in your model.</p>
</div>
<div class="question-begin">
Question 6
</div>
<div class="question-body">
<p>Calculate the variance inflation factor (VIF) for the predictors in the model.</p>
<p>Write a sentence summarising whether or not you consider multicollinearity to be a problem here.</p>
</div>
<p class="question-end">
</p>
<div class="solution-begin">
<span id="sol-start-90" class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-90&#39;, &#39;sol-start-90&#39;)"> Solution </span>
</div>
<div id="sol-body-90" class="solution-body" style="display: none;">
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">vif</span>(wb_mdl1)</span></code></pre></div>
<pre><code>## outdoor_time   social_int 
##      1.13023      1.13023</code></pre>
<div class="int">
<p>The VIF values for all predictors are &lt;5, indicating that multicollinearity is not adversely affecting model estimates.</p>
</div>
</div>
<p class="solution-end">
</p>
</div>
<div id="individual-case-diagnostics" class="section level2">
<h2>Individual Case Diagnostics</h2>
<div class="frame">
<p>We have seen in the case of the simple linear regression that individual cases in our data can influence our model more than others. We know about:</p>
<ul>
<li><strong>Regression outliers:</strong> A large residual <span class="math inline">\(\hat \epsilon_i\)</span> - i.e., a big discrepancy between their predicted y-value and their observed y-value.
<ul>
<li><strong>Standardised residuals:</strong> For residual <span class="math inline">\(\hat \epsilon_i\)</span>, divide by the estimate of the standard deviation of the residuals. In R, the <code>rstandard()</code> function will give you these</li>
<li><strong>Studentised residuals:</strong> For residual <span class="math inline">\(\hat \epsilon_i\)</span>, divide by the estimate of the standard deviation of the residuals excluding case <span class="math inline">\(i\)</span>. In R, the <code>rstudent()</code> function will give you these.</li>
</ul></li>
<li><strong>High leverage cases:</strong> These are cases which have considerable <em>potential</em> to influence the regression model (e.g., cases with an unusual combination of predictor values).
<ul>
<li><strong>Hat values:</strong> are used to assess leverage. In R, The <code>hatvalues()</code> function will retrieve these.</li>
</ul></li>
<li><strong>High influence cases:</strong> When a case has high leverage <em>and</em> is an outlier, it will have a large influence on the regression model.
<ul>
<li><strong>Cook’s Distance:</strong> combines <em>leverage</em> (hatvalues) with <em>outlying-ness</em> to capture influence. In R, the <code>cooks.distance()</code> function will provide these.
Alongside Cook’s Distance, we can examine the extent to which model estimates and predictions are affected when an entire case is dropped from the dataset and the model is refitted.<br />
</li>
</ul></li>
<li><strong>DFFit:</strong> the change in the predicted value at the <span class="math inline">\(i^{th}\)</span> observation with and without the <span class="math inline">\(i^{th}\)</span> observation is included in the regression.<br />
</li>
<li><strong>DFbeta:</strong> the change in a specific coefficient with and without the <span class="math inline">\(i^{th}\)</span> observation is included in the regression.<br />
</li>
<li><strong>DFbetas:</strong> the change in a specific coefficient divided by the standard error, with and without the <span class="math inline">\(i^{th}\)</span> observation is included in the regression.<br />
</li>
<li><strong>COVRATIO:</strong> measures the effect of an observation on the covariance matrix of the parameter estimates. In simpler terms, it captures an observation’s influence on standard errors.</li>
</ul>
<p>You can get a whole bucket-load of these measures with the <code>influence.measures()</code> function:</p>
<ul>
<li><code>influence.measures(my_model)</code> will give you out a dataframe of the various measures.</li>
<li><code>summary(influence.measures(my_model))</code> will provide a nice summary of what R deems to be the influential points.</li>
</ul>
</div>
<div class="green">
<p>For questions 8-12, we will be working with our <code>wb_mdl1</code> only. Feel free to apply the below to your <code>rv_mdl1</code> too as as extra practice.</p>
</div>
<div class="question-begin">
Question 7
</div>
<div class="question-body">
<p>Create a new tibble which contains:</p>
<ol style="list-style-type: decimal">
<li>The original variables from the model (Hint, what does <code>wb_mdl1$model</code> give you?)</li>
<li>The fitted values from the model <span class="math inline">\(\hat y\)</span><br />
</li>
<li>The residuals <span class="math inline">\(\hat \epsilon\)</span></li>
<li>The studentised residuals</li>
<li>The hat values</li>
<li>The Cook’s Distance values.</li>
</ol>
</div>
<p class="question-end">
</p>
<div class="solution-begin">
<span id="sol-start-91" class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-91&#39;, &#39;sol-start-91&#39;)"> Solution </span>
</div>
<div id="sol-body-91" class="solution-body" style="display: none;">
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>mdl_diagnost <span class="ot">&lt;-</span> </span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>  wb_mdl1<span class="sc">$</span>model,</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">fitted =</span> <span class="fu">fitted</span>(wb_mdl1),</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">resid =</span> <span class="fu">residuals</span>(wb_mdl1),</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">studres =</span> <span class="fu">rstudent</span>(wb_mdl1),</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">hats =</span> <span class="fu">hatvalues</span>(wb_mdl1),</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">cooksd =</span> <span class="fu">cooks.distance</span>(wb_mdl1)</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question 8
</div>
<div class="question-body">
<p>Looking at the studentised residuals, are there any outliers?</p>
</div>
<p class="question-end">
</p>
<div class="solution-begin">
<span id="sol-start-92" class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-92&#39;, &#39;sol-start-92&#39;)"> Solution </span>
</div>
<div id="sol-body-92" class="solution-body" style="display: none;">
<p>In a standard normal distribution, 95% of the values are roughly between -2 and 2.</p>
<p>Because of this, studentised residuals of <span class="math inline">\(&gt;2\)</span> or <span class="math inline">\(&lt; -2\)</span> indicate potential outlyingness.</p>
<p>We can ask R whether the <em>absolute</em> values are <span class="math inline">\(&gt;2\)</span>:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">abs</span>(mdl_diagnost<span class="sc">$</span>studres) <span class="sc">&gt;</span> <span class="dv">2</span></span></code></pre></div>
<pre><code>##     1     2     3     4     5     6     7     8     9    10    11    12    13 
## FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE 
##    14    15    16    17    18    19    20    21    22    23    24    25    26 
## FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE 
##    27    28    29    30    31    32 
## FALSE FALSE FALSE FALSE FALSE FALSE</code></pre>
<p>We could <em>filter</em> our newly created tibble to these observations:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>mdl_diagnost <span class="sc">%&gt;%</span> </span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">abs</span>(studres)<span class="sc">&gt;</span><span class="dv">2</span>)</span></code></pre></div>
<pre><code>## # A tibble: 0 × 8
## # … with 8 variables: wellbeing &lt;dbl&gt;, outdoor_time &lt;dbl&gt;, social_int &lt;dbl&gt;,
## #   fitted &lt;dbl&gt;, resid &lt;dbl&gt;, studres &lt;dbl&gt;, hats &lt;dbl&gt;, cooksd &lt;dbl&gt;</code></pre>
<p>There are zero rows.</p>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question 9
</div>
<div class="question-body">
<p>Looking at the hat values, are there any observations with high leverage?</p>
</div>
<p class="question-end">
</p>
<div class="solution-begin">
<span id="sol-start-93" class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-93&#39;, &#39;sol-start-93&#39;)"> Solution </span>
</div>
<div id="sol-body-93" class="solution-body" style="display: none;">
<p>Recall from the lectures, hat values of more than <span class="math inline">\(2 \bar{h}\)</span> (2 times the average hat value) are considered high leverage.</p>
<p>The average hat value, <span class="math inline">\(\bar{h}\)</span> is calculated as <span class="math inline">\(\frac{k + 1}{n}\)</span>, where <span class="math inline">\(k\)</span> is the number of predictors, and <span class="math inline">\(n\)</span> is the sample size.
For our model:
<span class="math display">\[
\bar h = \frac{k+1}{n} = \frac{2+1}{32} = \frac{3}{32} = 0.094
\]</span></p>
<p>We can ask whether any of observations have hat values which are greater than <span class="math inline">\(2 \bar h\)</span>:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>mdl_diagnost <span class="sc">%&gt;%</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(hats <span class="sc">&gt;</span> (<span class="dv">2</span><span class="sc">*</span><span class="fl">0.094</span>))</span></code></pre></div>
<pre><code>## # A tibble: 0 × 8
## # … with 8 variables: wellbeing &lt;dbl&gt;, outdoor_time &lt;dbl&gt;, social_int &lt;dbl&gt;,
## #   fitted &lt;dbl&gt;, resid &lt;dbl&gt;, studres &lt;dbl&gt;, hats &lt;dbl&gt;, cooksd &lt;dbl&gt;</code></pre>
<p>Note that 0 observations have high leverage.</p>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question 10
</div>
<div class="question-body">
<p>Looking at the Cook’s Distance values, are there any highly influential points?<br />
You can also display these graphically using <code>plot(model, which = 4)</code> and <code>plot(model, which = 5)</code>.</p>
</div>
<p class="question-end">
</p>
<div class="solution-begin">
<span id="sol-start-94" class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-94&#39;, &#39;sol-start-94&#39;)"> Solution </span>
</div>
<div id="sol-body-94" class="solution-body" style="display: none;">
<p>Recall from the lectures that we have a Cook’s Distance cut-off of <span class="math inline">\(\frac{4}{n-k-1}\)</span>, where <span class="math inline">\(k\)</span> is the number of predictors, and <span class="math inline">\(n\)</span> is the sample size.<br />
For our model:
<span class="math display">\[
D_{cutoff} = \frac{4}{n-k-1} = \frac{4}{32 - 2 - 1} = \frac{4}{29} = 0.138
\]</span></p>
<p>There are no observations which have a high influence on our model estimates:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>mdl_diagnost <span class="sc">%&gt;%</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(cooksd <span class="sc">&gt;</span> <span class="fl">0.138</span>)</span></code></pre></div>
<pre><code>## # A tibble: 0 × 8
## # … with 8 variables: wellbeing &lt;dbl&gt;, outdoor_time &lt;dbl&gt;, social_int &lt;dbl&gt;,
## #   fitted &lt;dbl&gt;, resid &lt;dbl&gt;, studres &lt;dbl&gt;, hats &lt;dbl&gt;, cooksd &lt;dbl&gt;</code></pre>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question 11
</div>
<div class="question-body">
<p>Use the function <code>influence.measures()</code> to extract these delete-1 measures of influence.</p>
<p>Try plotting the distributions of some of these measures.</p>
<p><strong>Tip:</strong> the function <code>influence.measures()</code> returns an <code>infl</code>-type object. To plot this, we need to find a way to extract the actual numbers from it.<br />
What do you think <code>names(influence.measures(wb_mdl1))</code> shows you? How can we use <code>influence.measures(wb_mdl1)$&lt;insert name here&gt;</code> to extract the matrix of numbers?</p>
<!-- Cooks > qf(0.5, k + 1, n - k - 1) -->
</div>
<p class="question-end">
</p>
<div class="solution-begin">
<span id="sol-start-95" class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-95&#39;, &#39;sol-start-95&#39;)"> Solution </span>
</div>
<div id="sol-body-95" class="solution-body" style="display: none;">
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">influence.measures</span>(wb_mdl1)</span></code></pre></div>
<pre><code>## Influence measures of
##   lm(formula = wellbeing ~ outdoor_time + social_int, data = wbdata) :
## 
##      dfb.1_ dfb.otd_ dfb.scl_   dffit cov.r   cook.d    hat inf
## 1   0.43653 -0.11116 -0.32167  0.4477 1.157 0.066470 0.1489    
## 2  -0.28160  0.03170  0.22954 -0.2917 1.225 0.028838 0.1414    
## 3   0.29581  0.07604 -0.29025  0.3540 1.088 0.041520 0.0967    
## 4  -0.26445 -0.13055  0.29341 -0.3508 1.117 0.040991 0.1071    
## 5  -0.27084  0.22733  0.10472 -0.3290 1.279 0.036700 0.1766    
## 6   0.12462 -0.02693 -0.08288  0.1460 1.141 0.007277 0.0604    
## 7  -0.17361 -0.03392  0.15313 -0.2235 1.087 0.016770 0.0597    
## 8  -0.02879 -0.07259  0.06069 -0.0918 1.309 0.002906 0.1556    
## 9   0.16925  0.08820 -0.17834  0.2477 1.088 0.020553 0.0668    
## 10 -0.24768  0.33112 -0.00551 -0.4267 1.027 0.059217 0.0956    
## 11 -0.02018 -0.02535  0.02534 -0.0492 1.166 0.000834 0.0518    
## 12  0.04644  0.38731 -0.22045  0.4474 1.164 0.066462 0.1517    
## 13 -0.15606  0.21587 -0.02477 -0.3135 1.017 0.032241 0.0626    
## 14  0.13390 -0.31537  0.10705  0.3905 1.039 0.049887 0.0899    
## 15  0.14774 -0.25595  0.08688  0.4273 0.815 0.055918 0.0487    
## 16 -0.11881  0.17855 -0.06061 -0.3502 0.873 0.038519 0.0422    
## 17  0.00121 -0.07684  0.02608 -0.1031 1.177 0.003653 0.0703    
## 18  0.00329  0.04637 -0.01574  0.0739 1.159 0.001877 0.0516    
## 19  0.04301 -0.15310  0.09227  0.2432 1.055 0.019693 0.0546    
## 20  0.05819 -0.10961 -0.03803 -0.2189 1.065 0.016025 0.0508    
## 21 -0.01498  0.00131  0.03428  0.0875 1.131 0.002622 0.0380    
## 22  0.12553 -0.15510 -0.09098 -0.3084 1.020 0.031247 0.0622    
## 23 -0.03324 -0.00580  0.05840  0.1049 1.138 0.003770 0.0466    
## 24  0.24606 -0.23731 -0.18568 -0.4783 0.911 0.071967 0.0774    
## 25  0.06123  0.10878 -0.16017 -0.2209 1.131 0.016498 0.0771    
## 26 -0.02732 -0.29363  0.23790  0.3643 1.243 0.044752 0.1666    
## 27 -0.30514  0.33726  0.20108  0.5966 0.830 0.108234 0.0858    
## 28  0.06176 -0.07036 -0.03455 -0.1080 1.263 0.004013 0.1280    
## 29 -0.15327 -0.04611  0.23001  0.3039 1.067 0.030646 0.0754    
## 30  0.11226  0.25745 -0.30386 -0.3826 1.238 0.049262 0.1686    
## 31 -0.07637 -0.05313  0.12879  0.1542 1.214 0.008153 0.1047    
## 32  0.10249 -0.07000 -0.07662 -0.1399 1.353 0.006736 0.1864   *</code></pre>
<p>Let’s plot the distribution of COVRATIO statistics.<br />
Recall that values which are <span class="math inline">\(&gt;1+\frac{3(k+1)}{n}\)</span> or <span class="math inline">\(&lt;1-\frac{3(k+1)}{n}\)</span> are considered as having strong influence.<br />
For our model:
<span class="math display">\[
1 \pm \frac{3(k+1)}{n} \quad = \quad 1 \pm\frac{3(2+1)}{32} \quad = \quad 1\pm \frac{9}{32} \quad = \quad 1\pm0.28
\]</span></p>
<p>The “infmat” bit of an <code>infl</code>-type object contains the numbers. To use it with ggplot, we will need to turn it into a dataframe (<code>as.data.frame()</code>), or a tibble (<code>as_tibble()</code>):</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>infdata <span class="ot">&lt;-</span> <span class="fu">influence.measures</span>(wb_mdl1)<span class="sc">$</span>infmat <span class="sc">%&gt;%</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as_tibble</span>()</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> infdata, <span class="fu">aes</span>(<span class="at">x =</span> cov.r)) <span class="sc">+</span> </span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>() <span class="sc">+</span></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept =</span> <span class="fu">c</span>(<span class="dv">1</span><span class="fl">-0.28</span>)))<span class="sc">+</span></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept =</span> <span class="fu">c</span>(<span class="dv">1</span><span class="fl">+0.28</span>)))</span></code></pre></div>
<p><img src="1_09_assumptions_files/figure-html/unnamed-chunk-20-1.png" width="60%" style="display: block; margin: auto;" /></p>
<p>It looks like a few observations may be having quite a high influence here. This is perhaps not that surprising as we only have 32 datapoints.</p>
</div>
<p class="solution-end">
</p>
<hr />
<hr />
</div>
</div>
<div id="less-guided-exercises---extra-practice" class="section level1">
<h1>Less guided exercises - extra practice</h1>
<div class="question-begin">
Question 12
</div>
<div class="question-body">
<p>Create a new section header in your Rmarkdown document, as we are moving onto a different dataset.</p>
<p>The code below loads the dataset of 656 participants’ scores on Big 5 Personality traits, perceptions of social ranks, and scores on a depression and anxiety scale.<br />
<br></p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>scs_study <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;https://uoepsy.github.io/data/scs_study.csv&quot;</span>)</span></code></pre></div>
<p><br></p>
<ol style="list-style-type: decimal">
<li>Fit the following interaction model:
<ul>
<li><span class="math inline">\(\text{DASS-21 Score} = \beta_0 + \beta_1 \cdot \text{SCS Score} + \beta_2 \cdot \text{Neuroticism} + \beta_3 \cdot \text{SCS score} \cdot \text{Neuroticism} + \epsilon\)</span></li>
</ul></li>
<li>Check that the model meets the assumptions of the linear model (<strong>Tip:</strong> to get a broad overview you can pass your model to the <code>plot()</code> function to get a series of plots).</li>
<li>If you notice any violated assumptions:
<ul>
<li>address the issues by, e.g., excluding observations from the analysis, or replacing outliers with the next most extreme value (<em>Winsorisation</em>).</li>
<li>after fitting a new model which you hope addresses violations, you need to check <strong>all</strong> of your assumptions again. It can be an iterative process, and the most important thing is that your <em>final</em> model (the one you plan to <strong>use</strong>) meets all the assumptions.</li>
</ul></li>
</ol>
<hr />
<p><strong>Tips:</strong></p>
<ul>
<li>When there is an interaction in the model, assessing linearity becomes difficult. In fact, <code>crPlots()</code> will not work. To assess, you can create a residuals-vs-fitted plot like we saw in the guided exercises above.<br />
</li>
<li>Interaction terms often result in multicollinearity, because these terms are made up of the product of some ‘main effects’. Mean-centering the variables like we have here will reduce this source of structural multicollinearity (“structural” here refers to the fact that multicollinearity is due to our model specification, rather than the data itself)<br />
</li>
<li>You can fit a model and exclude specific observations. For instance, to remove the 3rd and 5th rows of the dataset: <code>lm(y ~ x1 + x2, data = dataset[-c(3,5),])</code>. Be careful to remember that these values remain in the dataset, they have simply been excluded from the model fit.</li>
</ul>
</div>
<p class="question-end">
</p>
<div class="solution-begin">
<span id="sol-start-96" class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-96&#39;, &#39;sol-start-96&#39;)"> Solution </span>
</div>
<div id="sol-body-96" class="solution-body" style="display: none;">
<p>We’re going to mean-center the <code>scs</code> variable from the outset.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>scs_study <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;https://uoepsy.github.io/data/scs_study.csv&quot;</span>)  </span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>scs_study <span class="ot">&lt;-</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>  scs_study <span class="sc">%&gt;%</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">scs_mc =</span> scs <span class="sc">-</span> <span class="fu">mean</span>(scs)</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>dass_mdl2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(dass <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> scs_mc <span class="sc">*</span> zn, <span class="at">data =</span> scs_study)</span></code></pre></div>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(dass_mdl2)</span></code></pre></div>
<p><img src="1_09_assumptions_files/figure-html/unnamed-chunk-24-1.png" width="95%" style="display: block; margin: auto;" /></p>
<p>From quick visual inspection, it looks like there is at least one very influential point, which has been labelled for us as case number 35.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>scs_study[<span class="dv">35</span>, ]</span></code></pre></div>
<pre><code>## # A tibble: 1 × 8
##      zo    zc    ze     za    zn   scs  dass scs_mc
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
## 1 0.645 -1.49 0.970 -0.121  2.24    54    65   18.2</code></pre>
<p>The code below fits a new model and assigns it the name <code>dass_mdl3</code>. How is it different from the previous model?</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>dass_mdl3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(dass <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> scs_mc <span class="sc">*</span> zn, <span class="at">data =</span> scs_study[<span class="sc">-</span><span class="dv">35</span>, ])</span></code></pre></div>
<p>Does this new model meet the assumptions of multiple regression?</p>
<p><strong>Linearity</strong></p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(dass_mdl3, <span class="at">which =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="1_09_assumptions_files/figure-html/unnamed-chunk-27-1.png" width="60%" style="display: block; margin: auto;" /></p>
<p><strong>Equal variances (Homoscedasticity)</strong></p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="fu">residualPlots</span>(dass_mdl3)</span></code></pre></div>
<p><img src="1_09_assumptions_files/figure-html/unnamed-chunk-28-1.png" width="60%" style="display: block; margin: auto;" /></p>
<pre><code>##            Test stat Pr(&gt;|Test stat|)
## scs_mc        1.6260           0.1044
## zn           -0.5074           0.6121
## Tukey test   -1.3170           0.1878</code></pre>
<p><strong>Independence of errors</strong></p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">resid</span>(dass_mdl3))</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">fitted</span>(dass_mdl3), <span class="fu">resid</span>(dass_mdl3))</span></code></pre></div>
<p><img src="1_09_assumptions_files/figure-html/unnamed-chunk-29-1.png" width="60%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span></code></pre></div>
<p><strong>Normality</strong></p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qqnorm</span>(<span class="fu">resid</span>(dass_mdl3))</span></code></pre></div>
<p><img src="1_09_assumptions_files/figure-html/unnamed-chunk-30-1.png" width="60%" style="display: block; margin: auto;" /></p>
<p><strong>Check for multicollinearity</strong></p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">vif</span>(dass_mdl3)</span></code></pre></div>
<pre><code>##    scs_mc        zn scs_mc:zn 
##  1.010026  1.010174  1.000240</code></pre>
</div>
<p class="solution-end">
</p>
<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;">

</div>
</div>

<link rel="stylesheet" href="https://uoepsy.github.io/assets/css/ccfooter.css" />
<div class="ccfooter"></div>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
