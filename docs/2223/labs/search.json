[
  {
    "objectID": "1_01_function.html",
    "href": "1_01_function.html",
    "title": "Functions and Models",
    "section": "",
    "text": "At the end of this lab, you will:\n\nHave reviewed the main concepts from introductory statistics.\nUnderstand the concept of a function.\nBe able to discuss what a statistical model is.\nUnderstand the link between models and functions.\n\n\nHave attended and/or watched Week 1 lectures.\nHave installed R and RStudio on your own computer (unless you have a Chromebook where you may continue to use the PPLS RStudio Server).\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\nggExtra\nkableExtra\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/handheight.csv."
  },
  {
    "objectID": "1_01_function.html#functions-and-mathematical-models-plots",
    "href": "1_01_function.html#functions-and-mathematical-models-plots",
    "title": "Functions and Models",
    "section": "Functions and Mathematical Models: Plots",
    "text": "Functions and Mathematical Models: Plots\n\nQuestion 4\n\n\nCreate a data set called squares containing the perimeter of four squares having sides of length \\(0, 2, 5, 9\\) metres, and then plot the squares data as points\n\n\n\n\n\n\nHint\n\n\n\n\n\nRemember that to combine multiple numbers together we use the function c().\n\n\n\n\n\n\n\n Solution \n\n\n\n#Create 'squares' dataset using tibble()\nsquares <- tibble(\n  side = c(0, 2, 5, 9),\n  perimeter = 4 * side\n)\n\nsquares\n\n# A tibble: 4 × 2\n   side perimeter\n  <dbl>     <dbl>\n1     0         0\n2     2         8\n3     5        20\n4     9        36\n\n\n\n#Create Plot\nggplot(data = squares, aes(x = side, y = perimeter)) +\n  geom_point() +\n  labs(x = 'Side (m)', y = 'Perimeter (m)')\n\n\n\nFigure 1: ?(caption)\n\n\n\n\n\n\n\n\n\nQuestion 5\n\n\nGenerate one hundred data points, and use them to visualise the relationship between side and perimeter of squares. To do so, you need to complete four steps:\n\nCreate a sequence of one hundred side lengths (x) going from 0 to 3 metres.\nCompute the corresponding perimeters (y).\nPlot the side and perimeter data as points on a graph.\nVisualise the functional relationship between side and perimeter of squares. To do so, use the function geom_line() to connect the computed points with lines.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nRemember that to create a sequence of numbers, we can use the function seq().\n\n\n\n\n\n\n\n Solution \n\n\nLet’s start by creating the side and perimeter data:\n\n#step 1 & 2\nsquares_grid <- tibble(\n  side = seq(0, 3, length.out = 100),\n  perimeter = 4 * side\n)\n\nPlot the individual points:\n\n# step 3\nggplot(data = squares_grid, aes(x = side, y = perimeter)) +\n  geom_point() +\n  labs(x = 'Side (m)', y = 'Perimeter (m)', title = 'Perimeter = 4*Side')\n\n\n\n\nVisualise the functional relationship by connecting the individual points with lines:\n\n#step 4\nggplot(data = squares_grid, aes(x = side, y = perimeter)) +\n  geom_line(colour = 'blue') +\n  labs(x = 'Side (m)', y = 'Perimeter (m)', title = 'Perimeter = 4*Side')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe function \\(y = 4 \\ x\\) that you plotted above is an example of a function representing a mathematical model.\nWe typically validate a model using experimental data. However, we all know how squares work and that two squares with the same side will have the same perimeter (more on this later).\n\n\n\n\nQuestion 6\n\n\nThe Scottish National Gallery kindly provided us with measurements of side and perimeter (in metres) for a sample of 10 square paintings.\nThe data are provided below:\n\nsng <- tibble(\n  side = c(1.3, 0.75, 2, 0.5, 0.3, 1.1, 2.3, 0.85, 1.1, 0.2),\n  perimeter = c(5.2, 3.0, 8.0, 2.0, 1.2, 4.4, 9.2, 3.4, 4.4, 0.8)\n)\n\nPlot the mathematical model of the relationship between side and perimeter for squares, and superimpose on top the experimental data from the Scottish National Gallery.\n\n\n\n\n Solution \n\n\n\nsng <- tibble(\n  side = c(1.3, 0.75, 2, 0.5, 0.3, 1.1, 2.3, 0.85, 1.1, 0.2),\n  perimeter = c(5.2, 3.0, 8.0, 2.0, 1.2, 4.4, 9.2, 3.4, 4.4, 0.8)\n)\n\nggplot() +\n  geom_line(data = squares_grid, aes(x = side, y = perimeter), colour = 'blue') +\n  geom_point(data = sng, aes(x = side, y = perimeter), colour = 'black', \n             alpha = 0.5, size = 3) +\n  labs(x = 'Side (m)', y = 'Perimeter (m)')\n\n\n\nFigure 2: The exact relationship between side and perimeter of squares\n\n\n\n\nThe above plot shows perfect agreement between the observed data and the model.\n\n\n\n\n\nQuestion 7\n\n\nUse the mathematical model to predict the perimeter of a painting with a side of 1.5 metres.\n\n\n\n\n\n\nHint\n\n\n\n\n\nDon’t forget to always include the measurement units when reporting/writing-up results!\n\n\n\n\n\n\n\n Solution \n\n\nWe do not have a painting with a side of 1.5 metres within the random sample of paintings from the Scottish National Gallery. However, we can predict the perimeter of an unobserved squared painting having a 1.5 metre side using the mathematical model.\nYou can obtain this prediction using either a visual approach or an algebraic one.\n\n\nVisual Approach\nAlgebraic Approach\n\n\n\n\n\n\n\n\nSometimes we can directly read a predicted value from the graph of the functional relationship.\nConsider the plot created in the previous question. First, we need to check where x = 1.5. Then, we draw a vertical dashed line until it meets the blue line. The y value corresponding to x = 1.5 can be read off the y-axis.\nHowever, in this case it is not that easy to read it from the drawing…\n\n\nYou can substitute the x value in the formula and calculate the corresponding y value.\n\\[\ny = 4 * x = 4 * 1.5 = 6\n\\]\n\n\n\n\n\n\n\n\n\nThe predicted perimeter of squared paintings having a 1.5m side is 6m."
  },
  {
    "objectID": "1_01_function.html#study-overview",
    "href": "1_01_function.html#study-overview",
    "title": "Functions and Models",
    "section": "Study Overview",
    "text": "Study Overview\n\nResearch Question\nHow does handspan vary as a function of height?\n\nConsider now the relationship between height (in inches) and handspan (in cm). Utts and Heckard (2015) provided data for a sample of 167 students which reported their height and handspan as part of a class survey.\nUsing the handheight data you already loaded at the start of the lab, your task is to investigate how handspan varies as a function of height for the students in the sample.\n\n Handheight codebook.\n\n\nDescription\nThe data set records the height and handspan reported by a random sample of 167 students as part of a class survey.\nThe variables are:\n\n\nheight, measured in inches\n\nhandspan, measured in centimetres\n\nPreview\nThe first six rows of the data are:\n\n\n\n\n\n height \n    handspan \n  \n\n\n 68 \n    21.5 \n  \n\n 71 \n    23.5 \n  \n\n 73 \n    22.5 \n  \n\n 64 \n    18.0 \n  \n\n 68 \n    23.5 \n  \n\n 59 \n    20.0 \n  \n\n\n\n\n\n\n\n\n\nQuestion 8\n\n\nUsing a scatterplot (since the variables are numeric and continuous) to visualise the relationship between the two numeric variables, comment on any main differences you notice with the relationship between side and perimeter of squares. Note if you detected outliers or points that do not fit with the pattern in the rest of the data.\n\n\n\n\n Solution \n\n\n\nplt <- ggplot(handheight, aes(x = height, y = handspan)) +\n  geom_point(size = 3, alpha = 0.5) +\n  labs(x = 'Height (in.)', y = 'Handspan (cm)')\n\nplt\n\n\n\nFigure 3: Simple Scatterplot\n\n\n\n\nWe can also add marginal boxplots for each variable using the package ggExtra.\n\nggMarginal(plt, type = 'boxplot')\n\n\n\nFigure 4: The statistical relationship between height and handspan\n\n\n\n\nOutliers are extreme observations that are not possible values of a variable or that do not seem to fit with the rest of the data. This could either be:\n\n\nmarginally along one axis: points that have an unusual (too high or too low) x-coordinate or y-coordinate;\n\njointly: observations that do not fit with the rest of the point cloud.\n\nThe boxplots in Figure 4 do not highlight any outliers in the marginal distributions of height and handspan. Furthermore, from the scatterplot we do not notice any extreme observations or points that do not fit with the rest of the point cloud.\nWe notice a moderate, positive linear relationship between height and handspan.\nRecall Figure 2, displaying the relationship between side and perimeters of squares. In the plot we notice two points on top of each other, reflecting the fact that two squares having the same side will always have the same perimeter. In fact, the data from the Scottish National Gallery include two squared paintings with a side of 1.1m, both having a measured perimeter of 4.4m.\nFigure 4, instead, displays the relationship between height and handspan of a sample of students. The first thing that grabs our attention is the fact that students having the same height do not necessarily have the same handspan. Rather, we clearly see a variety of handspan values for students all having a height of, for example, 70in. To be more precise, the seven students who are 70 in. tall all have differing handspans.\n\n\n\n\n\nQuestion 9\n\n\nUsing the following command, superimpose on top of the scatterplot a best-fit line describing how handspan varies as a function of height. For the moment, the argument se = FALSE tells R to not display uncertainty bands.\n\ngeom_smooth(method = lm, se = FALSE)\n\nComment on any differences between the lines representing the linear relationship between (a) the side and perimeter of square and (b) height and handspan.\n\n\n\n\n Solution \n\n\n\nggplot(handheight, aes(x = height, y = handspan)) +\n  geom_point(size = 3, alpha = 0.5) +\n  geom_smooth(method = lm, se = FALSE) +\n  labs(x = 'Height (in.)', y = 'Handspan (cm)')\n\n\n\nFigure 5: The best-fit line\n\n\n\n\nThe line representing the relationship between side and perimeter of squares is able to predict the actual perimeter value from the measurement of the side of a square. This is possible because the relationship between side and perimeter is an exact one.\nThat is, any squares having the same side will have the same perimeter, and there will be no variation in those values.\nThe line that best fits the relationship between height and handspan (see Figure 5), instead, is only able to predict the average handspan for a given value of height.\nThis is because there will be a distribution of handspans at each value of height. The line will fit the trend/pattern in the values, but there will be individual-to-individual variability that we must accept around that average pattern.\n\n\n\n\n\nQuestion 10\n\n\n\n\n\nThe line of best-fit is given by:1\n\\[\n\\widehat{Handspan} = -3 + 0.35 \\ Height\n\\]\nCalculate the predicted handspan of a student who is (a) 73in tall, and (b) 5in tall.\n\n\n\n\n Solution \n\n\n\nThe predicted average handspan for students who are 73in tall is: \\(-3 + 0.35 * 73 = 22.55\\)cm. \n\nThe predicted average handspan for students who are 5in tall is: \\(-3 + 0.35 * 5 = -1.25\\)cm.\n\nBut wait, handspan can not be negative… This does not make any sense! That’s right, we went too far off the range of the available data on heights, which were between 57in and 78in. We extrapolated. This is very dangerous…\n\n\n\n\nSource: Randall Munroe, xkcd.com"
  },
  {
    "objectID": "1_02_slr.html",
    "href": "1_02_slr.html",
    "title": "Intro to Linear Regression",
    "section": "",
    "text": "At the end of this lab, you will:\n\nBe able to specify a simple linear model.\nUnderstand what fitted values and residuals are.\nBe able to interpret the coefficients of a fitted model.\nBe able to test hypotheses and construct confidence intervals for the regression coefficients.\n\n\nBe up to date with lectures from Weeks 1 & 2\nHave completed Week 1 lab exercises\n\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/riverview.csv."
  },
  {
    "objectID": "1_02_slr.html#data-exploration",
    "href": "1_02_slr.html#data-exploration",
    "title": "Intro to Linear Regression",
    "section": "Data Exploration",
    "text": "Data Exploration\nThe common first port of call for almost any statistical analysis is to explore the data, and we can do this visually and/or numerically.\n\n\n\n\n\n\n\n\nMarginal Distributions\nBivariate Associations\n\n\n\nDescription\nThe distribution of each variable (e.g., employee incomes and education levels) without reference to the values of the other variables\nDescribing the relationship between two numeric variables\n\n\n\nVisually \n\n\nPlot each variable individually.  You could use, for example, geom_density() for a density plot or geom_histogram() for a histogram to comment on and/or examine: \n\nThe shape of the distribution. Look at the shape, centre and spread of the distribution. Is it symmetric or skewed? Is it unimodal or bimodal?\n\n\nIdentify any unusual observations. Do you notice any extreme observations (i.e., outliers)?\n\n\n\nPlot associations among two variables.  You could use, for example, a scatterplot to comment on and/or examine: \nThe direction of the association indicates whether there is a positive or negative association\n\n\nThe form of association refers to whether the relationship between the variables can be summarized well with a straight line or some more complicated pattern\n\n\nThe strength of association entails how closely the points fall to a recognizable pattern such as a line\n\n\nUnusual observations that do not fit the pattern of the rest of the observations and which are worth examining in more detail\n\n\n\n\n\nNumerically \n\nCompute and report summary statistics e.g., mean, standard deviation, median, min, max, etc.  You could, for example, calculate summary statistics such as the mean (mean()) and standard deviation (sd()), etc. within summarize()\n\nCompute and report the correlation coefficient.  You can use the cor() function to calculate this\n\n\n\nMarginal Distributions\n\nQuestion 1\n\n\nVisualise and describe the marginal distribution of employee incomes.\n\n\n\n\n Solution \n\n\nVisualisation of distribution:\n\nggplot(data = riverview, aes(x = income)) +\n  geom_density() +\n  geom_boxplot(width = 1/300) +\n  labs(x = \"Income (in thousands of U.S. dollars)\", \n       y = \"Probability density\")\n\n\n\nFigure 1: Density plot and boxplot of employee incomes\n\n\n\n\nThe plot suggested that the distribution of employee incomes was unimodal, and most of the incomes were between roughly $45,000 and $70,000. The lowest income in the sample was approximately $25,000 and the highest over $80,000. This suggested there was a fair high degree of variation in the data. Furthermore, the boxplot did not highlight any outliers in the data.\nSummary statistics for the employees’ incomes:\n\ndesc_income <- riverview %>% \n  summarize(\n    M = mean(income), \n    SD = sd(income)\n    )\ndesc_income\n\n# A tibble: 1 × 2\n      M    SD\n  <dbl> <dbl>\n1  53.7  14.6\n\n\nFollowing the exploration above, we can describe the income variable as follows:\n\n\n\n\n\n\nThe marginal distribution of income was unimodal with a mean of approximately $53,700. There was variation in employees’ salaries (SD = $14,553).\n\n\n\n\n\n\n\nQuestion 2\n\n\nVisualise and describe the marginal distribution of education level.\n\n\n\n\n Solution \n\n\nVisualisation of distribution:\n\nggplot(data = riverview, aes(x = education)) +\n  geom_density() +\n  geom_boxplot(width = 1/100) +\n  labs(x = \"Education (in years)\", \n       y = \"Probability density\")\n\n\n\nFigure 2: Density plot and boxplot of employee education levels\n\n\n\n\nSummary statistics for the employees’ level of education:\n\ndesc_education <- riverview %>%\n  summarize(\n    M = mean(education),\n    SD = sd(education)\n    )\ndesc_education\n\n# A tibble: 1 × 2\n      M    SD\n  <dbl> <dbl>\n1    16  4.36\n\n\n\n\n\n\n\n\n\nThe marginal distribution of education was unimodal with an average of of 16 years. There was variation in employees’ level of education (SD = 4.4 years).\n\n\n\n\n\n\nAssociations among Variables\n\nQuestion 3\n\n\nCreate a scatterplot of income and education level before calculating the correlation between income and education level.\nMaking reference to both the plot and correlation coefficient, describe the association between income and level of education among the employees in the sample.\n\n\n\n\n\n\nHint\n\n\n\n\n\nWe are trying to investigate how income varies when varying years of formal education. Hence, income is the dependent variable (on the y-axis), and education is the independent variable (on the x-axis).\n\n\n\n\n\n\n\n Solution \n\n\nLet’s produce a scatterplot:\n\nggplot(data = riverview, aes(x = education, y = income)) +\n  geom_point(alpha = 0.5) +\n  labs(x = \"Education (in years)\", \n       y = \"Income (in thousands of U.S. dollars)\")\n\n\n\nFigure 3: The association between employees’ education level and income\n\n\n\n\nTo comment on the strength of the linear association we compute the correlation coefficient:\n\ncorr <- riverview %>%\n  select(education, income) %>%\n  cor()\ncorr\n\n          education    income\neducation 1.0000000 0.7947847\nincome    0.7947847 1.0000000\n\n\nthat is,\n\\[\nr_{\\text{education, income}} = 0.79\n\\]\n\n\n\n\n\n\n\nThere was a strong positive linear association between education level and income for the employees in the sample. High incomes tended to be observed, on average, with more years of formal education (\\(r\\) = .79).\nThe scatterplot did not highlight any outliers."
  },
  {
    "objectID": "1_02_slr.html#model-specification-and-fitting",
    "href": "1_02_slr.html#model-specification-and-fitting",
    "title": "Intro to Linear Regression",
    "section": "Model Specification and Fitting",
    "text": "Model Specification and Fitting\nThe scatterplot highlighted a linear relationship, where the data points were scattered around an underlying linear pattern with a roughly-constant spread as x varied.\nHence, we will try to fit a simple (i.e., one x variable only) linear regression model:\n\\[\ny = \\beta_0 + \\beta_1 x + \\epsilon\n\\\\\n\\quad \\text{where} \\quad \\epsilon \\sim N(0, \\sigma) \\text{ independently}\n\\]\nwhere “\\(\\epsilon \\sim N(0, \\sigma) \\text{ independently}\\)” means that the errors around the line have mean zero and constant spread as x varies.\n\nQuestion 4\n\n\nUsing the lm() function, fit a simple linear model to predict income (DV) by Education (IV), naming the output mdl.\nWrite down the equation of the fitted line.\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe syntax of the lm() function is:\n\n[model name] <- lm([response variable i.e., dependent variable] ~ [explanatory variable i.e., independent variable], data = [dataframe])\n\n\n\n\n\n\n\n\n Solution \n\n\nThe fitted model can be written as\n\\[\n\\widehat{Income} = \\hat \\beta_0 + \\hat \\beta_1 \\ Education\n\\]\nor\n\\[\n\\widehat{Income} = \\hat \\beta_0 \\cdot 1 + \\hat \\beta_1 \\cdot Education\n\\]\nWhen we specify the linear model in R, we include after the tilde sign, ~, the variables that appear to the right of the \\(\\hat \\beta\\)s. That’s why the 1 is included.\nAs the variables are in the riverview dataframe, we would write:\n\nmdl <- lm(income ~ 1 + education, data = riverview)\nmdl\n\n\nCall:\nlm(formula = income ~ 1 + education, data = riverview)\n\nCoefficients:\n(Intercept)    education  \n     11.321        2.651  \n\n\nNote that by calling the name of the fitted model, mdl, you can see the estimated regression coefficients \\(\\hat \\beta_0\\) and \\(\\hat \\beta_1\\). The fitted line is\n\n\n\n\n\n\n\\[\n\\widehat{Income} = 11.32 + 2.65 \\ Education \\\\\n\\]\n\n\n\n\n\n\n\n\nQuestion 5\n\n\nExplore the following equivalent ways to obtain the estimated regression coefficients — that is, \\(\\hat \\beta_0\\) and \\(\\hat \\beta_1\\) — from the fitted model:\n\nmdl\nmdl$coefficients\ncoef(mdl)\ncoefficients(mdl)\nsummary(mdl)\n\n\n\n\n\n Solution \n\n\nThe estimated parameters returned by the below methods are all equivalent. However, summary() returns more information.\n\n\nmdl()\nmdl$coefficients\ncoef(mdl)\ncoefficients(mdl)\nsummary(mdl)\n\n\n\nSimply invoke the name of the fitted model:\n\nmdl\n\n\nCall:\nlm(formula = income ~ 1 + education, data = riverview)\n\nCoefficients:\n(Intercept)    education  \n     11.321        2.651  \n\n\n\n\n\nmdl$coefficients\n\n(Intercept)   education \n  11.321379    2.651297 \n\n\n\n\n\ncoef(mdl)\n\n(Intercept)   education \n  11.321379    2.651297 \n\n\n\n\n\ncoefficients(mdl)\n\n(Intercept)   education \n  11.321379    2.651297 \n\n\n\n\nLook under the “Estimate” column:\n\nsummary(mdl)\n\n\nCall:\nlm(formula = income ~ 1 + education, data = riverview)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.809  -5.783   2.088   5.127  18.379 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  11.3214     6.1232   1.849   0.0743 .  \neducation     2.6513     0.3696   7.173 5.56e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.978 on 30 degrees of freedom\nMultiple R-squared:  0.6317,    Adjusted R-squared:  0.6194 \nF-statistic: 51.45 on 1 and 30 DF,  p-value: 5.562e-08\n\n\n\n\n\n\n\n\n\n\n\nThe estimated intercept is \\(\\hat \\beta_0 = 11.32\\) and the estimated slope is \\(\\hat \\beta_1 = 2.65\\).\n\n\n\n\n\n\n\n\nQuestion 6\n\n\nExplore the following equivalent ways to obtain the estimated standard deviation of the errors — that is, \\(\\hat \\sigma\\) — from the fitted model mdl:\n\nsigma(mdl)\nsummary(mdl)\n\n\n Huh? What is \\(\\sigma\\)?\n\n\nThe standard deviation of the errors, denoted by \\(\\sigma\\) is an important quantity to estimate because it measures how much individual data points tend to deviate above and below the regression line.\nA small \\(\\sigma\\) indicates that the points hug the line closely and we should expect fairly accurate predictions, while a large \\(\\sigma\\) suggests that, even if we estimate the line perfectly, we can expect individual values to deviate from it by substantial amounts.\nThe estimated standard deviation of the errors is (surprisingly) denoted \\(\\hat \\sigma\\) and is equal to\n\\[\n\\hat \\sigma = \\sqrt{\\frac{SS_{Residual}}{n - 2}}\n\\]\n\n\n\n\n\n\n\n Solution \n\n\nThe estimated standard deviation of the errors can be equivalently obtained by the below methods. However, summary() returns more information.\n\n\nsigma(mdl)\nsummary(mdl)\n\n\n\n\nsigma(mdl)\n\n[1] 8.978116\n\n\n\n\nLook at the “Residual standard error” entry of the summary(mdl) output:\n\nsummary(mdl)\n\n\nCall:\nlm(formula = income ~ 1 + education, data = riverview)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.809  -5.783   2.088   5.127  18.379 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  11.3214     6.1232   1.849   0.0743 .  \neducation     2.6513     0.3696   7.173 5.56e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.978 on 30 degrees of freedom\nMultiple R-squared:  0.6317,    Adjusted R-squared:  0.6194 \nF-statistic: 51.45 on 1 and 30 DF,  p-value: 5.562e-08\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe term “Residual standard error” is a misnomer, as the help page for sigma says (check ?sigma). However, it’s hard to get rid of this bad name as it has been used in too many books showing R output.\n\n\n\n\n\n\n\n\n\n\n\nThe estimated standard deviation of the errors is \\(\\hat \\sigma = 8.98\\).\n\n\n\n\n\n\n\n\nQuestion 7\n\n\nInterpret the estimated intercept and slope in the context of the research question.\n\n\n\n\n Solution \n\n\nWe can interpret the estimated intercept as follows:\n\n\n\n\n\n\nThe estimated average income associated to zero years of formal education is $11,321.\n\n\n\nFor the estimated slope we might write:\n\n\n\n\n\n\nThe estimated increase in average income associated to a one year increase in education is $2,651.\n\n\n\n\n\n\n\n\nQuestion 8\n\n\nInterpret the estimated standard deviation of the errors in the context of the research question.\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo interpret the estimated standard deviation of the errors we can use the fact that about 95% of values from a normal distribution fall within two standard deviations of the centre.\n\n\n\n\n\n\n\n Solution \n\n\nWe can interpret the estimated standard deviation of the errors as follows:\n\n\n\n\n\n\nFor any particular level of education, employee incomes should be distributed above and below the regression line with standard deviation estimated to be \\(\\hat \\sigma = 8.98\\). Since \\(2 \\hat \\sigma = 2 (8.98) = 17.96\\), we expect most (about 95%) of the employee incomes to be within about $18,000 from the regression line.\n\n\n\n\n\n\n\n\nQuestion 9\n\n\nPlot the data and the fitted regression line. To do so:\n\nExtract the estimated regression coefficients e.g., via betas <- coef(mdl)\n\nExtract the first entry of betas (i.e., the intercept) via betas[1]\n\nExtract the second entry of betas (i.e., the slope) via betas[2]\n\nProvide the intercept and slope to the function\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nIn your ggplot(), you will need to specify geom_abline(). This might help get you started:\n\ngeom_abline(intercept = <intercept>, slope = <slope>)\n\n\n\n\n\n\n\n\n Solution \n\n\nThe function coef(mdl) returns a vector: that is, a sequence of numbers all of the same type. To get the first element of the sequence you append [1], and [2] for the second.\nWe can plot the model as follows:\n\nbetas <- coef(mdl)\nintercept <- betas[1]\nslope <- betas[2]\n\nggplot(data = riverview, aes(x = education, y = income)) +\n  geom_point(alpha = 0.5) +\n  geom_abline(intercept = intercept, slope = slope, \n              color = 'blue', size = 1) + \n  labs(x = \"Education (in years)\", \n       y = \"Income (in thousands of U.S. dollars)\")"
  },
  {
    "objectID": "1_02_slr.html#fitted-and-predicted-values",
    "href": "1_02_slr.html#fitted-and-predicted-values",
    "title": "Intro to Linear Regression",
    "section": "Fitted and Predicted Values",
    "text": "Fitted and Predicted Values\nTo compute the model-predicted values for the data in the sample, we can use various funcitons:\n\npredict(<fitted model>)\nfitted(<fitted model>)\nfitted.values(<fitted model>)\nmdl$fitted.values\n\nFor example, this will give us the estimated income (point on our regression line) for each observed value of education level.\n\npredict(mdl)\n\n       1        2        3        4        5        6        7        8 \n32.53175 32.53175 37.83435 37.83435 37.83435 43.13694 43.13694 43.13694 \n       9       10       11       12       13       14       15       16 \n43.13694 48.43953 48.43953 48.43953 51.09083 53.74212 53.74212 53.74212 \n      17       18       19       20       21       22       23       24 \n53.74212 53.74212 56.39342 59.04472 59.04472 61.69601 61.69601 64.34731 \n      25       26       27       28       29       30       31       32 \n64.34731 64.34731 64.34731 66.99861 66.99861 69.64990 69.64990 74.95250 \n\n\nWe can also compute model-predicted values for other (unobserved) data:\n\npredict(<fitted model>, newdata = <dataframe>)\n\nWe first need to remember that the model predicts income using the independent variable education. Hence, if we want predictions for new data, we first need to create a tibble with a column called education containing the years of education for which we want the prediction.\n\nnewdata <- tibble(education = c(11, 23))\nnewdata\n\n# A tibble: 2 × 1\n  education\n      <dbl>\n1        11\n2        23\n\n\nThen we take newdata and add a new column called income_hat, computed as the prediction from the fitted mdl using the newdata above:\n\nnewdata <- newdata %>%\n  mutate(\n    income_hat = predict(mdl, newdata = newdata)\n  )\nnewdata\n\n# A tibble: 2 × 2\n  education income_hat\n      <dbl>      <dbl>\n1        11       40.5\n2        23       72.3"
  },
  {
    "objectID": "1_02_slr.html#residuals",
    "href": "1_02_slr.html#residuals",
    "title": "Intro to Linear Regression",
    "section": "Residuals",
    "text": "Residuals\nThe residuals represent the deviations between the actual responses and the predicted responses and can be obtained either as\n\n\nmdl$residuals;\n\nresid(mdl);\n\nresiduals(mdl);\ncomputing them as the difference between the response and the predicted response."
  },
  {
    "objectID": "1_03_mlr.html",
    "href": "1_03_mlr.html",
    "title": "Multiple Linear Regression",
    "section": "",
    "text": "Setup\n\nSetup\n\n\n\nCreate a new RMarkdown file\nLoad the required package(s)\nRead the wellbeing dataset into R, assigning it to an object named mwdata\n\n\n\n\n\n\n Solution \n\n\n\n#Loading the required package(s)\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(sjPlot)\n\n# Reading in data and storing to an object named 'mwdata'\nmwdata <- read_csv(\"https://uoepsy.github.io/data/wellbeing.csv\")\n\n\n\n\nStudy Overview\n\nResearch Question\nIs there an association between well-being and time spent outdoors after taking into account the association between well-being and social interactions?\n\n\n Wellbeing data codebook.\n\n\nDescription\nResearchers interviewed 32 participants, selected at random from the population of residents of Edinburgh & Lothians. They used the Warwick-Edinburgh Mental Wellbeing Scale (WEMWBS), a self-report measure of mental health and well-being. The scale is scored by summing responses to each item, with items answered on a 1 to 5 Likert scale. The minimum scale score is 14 and the maximum is 70.\nThe researchers also asked participants to estimate the average number of hours they spend outdoors each week, the average number of social interactions they have each week (whether on-line or in-person), and whether they believe that they stick to a routine throughout the week (Yes/No).\nThe data in wellbeing.csv contain five attributes collected from a random sample of \\(n=32\\) hypothetical residents over Edinburgh & Lothians, and include:\n\n\nwellbeing: Warwick-Edinburgh Mental Wellbeing Scale (WEMWBS), a self-report measure of mental health and well-being. The scale is scored by summing responses to each item, with items answered on a 1 to 5 Likert scale. The minimum scale score is 14 and the maximum is 70.\n\n\noutdoor_time: Self report estimated number of hours per week spent outdoors\n\n\nsocial_int: Self report estimated number of social interactions per week (both online and in-person)\n\nroutine: Binary Yes/No response to the question “Do you follow a daily routine throughout the week?”\n\nlocation: Location of primary residence (City, Suburb, Rural)\n\nPreview\nThe first six rows of the data are:\n\n\n\n\n\n\n\nwellbeing\n      outdoor_time\n      social_int\n      location\n      routine\n    \n\n\n30\n7\n8\nSuburb\nRoutine\n\n\n21\n9\n8\nCity\nNo Routine\n\n\n38\n14\n10\nSuburb\nRoutine\n\n\n27\n16\n10\nCity\nNo Routine\n\n\n20\n1\n10\nRural\nNo Routine\n\n\n37\n11\n12\nSuburb\nNo Routine\n\n\n\n\n\n\n\n\n\n\nQuestion 1\n\n\nProduce plots of the marginal distributions (the distributions of each variable in the analysis without reference to the other variables) of the wellbeing, outdoor_time, and social_int variables.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nYou could use, for example, geom_density() for a density plot or geom_histogram() for a histogram.\nLook at the shape, center and spread of the distribution. Is it symmetric or skewed? Is it unimodal or bimodal?\n\n\n\n\n\n\n\n\n Solution \n\n\nWe should be familiar now with how to visualise a marginal distribution. You might choose histograms, density curves, or boxplots, or a combination:\n\nwellbeing_plot <- \n  ggplot(data = mwdata, aes(x = wellbeing)) +\n  geom_density() +\n  geom_boxplot(width = 1/250) +\n  labs(x = \"Score on WEMWBS (range 14-70)\", y = \"Probability\\ndensity\")\n\noutdoortime_plot <- \n  ggplot(data = mwdata, aes(x = outdoor_time)) +\n  geom_density() +\n  geom_boxplot(width = 1/200) +\n  labs(x = \"Time spent outdoors per week (hours)\", y = \"Probability\\ndensity\")\n\nsocial_plot <- \n  ggplot(data = mwdata, aes(x = social_int)) +\n  geom_density() +\n  geom_boxplot(width = 1/150) +\n  labs(x = \"Number of social interactions per week\", y = \"Probability\\ndensity\")\n\n# the \"patchwork\" library allows us to arrange multiple plots\nwellbeing_plot / outdoortime_plot / social_plot\n\n\n\nFigure 1: Marginal distribution plots of wellbeing sores, weekly hours spent outdoors, and social interactions\n\n\n\n\nSummary statistics for wellbeing, outdoor time, and social interactions:\n\ndescriptives <- mwdata %>% \n  summarize(\n    M_Wellbeing = mean(wellbeing), \n    SD_Wellbeing = sd(wellbeing),\n    M_OutTime = mean(outdoor_time), \n    SD_OutTime = sd(outdoor_time),\n    M_SocInt = mean(social_int), \n    SD_SocInt = sd(social_int)\n    )\ndescriptives\n\n# A tibble: 1 × 6\n  M_Wellbeing SD_Wellbeing M_OutTime SD_OutTime M_SocInt SD_SocInt\n        <dbl>        <dbl>     <dbl>      <dbl>    <dbl>     <dbl>\n1          43         11.7      14.8       6.95       16      4.36\n\n\n\n\nThe marginal distribution of scores on the WEMWBS is unimodal with a mean of approximately 43. There is variation in WEMWBS scores (SD = 11.7).\n\nThe marginal distribution of weekly hours spent outdoors is unimodal with a mean of approximately 14.8. There is variation in weekly hours spent outdoors (SD = 6.9).\n\nThe marginal distribution of numbers of social interactions per week is unimodal with a mean of approximately 16. There is variation in numbers of social interactions (SD = 4.4).\n\n\n\n\n\n\n\nQuestion 2\n\n\nProduce plots of the associations between the outcome variable (wellbeing) and each of the explanatory variables.\n\n\n\n\n\n\nHint\n\n\n\n\n\nThink about:\n\n\nDirection of association\n\nForm of association (can it be summarised well with a straight line?)\n\n\nStrength of association (how closely do points fall to a recognizable pattern such as a line?)\n\nUnusual observations that do not fit the pattern of the rest of the observations and which are worth examining in more detail.\n\nPlot tips:\n\nuse \\n to wrap text in your titles and or axis labels\nconsider using geom_smooth() to superimpose the best-fitting line describing the association of interest\n\n\n\n\n\n\n\n\n Solution \n\n\n\nwellbeing_outdoor <- \n  ggplot(data = mwdata, aes(x = outdoor_time, y = wellbeing)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", se = FALSE) + \n  labs(x = \"Time spent outdoors \\nper week (hours)\", y = \"Wellbeing score (WEMWBS)\")\n\nwellbeing_social <- \n  ggplot(data = mwdata, aes(x = social_int, y = wellbeing)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", se = FALSE) + \n  labs(x = \"Number of social interactions \\nper week\", y = \"Wellbeing score (WEMWBS)\")\n\n# place plots adjacent to one another\nwellbeing_outdoor | wellbeing_social\n\n\n\nFigure 2: Scatterplots displaying the relationships between scores on the WEMWBS and a) weekly outdoor time (hours), and b) weekly number of social interactions\n\n\n\n\n\n\n\n\n\nQuestion 3\n\n\nProduce a correlation matrix of the variables which are to be used in the analysis, and write a short paragraph describing the associations.\n\nCorrelation matrix\nA table showing the correlation coefficients - \\(r_{(x,y)}=\\frac{\\mathrm{cov}(x,y)}{s_xs_y}\\) - between variables. Each cell in the table shows the relationship between two variables. The diagonals show the correlation of a variable with itself (and are therefore always equal to 1).\n\nIn R, we can create a correlation matrix by giving the cor() function a dataframe. However, we only want to give it 3 columns here. Think about how we select specific columns, either using select(), or giving the column numbers inside [].\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nMake sure to round your numbers in-line with APA 7th edition guidelines. The round() function will come in handy here, as might this APA numbers and statistics guide!\n\n\n\n\n\n\n\n Solution \n\n\nWe can either use:\n\n# correlation matrix of the first 3 columns\nround(cor(mwdata[,1:3]), digits = 2)\n\nor:\n\n# select only the columns we want by name, and pass this to cor()\nmwdata %>% \n  select(wellbeing, outdoor_time, social_int) %>%\n  cor() %>%\n    round(digits = 2)\n\n             wellbeing outdoor_time social_int\nwellbeing         1.00         0.58       0.79\noutdoor_time      0.58         1.00       0.34\nsocial_int        0.79         0.34       1.00\n\n\n\n\n\n\n\n\n\nThere was a moderate, positive, linear association between weekly outdoor time and WEMWBS scores for the participants in the sample (\\(r\\) = .58). Higher number of hours spent outdoors each week was associated, on average, with higher wellbeing scores,\n\nThere was a moderate, positive, linear association between the weekly number of social interactions and WEMWBS scores for the participants in the sample (\\(r\\) = .79). More social interactions were associated, on average, with higher wellbeing scores.\nThere was a weak positive correlation between weekly outdoor time and the weekly number of social interactions (\\(r\\) = .34).\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that there is a weak correlation between our two explanatory variables (outdoor_time and social_int). We will return to how this might affect our model when later on we look at the assumptions of multiple regression.\n\n\n\n\n\n\n\nQuestion 4\n\n\nThe scatterplots we created above show moderate, positive, and linear relationships both between outdoor time and wellbeing, and between numbers of social interactions and wellbeing.\n\nSpecify the form of your model, where \\(y\\) = scores on the WEMWBS, \\(x_1\\) = weekly number of social interactions, and \\(x_2\\) = weekly outdoor time.\nWhat are the parameters of the model. How do we denote parameter estimates?\nFit the linear model in using lm(), assigning the output to an object called mdl1.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nAs we did for simple linear regression, we can fit our multiple regression model using the lm() function. We can add as many explanatory variables as we like, separating them with a +.\n\n( <response variable> ~ 1 + <explanatory variable 1> + <explanatory variable 2> + ... , data = <dataframe> )\n\n\n\n\n\n\n\n\n Solution \n\n\nA model for the relationship between \\(x_1\\) = weekly outdoor time, \\(x_2\\) = weekly numbers of social interactions and \\(y\\) = scores on the WEMWBS is given by:\n\\[\ny = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\epsilon \\\\ \\quad \\\\\n\\text{where} \\quad \\epsilon \\sim N(0, \\sigma) \\text{ independently}\n\\]\nIn the model specified above,\n\n\n\\(\\mu_{y|x_1, x_2} = \\beta_0 + \\beta_1 x + \\beta_2 x_2\\) represents the systematic part of the model giving the mean of \\(y\\) at each combination of values of \\(x_1\\) and \\(x_2\\);\n\n\\(\\epsilon\\) represents the error (deviation) from that mean, and the errors are independent from one another.\n\nThe parameters of our model are:\n\n\n\\(\\beta_0\\) (The intercept);\n\n\\(\\beta_1\\) (The slope across values of \\(x_1\\));\n\n\\(\\beta_2\\) (The slope across values of \\(x_2\\));\n\n\n\\(\\sigma\\) (The standard deviation of the errors).\n\nWhen we estimate these parameters from the available data, we have a fitted model (recall that the h\\(\\hat{\\textrm{a}}\\)ts are used to distinguish our estimates from the true unknown parameters):\n\\[\n\\widehat{Wellbeing} = \\hat \\beta_0 + \\hat \\beta_1 \\cdot Social Interactions + \\hat \\beta_2 \\cdot Outdoor Time\n\\]\nAnd we have residuals \\(\\hat \\epsilon = y - \\hat y\\) which are the deviations from the observed values and our model-predicted responses.\nFitting the model in R:\n\nmdl1 <- lm(wellbeing ~ social_int + outdoor_time, data = mwdata)\n\n\n\n\n\n\nVisual\nNote that for simple linear regression we talked about our model as a line in 2 dimensions: the systematic part \\(\\beta_0 + \\beta_1 x\\) defined a line for \\(\\mu_y\\) across the possible values of \\(x\\), with \\(\\epsilon\\) as the random deviations from that line. But in multiple regression we have more than two variables making up our model.\nIn this particular case of three variables (one outcome + two explanatory), we can think of our model as a regression surface (see Figure 3). The systematic part of our model defines the surface across a range of possible values of both \\(x_1\\) and \\(x_2\\). Deviations from the surface are determined by the random error component, \\(\\hat \\epsilon\\).\n\n\n\n\nFigure 3: Regression surface for wellbeing ~ social_int + outdoor_time, from two different angles\n\n\n\n\nDon’t worry about trying to figure out how to visualise it if we had any more explanatory variables! We can only concieve of 3 spatial dimensions. One could imagine this surface changing over time, which would bring in a 4th dimension, but beyond that, it’s not worth trying!.\n\n\n\nQuestion 5\n\n\nState the research question in the form of a testable hypothesis.\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou must define both a null (\\(H_0\\)) and alternative hypothesis (\\(H_1\\)).\n\n\n\n\n\n\n\n Solution \n\n\nIn words:\n\\(H_0\\): There is no association between well-being and time spent outdoors after taking into account the relationship between well-being and social interactions\n\\(H_1\\): There is an association between well-being and time spent outdoors after taking into account the relationship between well-being and social interactions\nIn symbols:\n\\(H_0: \\beta_2 = 0\\)\n\\(H_1: \\beta_2 \\neq 0\\)\n\n\n\n\n\nQuestion 6\n\n\nUsing any of:\n\nmdl1\nmdl1$coefficients\ncoef(mdl1)\ncoefficients(mdl1)\nsummary(mdl1)\n\nWrite out the estimated parameter values of:\n\n\n\\(\\hat \\beta_0\\), the estimated average wellbeing score associated with zero hours of outdoor time and zero social interactions per week.\n\n\n\\(\\hat \\beta_1\\), the estimated increase in average wellbeing score associated with an additional social interaction per week (an increase of one), holding weekly outdoor time constant.\n\n\n\\(\\hat \\beta_2\\), the estimated increase in average wellbeing score associated with one hour increase in weekly outdoor time, holding the number of social interactions constant\n\n\n\n\n\n\n\n\nNote\n\n\n\nQ: What do we mean by hold constant / controlling for / partialling out / residualizing for?\nA: When the remaining explanatory variables are held at the same value or are fixed.\n\n\n\n\n\n\n Solution \n\n\n\n\nmdl1$coefficients\ncoef(mdl1)\ncoefficients(mdl1)\nsummary(mdl1)\n\n\n\n\nmdl1$coefficients\n\n (Intercept)   social_int outdoor_time \n   5.3703775    1.8034489    0.5923673 \n\n\n\n\n\ncoef(mdl1)\n\n (Intercept)   social_int outdoor_time \n   5.3703775    1.8034489    0.5923673 \n\n\n\n\n\ncoefficients(mdl1)\n\n (Intercept)   social_int outdoor_time \n   5.3703775    1.8034489    0.5923673 \n\n\n\n\nLook under the “Estimate” column:\n\nsummary(mdl1)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.742 -4.915 -1.255  5.628 10.936 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    5.3704     4.3205   1.243   0.2238    \nsocial_int     1.8034     0.2691   6.702 2.37e-07 ***\noutdoor_time   0.5924     0.1689   3.506   0.0015 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.148 on 29 degrees of freedom\nMultiple R-squared:  0.7404,    Adjusted R-squared:  0.7224 \nF-statistic: 41.34 on 2 and 29 DF,  p-value: 3.226e-09\n\n\n\n\n\n\n\n\\(\\hat \\beta_0\\) = 5.37\n\n\n\\(\\hat \\beta_1\\) = 1.8\n\n\n\\(\\hat \\beta_2\\) = 0.59\n\n\n\n\n\n\nQuestion 7\n\n\nWithin what distance from the model predicted values (the regression surface) would we expect 95% of wEMWBS wellbeing scores to be?\n\n\n\n\n\n\nHint\n\n\n\n\n\nEither sigma() or part of the output from summary() will help you here.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nsigma(mdl1)\nsummary(mdl1)\n\n\n\n\nsigma(mdl1)\n\n[1] 6.148276\n\n\n\n\nLook at the “Residual standard error” entry of the summary(mdl) output:\n\nsummary(mdl1)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.742 -4.915 -1.255  5.628 10.936 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    5.3704     4.3205   1.243   0.2238    \nsocial_int     1.8034     0.2691   6.702 2.37e-07 ***\noutdoor_time   0.5924     0.1689   3.506   0.0015 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.148 on 29 degrees of freedom\nMultiple R-squared:  0.7404,    Adjusted R-squared:  0.7224 \nF-statistic: 41.34 on 2 and 29 DF,  p-value: 3.226e-09\n\n\n\n\n\nThe estimated standard deviation of the errors is \\(\\hat \\sigma\\) = 6.15. We would expect 95% of wellbeing scores to be within about 12.3 (\\(2 \\hat \\sigma\\)) from the model fit.\n\n\n\n\n\nQuestion 8\n\n\nBased on the model, predict the wellbeing scores for the following individuals:\n\nLeah: Social Interactions = 24; Outdoor Time = 3\nSean: Social Interactions = 19; Outdoor Time = 26\nMike: Social Interactions = 15; Outdoor Time = 20\nDonna: Social Interactions = 7; Outdoor Time = 2\n\nWho has the highest predicted wellbeing score, and who has the lowest?\n\n\n\n\n Solution \n\n\nFirst we need to pass the data into R:\n\nwellbeing_query <- tibble(social_int = c(24, 19, 15, 7),\n                          outdoor_time = c(3, 26, 20, 2))\n\nAnd next use predict() to get their estimated wellbeing scores:\n\npredict(mdl1, newdata = wellbeing_query)\n\n       1        2        3        4 \n50.43025 55.03746 44.26946 19.17925 \n\n\nSean has the highest predicted wellbeing score (55.04), and Donna the lowest (19.18).\n\n\n\n\n\nQuestion 9\n\n\nShould we reject or fail to reject \\(H_0\\)? Why?\n\n\n\n\n Solution \n\n\nThe research question asked whether there was an association between well-being and time spent outdoors after taking into account the association between well-being and social interactions. This was equivalent to testing the following null hypothesis:\n\\(H_0: \\beta_2 = 0\\)\nBased on the model output (if we considered effects to be significant at \\(\\alpha\\) = .05), we should reject the null hypothesis since our \\(p\\)-value smaller than this (\\(p\\) = .0015). In short, we reject the null since \\(p\\) < .05.\n\n\n\n\n\nQuestion 10\n\n\nInterpret the outdoor time coefficient in the context of the research question.\n\n\n\n\n Solution \n\n\nA multiple regression model was used to determine if there was an association between well-being and time spent outdoors after taking into account the association between well-being and social interactions. Outdoor time was significantly associated with wellbeing scores (\\(\\beta\\) = 0.59, SE = 0.17, \\(p\\) < .001) after controlling for the number of weekly social interactions. Results suggested that for every additional hour spent outdoors each week, wellbeing scores increased by 0.59 points."
  },
  {
    "objectID": "1_04_model_fit.html",
    "href": "1_04_model_fit.html",
    "title": "Model Fit and Standardization",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand how to interpret significance tests for \\(\\beta\\) coefficients\nUnderstand how to calculate the interpret \\(R^2\\) and adjusted-\\(R^2\\) as a measure of model quality.\nUnderstand the calculation and interpretation of the \\(F\\)-test of model utility.\nUnderstand how to standardize model coefficients and when this is appropriate to do.\n\n\nBe up to date with lectures\nHave completed previous lab exercises from Week 1, Week 2, and Week 3\n\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npatchwork\nsjPlot\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/wellbeing.csv.\nNote: this is the same data as Lab 3."
  },
  {
    "objectID": "1_04_model_fit.html#lab-purpose",
    "href": "1_04_model_fit.html#lab-purpose",
    "title": "Model Fit and Standardization",
    "section": "Lab Purpose",
    "text": "Lab Purpose\nIn this lab (Lab 4), you will focus on the statistics contained within the highlighted sections of the summary() output below. You will be both calculating these by hand and deriving via R code before interpreting these values in the context of the research question following APA guidelines.\n\n\n\n\n\n\n\nQuestion 3\n\n\nTest the hypothesis that the population slope for outdoor time is zero — that is, that there is no linear association between wellbeing and outdoor time (after controlling for the number of social interactions) in the population.\n\n\n\n\n\n\nHint\n\n\n\n\n\nRecall the formula for obtaining a test statistic:\nA test statistic for the null hypothesis \\(H_0: \\beta_j = 0\\) is\n\\[\nt = \\frac{\\hat \\beta_j - 0}{SE(\\hat \\beta_j)}\n\\]\nwhich follows a \\(t\\)-distribution with \\(n-k-1 = n - 2 - 1 = n - 3\\) degrees of freedom.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nManually\nR function\n\n\n\nWe calculate the test statistic for \\(\\beta_2\\)\n\\[\nt = \\frac{\\hat \\beta_2 - 0}{SE(\\hat \\beta_2)} = \\frac{0.5924 - 0}{0.1689} = 3.5074\n\\]\nand compare it with the 5% critical value from a \\(t\\)-distribution with \\(n-3\\) degrees of freedom, which is:\n\nn <- nrow(mwdata)\ntstar <- qt(0.975, df = n - 3)\ntstar\n\n[1] 2.04523\n\n#tstar = 2.04523\n\nAs \\(|t|\\) (\\(|t|\\) = 3.51) is much larger than \\(t^*\\) (\\(t^*\\) = 2.05), we can reject then null hypothesis as we have strong evidence against it.\nThe \\(p\\)-value, shown below, also confirms this conclusion.\n\n2 * (1 - pt(3.506, n - 3))\n\n[1] 0.001500588\n\n\n\n\nPlease note that the same information was already contained in the row corresponding to the variable “outdoor_time” in the output of summary(mdl), which reported the \\(t\\)-statistic under t value and the \\(p\\)-value under Pr(>|t|):\n\nsummary(mdl1)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.742 -4.915 -1.255  5.628 10.936 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    5.3704     4.3205   1.243   0.2238    \nsocial_int     1.8034     0.2691   6.702 2.37e-07 ***\noutdoor_time   0.5924     0.1689   3.506   0.0015 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.148 on 29 degrees of freedom\nMultiple R-squared:  0.7404,    Adjusted R-squared:  0.7224 \nF-statistic: 41.34 on 2 and 29 DF,  p-value: 3.226e-09\n\n\nThe result is exactly the same (up to rounding errors) as calculating manually.\nBefore we interpret the results, note that sometimes \\(p\\)-values will be reported to \\(e^X\\). For example, look in the Pr(>|t|) column for “social_int”. The value \\(2.37e^{-07}\\) simply means \\(2.37 \\times 10^{-7}\\). This is a very small value (i.e., 0.000000237), hence we will report it as <.001 following the APA guidelines.\n\n\n\n\n\n\n\n\n\nWe performed a \\(t\\)-test against the null hypothesis that outdoor time was not associated with wellbeing scores after controlling for social interactions. A significant association was found between outdoor time (in hours per week) and wellbeing (WEMWBS scores) \\(t(29) = 3.51,\\ p = 002\\), two-sided. Thus, we have evidence to reject the null hypothesis.\n\n\n\n\n\n\n\n\nQuestion 4\n\n\nObtain 95% confidence intervals for the regression coefficients, and write a sentence about each one.\n\n\n\n\n\n\nHint\n\n\n\n\n\nRecall the formula for obtaining a confidence interval:\nA confidence interval for the population slope is\n\\[\n\\hat \\beta_j \\pm t^* \\cdot SE(\\hat \\beta_j)\n\\]\nwhere \\(t^*\\) denotes the critical value chosen from t-distribution with \\(n-k-1 = n - 2 - 1 = n - 3\\) degrees of freedom for a desired \\(\\alpha\\) level of confidence.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nManually\nR function\n\n\n\nFor 95% confidence we have \\(t^* = 2.05\\):\n\nn <- nrow(mwdata)\ntstar <- qt(0.975, df = n - 3)\ntstar\n\n[1] 2.04523\n\n\nThe confidence intervals are:\n\ntibble(\n  b0_LowerCI = round(5.3704 - (qt(0.975, n-3) * 4.3205), 3),\n  b0_UpperCI = round(5.3704 + (qt(0.975, n-3)* 4.3205), 3),\n  b1_LowerCI = round(1.8034 - (qt(0.975, n-3) * 0.2691), 3),\n  b1_UpperCI = round(1.8034 + (qt(0.975, n-3)* 0.2691), 3),\n  b2_LowerCI = round(0.5924 - (qt(0.975, n-3) * 0.1689), 3),\n  b2_UpperCI = round(0.5924 + (qt(0.975, n-3)* 0.1689), 3)\n      )\n\n# A tibble: 1 × 6\n  b0_LowerCI b0_UpperCI b1_LowerCI b1_UpperCI b2_LowerCI b2_UpperCI\n       <dbl>      <dbl>      <dbl>      <dbl>      <dbl>      <dbl>\n1      -3.47       14.2       1.25       2.35      0.247      0.938\n\n\n\n\nWe can easily obtain the confidence intervals for the regression coefficients using the command confint():\n\nconfint(mdl1, level = 0.95)\n\n                  2.5 %     97.5 %\n(Intercept)  -3.4660660 14.2068209\nsocial_int    1.2530813  2.3538164\noutdoor_time  0.2468371  0.9378975\n\n\nThe result is exactly the same (up to rounding errors) as calculating manually.\n\n\n\n\n\n\n\n\n\n\nThe average wellbeing score for all those with zero hours of outdoor time and zero social interactions per week was between -3.47 and 14.21.\n\nWhen holding weekly outdoor time constant, each increase of one social interaction per week was associated with a difference in wellbeing scores between 1.25 and 2.35, on average.\n\nWhen holding the number of social interactions per week constant, each one hour increase in weekly outdoor time was associated with a difference in wellbeing scores between 0.25 and 0.94, on average.\n\n\n\n\n\n\n\n\n\nQuestion 5\n\n\nWhat is the proportion of the total variability in wellbeing scores explained by the model?\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe question asks to compute the value of \\(R^2\\). Since the model includes 2 predictors, you should report the Adjusted \\(R^2\\).\n\n\n\n\n\n\n\n Solution \n\n\nThe proportion of the total variability explained is given by R-squared.\nThe R-squared coefficient is defined as:\n\\[\nR^2 = \\frac{SS_{Model}}{SS_{Total}} = 1 - \\frac{SS_{Residual}}{SS_{Total}}\n\\]\nThe Adjusted R-squared coefficient is defined as:\n\\[\n\\hat R^2 = 1 - \\frac{(1 - R^2)(n-1)}{n-k-1}\n\\quad \\\\\n\\begin{align}\n& \\text{Where:} \\\\\n& n = \\text{sample size} \\\\\n& k = \\text{number of explanatory variables} \\\\\n\\end{align}\n\\]\n\n\nManually\nR function\n\n\n\nIn R we can write:\n\n#R squared & adjusted R squared\n\nwellbeing_fitted <- mwdata %>%\n  mutate(\n    wellbeing_hat = predict(mdl1),\n    resid = wellbeing - wellbeing_hat\n  )\n\n\nwellbeing_fitted %>%\n  summarise(\n    SSModel = sum( (wellbeing_hat - mean(wellbeing))^2 ),\n    SSTotal = sum( (wellbeing - mean(wellbeing))^2 )\n  ) %>%\n  summarise(\n    RSquared = SSModel / SSTotal,\n    AdjRSquared = 1-((1-(RSquared))*(32-1)/(32-2-1))\n  )\n\n# A tibble: 1 × 2\n  RSquared AdjRSquared\n     <dbl>       <dbl>\n1    0.740       0.722\n\n\n\n\n\n#look in second bottom row - Multiple R Squared and Adjusted R Squared both reported here\nsummary(mdl1)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.742 -4.915 -1.255  5.628 10.936 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    5.3704     4.3205   1.243   0.2238    \nsocial_int     1.8034     0.2691   6.702 2.37e-07 ***\noutdoor_time   0.5924     0.1689   3.506   0.0015 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.148 on 29 degrees of freedom\nMultiple R-squared:  0.7404,    Adjusted R-squared:  0.7224 \nF-statistic: 41.34 on 2 and 29 DF,  p-value: 3.226e-09\n\n\nThe output of summary() displays the Adjusted \\(R\\)-squared value in the following line:\nAdjusted R-squared:  0.7224 \n\n\n\n\nInterpretation\n\n\n\n\n\n\nApproximately 72% of the total variability in wellbeing scores is explained by associations with social interactions and outdoor time.\n\n\n\n\n\n\n\n\nQuestion 6\n\n\nPerform a model utility test at the 5% significance level and report your results.\nIn other words, conduct an \\(F\\)-test against the null hypothesis that the model is ineffective at predicting wellbeing scores using social interactions and outdoor time by computing the \\(F\\)-statistic using its definition.\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe F-ratio is used to test the null hypothesis that all regression slopes are zero.\nIt is called the F-ratio because it is the ratio of the how much of the variation is explained by the model (per paramater) versus how much of the variation is left unexplained in the residuals (per remaining degrees of freedom).\n\\[\nF_{df_{model},df_{residual}} = \\frac{MS_{Model}}{MS_{Residual}} = \\frac{SS_{Model}/df_{Model}}{SS_{Residual}/df_{Residual}} \\\\\n\\quad \\\\\n\\begin{align}\n& \\text{Where:} \\\\\n& df_{model} = k \\\\\n& df_{residual} = n-k-1 \\\\\n& n = \\text{sample size} \\\\\n& k  = \\text{number of explanatory variables} \\\\\n\\end{align}\n\\]\n\n\n\n\n\n\n\n Solution \n\n\n\n\nManually\nR function\n\n\n\n\ndf1 <- 2\ndf2 <- nrow(mwdata) - 2 - 1\nf_star <- qf(0.95, df1, df2)\nf_star\n\n[1] 3.327654\n\n\n\nmodel_utility <- wellbeing_fitted %>%\n  summarise(\n    SSModel = sum((wellbeing_hat - mean(wellbeing))^2 ),\n    SSResid = sum( resid^2 ),\n    MSModel = SSModel / df1,\n    MSResid = SSResid / df2,\n    FObs = MSModel / MSResid\n  )\nmodel_utility\n\n# A tibble: 1 × 5\n  SSModel SSResid MSModel MSResid  FObs\n    <dbl>   <dbl>   <dbl>   <dbl> <dbl>\n1   3126.   1096.   1563.    37.8  41.3\n\n\nWe can also compute the p-value:\n\npvalue <- 1 - pf(model_utility$FObs, df1, df2)\npvalue\n\n[1] 3.225548e-09\n\n\nThe value 3.225548e-09 simply means \\(3.2 \\times 10^{-9}\\), so it’s a really small number.\n\n\n\n#look in bottom row\nsummary(mdl1)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + outdoor_time, data = mwdata)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.742 -4.915 -1.255  5.628 10.936 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    5.3704     4.3205   1.243   0.2238    \nsocial_int     1.8034     0.2691   6.702 2.37e-07 ***\noutdoor_time   0.5924     0.1689   3.506   0.0015 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.148 on 29 degrees of freedom\nMultiple R-squared:  0.7404,    Adjusted R-squared:  0.7224 \nF-statistic: 41.34 on 2 and 29 DF,  p-value: 3.226e-09\n\n\nThe relevant row is the following:\n\nF-statistic: 41.34 on 2 and 29 DF,  p-value: 3.226e-09\n\n\n\n\n\n\n\n\n\n\nWe performed an \\(F\\)-test of model utility at the 5% significance level, where \\(F(2,29) = 41.34, p <.001\\).\nThe large \\(F\\)-statistic and small \\(p\\)-value (\\(<.001\\)) suggested that we have very strong evidence against the null hypothesis that the model is ineffective.\nIn other words, the data provide strong evidence that the number of social interactions and outdoor time are effective predictors of wellbeing scores.\n\n\n\n\n\n\n\n\nQuestion 7\n\n\nProduce a visualisation of the association between wellbeing and outdoor time, after accounting for social interactions.\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo visualise just one association, you might need to specify the terms argument in plot_model(). Don’t forget you can look up the documentation by typing ?plot_model in the console.\n\n\n\n\n\n\n\n Solution \n\n\n\nplot_model(mdl1, type = \"eff\",\n           terms = c(\"outdoor_time\"), \n           show.data = TRUE)"
  },
  {
    "objectID": "1_04_model_fit.html#standardization",
    "href": "1_04_model_fit.html#standardization",
    "title": "Model Fit and Standardization",
    "section": "Standardization",
    "text": "Standardization\n\nQuestion 8\n\n\nFit the regression model using the standardized response and explanatory variables.\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can either:\n\nAdd to the “mwdata” dataset three variables called z_wellbeing, z_social_int, and z_outdoor_time representing the standardized welllbeing, social interactions and outdoor time variables, respectively.\n\nRecall the formula for the \\(z\\)-score:\n\\[\nz_x = \\frac{x - \\bar{x}}{s_x}, \\qquad z_y = \\frac{y - \\bar{y}}{s_y}\n\\]\nOR\n\nUse the scale() function when specifying your lm() statement.\n\n\n\n\n\n\n\n\n Solution \n\n\n\n\nZ-Score\nscale function\n\n\n\nz score variables\n\nmwdata <- mwdata %>%\n  mutate(\n    z_wellbeing = (wellbeing - mean(wellbeing)) / sd(wellbeing),\n    z_social_int = (social_int - mean(social_int)) / sd(social_int),\n    z_outdoor_time = (outdoor_time - mean(outdoor_time)) / sd(outdoor_time)\n  )\n\nCheck that they are standardized\n\nmwdata %>%\n  summarise(\n    M_z_wellbeing = round(mean(z_wellbeing),2), SD_z_wellbeing = sd(z_wellbeing), \n    M_z_social_int = round(mean(z_social_int),2), SD_z_social_int = sd(z_social_int),\n    M_z_outdoor_time = round(mean(z_outdoor_time),2), SD_z_outdoor_time = sd(z_outdoor_time)\n  )\n\n# A tibble: 1 × 6\n  M_z_wellbeing SD_z_wellbeing M_z_social_int SD_z_social_int M_z_outd…¹ SD_z_…²\n          <dbl>          <dbl>          <dbl>           <dbl>      <dbl>   <dbl>\n1             0              1              0               1          0       1\n# … with abbreviated variable names ¹​M_z_outdoor_time, ²​SD_z_outdoor_time\n\n#mean of 0, SD of 1 - all good to go\n\nRun model\n\n#with z scoring\nmdl_z <- lm(z_wellbeing ~ z_social_int + z_outdoor_time, data = mwdata)\nsummary(mdl_z)\n\n\nCall:\nlm(formula = z_wellbeing ~ z_social_int + z_outdoor_time, data = mwdata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.8347 -0.4212 -0.1075  0.4822  0.9371 \n\nCoefficients:\n                Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    1.327e-16  9.313e-02   0.000   1.0000    \nz_social_int   6.742e-01  1.006e-01   6.702 2.37e-07 ***\nz_outdoor_time 3.527e-01  1.006e-01   3.506   0.0015 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5268 on 29 degrees of freedom\nMultiple R-squared:  0.7404,    Adjusted R-squared:  0.7224 \nF-statistic: 41.34 on 2 and 29 DF,  p-value: 3.226e-09\n\nround(summary(mdl_z)$coefficients,3)\n\n               Estimate Std. Error t value Pr(>|t|)\n(Intercept)       0.000      0.093   0.000    1.000\nz_social_int      0.674      0.101   6.702    0.000\nz_outdoor_time    0.353      0.101   3.506    0.001\n\n\n\n\n\nmdl_s <- lm(scale(wellbeing) ~ scale(social_int) + scale(outdoor_time), data = mwdata)\nsummary(mdl_s)\n\n\nCall:\nlm(formula = scale(wellbeing) ~ scale(social_int) + scale(outdoor_time), \n    data = mwdata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.8347 -0.4212 -0.1075  0.4822  0.9371 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         1.327e-16  9.313e-02   0.000   1.0000    \nscale(social_int)   6.742e-01  1.006e-01   6.702 2.37e-07 ***\nscale(outdoor_time) 3.527e-01  1.006e-01   3.506   0.0015 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5268 on 29 degrees of freedom\nMultiple R-squared:  0.7404,    Adjusted R-squared:  0.7224 \nF-statistic: 41.34 on 2 and 29 DF,  p-value: 3.226e-09\n\nround(summary(mdl_s)$coefficients,3)\n\n                    Estimate Std. Error t value Pr(>|t|)\n(Intercept)            0.000      0.093   0.000    1.000\nscale(social_int)      0.674      0.101   6.702    0.000\nscale(outdoor_time)    0.353      0.101   3.506    0.001\n\n\n\n\n\nFrom comparing either the summary() or rounded output, you should see that the estimates are the same under both approaches.\n\n\n\n\n\nQuestion 9\n\n\nCreate a table to present your results from the standardized model.\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse tab_model() from the sjPlot package.\nRemember that you can rename your DV and IV labels by specifying dv.labels and pred.labels.\n\n\n\n\n\n\n\n Solution \n\n\n\ntab_model(mdl_z,\n          dv.labels = \"Wellbeing (WEMWBS Scores)\",\n          pred.labels = c(\"z_social_int\" = \"Social Interactions (number per week)\",\n                          \"z_outdoor_time\" = \"Outdoor Time (hours per week)\"),\n          title = \"Regression table for Wellbeing model. Outcome variable and predictors are Z-scored\")\n\n\n\nRegression table for Wellbeing model. Outcome variable and predictors are Z-scored\n\n \nWellbeing (WEMWBS Scores)\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n0.00\n-0.19 – 0.19\n1.000\n\n\nSocial Interactions(number per week)\n0.67\n0.47 – 0.88\n<0.001\n\n\nOutdoor Time (hours perweek)\n0.35\n0.15 – 0.56\n0.001\n\n\nObservations\n32\n\n\nR2 / R2 adjusted\n0.740 / 0.722\n\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nInterpret the standardized variables presented in the above table.\n\n\n\n\n Solution \n\n\n\nFor every standard deviation increase in social interactions, wellbeing scores increased on average by 0.67 standard deviations.\nFor every standard deviation increase in outdoor time, wellbeing scores increased on average by 0.35 standard deviations."
  },
  {
    "objectID": "1_05_cat_recap.html",
    "href": "1_05_cat_recap.html",
    "title": "Categorical Predictors & Block 1 Recap",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand the meaning of (and how to interpret) a multiple regression model with a binary predictor\nUnderstand how to specify a new baseline/reference level for categorical variables\n\n\nBe up to date with lectures\nHave completed Labs 1 - 4\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npatchwork\nsjPlot\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/wellbeing.csv.\nNote: this is the same data as Lab 3 & 4."
  },
  {
    "objectID": "1_05_cat_recap.html#study-overview",
    "href": "1_05_cat_recap.html#study-overview",
    "title": "Categorical Predictors & Block 1 Recap",
    "section": "Study Overview",
    "text": "Study Overview\n\nResearch Question\nIs there an assocation between well-being and time spent outdoors after taking into account the assocation between well-being and having a routine?\n\n\n Wellbeing data codebook.\n\n\nDescription\nResearchers interviewed 32 participants, selected at random from the population of residents of Edinburgh & Lothians. They used the Warwick-Edinburgh Mental Wellbeing Scale (WEMWBS), a self-report measure of mental health and well-being. The scale is scored by summing responses to each item, with items answered on a 1 to 5 Likert scale. The minimum scale score is 14 and the maximum is 70.\nThe researchers also asked participants to estimate the average number of hours they spend outdoors each week, the average number of social interactions they have each week (whether on-line or in-person), and whether they believe that they stick to a routine throughout the week (Yes/No).\nThe data in wellbeing.csv contain five attributes collected from a random sample of \\(n=32\\) hypothetical residents over Edinburgh & Lothians, and include:\n\n\nwellbeing: Warwick-Edinburgh Mental Wellbeing Scale (WEMWBS), a self-report measure of mental health and well-being. The scale is scored by summing responses to each item, with items answered on a 1 to 5 Likert scale. The minimum scale score is 14 and the maximum is 70.\n\n\noutdoor_time: Self report estimated number of hours per week spent outdoors\n\n\nsocial_int: Self report estimated number of social interactions per week (both online and in-person)\n\nroutine: Binary Yes/No response to the question “Do you follow a daily routine throughout the week?”\n\nlocation: Location of primary residence (City, Suburb, Rural)\n\nPreview\nThe first six rows of the data are:\n\n\n\n\n\n\n\nwellbeing\n      outdoor_time\n      social_int\n      location\n      routine\n    \n\n\n30\n7\n8\nSuburb\nRoutine\n\n\n21\n9\n8\nCity\nNo Routine\n\n\n38\n14\n10\nSuburb\nRoutine\n\n\n27\n16\n10\nCity\nNo Routine\n\n\n20\n1\n10\nRural\nNo Routine\n\n\n37\n11\n12\nSuburb\nNo Routine"
  },
  {
    "objectID": "1_07_int1_nc.html",
    "href": "1_07_int1_nc.html",
    "title": "Interactions I: Num x Cat",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand the concept of an interaction.\nBe able to interpret the meaning of a numeric \\(\\times\\) categorical interaction.\nVisualize and probe interactions.\n\n\nBe up to date with lectures\nHave completed all labs from Semester 1 Block 1 (Weeks 1 - 5)\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\npatchwork\nsandwich\ninteractions\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/wellbeing_rural.csv."
  },
  {
    "objectID": "1_07_int1_nc.html#exercises",
    "href": "1_07_int1_nc.html#exercises",
    "title": "Interactions I: Num x Cat",
    "section": "Exercises",
    "text": "Exercises\n\nQuestion 1\n\n\nFormally state:\n\na linear model to investigate if the association between wellbeing and social interactions differs among rural and non-rural residents\nyour chosen significance level\nthe null and alternative hypotheses\n\n\n\n“Except in special circumstances, a model including a product term for interaction between two explanatory variables should also include terms with each of the explanatory variables individually, even though their coefficients may not be significantly different from zero. Following this rule avoids the logical inconsistency of saying that the effect of \\(X_1\\) depends on the level of \\(X_2\\) but that there is no effect of \\(X_1\\).”\n— Ramsey and Schafer (2012)\n\n\n\n\n\n\n Solution \n\n\nTo address the research question, we are going to fit the following model, where \\(y\\) = wellbeing; \\(x_1\\) = social interactions; and \\(x_2\\) = whether or not the respondent lives in a rural location.\n\\[\ny = \\beta_0 + \\beta_1  x_1 + \\beta_2  x_2 + \\beta_3 (x_1 \\cdot x_2) + \\epsilon \\\\\n\\quad \\\\ \\text{where} \\quad \\epsilon \\sim N(0, \\sigma) \\quad \\text{independently}\n\\]\nor\n\\[\n\\begin{split}\n\\text{Wellbeing} = \\beta_0 + \\beta_1 \\cdot Social Interactions + \\beta_2 \\cdot Location_{Rural} \\\\+ \\beta_3 \\cdot (Social Interactions \\cdot Location_{Rural}) + \\epsilon \\\\\n\\end{split}\n\\]\nEffects will be considered statistically significant at \\(\\alpha=.05\\)\nOur hypotheses are:\n\\(H_0: \\beta_3 = 0\\)\nThe association between wellbeing and social interactions is not moderated by whether or not a person lives in a rural area.\n\\(H_1: \\beta_3 \\neq 0\\)\nThe association between wellbeing and social interactions is moderated by whether or not a person lives in a rural area.\n\n\n\n\n\nQuestion 2\n\n\nCheck coding of variables (e.g., that categorical variables are coded as factors).\nNote that the “location” variable currently has three levels (Rural/Suburb/City). In order to address the research question, we only want two (Rural/Not Rural) locations - you will need to fix this.\nSpecify ‘not rural’ as your reference group.\n\n\n\n\n\n\nHint\n\n\n\n\n\nOne way to do this would be to use ifelse() to define a variable which takes one value (“Rural”) if the observation meets from some condition, or another value (“Not Rural”) if it does not. Type ?ifelse in the console if you want to see the help function. You can use it to add a new variable either inside mutate(), or using data$new_variable_name <- ifelse(test, x, y) syntax.\n\n\n\n\n\n\n\n Solution \n\n\nCreate a new variable for Rural/Not Rural:\n\n#if location is rural, assign name 'rural'. If another value (i.e., city or suburb) assign name 'not rural'.\n# In other words, if location = rural assign name rural; if location != rural then assign name not rural.\nwrdata <- wrdata %>% \n  mutate(\n    isRural = ifelse(location == \"rural\", \"rural\", \"not rural\")\n  )\n\nCheck coding of variables within wrdata and ensure isRural is a factor with two levels, ‘rural’ and ‘not rural’:\n\nstr(wrdata) #returns overall 'structure' of data. Or could run is.factor() for specific variable of interest\n\ntibble [200 × 8] (S3: tbl_df/tbl/data.frame)\n $ age         : num [1:200] 28 56 25 60 19 34 41 41 35 53 ...\n $ outdoor_time: num [1:200] 12 5 19 25 9 18 17 11 12 13 ...\n $ social_int  : num [1:200] 13 15 11 15 18 13 19 12 13 15 ...\n $ routine     : num [1:200] 1 1 1 0 1 1 1 1 0 1 ...\n $ wellbeing   : num [1:200] 36 41 35 35 32 34 39 43 35 37 ...\n $ location    : chr [1:200] \"rural\" \"rural\" \"rural\" \"rural\" ...\n $ steps_k     : num [1:200] 21.6 12.3 49.8 NA 48.1 67.3 1.9 50.9 NA 35.5 ...\n $ isRural     : chr [1:200] \"rural\" \"rural\" \"rural\" \"rural\" ...\n\nwrdata$isRural <- as_factor(wrdata$isRural)\nis.factor(wrdata$isRural) #check that isRural is now a factor\n\n[1] TRUE\n\n\n\n#specify 'not rural' as reference group\nwrdata$isRural <- relevel(wrdata$isRural, 'not rural')\n\n\n\n\n\n\nQuestion 3\n\n\nVisualise your data, and interpret your plots.\nIn particular:\n\nExplore the associations among the variables included in your analysis\nProduce a visualisation of the association between weekly number of social interactions and well-being, with separate facets for rural vs non-rural respondents OR with different colours for each level of the isRural variable.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nThe pairs.panels() function from the psych package will can plot all variables in a dataset against one another. This will save you the time you would have spent creating individual plots, but is only useful for continuous variables.\nTo include facets, Within your ggplot() argument you will need to specify + facet_wrap() in order to produce facets for each location. It would also be useful to specify geom_smooth(method=\"lm\")\n\n\n\n\n\n\n\n\n\n Solution \n\n\nLet’s first plot the continuous variables included within our model (note that we could use this for the whole dataset, but we don’t want to include irrelevant variables):\n\nwrdata %>% \n  select(wellbeing, social_int) %>%\n  pairs.panels()\n\n\n\n\n\n\n\n\n\n\nWellbeing and social interactions appear to follow unimodal distributions. There was a weak, positive association between wellbeing and social interactions (\\(r\\) = .24).\n\n\n\nNow lets look at wellbeing scores by location:\n\nggplot(data = wrdata, aes(x = isRural, y = wellbeing)) +\n  geom_boxplot() + \n  labs(x = \"Location\", y = \"Wellbeing (WEMWBS Scores)\")\n\n\n\n\n\n\n\n\n\n\nThose in rural locations appear to have lower wellbeing scores in comparison to those in non-rural locations.\n\n\n\nNext, lets produce our plots with a facet for rural vs non-rural residents:\n\nggplot(data = wrdata, aes(x = social_int, y = wellbeing)) +\n  geom_point() +\n  geom_smooth(method=\"lm\", se=FALSE) +\n  facet_wrap(~isRural) + \n  labs(x = \"Social Interactions (number per week)\", y = \"Wellbeing (WEMWBS Scores)\")\n\n\n\n\nOr instead of facets, we could use different colours for each location (rural vs non-rural):\n\nggplot(data = wrdata, aes(x = social_int, y = wellbeing, colour = isRural)) +\n  geom_point() + \n  geom_smooth(method=\"lm\", se=FALSE) +\n    scale_colour_discrete(\n    name =\"Location\",\n    labels=c(\"Not Rural\", \"Rural\")) + \n    labs(x = \"Social Interactions (number per week)\", y = \"Wellbeing (WEMWBS Scores)\")\n\n\n\n\n\n\n\n\n\n\nThose in non-rural locations appear to have higher wellbeing scores across almost all levels of social interactions. The slopes appear to be different for each location, where the greatest difference in wellbeing scores by location is most visible the highest number of social interactions.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nHow can we tell that there is an interaction?\nThe lines in the two plots above are not running in parallel - this suggests the presence of an interaction. Specifically in our example, the non-parallel lines suggest an interaction effect based on location, as the number of social interactions does not appear to have the same influence on rural and non-rural residents’ wellbeing scores.\n\n\n\n\n\n\n\nQuestion 4\n\n\nFit your model using lm(), and assign it as an object with the name “rural_mod”.\n\n\n\n\n\n\nHint\n\n\n\n\n\nWhen fitting a regression model in R with two explanatory variables A and B, and their interaction, these three are equivalent:\n\ny ~ A + B + A:B\ny ~ A + B + A*B\ny ~ A*B\n\n\n\n\n\n\n\n\n Solution \n\n\n\n#fit model including interaction between social_int and isRural\nrural_mod <- lm(wellbeing ~  social_int * isRural, data = wrdata)\n\n#check model output\nsummary(rural_mod)\n\n\nCall:\nlm(formula = wellbeing ~ social_int * isRural, data = wrdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12.4845  -2.7975   0.0155   2.4539  15.6743 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              30.9986     1.4284  21.702  < 2e-16 ***\nsocial_int                0.6488     0.1160   5.593 7.42e-08 ***\nisRuralrural              1.3866     2.0510   0.676  0.49981    \nsocial_int:isRuralrural  -0.5176     0.1615  -3.206  0.00157 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.558 on 196 degrees of freedom\nMultiple R-squared:  0.2962,    Adjusted R-squared:  0.2854 \nF-statistic: 27.49 on 3 and 196 DF,  p-value: 6.97e-15\n\n\n\n\n\n\n\nQuestion 5\n\n\nLook at the parameter estimates from your model, and write a description of what each one corresponds to on the plot shown in Figure 1 (it may help to sketch out the plot yourself and annotate it).\n\n\n\n\nFigure 1: Multiple regression model: Wellbeing ~ Social Interactions * is Rural\n\n\n\n\n\n Options\n\n\nHere are some options to choose from:\n\nThe point at which the red line cuts the y-axis (where social_int = 0)\nThe point at which the blue line cuts the y-axis (where social_int = 0)\nThe vertical distance from the red to the blue line at the y-axis (where social_int = 0)\nThe vertical distance from the blue to the red line at the y-axis (where social_int = 0)\nThe vertical distance from the blue to the red line at the center of the plot\n\nThe vertical distance from the red to the blue line at the center of the plot\n\nThe slope (vertical increase on the y-axis associated with a 1 unit increase on the x-axis) of the red line\nThe slope (vertical increase on the y-axis associated with a 1 unit increase on the x-axis) of the blue line\nHow the slope of the line changes when you move from the red to the blue line\n\n\n\n\n\n\n\n\n Solution \n\n\nRecall that we can obtain our parameter estimates using various functions such as summary(),coef(), coefficients(), etc.\n\ncoefficients(rural_mod)\n\n            (Intercept)              social_int            isRuralrural \n             30.9985688               0.6487945               1.3865688 \nsocial_int:isRuralrural \n             -0.5175856 \n\n\n\n\n\\(\\beta_0\\) = (Intercept) = 31\n\nOn plot: The point at which the red line cuts the y-axis\nInterpretation: The intercept, or predicted wellbeing score when the number of social interactions per week is 0, and when location is not rural.\n\n\n\n\\(\\beta_1\\) = social_int = 0.65\n\nOn plot: The slope (vertical increase on the y-axis associated with a 1 unit increase on the x-axis) of the red line.\nInterpretation: The simple slope of social interactions (number per week) for location reference group (not rural).\n\n\n\n\\(\\beta_2\\) = isRuralrural = 1.39\n\nOn plot: The vertical distance from the red to the blue line at the y-axis (where social_int = 0).\n\nInterpretation: The simple effect of location (or the difference in wellbeing scores between rural and non rural residents) when number of social interactions is 0.\n\n\n\n\\(\\beta_3\\) social_int:isRuralrural = -0.52\n\nOn plot: How the slope of the line changes when you move from the red to the blue line.\nInterpretation: The interaction between social interactions (number per week) and location (rural/not rural) - the difference in the simple slopes of social interactions for rural vs non-rural residents.\n\n\n\n\n\n\n\n\nQuestion 6\n\n\nMean center the continuous IV(s), and re-run your model with mean centered variable(s).\n\n\n\n\n Solution \n\n\nCreate mean centered variable for ‘social_int’:\n\nwrdata <-\n wrdata %>%\n  mutate(\n   mc_social_int = social_int - mean(social_int)\n    )\n\nRe-run model:\n\n#fit model including interaction between social_int and isRural\nrural_mod1 <- lm(wellbeing ~  mc_social_int * isRural, data = wrdata)\n\n#check model output\nsummary(rural_mod1)\n\n\nCall:\nlm(formula = wellbeing ~ mc_social_int * isRural, data = wrdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12.4845  -2.7975   0.0155   2.4539  15.6743 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                 38.8263     0.4581  84.754  < 2e-16 ***\nmc_social_int                0.6488     0.1160   5.593 7.42e-08 ***\nisRuralrural                -4.8581     0.6478  -7.500 2.17e-12 ***\nmc_social_int:isRuralrural  -0.5176     0.1615  -3.206  0.00157 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.558 on 196 degrees of freedom\nMultiple R-squared:  0.2962,    Adjusted R-squared:  0.2854 \nF-statistic: 27.49 on 3 and 196 DF,  p-value: 6.97e-15\n\n\n\n\n\n\n\nQuestion 7\n\n\nNote any differences between the summary() output between the “rural_mod” and “rural_mod1” models. Pay particular attention to your coefficients and their significance values. Why do you think these differences have been observed?\n\n\n\n\n\n\nHint\n\n\n\n\n\nThis plot illustrates the difference between the “rural_mod” and “rural_mod1” models.\n\n\n\n\nFigure 2: Difference when social interactions is not vs is mean centered.Note that the lines without SE intervals on the left plot represent predicted values below the minimum observed number of social interactions, to ensure that zero on the x-axis is visible\n\n\n\n\n\n\n\n\n\n\n\n Solution \n\n\nRecall that when there is an interaction A\\(\\times\\)B, the coefficients A and B are no longer main effects. Instead, they are conditional effects upon the other being zero.\nIn our “rural_mod”, the isRural coefficient is the difference in rural vs non-rural when social interactions is 0. In our “rural_mod1”, this difference is when social interactions is the mean (12.06).\nWhilst the difference in rural vs non-rural may not be significantly different when social interactions is zero, there is a significant difference at the average number of social interactions (as you can see from the plot below - note that this is the same plot as in the hint).\n\n\n\n\nFigure 3: Difference when social interactions is not vs is mean centered\n\n\n\n\n\n\n\n\n\nQuestion 8\n\n\nUsing the probe_interaction() function from the interactions package, visualise the interaction effects from your model.\nTry to summarise the interaction effects in a short and concise sentence.\n\n\n\n\n\n\nHint\n\n\n\n\n\nMake sure to give your plot informative titles/labels. You, for example, likely want to give your plot:\n\na clear and concise title (specify main.title =)\naxis labels with units or scale included (specify x.label = and y.label =)\na legend title (specify legend.main =)\n\n\n\n\n\n\n\n\n Solution \n\n\n\nplt_rural_mod <- probe_interaction(model = rural_mod1, \n                  pred = mc_social_int, \n                  modx = isRural, \n                  interval = T,\n                  main.title = \"Predicted Wellbeing Scores across \\n Social Interactions by Location\",\n                  x.label = \"Number of Social Interactions per Week (mean centred)\",\n                  y.label = \"Wellbeing (WEMWBS Scores)\",\n                  legend.main = \"Location\")\n\nLet’s look at our plot:\n\nplt_rural_mod$interactplot\n\n\n\nFigure 4: Predicted Wellbeing Scores across Social Interactions by Location\n\n\n\n\n\n\n\n\n\n\nThis suggested that for individuals living in non-rural locations, wellbeing scores increased at a steeper rate across the number of social interactions in comparison to those in rural locations.\n\n\n\n\n\n\n\n\nQuestion 9\n\n\nProvide key model results in a formatted table.\n\n\n\n\n Solution \n\n\n\n#create table for results\ntab_model(rural_mod1,\n          dv.labels = \"Wellbeing (WEMWBS Scores)\",\n          pred.labels = c(\"mc_social_int\" = \"Social Interactions (number per week)\",\n                          \"isRuralrural\" = \"Location - Rural\",\n                          \"mc_social_int:isRuralrural\" = \"Social Interactions * Location - Rural\"),\n          title = \"Regression Table for Wellbeing Model\")\n\n\n\n\nTable 1:  Regression Table for Wellbeing Model \n\n \nWellbeing (WEMWBS Scores)\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n38.83\n37.92 – 39.73\n<0.001\n\n\nSocial Interactions(number per week)\n0.65\n0.42 – 0.88\n<0.001\n\n\nLocation - Rural\n-4.86\n-6.14 – -3.58\n<0.001\n\n\nSocial Interactions *Location - Rural\n-0.52\n-0.84 – -0.20\n0.002\n\n\nObservations\n200\n\n\nR2 / R2 adjusted\n0.296 / 0.285\n\n\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nInterpret your results in the context of the research question and report your model in full.\nMake reference to the interaction plot and regression table.\n\n\n“The best method of communicating findings about the presence of a significant interaction may be to present a table or graph of the estimated means at various combinations of the interacting variables.”\n— Ramsey and Schafer (2012)\n\n\n\n\n\n\n Solution \n\n\nMake sure to write your results up following APA guidelines:\n\n\n\n\n\n\nFull regression results including 95% Confidence Intervals are shown in Table 1. The \\(F\\)-test for model utility was significant \\((F(3,196) = 27.49, p<.001)\\), and the model explained approximately 28.54% of the variability in wellbeing scores.\nThere was a significant conditional association between wellbeing (WEMWBS Scores) and social interactions (\\(\\beta\\) = 0.65, \\(SE\\) = 0.12, \\(p\\) < .001), which suggested that for those living in non-rural locations, wellbeing scores increased by 0.65 for every additional social interaction per week. A significant conditional association was also evident between wellbeing and location (\\(\\beta\\) = -4.86, \\(SE\\) = 0.65, \\(p\\) < .001), which suggested that for those with the average number of social interactions per week (\\(M\\) = 12.06), wellbeing scores were 4.86 points lower for those in rural areas in comparison to those in non-rurual.\nThe association between wellbeing (WEMWBS Scores) and social interactions was found to be dependent upon location (rural/non-rural), where the slope was less steep for those in rural locations (\\(\\beta\\) = -0.52, \\(SE\\) = 0.16, \\(p\\) = .002). This interaction is visually presented in Figure 4. The effect of every additional social interaction per week on wellbeing (WEMWBS Scores) was 0.52 less for those living in rural locations in comparison to those in non-rural locations. Therefore, we have evidence to reject the null hypothesis (that the association between wellbeing and social interactions is not moderated by whether or not a person lives in a rural area)."
  },
  {
    "objectID": "1_08_int2_nn.html",
    "href": "1_08_int2_nn.html",
    "title": "Interactions II: Num x Num",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand the concept of an interaction.\nBe able to interpret the meaning of a numeric \\(\\times\\) numeric interaction.\nUnderstand the principle of marginality and why this impacts modelling choices with interactions.\nVisualize and probe interactions.\n\n\nBe up to date with lectures\nHave completed previous lab exercises from Week 7\n\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\nsjPlot\nkableExtra\nsandwich\ninteractions\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/scs_study.csv."
  },
  {
    "objectID": "1_08_int2_nn.html#exercises",
    "href": "1_08_int2_nn.html#exercises",
    "title": "Interactions II: Num x Num",
    "section": "Exercises",
    "text": "Exercises\n\nQuestion 1\n\n\nFormally state:\n\na linear model to investigate whether the effect of social comparison on symptoms of depression, anxiety and stress varies depending on level of Neuroticism\nyour chosen significance level\nthe null and alternative hypotheses\n\n\n\n\n\n Solution \n\n\n\\[\n{DASS-21 Score} = \\beta_0 + \\beta_1 \\cdot SCS Score + \\beta_2 \\cdot Neuroticism  + \\beta_3 \\cdot (SCS Score \\cdot Neuroticism)\n\\]\nEffects will be considered statistically significant at \\(\\alpha=.05\\)\nOur hypotheses are:\n\\(H_0: \\beta_3 = 0\\)\nThe effect of social comparison on symptoms of depression, anxiety and stress does not vary depending on level of Neuroticism\n\\(H_1: \\beta_3 \\neq 0\\)\nThe effect of social comparison on symptoms of depression, anxiety and stress does vary depending on level of Neuroticism.\n\n\n\n\n\nQuestion 2\n\n\nProvide a table of descriptive statistics and visualise your data.\nRemember to interpret these plots in the context of the study.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nThe describe() function is from the psych package; and kable() and kable_styling() (which are used to make a nice table) from kableExtra would be useful to present your descriptive statistics.\nThe pairs.panels() function from the psych package will plot all variables in a dataset against one another. This will save you the time you would have spent creating individual plots.\n\n\n\n\n\n\n\n\n Solution \n\n\nFirst, lets look at our descriptive statistics and present in a well formatted table:\n\n# note that we are selecting our three variables of interest (dass, scs, zn)\n# we are then passing these to the kable() and kable_styling() functions so that we end up with a nice looking table, and specify digits = 2 so that output is rounded to 2 decimal places\n\ndescribe(scs_study %>% \n             select(dass, scs, zn)) %>% \n             kable(caption = \"Descriptive Statistics - DASS-21, SCS, and Neuroticism (Z-Scored)\", digits = 2) %>%\n             kable_styling()\n\n\n\n\nTable 1:  Descriptive Statistics - DASS-21, SCS, and Neuroticism (Z-Scored) \n \n   \n    vars \n    n \n    mean \n    sd \n    median \n    trimmed \n    mad \n    min \n    max \n    range \n    skew \n    kurtosis \n    se \n  \n\n\n dass \n    1 \n    656 \n    44.72 \n    6.76 \n    44.00 \n    44.62 \n    5.93 \n    23.00 \n    68.00 \n    45.0 \n    0.18 \n    0.33 \n    0.26 \n  \n\n scs \n    2 \n    656 \n    35.77 \n    3.53 \n    35.00 \n    35.59 \n    2.97 \n    27.00 \n    54.00 \n    27.0 \n    0.60 \n    0.96 \n    0.14 \n  \n\n zn \n    3 \n    656 \n    0.00 \n    1.00 \n    -0.21 \n    -0.10 \n    1.00 \n    -1.45 \n    3.35 \n    4.8 \n    0.80 \n    0.04 \n    0.04 \n  \n\n\n\n\n\n Next, look at associations among variables of interest:\n\nscs_study %>% \n  select(dass, scs, zn) %>%\n  pairs.panels()\n\n\n\n\nDescription of individual variables:\n\n\n\n\n\n\n\nThe marginal distribution of scores on the Depression, Anxiety and Stress Scale (DASS-21) was unimodal with a mean of 44.72 and a standard deviation of 6.76.\nThe marginal distribution of score on the Social Comparison Scale (SCS) was unimodal with a mean of 35.77 and a standard deviation of 3.53.\nThe marginal distribution of Neuroticism (Z-scored) was positively skewed.\n\n\n\n\nDescription of correlations:\n\n\n\n\n\n\n\nThere was a weak, negative association between scores on the Social Comparison Scale and scores on the Depression Anxiety and Stress Scale for the participants in the sample (\\(r\\) = -.23). Severity of symptoms measured on the DASS-21 were lower, on average, for those who more favorably perceived their social rank.\n\nThere was a weak, positive association between the levels of Neuroticism and scores on the DASS-21 (\\(r\\) = .20). Participants who are more neurotic tend to, on average, display a higher severity of symptoms of depression, anxiety and stress.\n\n\n\n\n\n\n\n\n\n\nQuestion 3\n\n\nRun the two code chunks below. It takes the dataset, and uses the cut() function to add a new variable called “zn_group”, which is the “zn” variable split into 4 groups.\n\nscs_study <-\n  scs_study %>%\n  mutate(\n    zn_group = cut(zn, 4)\n  )\n\nWe can see how it has split the “zn” variable by plotting the two against one another (note that the levels of the new variable are named according to the cut-points):\n\nggplot(data = scs_study, aes(x = zn_group, y = zn)) + \n  geom_point()\n\n\n\n\nPlot the association between scores on the SCS and scores on the DASS-21, for each group of the variable we just created.\nHow does the pattern differ across groups? Does it suggest an interaction?\n\n\n\n\n\n\nHint\n\n\n\n\n\nRather than creating four separate plots, you might want to map some feature of the plot to the variable we created in the data, or make use of facet_wrap()/facet_grid().\nRemember that you can specify geom_smooth() to add a trend line\n\n\n\n\n\n\n\n Solution \n\n\n\nggplot(data = scs_study, aes(x = scs, y = dass, col = zn_group)) + \n  geom_point() + \n  geom_smooth(method='lm', se = FALSE) +\n  facet_grid(~zn_group) +\n  labs(x = \"SCS Scores \", y = \"DASS-21 Scores\") +\n  theme(legend.position = \"none\") # removes the legend\n\n\n\n\nThe association between SCS scores and DASS-21 scores appears to be different across these groups. For those with a relatively high Neuroticism score, the association seems stronger, while for those with a low Neuroticism score there is almost no discernible association.\nThis does suggest an interaction - the association of DASS-21 ~ SCS differs across the values of Neuroticism.\n\n\n\n\n\nVisualising Interaction Terms\nCutting one of the explanatory variables up into groups essentially turns a numeric variable into a categorical one. We did this just to make it easier to visualise how an association differs across the values of another variable, because we can imagine a separate line for the association between SCS and DASS-21 scores for each of the groups of Neuroticism. However, in grouping a numeric variable like this we lose information. Neuroticism is measured on a continuous scale, and we want to capture how the association between SCS and DASS-21 differs across that continuum (rather than cutting it into chunks).\nWe could imagine cutting it into more and more chunks (see Figure 1), until what we end up with is an infinite number of lines - i.e., a three-dimensional plane/surface (recall that in for a multiple regression model with 2 explanatory variables, we can think of the model as having three-dimensions). The inclusion of the interaction term simply results in this surface no longer being necessarily flat. You can see this in Figure 2).\n\n\n\n\nFigure 1: Separate regression lines DASS ~ SCS for Neuroticism when cut into 4 (left) or 6 (center) or 12 (right) groups.\n\n\n\n\n\n\n\nFigure 2: 3D plot of regression surface with interaction. You can explore the plot in the figure below from different angles by moving it around with your mouse.\n\n\n\n\n\n\nQuestion 4\n\n\nConsider that Neuroticism has already been \\(z\\)-scored, but scs has not. To ensure that we can compare the effects of our estimates (and so they are both on meaningful scales), standardize the scs variable.\n\n\n\n\n\n\nHint\n\n\n\n\n\nRecall the formula for the \\(z\\)-score:\n\\[\nz_x = \\frac{x - \\bar{x}}{s_x}, \\qquad z_y = \\frac{y - \\bar{y}}{s_y}\n\\]\n\n\n\n\n\n\n\n Solution \n\n\n\n# standardize scs score\nscs_study <- \n  scs_study %>% \n    mutate(\n      zscs = (scs-mean(scs))/sd(scs)\n    )\n\n\n\n\n\n\nQuestion 5\n\n\nFit your model (including the standardized variables) using lm(), and assign it as an object with the name “dass_mdl”.\n\n\n\n\n\n\nHint\n\n\n\n\n\nWhen fitting a regression model in R with two explanatory variables A and B, and their interaction, these three are equivalent:\n\ny ~ A + B + A:B\ny ~ A + B + A*B\ny ~ A*B\n\n\n\n\n\n\n\n\n Solution \n\n\n\n#fit interaction model\ndass_mdl <- lm(dass ~  zscs*zn, data = scs_study)\n\n#check model output\nsummary(dass_mdl)\n\n\nCall:\nlm(formula = dass ~ zscs * zn, data = scs_study)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-16.301  -3.825  -0.173   3.733  45.777 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  44.9324     0.2405 186.807  < 2e-16 ***\nzscs         -1.5691     0.2416  -6.495 1.64e-10 ***\nzn            1.5798     0.2409   6.559 1.11e-10 ***\nzscs:zn      -1.8332     0.2316  -7.915 1.06e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.123 on 652 degrees of freedom\nMultiple R-squared:  0.1825,    Adjusted R-squared:  0.1787 \nF-statistic:  48.5 on 3 and 652 DF,  p-value: < 2.2e-16\n\n\n\n\n\n\n\nQuestion 6\n\n\nInterpret your coefficients in the context of the study.\n\n\n\n\n Solution \n\n\nRecall that we can obtain our parameter estimates using various functions such as summary(),coef(), coefficients(), etc.\n\ncoefficients(dass_mdl)\n\n(Intercept)        zscs          zn     zscs:zn \n  44.932448   -1.569097    1.579769   -1.833169 \n\n\n\n\n\\(\\beta_0\\) = (Intercept) = 44.93\n\nThe intercept, or predicted DASS-21 score for average SCS score (Mean = 0) and average Neuroticism score (Mean = 0).\n\n\n\n\\(\\beta_1\\) = zscs = -1.57\n\nThe simple slope of SCS scores for average Nueroticism scores (Mean = 0).\nFor an individual with average Neuroticism levels, DASS-21 scores decreased by 1.57 standard deviations for every 1 standard deviation increase in SCS scores.\n\n\n\n\\(\\beta_2\\) = zn = 1.58\n\nThe simple slope of Neuroticism for average SCS scores (Mean = 0).\nFor those with average SCS scores, DASS-21 scored increased by 1.58 for every 1 standard deviation increase in Neuroticism.\n\n\n\n\\(\\beta_3\\) zscs:zn = -1.83\n\nThe interaction between SCS score and Neuroticism on DASS-21 Scores\nFor every 1 standard deviation increase in SCS scores, the association between Neuroticism and DASS-21 scores decreases by an additional 1.83 standard deviations.\n\n\n\n\n\n\n\n\nQuestion 7\n\n\nUsing the probe_interaction() function from the interactions package, visualise the interaction effects from your model.\nTry to summarise the interaction effects in a short and concise sentence.\n\n\n\n\n\n\nHint\n\n\n\n\n\nBecause we are looking at a numeric x numeric interaction, we want to specify jnplot = T (see this weeks lecture, slides 17-21 for a worked example).\nRemember to give your plot informative titles/labels. You, for example, likely want to give your plot:\n\na clear and concise title (specify main.title =)\naxis labels with units or scale included (specify x.label = and y.label =)\na legend title (specify legend.main =)\n\n\n\n\n\n\n\n\n Solution \n\n\n\nplt_dass_mdl <- probe_interaction(model = dass_mdl, \n                  pred = zscs, \n                  modx = zn, \n                  cond.int = T,\n                  interval = T, \n                  jnplot = T,\n                  main.title = \"Neuroticism moderating the effect of\\nsocial comparison on depression and anxiety\",\n                  x.label = \"Social Comparison Scale (Z-scored)\",\n                  y.label = \"DASS-21 Scores\",\n                  legend.main = \"Neuroticism (Z-scored)\")\n\nLet’s look at the plot - to do so you need to call interactplot from your object plt_dass_mdl:\n\nplt_dass_mdl$interactplot\n\n\n\nFigure 3: Simple Sloes for +/- 1 SD and Mean Neuroticism Scores\n\n\n\n\nThe effect of SCS scores on DASS-21 scores was more negatively pronounced for those with higher Neuroticism scores.\n\n\n\n\n\nQuestion 8\n\n\nConduct a simple slopes analysis.\n\n\n\n\n\n\nHint\n\n\n\n\n\nIf you wanted to see only the simple slopes or only the Johnson-Neyman plot, you could call $simslopes$slopes or simslopes$jnplot respectively from your object plt_dass_mdl.\n\n\n\n\n\n\n\n Solution \n\n\n\nplt_dass_mdl$simslopes\n\nJOHNSON-NEYMAN INTERVAL \n\nWhen zn is OUTSIDE the interval [-1.28, -0.55], the slope of zscs is p <\n.05.\n\nNote: The range of observed values of zn is [-1.45, 3.35]\n\n\nSIMPLE SLOPES ANALYSIS \n\nWhen zn = -1.000000e+00 (- 1 SD): \n\n                               Est.   S.E.   t val.      p\n--------------------------- ------- ------ -------- ------\nSlope of zscs                  0.26   0.35     0.76   0.45\nConditional intercept         43.35   0.34   127.47   0.00\n\nWhen zn = -8.610271e-16 (Mean): \n\n                               Est.   S.E.   t val.      p\n--------------------------- ------- ------ -------- ------\nSlope of zscs                 -1.57   0.24    -6.50   0.00\nConditional intercept         44.93   0.24   186.81   0.00\n\nWhen zn =  1.000000e+00 (+ 1 SD): \n\n                               Est.   S.E.   t val.      p\n--------------------------- ------- ------ -------- ------\nSlope of zscs                 -3.40   0.32   -10.59   0.00\nConditional intercept         46.51   0.34   136.52   0.00\n\n\n\n\nFigure 4: Johnson-Neyman Plot\n\n\n\n\nThe Johnson-Neyman technique indicated that the association between DASS-21 scores and SCS was significant when Neuroticism scores were less than 1.28 standard deviations below the mean or more than -0.55 standard deviations above the mean.\n\n\n\n\n\nQuestion 9\n\n\nProvide key model results in a formatted table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse tab_model() from the sjPlot package.\nRemember that you can rename your DV and IV labels by specifying dv.labels and pred.labels.\n\n\n\n\n\n\n\n Solution \n\n\n\n#create table for results\ntab_model(dass_mdl,\n          dv.labels = \"DASS-21 Scores\",\n          pred.labels = c(\"zscs\" = \"Social Comparison Scale (Z-scored)\",\n                          \"zn\" = \"Neuroticism (Z-scored)\",\n                          \"zscs:zn\" = \"Social Comparison Scale (Z-scored): Neutoricism (Z-scored)\"),\n          title = \"Regression table for DASS-21 model\")\n\n\n\n\nTable 2:  Regression table for DASS-21 model \n\n \nDASS-21 Scores\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n44.93\n44.46 – 45.40\n<0.001\n\n\nSocial Comparison Scale(Z-scored)\n-1.57\n-2.04 – -1.09\n<0.001\n\n\nNeuroticism (Z-scored)\n1.58\n1.11 – 2.05\n<0.001\n\n\nSocial Comparison Scale(Z-scored): Neutoricism(Z-scored)\n-1.83\n-2.29 – -1.38\n<0.001\n\n\nObservations\n656\n\n\nR2 / R2 adjusted\n0.182 / 0.179\n\n\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nInterpret your results in the context of the research question and report your model in full.\nMake reference to the interaction plot and regression table.\n\n\n\n\n Solution \n\n\nMake sure to write your results up following APA guidelines:\n\n\n\n\n\n\nFull regression results including 95% Confidence Intervals are shown in Table 2. The \\(F\\)-test for model utility was significant \\((F(3,652) = 48.50, p<.001)\\), and the model explained approximately 17.87% of the variability in DASS-21 scores.\nThere was a significant conditional association between DASS-21 Scores and SCS scores (Z-scored) (\\(\\beta\\) = -1.57, SE = 0.24, \\(p\\) < .001), suggesting that for those with average Neuroticism scores (\\(M\\) = 0),DASS-21 scores decreased by 1.57 for every 1 standard deviation increase in SCS scores.\nA significant conditional association was also evident between DASS-21 Scores and Neuroticism (Z-scored) (\\(\\beta\\) = 1.58, SE = 0.24, \\(p\\) <.001), suggesting that for those with average SCS scores (\\(M\\) = 0), DASS-21 scores increased by 1.58 for every 1 standard deviation increase in Neuroticism.\nThe association between symptoms of depression and anxiety (DASS-21 scores) and social comparison was found to be dependent upon the level of Neuroticism, with a greater negative association between the two for those with high levels of Neuroticism (\\(\\beta\\) = -1.83, SE = 0.23, \\(p\\) <.001). This buffering interaction suggested that for every standard deviation increase in SCS Scores, the negative influence of Neuroticism on DASS-21 scores was reduced by 1.83 standard deviations (see Figure 3). We further used the Johnson-Neyman technique to probe the interaction, and to identify regions of significance. We identified that Neuroticism values (z-scored) outside the range of -1.28 to -0.55 were significant (see Figure 4).\nTherefore, we have evidence to reject the null hypothesis (that the effect of social comparison on symptoms of depression, anxiety and stress does not vary depending on level of Neuroticism)."
  },
  {
    "objectID": "1_09_int3_cc.html",
    "href": "1_09_int3_cc.html",
    "title": "Interactions III: Cat x Cat",
    "section": "",
    "text": "Study Overview\n\nResearch Question\nAre there differences in types of memory deficits for those experiencing different cognitive impairment(s)?\n\nA group of researchers wants to test a hypothesised theory according to which the difference in performance between explicit and implicit memory tasks will be greatest for Huntington patients in comparison to controls. On the other hand, the difference in performance between explicit and implicit memory tasks will not significantly differ between patients with amnesia in comparison to controls.\n\n Cognitive Exp 3x2 data codebook.\n\n\nDescription\nThe researchers designed a study yielding a 3 by 2 factorial design to test this theory. The first factor, “Diagnosis”, classifies the three types of individuals:\n\n1 denotes amnesic patients;\n2 denotes Huntingtons patients; and\n3 denotes a control group of individuals with no known neurological disorder.\n\nThe second factor, “Task”, tells us to which of two tasks each study participant was randomly assigned to:\n\n1 = grammar task, which consists of classifying letter sequences as either following or not following grammatical rules; and\n2 = recognition task, which consists of recognising particular stimuli as stimuli that have previously been presented during the task.\n\nKeep in mind that each person has been randomly assigned to one of the two tasks, so there are five observations per cell of the design.1\nThe tasks chosen by the researchers have been picked to map onto the theoretical differences between the three types of research participants. The first task (grammar) is known to reflect implicit memory processes, whereas the recognition task is known to reflect explicit memory processes. If the theory is correct, we would expect the difference in scores between the recognition and grammar tasks to be relatively similar for the control and amnesiac groups, but relatively larger for the Huntingtons group compared to controls.\nPreview\nThe first ten rows of the data are:\n\n\n\n\n\n\n\nDiagnosis\n      Task\n      Y\n    \n\n\n1\n1\n44\n\n\n1\n1\n63\n\n\n1\n1\n76\n\n\n1\n1\n72\n\n\n1\n1\n45\n\n\n1\n2\n70\n\n\n\n\n\n\n\n\n\nSetup\n\nSetup\n\n\n\nCreate a new RMarkdown file\nLoad the required package(s)\nRead the cognitive_experiment_3_by_2 dataset into R, assigning it to an object named cog\n\n\n\n\n\n\n Solution \n\n\n\n#Loading the required package(s)\nlibrary(tidyverse)\nlibrary(psych)\nlibrary(sjPlot)\nlibrary(kableExtra) \nlibrary(sandwich)\nlibrary(interactions)\n\n#Reading in data and storing in object named 'cog'\ncog <- read_csv(\"https://uoepsy.github.io/data/cognitive_experiment_3_by_2.csv\")\n\n\n\n\nExercises\n\nQuestion 1\n\n\nExamine the dataset, and perform any necessary and appropriate data management steps.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nConvert categorical variables to factors\nLabel appropriately factors to aid with your model interpretations\nIf needed, provide better variable names\n\nNote that all of these steps can be done in combination - the mutate() and factor() functions will likely be useful here.\n\n\n\n\n\n\n\n Solution \n\n\nLet’s have a look at the data to see what we’re working with:\n\n#first look at dataset structure\nstr(cog)\n\nspec_tbl_df [30 × 3] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Diagnosis: num [1:30] 1 1 1 1 1 1 1 1 1 1 ...\n $ Task     : num [1:30] 1 1 1 1 1 2 2 2 2 2 ...\n $ Y        : num [1:30] 44 63 76 72 45 70 51 82 66 56 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Diagnosis = col_double(),\n  ..   Task = col_double(),\n  ..   Y = col_double()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\n#now lets look at top 6 rows (or the head) of the dataset\nhead(cog)\n\n# A tibble: 6 × 3\n  Diagnosis  Task     Y\n      <dbl> <dbl> <dbl>\n1         1     1    44\n2         1     1    63\n3         1     1    76\n4         1     1    72\n5         1     1    45\n6         1     2    70\n\n\nThe columns Diagnosis and Task should be coded into factors with better labels, as currently, without making reference to the codebook, it is not clear what “1” and “2” represent. It is also unclear what the Y column represents - this should be renamed.\n\n#We can make all of the changes noted above in one (long) command. \n#First we can use the function `factor()` by specifying the current levels and what labels each level should map to. \n#We can also simply rename the Y column to score. \n\ncog <- cog %>%\n    mutate(\n        Diagnosis = factor(Diagnosis, \n                           levels = c(1, 2, 3),\n                           labels = c('Amnesic', 'Huntingtons', 'Control')),\n        Task = factor(Task, \n                      levels = c(1, 2),\n                      labels = c('Grammar', 'Recognition'))) %>%\n    rename(Score = Y)\n\n#Use head() function to check renaming\nhead(cog)\n\n# A tibble: 6 × 3\n  Diagnosis Task        Score\n  <fct>     <fct>       <dbl>\n1 Amnesic   Grammar        44\n2 Amnesic   Grammar        63\n3 Amnesic   Grammar        76\n4 Amnesic   Grammar        72\n5 Amnesic   Grammar        45\n6 Amnesic   Recognition    70\n\n\n\n\n\n\n\nQuestion 2\n\n\nChoose appropriate reference levels for the Diagnosis and Task variables.\n\n\n\n\n Solution \n\n\nThe Diagnosis factor has a group coded ‘Control’ which lends itself naturally to be the reference category.\n\ncog$Diagnosis <- relevel(cog$Diagnosis, 'Control')\n\nlevels(cog$Diagnosis)\n\n[1] \"Control\"     \"Amnesic\"     \"Huntingtons\"\n\n\nThere is no natural reference category for the Task factor, so we will leave it unaltered. However, if you are of a different opinion, please note that there is no absolute correct answer. As long as you interpret the model correctly, you will reach to the same conclusions as someone that has chosen a different baseline category.\n\n\n\n\n\nQuestion 3\n\n\nFormally state:\n\na linear model to investigate whether there are differences in types of memory deficits for those experiencing different cognitive impairment(s)\nyour chosen significance level\nthe null and alternative hypotheses\n\n\n\n\n\n Solution \n\n\nBefore stating the model, you first need to define the dummy variables for Diagnosis:\n\\[\nD_\\text{Amnesic} = \\begin{cases}\n1 & \\text{if Diagnosis is Amnesic} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\quad\nD_\\text{Huntingtons} = \\begin{cases}\n1 & \\text{if Diagnosis is Huntingtons} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\quad\n(\\text{Control is base level})\n\\]\nAnd for Task:\n\\[\nT_\\text{Recognition} = \\begin{cases}\n1 & \\text{if Task is Recognition} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\quad\n(\\text{Grammar is base level})\n\\]\nThe model becomes:\n\\[\n\\begin{aligned}\nScore &= \\beta_0 \\\\\n      &+ \\beta_1 D_\\text{Amnesic} + \\beta_2 D_\\text{Huntingtons}  \\\\\n      &+ \\beta_3 T_\\text{Recognition}  \\\\\n      &+ \\beta_4 (D_\\text{Amnesic} * T_\\text{Recognition}) + \\beta_5 (D_\\text{Huntingtons} * T_\\text{Recognition})  \\\\\n      &+ \\epsilon\n\\end{aligned}\n\\]\nEffects will be considered statistically significant at \\(\\alpha=.05\\)\nOur hypotheses are:\n\\(H_0: \\beta_5 = 0\\)\nThe difference in performance between explicit and implicit memory tasks does not significantly differ between patients with Huntingtons in comparison to Controls.\n\\(H_1: \\beta_5 \\neq 0\\)\nThe difference in performance between explicit and implicit memory tasks does significantly differ between patients with Huntingtons in comparison to Controls.\n\n\n\n\n\nQuestion 4\n\n\nProvide a table of descriptive statistics and visualise your data.\nRemember to interpret your plot in the context of the study.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nFor your table of descriptive statistics, both the group_by() and summarise() functions will come in handy here.\nRecall that when visualising categorical variables, geom_boxplot() may be most appropriate to use.\n\n\n\n\n\n\n\n\n Solution \n\n\nFirst, lets look at our descriptive statistics and present in a well formatted table:\n\ncog_desc <- cog %>% \n            group_by(Diagnosis, Task) %>%\n            summarise(Mean = mean(Score),\n                      SD = sd(Score),\n                      Min = min(Score),\n                      Max = max(Score)) %>% \n            kable(caption = \"Descriptive Statistics\", digits = 2) %>%\n            kable_styling()\n\ncog_desc\n\n\n\n\nTable 1:  Descriptive Statistics \n \n Diagnosis \n    Task \n    Mean \n    SD \n    Min \n    Max \n  \n\n\n Control \n    Grammar \n    80 \n    11.68 \n    70 \n    98 \n  \n\n Control \n    Recognition \n    95 \n    12.98 \n    80 \n    107 \n  \n\n Amnesic \n    Grammar \n    60 \n    14.92 \n    44 \n    76 \n  \n\n Amnesic \n    Recognition \n    65 \n    12.17 \n    51 \n    82 \n  \n\n Huntingtons \n    Grammar \n    40 \n    13.25 \n    24 \n    55 \n  \n\n Huntingtons \n    Recognition \n    95 \n    13.38 \n    80 \n    108 \n  \n\n\n\n\n\nNext, look at associations among variables of interest:\n\ncog_plt <- ggplot(cog, aes(x = Diagnosis, y = Score, fill = Task)) + \n  geom_boxplot() \ncog_plt\n\n\n\nFigure 1: Associations among Score, Diagnosis, and Task\n\n\n\n\n\nParticipants with Amnesia do not appear to differ in Score for Recognition or Grammar tasks. In comparison to Controls, Amnesic patients score lower on both tasks, but not considerably so.\nParticipants with Huntingtons do differ in Score for Recognition and Grammar tasks, with higher scores on Recognition tasks. In comparison to Controls, Huntingtons patients score similarly on Recognition tasks, but considerably lower on Grammar tasks.\n\n\n\n\n\n\nQuestion 5\n\n\nFit the specified model using lm(), and store the model in an object named “cog_mdl”.\n\n\n\n\n\n\nNote\n\n\n\nFortunately, R computes the dummy variables for us! Thus. each row in the summary() output of the model will correspond to one of the estimated \\(\\beta\\)’s in the equation above.\n\n\n\n\n\n\n Solution \n\n\n\n#fit interaction model\ncog_mdl <- lm(Score ~ Diagnosis * Task, data = cog)\n\n#check model output\nsummary(cog_mdl)\n\n\nCall:\nlm(formula = Score ~ Diagnosis * Task, data = cog)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-16.00 -12.25   2.00  11.75  18.00 \n\nCoefficients:\n                                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                            80.000      5.859  13.653 8.27e-13 ***\nDiagnosisAmnesic                      -20.000      8.287  -2.414  0.02379 *  \nDiagnosisHuntingtons                  -40.000      8.287  -4.827 6.45e-05 ***\nTaskRecognition                        15.000      8.287   1.810  0.08281 .  \nDiagnosisAmnesic:TaskRecognition      -10.000     11.719  -0.853  0.40192    \nDiagnosisHuntingtons:TaskRecognition   40.000     11.719   3.413  0.00228 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 13.1 on 24 degrees of freedom\nMultiple R-squared:  0.7394,    Adjusted R-squared:  0.6851 \nF-statistic: 13.62 on 5 and 24 DF,  p-value: 2.359e-06\n\n\n\n\n\n\n\nQuestion 6\n\n\nRecall your table of descriptive statistics - map each coefficient from the summary() output from “cog_mdl” to the group means.\n\n\n\n\n Solution \n\n\n\ncog_desc\n\n\n\nDescriptive Statistics\n \n Diagnosis \n    Task \n    Mean \n    SD \n    Min \n    Max \n  \n\n\n Control \n    Grammar \n    80 \n    11.68 \n    70 \n    98 \n  \n\n Control \n    Recognition \n    95 \n    12.98 \n    80 \n    107 \n  \n\n Amnesic \n    Grammar \n    60 \n    14.92 \n    44 \n    76 \n  \n\n Amnesic \n    Recognition \n    65 \n    12.17 \n    51 \n    82 \n  \n\n Huntingtons \n    Grammar \n    40 \n    13.25 \n    24 \n    55 \n  \n\n Huntingtons \n    Recognition \n    95 \n    13.38 \n    80 \n    108 \n  \n\n\n\n\n\n\\(\\hat{\\beta}_0\\) = 80\n= Mean(Control, Grammar)\n\\(\\hat{\\beta}_1\\) = -20\n= Mean(Amnesic, Grammar) - Mean(Control, Grammar)\n= 60 - 80\n\\(\\hat{\\beta}_2\\) = -40\n= Mean(Huntingtons, Grammar) - Mean(Control, Grammar)\n= 40 - 80\n\\(\\hat{\\beta}_3\\) = 15\n= Mean(Control, Recognition) - Mean(Control, Grammar)\n= 95 - 80\n\\(\\hat{\\beta}_4\\) = -10\n= [Mean(Amnesic, Recognition) - Mean(Amnesic, Grammar)] -\n[Mean(Control, Recognition) - Mean(Control, Grammar)]\n= [65 - 60] - [95 - 80] = 5 - 15 = -10\n\\(\\hat{\\beta}_5\\) = 40\n= [Mean(Huntingtons, Recognition) - Mean(Huntingtons, Grammar)] -\n[Mean(Control, Recognition) - Mean(Control, Grammar)]\n= [95 - 40] - [95 - 80] = 55 - 15 = 40\n\n\n\n\n\n\nQuestion 7\n\n\nInterpret your coefficients in the context of the study.\n\n\n\n\n Solution \n\n\nRecall that we can obtain our parameter estimates using various functions such as summary(),coef(), coefficients(), etc.\n\ncoefficients(cog_mdl)\n\n                         (Intercept)                     DiagnosisAmnesic \n                                  80                                  -20 \n                DiagnosisHuntingtons                      TaskRecognition \n                                 -40                                   15 \n    DiagnosisAmnesic:TaskRecognition DiagnosisHuntingtons:TaskRecognition \n                                 -10                                   40 \n\n\n\n\n\\(\\beta_0\\) = (Intercept) = 80\n\nThe intercept, or predicted scores for those in the Control diagnosis condition on the Grammar task.\n\n\n\n\\(\\beta_1\\) = DiagnosisAmnesic = -20\n\nThe difference in scores between Amnesic and Control conditions on the Grammar task\nOn the Grammar task, individuals with Amnesia scored 20 points lower than Control participants.\n\n\n\n\\(\\beta_2\\) = DiagnosisHuntingtons = -40\n\nThe difference in score between Huntingtons and Control conditions on the Grammar task\nOn the Grammar task, individuals with Huntingtons scored 40 points lower than Control participants.\n\n\n\n\\(\\beta_3\\) TaskRecognition = 15\n\nThe difference in score between individuals in the Control diagnosis condition completing Recognition and Grammar tasks.\nControl participants scored 15 points higher when completing Recognition tasks in comparison to Grammar tasks.\n\n\n\n\\(\\beta_4\\) DiagnosisAmnesic:TaskRecognition = -10\n\nThe difference between score in Amnesic and Control diagnosis conditions between Recognition and Grammar tasks.\nThe difference between Grammar and Recognition tasks is 10 points lower in the Amnesiac vs Control diagnosis conditions.\n\n\n\n\\(\\beta_5\\) DiagnosisHuntingtons:TaskRecognition = 40\n\nThe difference between score in Huntingtons and Control diagnosis conditions between Recognition and Grammar tasks.\nThe difference between Grammar and Recognition tasks is 40 points higher in the Huntingtons vs Control diagnosis conditions.\n\n\n\n\n\n\n\n\nQuestion 8\n\n\nUsing the cat_plot() function from the interactions package, visualise the interaction effects from your model.\nTry to summarise the interaction effects in a few short and concise sentences.\n\n\n\n\n Solution \n\n\n\nplt_cog_mdl <- cat_plot(model = cog_mdl, \n                  pred = Diagnosis, \n                  modx = Task, \n                  main.title = \"Scores across Diagnois and Task\",\n                  x.label = \"Diagnosis\",\n                  y.label = \"Score\",\n                  legend.main = \"Task\")\nplt_cog_mdl\n\n\n\nFigure 2: Interaction Plot\n\n\n\n\nThe effect of Task on Scores does appear to vary depending on Diagnosis.\nThe difference in score between recognition and grammar tasks for Huntingtons patients is larger than the difference in score between recognition and grammar tasks for the Control patients.\nThe difference in score between recognition and grammar tasks for Amnesic patients however does not appear to be very different (given the overlapping intervals) than the difference in score between recognition and grammar tasks for the Control patients.\n\n\n\n\n\n\nHow do we know there is an interaction?\n\n\n\n\n\nIf you imagine connecting the dots of the same color with a line (you could specify geom = \"line\" in a new line in the code chunk above to do this), you can see that the two virtual lines are not parallel (see below plot), suggesting the presence of an interaction. The difference in score between recognition and grammar tasks for Huntingtons patients (consider the vertical difference) is larger than the difference in score between recognition and grammar tasks for the Control patients. If those vertical differences were the same, there would be no interaction.\n\n\n\n\nFigure 3: Interaction Plot with Connected Lines\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 9\n\n\nProvide key model results in a formatted table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse tab_model() from the sjPlot package.\nRemember that you can rename your DV and IV labels by specifying dv.labels and pred.labels.\n\n\n\n\n\n\n\n Solution \n\n\n\n#create table for results\ntab_model(cog_mdl, \n          show.stat = TRUE,\n          dv.labels = \"Scores\",\n          title = \"Regression table for Scores model\")\n\n\n\n\nTable 2:  Regression table for Scores model \n\n \nScores\n\n\nPredictors\nEstimates\nCI\nStatistic\np\n\n\n(Intercept)\n80.00\n67.91 – 92.09\n13.65\n<0.001\n\n\nDiagnosis [Amnesic]\n-20.00\n-37.10 – -2.90\n-2.41\n0.024\n\n\nDiagnosis [Huntingtons]\n-40.00\n-57.10 – -22.90\n-4.83\n<0.001\n\n\nTask [Recognition]\n15.00\n-2.10 – 32.10\n1.81\n0.083\n\n\nDiagnosis [Amnesic] *Task [Recognition]\n-10.00\n-34.19 – 14.19\n-0.85\n0.402\n\n\nDiagnosis [Huntingtons] *Task [Recognition]\n40.00\n15.81 – 64.19\n3.41\n0.002\n\n\nObservations\n30\n\n\nR2 / R2 adjusted\n0.739 / 0.685\n\n\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nInterpret your results in the context of the research question and report your model in full.\nMake reference to the interaction plot and regression table.\n\n\n\n\n Solution \n\n\nFull regression results including 95% Confidence Intervals are shown in Table 2. The \\(F\\)-test for model utility was significant \\((F(5,24) = 13.62, p <.001)\\), and the model explained approximately 68.5% of the variability in Scores.\nThe difference in scores between the recognition and grammar tasks, respectively measuring explicit and implicit memory, for amnesiac patients in comparison to controls was estimated to be -10 points, though this difference was not significantly different from zero \\((t(24) = -0.85, p = .40)\\).\nThe difference in scores between the recognition and grammar tasks, respectively measuring explicit and implicit memory, for Huntingtons patients in comparison to controls was significant, and indicated a difference of 40 points in explicit vs implicit memory performance \\((t(24) = 3.41, p = .002)\\). This interaction is visually presented in Figure 2.\nTherefore, we have evidence to reject the null hypothesis (the difference in performance between explicit and implicit memory tasks does not significantly differ between patients with Huntingtons in comparison to Controls).\n\n\n\n\n\nFootnotes\n\nSome researchers may point out that a design where each person was assessed on both tasks might have been more efficient. However, the task factor in such design would then be within-subjects, meaning that the scores corresponding to the same person would be correlated. To analyse such design we will need a different method which is discussed next year!↩︎"
  },
  {
    "objectID": "1_10_assump_diag.html",
    "href": "1_10_assump_diag.html",
    "title": "Assumptions and Diagnostics",
    "section": "",
    "text": "At the end of this lab, you will:\n\nBe able to state the assumptions underlying a linear model.\nSpecify the assumptions underlying a linear model with multiple predictors.\nAssess if a fitted model satisfies the assumptions of your model.\nAssess the effect of influential cases on linear model coefficients and overall model evaluations.\n\n\nBe up to date with lectures\nHave completed previous lab exercises from Week 7, Week 8, and Week 9\n\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\ncar\nsee\nperformance\n\nYou can download the data required for this lab here and here or read both datsets in via these links https://uoepsy.github.io/data/riverview.csv and https://uoepsy.github.io/data/wellbeing.csv."
  },
  {
    "objectID": "1_10_assump_diag.html#assumptions",
    "href": "1_10_assump_diag.html#assumptions",
    "title": "Assumptions and Diagnostics",
    "section": "Assumptions",
    "text": "Assumptions\n\nAssumptions\nYou can remember the four assumptions by memorising the acronym LINE:\n\n\nLinearity: The relationship between \\(y\\) and \\(x\\) is linear.\n\nIndependence of errors: The error terms should be independent from one another.\n\nNormality: The errors \\(\\epsilon\\) are normally distributed in the population.\n\nEqual variances (“Homoscedasticity”): The variability of the errors \\(\\epsilon\\) is constant across \\(x\\).\n\n\n\nQuestion 1\n\n\nLet’s start by using check_model() for both rv_mdl1 and wb_mdl1 models - we can refer to these plots as a guide as we work through the assumptions questions of the lab.\n\n\n\n\n\n\nThese plots cannot be used in your reports - they are to be used as a guide only.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nrv_mdl1 model\nwb_mdl1 model\n\n\n\n\ncheck_model(rv_mdl1)\n\n\n\n\n\n\n\ncheck_model(wb_mdl1)\n\n\n\n\n\n\n\nThe check_model() function is a useful way to check the assumptions of models, as it also returns some useful notes to aid your interpretation. From the above, it doesn’t appear that any of the assumptions for either have been violated, but we need to check each assumption individually with plots that are more suitable for a statistics report.\n\n\n\n\n\nQuestion 2\n\n\nCheck if the fitted model satisfies the linearity assumption for rv_mdl1.\nWrite a sentence summarising whether or not you consider the assumption to have been met. Justify your answer with reference to the plots.\n\n\n\n\n\n\nHint\n\n\n\n\n\nConsider plotting residual vs fitted values, and/or a scatterplot with loess lines\n\n\n\n\n\n\n\n Solution \n\n\nAs usual, there are multiple equivalent ways to check this. For a model with a single predictor, there are a couple of possibilities:\n\n\nResiduals vs fitted values\nScatterplots with loess lines\n\n\n\n\n#here what we need to see is that the red line is approximately horizontal at zero\nplot(rv_mdl1, which = 1) \n\n\n\n\n\n\n\n\n\n\nThe residuals appear to be randomly scattered around zero, without showing any pattern with respect to the fitted values. Thus, there is no sign of violation of the linearity assumption.\n\n\n\n\n\n\nggplot(rvdata, aes(x = education, y = income)) + \n    geom_point() + \n    geom_smooth(method = \"lm\", se=F) +\n    geom_smooth(method = \"loess\", se=F, col = \"red\") +\n    labs(x= \"Education (in years)\", y=\"Income (in thousands of US dollars)\", title = \"Scatterplot with linear (blue) and loess (red) lines\")\n\n\n\n\n\n\n\n\n\n\nFrom our scatterplot, the loess line closely follows the data. Hence, there is no sign of violation of the linearity assumption.\n\n\n\n\n\n\n\n\n\n\n\nQuestion 3\n\n\nCheck if the fitted model satisfies the linearity assumption for wb_mdl1.\nWrite a sentence summarising whether or not you consider the assumption to have been met. Justify your answer with reference to the plots.\n\n\n\n\n\n\nHint\n\n\n\n\n\nWhen we have multiple predictors, we need to use component-residual plots (also known as partial-residual plots) to check the assumption of linearity.\n\n\n\n\n\n\n\n Solution \n\n\n\ncrPlots(wb_mdl1)\n\n\n\n\n\n\n\n\n\n\nThe smoother (the pink line) follows quite closely to a linear relationship (the dashed blue line). This suggests that the linearity assumption is met.\n\n\n\n\n\n\n\n\nQuestion 4\n\n\nCheck if the fitted models rv_mdl1 and wb_mdl1 satisfy the equal variance assumption.\nWrite a sentence summarising whether or not you consider the assumption to have been met for each model. Justify your answer with reference to plots.\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse residualPlots() to plot residuals against the predictor.\nFor interpretation - the vertical spread of the residuals should roughly be the same everywhere.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nrv_mdl1 model\nwb_mdl1 model\n\n\n\nWe can visually assess by plotting the Pearson residuals against the fitted values:\n\nresidualPlots(rv_mdl1)\n\n\n\n\n           Test stat Pr(>|Test stat|)\neducation    -0.0744           0.9412\nTukey test   -0.0744           0.9407\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nQuick Tip\nAs the residuals can be positive or negative, we can make it easier to assess equal spread by improving the ‘resolution’ of the points.\nWe can make all residuals positive by discarding the sign (take the absolute value), and then take the square root to make them closer to each other.\nA plot of \\(\\sqrt{|\\text{Standardized residuals}|}\\) against the fitted values is shown below:\n\nplot(rv_mdl1, which = 3)\n\n\n\n\nThe plot above has the points closer to each other, and all above 0. The line seems to be relatively flat (as it should be if the spread was constant). The data met the assumption of equal variance.\n\n\n\n\n\n\n\n\n\nThe spread of the standardized residuals appears to be constant as the fitted values vary.\n\n\n\n\n\n\nresidualPlots(wb_mdl1)\n\n\n\n\n             Test stat Pr(>|Test stat|)\noutdoor_time   -0.3478           0.7306\nsocial_int     -0.1068           0.9157\nTukey test     -0.4189           0.6753\n\n\n\n\n\n\n\n\nPartial residual plots show no clear non-linear trends between residuals and predictors, hence there is little sign of non-constant variance. The data met the assumption of equal variance.\n\n\n\n\n\n\n\n\n\n\n\nQuestion 5\n\n\nFor both rv_mdl1 and wb_mdl1, visually assess whether there is autocorrelation in the error terms.\nWrite a sentence summarising whether or not you consider the assumption of independence to have been met for each (you may have to assume certain aspects of the study design).\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo get a single figure made up of 2 by 1 panels, you can use the command par(mfrow = c(1,2)). Then create the plot. Then you need to go back to a single figure made up by a single panel with the command par(mfrow = c(1,1)).\n\n\n\n\n\n\n\n Solution \n\n\n\n\nrv_mdl1 model\nwb_mdl1 model\n\n\n\n\npar(mfrow = c(1,2))\nplot(resid(rv_mdl1))\nplot(fitted(rv_mdl1), resid(rv_mdl1))\n\n\n\npar(mfrow = c(1,1))\n\n\n\n\n\n\n\nSince our data were collected from a between-persons study design, we can assume the errors to be independent. This is supported by the plot of the residuals vs their index, as this shows no clear dependence (if they were collected over time, for example, and there was an increasing trend this would highlight a violation). The residuals vs fitted plot shows that there is no association between the errors and the model predictions.\n\n\n\n\n\n\npar(mfrow = c(1,2))\nplot(resid(wb_mdl1))\nplot(fitted(wb_mdl1), resid(wb_mdl1))\n\n\n\npar(mfrow = c(1,1))\n\n\n\n\n\n\n\nSince our data were collected from a between-persons study design, we can assume the errors to be independent. This is supported by the plot of the residuals vs their index which shows no clear dependence, and the residuals vs fitted plot shows that there is no association between the errors and the model predictions.\n\n\n\n\n\n\n\n\n\n\n\nQuestion 6\n\n\nCheck if the fitted models rv_mdl1 and wb_mdl1 satisfy the normality assumption.\nWrite a sentence summarising whether or not you consider the assumption to have been met. Justify your answer with reference to the plots.\n\n\n\n\n\n\nHint\n\n\n\n\n\nWe can get the QQplot from plot(model, which = ???), and you can plot the frequency distribution of the residuals via hist(model$residuals).\nFor interpretation - remember that departures from a linear trend in QQ plots indicate a lack of normality.\n\n\n\n\n\n\n\n Solution \n\n\n\n\nrv_mdl1 model\nwb_mdl1 model\n\n\n\nHistogram:\n\nhist(rv_mdl1$residuals)\n\n\n\n\nQQ Plot:\n\nplot(rv_mdl1, which = 2)\n\n\n\n\n\n\n\n\n\n\nThe normal quantile plot follows a linear pattern and does not highlight any substantial skew or departure from normality.\n\n\n\n\n\nHistogram:\n\nhist(wb_mdl1$residuals)\n\n\n\n\nQQ Plot:\n\nplot(wb_mdl1, which = 2)\n\n\n\n\n\n\n\n\n\n\nThe QQplot indicated that the residuals follow close to a normal distribution. Although there is some evidence of heavier tails, given the small sample size (\\(n\\)=32) it is not of concern and we can be more conservative in our visual assessment of the plot.\n\n\n\n\n\n\n\n\n\n\n\nFor questions 7-10, we will be working with our wb_mdl1 only. Feel free to apply the below to your rv_mdl1 too as as extra practice during revision."
  },
  {
    "objectID": "1_10_assump_diag.html#multicollinearity",
    "href": "1_10_assump_diag.html#multicollinearity",
    "title": "Assumptions and Diagnostics",
    "section": "Multicollinearity",
    "text": "Multicollinearity\n\nQuestion 7\n\n\nFor wb_mdl1, calculate the variance inflation factor (VIF) for the predictors in the model.\nWrite a sentence summarising whether or not you consider multicollinearity to be a problem here.\n\n\n\n\n Solution \n\n\n\nvif(wb_mdl1)\n\noutdoor_time   social_int \n     1.13023      1.13023 \n\n\n\n\n\n\n\n\nThe VIF values for all predictors are <5, indicating that multicollinearity is not adversely affecting model estimates."
  },
  {
    "objectID": "1_10_assump_diag.html#diagnostics",
    "href": "1_10_assump_diag.html#diagnostics",
    "title": "Assumptions and Diagnostics",
    "section": "Diagnostics",
    "text": "Diagnostics\n\nQuestion 8\n\n\nCreate a new tibble which contains:\n\nThe original variables from the model (Hint, what does wb_mdl1$model give you?)\nThe fitted values from the model \\(\\hat y\\)\n\nThe residuals \\(\\hat \\epsilon\\)\n\nThe studentised residuals\nThe hat values\nThe Cook’s Distance values\n\n\n\n\n\n Solution \n\n\n\nmdl_diagnost <- \n  tibble(\n  wb_mdl1$model,\n  fitted = fitted(wb_mdl1),\n  resid = residuals(wb_mdl1),\n  studres = rstudent(wb_mdl1),\n  hats = hatvalues(wb_mdl1),\n  cooksd = cooks.distance(wb_mdl1)\n)\n\n\n\n\n\n\nQuestion 9\n\n\nFrom the tibble above, comment on the following:\n\nLooking at the studentised residuals, are there any outliers?\nLooking at the hat values, are there any observations with high leverage?\nLooking at the Cook’s Distance values, are there any highly influential points?\n\n\n\n\n\n Solution \n\n\n\n\nOutliers\nHigh Leverage\nInfluential Points\n\n\n\nIn a standard normal distribution, 95% of the values are roughly between -2 and 2. Because of this, studentised residuals of \\(>2\\) or \\(< -2\\) indicate potential outlyingness.\nWe can ask R whether the absolute values (by specifying abs()) are \\(>2\\):\n\ntable(abs(mdl_diagnost$studres) > 2)\n\n\nFALSE \n   32 \n\n\nAll values are FALSE, which tells us that none of the absolute values are \\(>2\\).\nWe could also filter our newly created tibble to these observations:\n\nmdl_diagnost %>% \n  filter(abs(studres)>2)\n\n# A tibble: 0 × 8\n# … with 8 variables: wellbeing <dbl>, outdoor_time <dbl>, social_int <dbl>,\n#   fitted <dbl>, resid <dbl>, studres <dbl>, hats <dbl>, cooksd <dbl>\n\n\nThere are zero rows in the tibble that have absolute values \\(>2\\).\n\n\n\n\n\n\nThere are no outliers in our data.\n\n\n\n\n\nRecall that hat values of more than \\(2 \\bar{h}\\) (2 times the average hat value) are considered high leverage. The average hat value, \\(\\bar{h}\\) is calculated as \\(\\frac{k + 1}{n}\\), where \\(k\\) is the number of predictors, and \\(n\\) is the sample size.\nFor our model:\n\\[\n\\bar h = \\frac{k+1}{n} = \\frac{2+1}{32} = \\frac{3}{32} = 0.094\n\\]\nWe can ask whether any of observations have hat values which are greater than \\(2 \\bar h\\):\n\nmdl_diagnost %>%\n  filter(hats > (2*0.094))\n\n# A tibble: 0 × 8\n# … with 8 variables: wellbeing <dbl>, outdoor_time <dbl>, social_int <dbl>,\n#   fitted <dbl>, resid <dbl>, studres <dbl>, hats <dbl>, cooksd <dbl>\n\n\nNo values have been returned (the tibble has zero rows), hence we do not have any observations that have hat values which are greater than \\(2 \\bar h\\).\n\n\n\n\n\n\nThere are 0 observations that have high leverage.\n\n\n\n\n\nRecall that we have a Cook’s Distance cut-off of \\(\\frac{4}{n-k-1}\\), where \\(k\\) is the number of predictors, and \\(n\\) is the sample size.\nFor our model:\n\\[\nD_{cutoff} = \\frac{4}{n-k-1} = \\frac{4}{32 - 2 - 1} = \\frac{4}{29} = 0.138\n\\]\nWe can ask whether any of observations have a high influence on our model estimates:\n\nmdl_diagnost %>%\n  filter(cooksd > 0.138)\n\n# A tibble: 0 × 8\n# … with 8 variables: wellbeing <dbl>, outdoor_time <dbl>, social_int <dbl>,\n#   fitted <dbl>, resid <dbl>, studres <dbl>, hats <dbl>, cooksd <dbl>\n\n\nNo values have been returned (the tibble has zero rows), hence we do not have any observations that have a high influence on our model estimates.\nYou can also display the Cook’s Distance values themselves using plot(model, which = 4):\n\nplot(wb_mdl1, which = 4)\n\n\n\n\n\n\n\n\n\n\nNone of our observations have a high influence on our model estimates, as the maximum value of Cook’s distance in our sample is 0.108, which is less than the cutt-off value of 0.138. Thus, we do not appear to have any influential points in our sample.\n\n\n\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nUse the function influence.measures() to extract these delete-1 measures of influence.\nTry plotting the distributions of some of these measures.\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe function influence.measures() returns an infl-type object. To plot this, we need to find a way to extract the actual numbers from it.\nWhat do you think names(influence.measures(wb_mdl1)) shows you? How can we use influence.measures(wb_mdl1)$<insert name here> to extract the matrix of numbers?\n\n\n\n\n\n\n\n Solution \n\n\n\n\n\n\ninf_mes <- influence.measures(wb_mdl1)\nround(inf_mes$infmat[1:10,],3)\n\n   dfb.1_ dfb.otd_ dfb.scl_  dffit cov.r cook.d   hat\n1   0.437   -0.111   -0.322  0.448 1.157  0.066 0.149\n2  -0.282    0.032    0.230 -0.292 1.225  0.029 0.141\n3   0.296    0.076   -0.290  0.354 1.088  0.042 0.097\n4  -0.264   -0.131    0.293 -0.351 1.117  0.041 0.107\n5  -0.271    0.227    0.105 -0.329 1.279  0.037 0.177\n6   0.125   -0.027   -0.083  0.146 1.141  0.007 0.060\n7  -0.174   -0.034    0.153 -0.223 1.087  0.017 0.060\n8  -0.029   -0.073    0.061 -0.092 1.309  0.003 0.156\n9   0.169    0.088   -0.178  0.248 1.088  0.021 0.067\n10 -0.248    0.331   -0.006 -0.427 1.027  0.059 0.096\n\n\nLet’s plot the distribution of COVRATIO statistics.\nRecall that values which are \\(>1+\\frac{3(k+1)}{n}\\) or \\(<1-\\frac{3(k+1)}{n}\\) are considered as having strong influence.\nFor our model:\n\\[\n1 \\pm \\frac{3(k+1)}{n} \\quad = \\quad 1 \\pm\\frac{3(2+1)}{32} \\quad = \\quad 1\\pm \\frac{9}{32} \\quad = \\quad 1\\pm0.28\n\\]\nThe “infmat” bit of an infl-type object contains the numbers, as we can see from out output above. To use it with ggplot, we will need to turn it into a dataframe (as.data.frame()), or a tibble (as_tibble()):\n\ninfdata <- inf_mes$infmat %>%\n  as_tibble()\n\nNow we can build our plot. It would be useful to add vertical lines at the values \\(\\quad 1\\pm0.28\\). To do so, we can use the geom_vline() function:\n\nggplot(data = infdata, aes(x = cov.r)) + \n  geom_histogram() +\n  geom_vline(aes(xintercept = c(1-0.28), col = \"blue\")) +\n  geom_vline(aes(xintercept = c(1+0.28), col = \"red\")) + \n  theme(legend.position = \"none\")  #remove legend\n\n\n\n\nIt looks like a few observations may be having quite a high influence here. This is perhaps not that surprising as we only have 32 datapoints.\n\n\n\n\n\n \n\n \n\n      © Copyright 2019-2022 The University of Edinburgh. Site licensed under the GNU AGPLv3 license."
  },
  {
    "objectID": "1_11_writeup_recap.html",
    "href": "1_11_writeup_recap.html",
    "title": "Write Up Example & Block 2 Recap",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand how to write-up and provide interpretation of a linear model with multiple predictors.\n\n\nBe up to date with lectures\nHave completed Labs 7-10\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npatchwork\nsjPlot\nsandwich\ninteractions\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/scs_study.csv.\nNote: This is the same data as Lab 8."
  },
  {
    "objectID": "1_11_writeup_recap.html#study-overview",
    "href": "1_11_writeup_recap.html#study-overview",
    "title": "Write Up Example & Block 2 Recap",
    "section": "Study Overview",
    "text": "Study Overview\n\nResearch Question\nControlling for other personality traits, does neuroticism moderate effects of social comparison on symptoms of depression, anxiety and stress?\n\nPrevious research has identified an association between an individual’s perception of their social rank and symptoms of depression, anxiety and stress. We are interested in the individual differences in this association.\nTo investigate whether the effect of social comparison on symptoms of depression, anxiety and stress varies depending on level of Neuroticism, we will need to fit a multiple regression model with an interaction term and control for other personality traits.\n\n Social Comparison Study data codebook\n\n\nDescription\nData from 656 participants containing information on scores on each trait of a Big 5 personality measure, their perception of their own social rank, and their scores on a measure of depression.\nThe data in scs_study.csv contain seven attributes collected from a random sample of \\(n=656\\) participants:\n\n\nzo: Openness (Z-scored), measured on the Big-5 Aspects Scale (BFAS)\n\nzc: Conscientiousness (Z-scored), measured on the Big-5 Aspects Scale (BFAS)\n\nze: Extraversion (Z-scored), measured on the Big-5 Aspects Scale (BFAS)\n\nza: Agreeableness (Z-scored), measured on the Big-5 Aspects Scale (BFAS)\n\nzn: Neuroticism (Z-scored), measured on the Big-5 Aspects Scale (BFAS)\n\nscs: Social Comparison Scale - An 11-item scale that measures an individual’s perception of their social rank, attractiveness and belonging relative to others. The scale is scored as a sum of the 11 items (each measured on a 5-point scale), with higher scores indicating more favourable perceptions of social rank.\n\ndass: Depression Anxiety and Stress Scale - The DASS-21 includes 21 items, each measured on a 4-point scale. The score is derived from the sum of all 21 items, with higher scores indicating higher a severity of symptoms.\n\nPreview\nThe first six rows of the data are:\n\n\n\n\n\n\n\nzo\n      zc\n      ze\n      za\n      zn\n      scs\n      dass\n    \n\n\n0.76\n1.58\n-0.79\n-0.09\n1.32\n30\n56\n\n\n0.30\n-0.27\n-0.09\n0.09\n-0.40\n30\n48\n\n\n-0.13\n0.66\n-0.80\n-0.95\n0.93\n35\n48\n\n\n1.06\n-1.02\n-0.16\n-0.50\n-0.02\n29\n48\n\n\n1.74\n-0.78\n-1.55\n-2.86\n-1.14\n41\n43\n\n\n0.22\n-0.41\n0.78\n0.90\n-0.25\n37\n60\n\n\n\n\n\n\n\n\n\n\n Provided Analysis Code\n\n\n\nlibrary(tidyverse) # for all things!\nlibrary(psych) # good for descriptive stats\nlibrary(kableExtra) # useful for creating nice tables\nlibrary(car) # for assumption tests\nlibrary(sandwich)\nlibrary(interactions) # for plotting models\n\nscs_study <- read_csv(\"https://uoepsy.github.io/data/scs_study.csv\")\n\n# standardise scs score\nscs_study <- \n  scs_study %>% \n    mutate(\n      zscs = (scs-mean(scs))/sd(scs)\n    )\n#alternatively, you could do zscs = scale(scs, center = TRUE, scale = TRUE)\n\n# the describe() function is from the psych package, and kable() from kableExtra which is used to make a nice table where the values are rounded to 2 decimal places using digits = 2. \ndescribe(scs_study %>% \n        select(dass, scs, zn))[,c(2:4,8:9)] %>% \n        kable(., caption = \"DASS-21, SCS, and Neuroticism Descriptive Statistics\", digits = 2) %>%\n        kable_styling()\n\n\n\nDASS-21, SCS, and Neuroticism Descriptive Statistics\n \n   \n    n \n    mean \n    sd \n    min \n    max \n  \n\n\n dass \n    656 \n    44.72 \n    6.76 \n    23.00 \n    68.00 \n  \n\n scs \n    656 \n    35.77 \n    3.53 \n    27.00 \n    54.00 \n  \n\n zn \n    656 \n    0.00 \n    1.00 \n    -1.45 \n    3.35 \n  \n\n\n\n\n\n# scatterplot matrix of dataset without the zscs variable\npairs.panels(scs_study %>% select(-zscs))\n\n\n\n\n\ndass_mdl <- lm(dass ~ zscs*zn + zo + zc + ze + za, data = scs_study)\npar(mfrow=c(2,2))\nplot(dass_mdl)\n\n\n\n# 35 seems to be a very influential point, lets remove it and re-run the model\n\n\ndass_mdl2 <- lm(dass ~ zscs*zn + zo + zc + ze + za, data = scs_study[-35, ])\n\n# check assumptions for updated model\npar(mfrow=c(2,2))\nplot(dass_mdl2)\n\n\n\npar(mfrow=c(1,1))\n\n# N.B. we cannot use crPlots for interactions\n\n\n# Additional diagnostic plots for independence and homoscedasticity\n\n# checking for independence\nplot(resid(dass_mdl2))\n\n\n\n# alternative check for equal variances (Homoscedasticity) - \nresidualPlots(dass_mdl2)\n\n\n\n\n           Test stat Pr(>|Test stat|)  \nzscs          1.8141          0.07013 .\nzn           -0.5911          0.55467  \nzo            1.7801          0.07553 .\nzc           -0.2403          0.81018  \nze           -0.9951          0.32004  \nza            0.0725          0.94219  \nTukey test   -1.6406          0.10089  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# multicollinearity\nvif(dass_mdl2)\n\nthere are higher-order terms (interactions) in this model\nconsider setting type = 'predictor'; see ?vif\n\n\n    zscs       zn       zo       zc       ze       za  zscs:zn \n1.015133 1.015736 1.013310 1.008235 2.332486 2.342220 1.012475 \n\n\n\n# model output\nsummary(dass_mdl2)\n\n\nCall:\nlm(formula = dass ~ zscs * zn + zo + zc + ze + za, data = scs_study[-35, \n    ])\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-17.1455  -3.8155  -0.0066   3.6905  18.1483 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 44.97703    0.22635 198.708  < 2e-16 ***\nzscs        -1.93818    0.23042  -8.412 2.58e-16 ***\nzn           1.41639    0.22661   6.250 7.44e-10 ***\nzo          -0.31435    0.22056  -1.425    0.155    \nzc           0.09134    0.22515   0.406    0.685    \nze           0.52695    0.34233   1.539    0.124    \nza           0.33847    0.34281   0.987    0.324    \nzscs:zn     -2.76609    0.24097 -11.479  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.733 on 647 degrees of freedom\nMultiple R-squared:  0.279, Adjusted R-squared:  0.2712 \nF-statistic: 35.76 on 7 and 647 DF,  p-value: < 2.2e-16\n\n\n\n#create table for results\ntab_model(dass_mdl2,\n          dv.labels = c(\"DASS-21 Scores\"),\n          pred.labels = c(\"zscs\"=\"Social Comparison Scale (Z-scored)\", \n                          \"zn\"=\"Neuroticism (Z-scored)\", \n                          \"zo\"=\"Openness (Z-scored)\", \n                          \"zc\"=\"Conscientiousness (Z-scored)\",\n                          \"ze\"=\"Extraversion (Z-scored)\",\n                          \"za\"=\"Agreeableness (Z-scored)\",\n                          \"zscs:zn\"=\"Social Comparison Scale (Z-scored): Neutoricism (Z-scored)\"),\n          title = \"Regression table for DASS-21 model\")\n\n\n\nRegression table for DASS-21 model\n\n \nDASS-21 Scores\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n44.98\n44.53 – 45.42\n<0.001\n\n\nSocial Comparison Scale(Z-scored)\n-1.94\n-2.39 – -1.49\n<0.001\n\n\nNeuroticism (Z-scored)\n1.42\n0.97 – 1.86\n<0.001\n\n\nOpenness (Z-scored)\n-0.31\n-0.75 – 0.12\n0.155\n\n\nConscientiousness(Z-scored)\n0.09\n-0.35 – 0.53\n0.685\n\n\nExtraversion (Z-scored)\n0.53\n-0.15 – 1.20\n0.124\n\n\nAgreeableness (Z-scored)\n0.34\n-0.33 – 1.01\n0.324\n\n\nSocial Comparison Scale(Z-scored): Neutoricism(Z-scored)\n-2.77\n-3.24 – -2.29\n<0.001\n\n\nObservations\n655\n\n\nR2 / R2 adjusted\n0.279 / 0.271\n\n\n\n\n\n#interaction plot and simple slopes:\nplt_scs_mdl <- probe_interaction(model = dass_mdl2, \n                  pred = zscs, \n                  modx = zn, \n                  cond.int = T,\n                  interval = T, \n                  jnplot = T,\n                  main.title = \"Neuroticism moderating the effect of\\nsocial comparison on depression and anxiety\",\n                  x.label = \"Social Comparison Scale (Z-scored)\",\n                  y.label = \"DASS-21 Scores\",\n                  legend.main = \"Neuroticism (Z-scored)\")\n\nplt_scs_mdl$interactplot\n\n\n\nplt_scs_mdl$simslopes\n\nJOHNSON-NEYMAN INTERVAL \n\nWhen zn is OUTSIDE the interval [-0.93, -0.52], the slope of zscs is p <\n.05.\n\nNote: The range of observed values of zn is [-1.45, 3.35]\n\n\n\n\n\nSIMPLE SLOPES ANALYSIS \n\nWhen zn = -1.000344918 (- 1 SD): \n\n                               Est.   S.E.   t val.      p\n--------------------------- ------- ------ -------- ------\nSlope of zscs                  0.83   0.33     2.49   0.01\nConditional intercept         43.53   0.32   136.42   0.00\n\nWhen zn = -0.003414067 (Mean): \n\n                               Est.   S.E.   t val.      p\n--------------------------- ------- ------ -------- ------\nSlope of zscs                 -1.93   0.23    -8.37   0.00\nConditional intercept         44.96   0.23   199.64   0.00\n\nWhen zn =  0.993516784 (+ 1 SD): \n\n                               Est.   S.E.   t val.      p\n--------------------------- ------- ------ -------- ------\nSlope of zscs                 -4.69   0.33   -14.05   0.00\nConditional intercept         46.39   0.32   145.48   0.00\n\n\n\n\n\nSetup\n\nSetup\n\n\n\nCreate a new RMarkdown file\nLoad the required package(s)\nRead the scs dataset into R, assigning it to an object named scs\n\n\n\n\n\n\n Solution \n\n\n\nlibrary(tidyverse)\nlibrary(psych) \nlibrary(kableExtra)\nlibrary(car)\nlibrary(sjPlot)\n\nscs <- read_csv(\"https://uoepsy.github.io/data/scs_study.csv\")\n\n\n\n\nThe 3-Act Structure\nWe need to present our report in three clear sections - think of your sections like the 3 key parts of a play or story - we need to (1) provide some background and scene setting for the reader, (2) present our results in the context of the research question, and (3) present a resolution to our story - relate our findings back to the question we were asked and provide our answer.\nAct I: Analysis Strategy\n\nQuestion 1\n\n\nAttempt to draft a discussion section based on the above research question and analysis provided.\n\n\n\n\n\n\n\n\n\nAnalysis Strategy - What to Include\n\n\n\n\n\nYour analysis strategy will contain a number of different elements detailing plans and changes to your plan. Remember, your analysis strategy should not contain any results. You may wish to include the following sections:\n\nVery brief data and design description:\n\nGive the reader some background on the context of your write-up. For example, you may wish to describe the data source, data collection strategy, study design, number of observational units.\nSpecify the variables of interest in relation to the research question, including their unit of measurement, the allowed range (for Likert scales), how they are scored, and if they are factors make sure to list the order of the levels.\n\n\nData management:\n\nDescribe any data cleaning and/or recoding.\nAre there any observations that have been excluded based on pre-defined criteria? How/why, and how many?\n* Describe any transformations performed to aid your interpretation (i.e., log transformation, mean centering, standardisation, etc.)\n\n\nModel specification:\n\nClearly state your hypotheses and specify your chosen significance level.\nWhat type of statistical analysis do you plan to use to answer the research question? (e.g., t-test, simple linear regression, multiple linear regression, etc.)\nIn some cases, you may wish to include some visualisations and descriptive tables to motivate your model specification.\nSpecify the model(s) to be fitted to answer your given research question and analysis structure. Clearly specify the response and explanatory variables included in your model(s) and remember to describe the coding of categorical variables (i.e., factors) so the reader is aware of any reference levels.\nDetail the steps that you will undertake to ensure that your model(s) do not violate the appropriate assumptions.\nIf applicable, detail any required changes/modifications to the model specification to satisfy assumptions. Consider the following: Was there anything you had to do differently than planned during the analysis? Did the modelling highlight issues in your data? Did you have to do anything (e.g., transform any variables, exclude any observations) in order to meet assumptions?\n\n\n\n\nNote that the * used on occasion in the above indicates that you may/should in some cases repeat these steps if you decide to make any modifications to your data (e.g., removing outliers, etc.).\n\nAs noted and encouraged throughout the course, one of the main benefits of using RMarkdown is the ability to include inline R code in your document. Try to incorporate this in your write up so you can automatically pull the specified values from your code. If you need a reminder on how to do this, see Lesson 4 of the Rmd Bootcamp.\n\n\n\n\n Example Write-Up of Analysis Strategy Section\n\n\nThe dataset contained information on 656 participants, including \\(Z\\)-scores on 5 personality traits assessed by the Big-Five Aspects Scale (BFAS; Openness, Conscientiousness, Extraversion, Agreeableness and Neuroticism). Participants were also assessed on the Social Comparison Scale (SCS), which is an 11-item scale measuring self-perception (relative to others) of social rank, attractiveness and belonging, and the Depression Anxiety and Stress Scale (DASS-21) - a 21 item measure with higher scores indicating higher severity of symptoms. For both of these measures, only total scores were available. Items in the SCS were measured on a 5-point scale, giving minimum and maximum possible scores of 11 and 55 respectively. Items in the DASS-21 were measured on a 4-point scale, meaning that scores could range from 21 to 84.\nAll participant data was complete (no missing values), with scores on the SCS and the DASS-21 all within possible ranges.\nTo investigate whether, when controlling for other personality traits, Neuroticism moderated the effect of social comparison on symptoms of depression, anxiety and stress, total scores on the DASS-21 were modeled using multiple linear regression. The \\(Z\\)-scored measures on each of the big-five personality traits were included as predictors, along with scores on the SCS (\\(Z\\)-scored) and its interaction with the measure of Neuroticism. Effects were considered statistically significant at \\(\\alpha = 0.05\\).\nThe following model specification was used:\n\\[\n\\begin{aligned}\n\\text{DASS-21}\n= \\beta_0 + \\beta_1 \\text{O} + \\beta_2 \\text{C} + \\beta_3 \\text{E} + \\beta_4 \\text{A}\n+ \\beta_5 \\text{N} + \\beta_6 \\text{SCS} + \\beta_7 (\\text{SCS} \\cdot \\text{N})\n+ \\epsilon  \\\\\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\n\\text{where } \\\\\n\\\\\n& \\text{O = Openness, z-scored} \\\\\n& \\text{C = Conscientiousness, z-scored} \\\\\n& \\text{E = Extraversion, z-scored} \\\\\n& \\text{A = Agreeableness, z-scored} \\\\\n& \\text{N = Neuroticism, z-scored} \\\\\n& \\text{SCS = Social Comparison Scale, z-scored} \\\\\n\\end{aligned}\n\\]\nTo address the research question of whether Neuroticism moderated the effect of social comparison on depression and anxiety, we tested whether the interaction between SCS and Neuroticism was significant. Formally, this corresponded to testing whether the interaction coefficient was equal to zero:\n\\[\n\\begin{aligned}\nH_0: \\beta_7 = 0  \\\\  \nH_1: \\beta_7 \\neq 0  \\\\\n\\end{aligned}\n\\]\nThe following assumptions were assessed visually using diagnostic plots: linearity (via plot of residuals vs fitted values; red line should be approximately horizontal, with residual values randomly scattered around zero and thus showing no pattern in relation to fitted values), independence (with the previous plot and a plot of residuals vs index; no dependence should be indicated), equal variances (via a scale-location plot; residuals should be evenly spread across the range of fitted values, where the spread should be constant across the range of fitted values), and normality (via a qqplot of the residuals; points should follow along the diagonal line). We also checked if there was any evidence of multicollinearity by checking VIF values, where values > 5 were considered to indicate moderate multicollinearity, and values > 10 severe. Outliers were assessed via Cooks Distance, where values >2 indicated influential points.\n\n\n\nAct II: Results\n\nQuestion 2\n\n\nAttempt to draft a results section based on your detailed analysis strategy and the analysis provided.\n\n\n\n\n\n\n\n\n\nResults - What To Include\n\n\n\n\n\nThe results section should follow from your analysis strategy. This is where you would present the evidence and results that will be used to answer the research questions and can support your conclusions. Make sure that you address all aspects of the approach you outlined in the analysis strategy.\nIn this section, it is useful to include tables and plots to clearly present your findings to your reader. It is important, however, to carefully select what is the key information that should be presented. You don’t want to overload the reader with unnecessary information, and you also want to save space in case there is a page limit. Make use of figures with multiple panels where you can.\nAs a broad guideline, you want to start with the results of an exploratory data analysis, presenting tables of summary statistics and exploratory plots. You may also want to visualise relationships between variables and report covariances or correlations. Then, you should move on to the results from your model. Remember that in the main part of the report you should only interpret and report for models that do not violate the assumptions. You should also interpret all of the results presented, and remember to make reference to and comment on your assumption and diagnostic checks for key models.\n\n\n\n\n Example Write-Up of Results Section\n\n\nDescriptive statistics are displayed in Table 1.\n\n\n\n\n\nTable 1:  Regression table for DASS-21 model \n \n   \n    n \n    mean \n    sd \n    min \n    max \n  \n\n\n dass \n    656 \n    44.72 \n    6.76 \n    23.00 \n    68.00 \n  \n\n scs \n    656 \n    35.77 \n    3.53 \n    27.00 \n    54.00 \n  \n\n zn \n    656 \n    0.00 \n    1.00 \n    -1.45 \n    3.35 \n  \n\n\n\n\n\nBivariate correlations showed a moderate negative association between DASS-21 and SCS scores; a moderate positive association between DASS-21 and Neuroticism, and a weak positive correlation between SCS and Neuroticism (see Figure 1).\n\n\n\n\nFigure 1: Bivariate scatter plots (below diagonal), histograms (diagonal), and Pearson correlation coefficient (above diagonal) for DASS-21 scores, SCS, and Big 5 Personality variables\n\n\n\n\nOne observation (unit 35) was judged to be too influential on the model (Cook’s Distance = 2.66) and as such was excluded from the final analysis, leaving 655 observations.\nThe final model met assumptions of linearity and independence (see top left panel of Figure 2; residuals were randomly scattered with a mean of zero and there was no clear dependence), homoscedasticity (see bottom left panel of Figure 2; there was a constant spread of residuals), and normality (see top right panel of Figure 2; the QQplot showed very little deviation from the diagonal line). All VIF values were <5, and hence there was no evidence of multicollinearity.\n\n\n\n\nFigure 2: Diagnostic Plots\n\n\n\n\n\n\n\nFull regression results including 95% Confidence Intervals are shown in Table 2. The \\(F\\)-test for model utility was significant (\\(F(7,647) = 35.76, p<.001\\)), and the model explained approximately 27.12% of the variability in DASS-21 Scores.\n\n\n\n\n\n\nTable 2:  Regression table for DASS-21 model \n\n \nDASS-21 Scores\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n44.98\n44.53 – 45.42\n<0.001\n\n\nSocial Comparison Scale(Z-scored)\n-1.94\n-2.39 – -1.49\n<0.001\n\n\nNeuroticism (Z-scored)\n1.42\n0.97 – 1.86\n<0.001\n\n\nOpenness (Z-scored)\n-0.31\n-0.75 – 0.12\n0.155\n\n\nConscientiousness(Z-scored)\n0.09\n-0.35 – 0.53\n0.685\n\n\nExtraversion (Z-scored)\n0.53\n-0.15 – 1.20\n0.124\n\n\nAgreeableness (Z-scored)\n0.34\n-0.33 – 1.01\n0.324\n\n\nSocial Comparison Scale(Z-scored): Neutoricism(Z-scored)\n-2.77\n-3.24 – -2.29\n<0.001\n\n\nObservations\n655\n\n\nR2 / R2 adjusted\n0.279 / 0.271\n\n\n\n\n\n\n\nResults showed a significant conditional association between SCS scores (\\(Z\\)-scored) and DASS-21 Scores (\\(\\beta\\) = -1.94, \\(SE\\) = 0.23, \\(p\\) <.001), which suggested that for those at the mean level of Neuroticism, scores on the DASS-21 decreased by 1.94 for every 1 standard deviation increase in SCS scores. A significant conditional association was also evident between Neuroticism (Z-scored) and DASS-21 Scores (\\(\\beta\\) = 1.42, \\(SE\\) = 0.23, \\(p\\) <.001), which suggested that for those with average scores on the SCS, scores on the DASS-21 increased by 1.42 for every 1 standard deviation increase in Neuroticism.\nCrucially, the association between social comparison and symptoms of depression and anxiety was found to be dependent upon the level of Neuroticism, with a greater negative association between the two for those with high levels of Neuroticism (\\(\\beta\\) = -2.77, \\(SE\\) = 0.24, \\(p\\) <.001). This interaction is visually presented in Figure 3.\n\n\n\n\n\n\n\nFigure 3: Interaction Plot\n\n\n\n\nThe results presented here indicated that the association between social comparison and depression and anxiety did depend upon individuals’ levels of Neuroticism, with perceived social rank perhaps leading to more symptoms of depression and anxiety for highly neurotic individuals. The Johnson-Neyman technique (see Figure 4) indicated that the association between DASS-21 scores and SCS was significant when Neuroticism scores were less than 0.93 standard deviations below the mean or more than -0.52 standard deviations above the mean.\n\n\n\n\nFigure 4: Simple Slopes\n\n\n\n\n\n\n\nAct III: Discussion\n\nQuestion 3\n\n\nAttempt to draft a discussion section based on your results and the analysis provided.\n\n\n\n\n\n\n\n\n\nDiscussion - What To Include\n\n\n\n\n\nIn the discussion section, you should summarise the key findings from the results section and provide the reader with take-home sentences drawing the analysis together and relating it back to the original question.\nThe discussion should be relatively brief, and should not include any statistical analysis - instead think of the discussion as a conclusion, providing an answer to the research question(s).\n\n\n\n\n Example Write-Up of Discussion Section\n\n\nPrevious research had identified an association between an individual’s perception of their social rank and symptoms of depression, anxiety and stress. We investigated if Neuroticism moderated effects of social comparison on symptoms of depression, anxiety, and stress after controlling for other personality traits.\nOur results led us to reject the null hypothesis that the interaction coefficient was equal to zero, as the results indicated that the association between social comparison and depression and anxiety did depend upon individuals’ levels of Neuroticism, with perceived social rank perhaps leading to more symptoms of depression and anxiety for highly neurotic individuals. However, it is important to note that we can make no claims on the directions of these associations from these data based on significance alone - it may be that social comparison leads to more depression and anxiety in neurotic individuals, but also consistent is the view that - for these individuals - higher levels of depression leads to a greater reduction in perceived social rank."
  },
  {
    "objectID": "2_01_model_comps.html",
    "href": "2_01_model_comps.html",
    "title": "Model Comparisons",
    "section": "",
    "text": "Study Overview\n\nResearch Questions\n\nRQ1: Is there an overall effect of the number of social interactions on wellbeing scores?\nRQ2: Does the association between number of social interactions and wellbeing differ between rural and non-rural residents?\nRQ3: Does weekly outdoor time explain a significant amount of variance in wellbeing scores over and above the interaction between weekly social interactions and location (rural vs not-rural)?\n\n\n\n Wellbeing/Rurality data codebook.\n\n\nDescription\nFrom the Edinburgh & Lothians, 100 city/suburb residences and 100 rural residences were chosen at random and contacted to participate in the study. The Warwick-Edinburgh Mental Wellbeing Scale (WEMWBS), was used to measure mental health and well-being.\nParticipants filled out a questionnaire including items concerning: estimated average number of hours spent outdoors each week, estimated average number of social interactions each week (whether on-line or in-person), whether a daily routine is followed (yes/no). For those respondents who had an activity tracker app or smart watch, they were asked to provide their average weekly number of steps.\nThe data in wellbeing.csv contain seven attributes collected from a random sample of \\(n=200\\) hypothetical residents over Edinburgh & Lothians, and include:\n\n\nwellbeing: Warwick-Edinburgh Mental Wellbeing Scale (WEMWBS), a self-report measure of mental health and well-being. The scale is scored by summing responses to each item, with items answered on a 1 to 5 Likert scale. The minimum scale score is 14 and the maximum is 70.\n\n\noutdoor_time: Self report estimated number of hours per week spent outdoors\n\n\nsocial_int: Self report estimated number of social interactions per week (both online and in-person)\n\nroutine: Binary 1=Yes/0=No response to the question “Do you follow a daily routine throughout the week?”\n\nlocation: Location of primary residence (City, Suburb, Rural)\n\nsteps_k: Average weekly number of steps in thousands (as given by activity tracker if available)\n\nage: Age in years of respondent\n\nPreview\nThe first six rows of the data are:\n\n\n\n\n\n\n\nage\n      outdoor_time\n      social_int\n      routine\n      wellbeing\n      location\n      steps_k\n    \n\n\n28\n12\n13\n1\n36\nrural\n21.6\n\n\n56\n5\n15\n1\n41\nrural\n12.3\n\n\n25\n19\n11\n1\n35\nrural\n49.8\n\n\n60\n25\n15\n0\n35\nrural\nNA\n\n\n19\n9\n18\n1\n32\nrural\n48.1\n\n\n34\n18\n13\n1\n34\nrural\n67.3\n\n\n\n\n\n\n\n\n\nSetup\n\nSetup\n\n\n\nCreate a new RMarkdown file\nLoad the required package(s)\nRead the wellbeing_rural dataset into R, assigning it to an object named wrdata\n\n\n\n\n\n\n Solution \n\n\n\n#Loading the required package(s)\nlibrary(tidyverse)\nlibrary(stargazer)\n\n#Reading in data and storing in object named 'wrdata'\nwrdata <- read_csv(\"https://uoepsy.github.io/data/wellbeing_rural.csv\")\n\n\n\n\nExercises\n\nQuestion 1\n\n\nCheck coding of variables (e.g., that categorical variables are coded as factors), and create a new binary variable which specifies whether or not each participant lives in a rural location.\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou will need to use two functions - firstly mutate(), and then ifelse() when creating your new variable (which should also be coded as a factor).\n\n\n\n\n\n\n\n Solution \n\n\n\n#before we create our new variable, it would be helpful to give a more informative name to the levels of the routine variable as opposed to 0s and 1s\n\nwrdata <-  wrdata %>% \n    mutate(\n        routine = factor(routine,\n                         levels = c(0,1),\n                         labels = c(\"No\", \"Yes\")),\n        isRural = factor(ifelse(location == \"rural\",\"rural\",\"not rural\"))\n    )\n\n\n\n\n\n\nQuestion 2\n\n\nUsing fct_relevel(), specify ‘not rural’ as your reference group for your newly created variable (i.e., the isRural variable).\n\n\n\n\n Solution \n\n\n\nwrdata$isRural <- fct_relevel(wrdata$isRural, \"not rural\")\n\n\n\n\n\n\nQuestion 3\n\n\nFit the below 5 models required to address the three research questions stated above. Note down which model(s) will be used to address each research question, and examine the results of each model.\nName the models as follows: “wb_mdl0”, “wb_mdl1”, “wb_mdl2”, “wb_mdl3”, and “wb_mdl4”.\n\n\\[\n\\text{Wellbeing} = \\beta_0  + \\epsilon\n\\]\n\n\\[\n\\text{Wellbeing} = \\beta_0  + \\beta_1 \\cdot Social Interactions + \\epsilon\n\\]\n\n\\[\n\\text{Wellbeing} = \\beta_0  + \\beta_1 \\cdot Social Interactions + \\beta_2 \\cdot Location_{Rural} + \\epsilon\n\\]\n\n\\[\n\\begin{split}\n\\text{Wellbeing} = \\beta_0 + \\beta_1 \\cdot Social Interactions + \\beta_2 \\cdot Location_{Rural} \\\\+ \\beta_3 \\cdot (Social Interactions \\cdot Location_{Rural}) + \\epsilon\n\\end{split}\n\\]\n\n\\[\n\\begin{split}\n\\text{Wellbeing} = \\beta_0 + \\beta_1 \\cdot Social Interactions + \\beta_2 \\cdot Location_{Rural} \\\\+ \\beta_3 \\cdot (Social Interactions \\cdot Location_{Rural}) + \\beta_4 \\cdot \\text{Outdoor Time} + \\epsilon\n\\end{split}\n\\]\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe summary() function will be useful to examine the model output.\n\n\n\n\n\n\n\n Solution \n\n\n\n#null/intercept only model\nwb_mdl0 <- lm(wellbeing ~ 1, data = wrdata)\nsummary(wb_mdl0)\n\n\nCall:\nlm(formula = wellbeing ~ 1, data = wrdata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-14.295  -3.295  -1.295   3.705  22.705 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  36.2950     0.3813   95.19   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.392 on 199 degrees of freedom\n\n#model with social interactions\nwb_mdl1 <- lm(wellbeing ~ social_int, data = wrdata)\nsummary(wb_mdl1)\n\n\nCall:\nlm(formula = wellbeing ~ social_int, data = wrdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.5628  -3.2741  -0.7908   3.3703  20.4706 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 32.40771    1.17532  27.573  < 2e-16 ***\nsocial_int   0.32220    0.09243   3.486 0.000605 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.247 on 198 degrees of freedom\nMultiple R-squared:  0.05781,   Adjusted R-squared:  0.05306 \nF-statistic: 12.15 on 1 and 198 DF,  p-value: 0.0006045\n\n#model with social interactions and location (rural vs non-rural)\nwb_mdl2 <- lm(wellbeing ~ social_int + isRural, data = wrdata)\nsummary(wb_mdl2)\n\n\nCall:\nlm(formula = wellbeing ~ social_int + isRural, data = wrdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.3711  -3.1794   0.1097   2.5407  17.6324 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  34.11591    1.07052  31.868  < 2e-16 ***\nsocial_int    0.38167    0.08257   4.622 6.85e-06 ***\nisRuralrural -4.85152    0.66283  -7.319 6.18e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.664 on 197 degrees of freedom\nMultiple R-squared:  0.2593,    Adjusted R-squared:  0.2517 \nF-statistic: 34.47 on 2 and 197 DF,  p-value: 1.453e-13\n\n#model with social interactions and location (rural vs non-rural) interaction term\nwb_mdl3 <- lm(wellbeing ~ social_int*isRural, data = wrdata)\nsummary(wb_mdl3)\n\n\nCall:\nlm(formula = wellbeing ~ social_int * isRural, data = wrdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12.4845  -2.7975   0.0155   2.4539  15.6743 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              30.9986     1.4284  21.702  < 2e-16 ***\nsocial_int                0.6488     0.1160   5.593 7.42e-08 ***\nisRuralrural              1.3866     2.0510   0.676  0.49981    \nsocial_int:isRuralrural  -0.5176     0.1615  -3.206  0.00157 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.558 on 196 degrees of freedom\nMultiple R-squared:  0.2962,    Adjusted R-squared:  0.2854 \nF-statistic: 27.49 on 3 and 196 DF,  p-value: 6.97e-15\n\n#model with social interactions and location (rural vs non-rural) term, and outdoor time\nwb_mdl4 <- lm(wellbeing ~ social_int*isRural + outdoor_time, data= wrdata)\nsummary(wb_mdl4)\n\n\nCall:\nlm(formula = wellbeing ~ social_int * isRural + outdoor_time, \n    data = wrdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12.7426  -2.6884  -0.1465   2.7122  14.3407 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(>|t|)    \n(Intercept)             27.61305    1.61227  17.127  < 2e-16 ***\nsocial_int               0.65490    0.11175   5.861 1.94e-08 ***\nisRuralrural             1.46796    1.97579   0.743   0.4584    \noutdoor_time             0.17704    0.04395   4.028 8.04e-05 ***\nsocial_int:isRuralrural -0.51129    0.15554  -3.287   0.0012 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.391 on 195 degrees of freedom\nMultiple R-squared:  0.3502,    Adjusted R-squared:  0.3369 \nF-statistic: 26.28 on 4 and 195 DF,  p-value: < 2.2e-16\n\n\nThe models required to address each research question (RQ) are as follows:\n\nRQ1: Models wb_mdl0 and wb_mdl1\nRQ2: Models wb_mdl2 and wb_mdl3\nRQ3: Models wb_mdl3 and wb_mdl4\n\n\n\n\n\n\nQuestion 4\n\n\nProvide key model results from the two models required to address RQ1 - whether there is an overall effect of the number of social interactions on wellbeing scores - in a single formatted table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou will need to use a new package to do this - stargazer.\nLike tab_model() that you have used in many previous labs, stargazer() can take lots of different arguments to customize and build a table. You may want to consider specifying the below (and remember you can use the helper function via ?stargazer() for further information about the functionality of the package):\n\n\ntitle = - specify the title of your table\n\ndep.var.labels = - specify the name of your dependent variable(s)\n\ncovariate.labels = - specify the names of your covariates (or independent) variables\n\ntype = - specify whether you want ‘html’ (use when knitting to HTML), ‘latex’ (use when knitting to PDF), or ‘text’ (use when knitting to Word)\n\ndigits = - specify rounding (remember APA standard is, in most cases, 2 decimal places)\n\nintercept.bottom = - specify if you want the intercept (or ‘constant’) value to be printed at the bottom (TRUE) or top (FALSE) of the output\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nYour table will only render once you have knitted your document. Within your code chunk options, you may need to specify results = 'asis'.\nYou can learn more about updating your code chunk options here, and you should end up with the below:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Solution \n\n\nstargazer(wb_mdl0, wb_mdl1,\n          title=\"Regression Model Results for RQ1\",\n          dep.var.labels=c(\"Wellbeing Score\"),\n          covariate.labels=c(\"Intercept\", \"Number of Social Interactions\"), \n          type = \"html\", \n          digits = 2,\n          single.row=TRUE, \n          align=TRUE,\n          intercept.bottom = FALSE)\n\n\n\nRegression Model Results for RQ1\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\nWellbeing Score\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n\n\n\n\n\n\nIntercept\n\n\n36.29*** (0.38)\n\n\n32.41*** (1.18)\n\n\n\n\nNumber of Social Interactions\n\n\n\n\n0.32*** (0.09)\n\n\n\n\n\n\n\n\nObservations\n\n\n200\n\n\n200\n\n\n\n\nR2\n\n\n0.00\n\n\n0.06\n\n\n\n\nAdjusted R2\n\n\n0.00\n\n\n0.05\n\n\n\n\nResidual Std. Error\n\n\n5.39 (df = 199)\n\n\n5.25 (df = 198)\n\n\n\n\nF Statistic\n\n\n\n\n12.15*** (df = 1; 198)\n\n\n\n\n\n\n\n\nNote:\n\n\np<0.1; p<0.05; p<0.01\n\n\n\n\n\n\n\n\nQuestion 5\n\n\nIs there a main effect of the number of weekly social interactions?\nCheck that the \\(F\\)-statistic and the \\(p\\)-value are the the same as that which is given at the bottom of summary(wb_mdl1).\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the anova() function to perform a model comparison between your model with social interactions (wb_mdl1) to the null model (wb_mdl0).\nRemember that the null model tests the null hypothesis that all beta coefficients are zero. By comparing wb_mdl0 to wb_mdl1, we can test whether we should include the IV of social_int.\n\n\n\n\n\n\n\n Solution \n\n\n\n# model comparison wb_mdl0 vs wb_mdl1\nanova(wb_mdl0, wb_mdl1)\n\nAnalysis of Variance Table\n\nModel 1: wellbeing ~ 1\nModel 2: wellbeing ~ social_int\n  Res.Df    RSS Df Sum of Sq     F    Pr(>F)    \n1    199 5785.6                                 \n2    198 5451.1  1    334.49 12.15 0.0006045 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# extract f statistic from summary of wb_mdl1\nsummary(wb_mdl1)$fstatistic\n\n    value     numdf     dendf \n 12.14975   1.00000 198.00000 \n\n# we can retrieve the p-value:\nfstat = summary(wb_mdl1)$fstatistic[1]\ndf_1 = summary(wb_mdl1)$fstatistic[2]\ndf_2 = summary(wb_mdl1)$fstatistic[3]\npf(fstat, df_1, df_2, lower.tail = FALSE)\n\n       value \n0.0006045334 \n\n\n\n\n\n\n\n\nThe number of social interactions was found to explain a significant amount of variance in wellbeing scores (\\(F\\)(1 )=12.15, \\(p\\)<.001). There was a main effect of social interactions.\n\n\n\n\n\n\n\n\nQuestion 6\n\n\nDoes the association between number of social interactions and wellbeing differ between rural and non-rural residents?\nProvide key model results from the two models in a single formatted table, and report the results of the model comparison in APA format.\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo address RQ2, you need to compare “wb_mdl2” and “wb_mdl3”\n\n\n\n\n\n\n\n Solution \n\n\nstargazer(wb_mdl2, wb_mdl3,\n          title=\"Regression Model Results for RQ2\",\n          dep.var.labels=c(\"Wellbeing Score\"),\n          covariate.labels=c(\"Intercept\", \"Number of Social Interactions\", \"Location - Rural\", \"Number of Social Interactions * Location - Rural\"), \n          type = \"html\", \n          digits = 2,\n          single.row=TRUE, \n          align=TRUE,\n          intercept.bottom = FALSE)\n\n\n\nRegression Model Results for RQ2\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\nWellbeing Score\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n\n\n\n\n\n\nIntercept\n\n\n34.12*** (1.07)\n\n\n31.00*** (1.43)\n\n\n\n\nNumber of Social Interactions\n\n\n0.38*** (0.08)\n\n\n0.65*** (0.12)\n\n\n\n\nLocation - Rural\n\n\n-4.85*** (0.66)\n\n\n1.39 (2.05)\n\n\n\n\nNumber of Social Interactions * Location - Rural\n\n\n\n\n-0.52*** (0.16)\n\n\n\n\n\n\n\n\nObservations\n\n\n200\n\n\n200\n\n\n\n\nR2\n\n\n0.26\n\n\n0.30\n\n\n\n\nAdjusted R2\n\n\n0.25\n\n\n0.29\n\n\n\n\nResidual Std. Error\n\n\n4.66 (df = 197)\n\n\n4.56 (df = 196)\n\n\n\n\nF Statistic\n\n\n34.47*** (df = 2; 197)\n\n\n27.49*** (df = 3; 196)\n\n\n\n\n\n\n\n\nNote:\n\n\np<0.1; p<0.05; p<0.01\n\n\n\n\n# model comparison wb_mdl0 vs wb_mdl1\nanova(wb_mdl2, wb_mdl3)\n\nAnalysis of Variance Table\n\nModel 1: wellbeing ~ social_int + isRural\nModel 2: wellbeing ~ social_int * isRural\n  Res.Df    RSS Df Sum of Sq      F   Pr(>F)   \n1    197 4285.6                                \n2    196 4072.1  1    213.49 10.276 0.001574 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nThere was a significant interaction between the number of social interactions and location (rural vs non-rural) (\\(F\\)(1 )=10.28, \\(p\\)<.001). This suggested that the association between number of social interactions and wellbeing did differ between rural and non-rural residents.\n\n\n\n\n\n\n\n\nQuestion 7\n\n\nLook at the amount of variation in wellbeing scores explained by models “wb_mdl3” and “wb_mdl4”.\nFrom this, can we answer the third research question of whether weekly outdoor time explains a significant amount of variance in wellbeing scores over and above the interaction between weekly social interactions and location (rural vs not-rural)?\nProvide justification/rationale for your answer.\n\n\n\n\n\n\nHint\n\n\n\n\n\nRecall from Semester 1 that to determine how much variation is explained by a model, we need to look at our \\(R^2\\) values (specifically the adjusted \\(R^2\\) value in this case since the models have multiple predictors.\n\n\n\n\n\n\n\n Solution \n\n\nLet’s look at the amount of variance explained by each model:\n\nsummary(wb_mdl3)$adj.r.squared\n\n[1] 0.2853841\n\nsummary(wb_mdl4)$adj.r.squared\n\n[1] 0.3369022\n\n\nThe model with weekly outdoor time as a predictor explains 34% of the variance, and the model without explains 29%. But, from only looking at the proportion of variance accounted for in each model, we cannot determine which model is statistically a better fit. To answer the question ‘Does including weekly outdoor time as a predictor provide a significantly better fit of the data?’ we need to statistically compare wb_mdl3 to wb_mdl4.\n\n\n\n\n\nQuestion 8\n\n\nDoes weekly outdoor time explain a significant amount of variance in wellbeing scores over and above the interaction between weekly social interactions and location (rural vs not-rural)?\nProvide key model results from the two models in a single formatted table, and report the results of the model comparison in APA format.\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo address RQ3, you need to compare “wb_mdl3” and “wb_mdl4”\n\n\n\n\n\n\n\n Solution \n\n\nstargazer(wb_mdl3, wb_mdl4,\n          title=\"Regression Model Results for RQ3\",\n          dep.var.labels=c(\"Wellbeing Score\"),\n          covariate.labels=c(\"Intercept\", \"Number of Social Interactions\", \"Location - Rural\", \"Outdoor Time (Hours)\", \"Number of Social Interactions * Location - Rural\"), \n          type = \"html\", \n          digits = 2,\n          single.row=TRUE, \n          align=TRUE,\n          intercept.bottom = FALSE)\n\n\n\nRegression Model Results for RQ3\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\nWellbeing Score\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n\n\n\n\n\n\nIntercept\n\n\n31.00*** (1.43)\n\n\n27.61*** (1.61)\n\n\n\n\nNumber of Social Interactions\n\n\n0.65*** (0.12)\n\n\n0.65*** (0.11)\n\n\n\n\nLocation - Rural\n\n\n1.39 (2.05)\n\n\n1.47 (1.98)\n\n\n\n\nOutdoor Time (Hours)\n\n\n\n\n0.18*** (0.04)\n\n\n\n\nNumber of Social Interactions * Location - Rural\n\n\n-0.52*** (0.16)\n\n\n-0.51*** (0.16)\n\n\n\n\n\n\n\n\nObservations\n\n\n200\n\n\n200\n\n\n\n\nR2\n\n\n0.30\n\n\n0.35\n\n\n\n\nAdjusted R2\n\n\n0.29\n\n\n0.34\n\n\n\n\nResidual Std. Error\n\n\n4.56 (df = 196)\n\n\n4.39 (df = 195)\n\n\n\n\nF Statistic\n\n\n27.49*** (df = 3; 196)\n\n\n26.28*** (df = 4; 195)\n\n\n\n\n\n\n\n\nNote:\n\n\np<0.1; p<0.05; p<0.01\n\n\n\n\nanova(wb_mdl3, wb_mdl4)\n\nAnalysis of Variance Table\n\nModel 1: wellbeing ~ social_int * isRural\nModel 2: wellbeing ~ social_int * isRural + outdoor_time\n  Res.Df    RSS Df Sum of Sq      F    Pr(>F)    \n1    196 4072.1                                  \n2    195 3759.3  1    312.85 16.228 8.043e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nWeekly outdoor time was found to explain a significant amount of variance in wellbeing scores over and above weekly social interactions and location (\\(F\\)(1 )=16.23, \\(p\\)<.001).\n\n\n\n\n\n\n\n\nQuestion 9\n\n\nCompare the two following models, each looking at the associations of Wellbeing scores and two different predictor variables.\n\\(\\text{Wellbeing} = \\beta_0 + \\beta_1 \\cdot \\text{Social Interactions} + \\beta_2 \\cdot \\text{Age} + \\epsilon\\)\n\\(\\text{Wellbeing} = \\beta_0 + \\beta_1 \\cdot \\text{Outdoor Time} + \\beta_2 \\cdot \\text{Routine} + \\epsilon\\)\nIn APA format, report which model you think best fits the data.\n\n\n\n\n\n\nHint\n\n\n\n\n\nCompare using AIC() and BIC() since the models are non-nested.\n\n\n\n\n\n\n\n Solution \n\n\n\n#fit models\nwb_socint_age <- lm(wellbeing ~ social_int + age, data = wrdata)\nwb_outdoor_routine <- lm(wellbeing ~ outdoor_time + routine, data = wrdata)\n\n\n#AIC values\nAIC(wb_socint_age, wb_outdoor_routine)\n\n                   df      AIC\nwb_socint_age       4 1236.575\nwb_outdoor_routine  4 1220.914\n\n#BIC values\nBIC(wb_socint_age, wb_outdoor_routine)\n\n                   df      BIC\nwb_socint_age       4 1249.769\nwb_outdoor_routine  4 1234.108\n\n\n\n\n\n\n\n\nWe used AIC and BIC model selection to distinguish between two possible models describing the association between several personal factors and wellbeing scores. The model with outdoor time and routine included as predictors was better fitting (AIC = 1220.91) the alternative model with weekly number of social interactions and age (AIC = 1236.58). Based on the BIC value of the former model (BIC = 1234.11) we concluded that it was substantively better fitting than the alternative, latter model (BIC = 1249.77).\n\n\n\n\n\n\n\n\nQuestion 10\n\n\nThe code below fits 5 different models based on our wrdata:\n\nmodel1 <- lm(wellbeing ~ social_int + outdoor_time, data = wrdata)\nmodel2 <- lm(wellbeing ~ social_int + outdoor_time + age, data = wrdata)\nmodel3 <- lm(wellbeing ~ social_int + outdoor_time + routine, data = wrdata)\nmodel4 <- lm(wellbeing ~ social_int + outdoor_time + routine + age, data = wrdata)\nmodel5 <- lm(wellbeing ~ social_int + outdoor_time + routine + steps_k, data = wrdata)\n\nFor each of the below pairs of models, what methods are/are not available for us to use for comparison and why?\n\n\nmodel1 vs model2\n\n\nmodel2 vs model3\n\n\nmodel1 vs model4\n\n\nmodel3 vs model5\n\n\nThis flowchart might help you to reach your decision:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou may need to examine the dataset, and check for accuracy (e.g., are there any impossible / out of range values?) and completeness (e.g., are there any missing values?).\n\n\n\n\n\n\n\n Solution \n\n\n\nmodel1 vs model2\nThese models are nested - model2 contains all the variables of model1 and they are fitted on the same dataset.\nWe can therefore use an \\(F\\)-test or AIC and BIC.\nmodel2 vs model3\nThese models are not nested, but they are fitted on the same dataset.\nWe can therefore use AIC or BIC, but we cannot use an \\(F\\)-test.\nmodel1 vs model4 These models are nested - model4 contains all the variables of model1 and they are fitted on the same dataset.\nWe can therefore use an \\(F\\)-test or AIC and BIC.\nmodel3 vs model5\nThese models are not nested, and they are not fitted on the same dataset. The “steps_k” variable contains missing values (over 30% of the data is missing for this variable), and so these whole rows are excluded from model5 (but they are included in model3). We cannot compare these models."
  },
  {
    "objectID": "2_02_effects.html",
    "href": "2_02_effects.html",
    "title": "Effects Coding",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand how to specify dummy and sum-to-zero coding\nInterpret the output from a model using dummy coding\nInterpret the output from a model using sum-to-zero coding\n\n\nBe up to date with lectures\nHave completed previous lab exercises from Week 1\n\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\nkableExtra\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/RestaurantSpending.csv"
  },
  {
    "objectID": "2_02_effects.html#dummy-coding",
    "href": "2_02_effects.html#dummy-coding",
    "title": "Effects Coding",
    "section": "Dummy Coding",
    "text": "Dummy Coding\n\nQuestion 3\n\n\nUsing dummy coding, choose an appropriate reference level to address the research question, and then formally state a linear model to investigate whether there are differences in restaurant spending based on background music conditions.\nDescribe and schematically represent the coding matrix used in the above model.\n\n\n\n\n\n\nHint\n\n\n\n\n\nWhen you reorder the levels, you should end up with the following coding of group means if you choose ‘none’ as your reference group:\n\n\n\\(\\mu_1\\) = mean of no music group\n\n\\(\\mu_2\\) = mean of pop music group\n\n\\(\\mu_3\\) = mean of classical music group\n\nWhen schematically representing the coding scheme, you should produce a matrix/table of 0s and 1s.\n\n\n\n\n\n\n\n Solution \n\n\nIt makes sense to have no music as our reference level, since both other groups involve some type of music playing:\n\n#set 'None' music type condition as our reference group. \nrest_spend$music <- fct_relevel(rest_spend$music , \"None\")\n\n#check the levels of the variable\nlevels(rest_spend$music)\n\n[1] \"None\"      \"Pop\"       \"Classical\"\n\n\nSpecify our model:\n\\[\n\\text{Restaurant Spending} = \\beta_0 + \\beta_1 \\cdot \\text{Music(Pop)} + \\beta_2 \\cdot \\text{Music(Classical)} + \\epsilon\n\\]\nIn words:\n\\[\n\\text{IsPopMusic} = \\begin{cases}\n1 & \\text{if observation is from the Pop Music category} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\]\n\\[\n\\text{IsClassicalMusic} = \\begin{cases}\n1 & \\text{if observation is from the Classical Music category} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\]\nSchematically:\n\\[\n\\begin{matrix}\n\\textbf{Level}  & \\textbf{IsPopMusic} & \\textbf{IsClassicalMusic} \\\\\n\\hline\n\\text{None}       & 0   & 0   \\\\\n\\text{Pop}            & 1   & 0   \\\\\n\\text{Clasical}             & 0   & 1\n\\end{matrix}\n\\]\n\n\n\n\n\nQuestion 4\n\n\nFit the specified model, and assign it the name “mdl_rg” (for reference group constraint).\nInterpret your coefficients in the context of the study.\n\n\n\n\n\n\nHint\n\n\n\n\n\nUnder the constraint \\(\\beta_1 = 0\\), meaning that the first factor level is the reference group,\n\n\n\\(\\beta_0\\) is interpreted as \\(\\mu_1\\), the mean response for the reference group (group 1);\n\n\\(\\beta_i\\) is interpreted as the difference between the mean response for group \\(i\\) and the reference group.\n\n\n\n\n\n\n\n\n Solution \n\n\n\n#fit model\nmdl_rg <- lm(amount ~ music, data = rest_spend)\n\n#check output\nsummary(mdl_rg)\n\n\nCall:\nlm(formula = amount ~ music, data = rest_spend)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-8.433 -1.886  0.127  1.755 11.285 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     22.1414     0.2593  85.373  < 2e-16 ***\nmusicPop        -0.2424     0.3668  -0.661    0.509    \nmusicClassical   2.0328     0.3668   5.542 5.81e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.841 on 357 degrees of freedom\nMultiple R-squared:  0.1151,    Adjusted R-squared:  0.1101 \nF-statistic: 23.21 on 2 and 357 DF,  p-value: 3.335e-10\n\n\nThe interpretation is as follows:\n\n\n\n\n\n\n\nCoefficient\nEstimate\nCorresponds to\n\n\n\n(Intercept)\n22.1414\n\\(\\hat \\beta_0 = \\hat \\mu_1\\)\n\n\nmusicPop\n-0.2424\n\\(\\hat \\beta_2 = \\hat \\mu_2 - \\hat \\beta_0 = \\hat \\mu_2 - \\hat \\mu_1\\)\n\n\nmusicClassical\n2.0328\n\\(\\hat \\beta_3 = \\hat \\mu_3 - \\hat \\beta_0 = \\hat \\mu_3 - \\hat \\mu_1\\)\n\n\n\nThe estimate corresponding to (Intercept) contains \\(\\hat \\beta_0 = \\hat \\mu_1 = 22.1414\\). The estimated average spending for those having no music playing in the background is approximately £22.14.\nThe next estimate corresponds to musicPop and is \\(\\hat \\beta_2 = -0.2424\\). The difference in mean spending between None and Pop is estimated to be \\(-0.2424\\). In other words, people with pop music playing in the background seem to spend approximately £0.24 less than those who have no music playing in the background.\nThe estimate corresponding to musicClassical is \\(\\hat \\beta_3 = 2.0328\\). This is the estimated difference in mean spending between None and Classical. People with classical music background in the background seem to spend approximately £2.03 more than those who have no music playing in the background.\nHence, for all levels except the reference group we see differences to the reference group while the estimate of the reference level can be found next to (Intercept).\nIt is also important to notice how the coefficients’ names are written. They are a combination of factor name and level name, such as musicPop. The only coefficient that is missing is musicNone, the one corresponding to the reference category None.\n\n\n\n\n\nQuestion 5\n\n\nIdentify the relevant pieces of information from the commands anova(mdl_rg) and summary(mdl_rg) that can be used to conduct an ANOVA \\(F\\)-test against the null hypothesis that all population means are equal.\nInterpret the \\(F\\)-test results in the context of the ANOVA null hypothesis, and present this output in an APA formatted table.\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo create a table, you can use the kable() function from the kableExtra package here, just like you do for tables of descriptive statistics. Note that we need to list how many digits we want our values to be rounded to in our table: + Degrees of freedom are whole numbers, so 1 will suffice + for all others, we want 2 (in line with APA, but to avoid a \\(p\\)-value of zero, specify 10\n\n\n\n\n\n\n\n Solution \n\n\n\n#examine summary\nsummary(mdl_rg)\n\n\nCall:\nlm(formula = amount ~ music, data = rest_spend)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-8.433 -1.886  0.127  1.755 11.285 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     22.1414     0.2593  85.373  < 2e-16 ***\nmusicPop        -0.2424     0.3668  -0.661    0.509    \nmusicClassical   2.0328     0.3668   5.542 5.81e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.841 on 357 degrees of freedom\nMultiple R-squared:  0.1151,    Adjusted R-squared:  0.1101 \nF-statistic: 23.21 on 2 and 357 DF,  p-value: 3.335e-10\n\n#run anova\nanova(mdl_rg)\n\nAnalysis of Variance Table\n\nResponse: amount\n           Df Sum Sq Mean Sq F value    Pr(>F)    \nmusic       2  374.7 187.348  23.211 3.335e-10 ***\nResiduals 357 2881.5   8.071                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe model summary returns the \\(F\\)-test of model utility which, in this case, corresponds to the ANOVA \\(F\\)-test against the null hypothesis of equal population means.\nThe relevant line from summary() is:\nF-statistic: 23.21 on 2 and 357 DF,  p-value: 3.335e-10\nThe relevant parts from anova() are:\n\n\nF value of 23.211\n\nThe Df column giving 2 and 357 degrees of freedom\nThe p-value of the test, reported under Pr(>F) as 3.335e-10 ***.\n\nWe can create a nice table of our anova results:\n\nanova(mdl_rg) %>%\n    kable(caption = \"Analysis of Variance Table\", digits = c(1, 2, 2, 2, 10)) %>%\n    kable_styling()\n\n\n\n\nTable 2:  Analysis of Variance Table \n \n   \n    Df \n    Sum Sq \n    Mean Sq \n    F value \n    Pr(>F) \n  \n\n\n music \n    2 \n    374.7 \n    187.35 \n    23.21 \n    3e-10 \n  \n\n Residuals \n    357 \n    2881.5 \n    8.07 \n    NA \n    NA \n  \n\n\n\n\n\nWe can write this up as follows:\n\n\n\n\n\n\nWe performed an analysis of variance against the null hypothesis of equal population mean spending across three types of background music, \\(F(2, 357) = 23.21\\), \\(p < .001\\).\nThe large observed \\(F\\)-statistic led to a very small p-value, meaning that such a large observed variability among the mean restaurant spending across the different music types, compared to the variability in the residuals, is very unlikely to happen by chance alone if the population means where all the same (see Table 2).\nFor this reason, at the 5% significance level, we reject the null hypothesis as there is strong evidence that at least two population means differ.\n\n\n\n\n\n\n\n\nQuestion 6\n\n\nObtain the estimated (or predicted) group means for the “None,” “Pop,” and “Classical” background music conditions by using the predict() function.\n\n\n\n\n\n\nHint\n\n\n\n\n\nStep 1: Define a data frame with a column having the same name as the factor in the fitted model (i.e., music). Then, specify all the groups (= levels) for which you would like the predicted mean.\nStep 2: Pass the data frame to the predict function using the newdata = argument. The predict() function will match the column named type with the predictor called type in the fitted model ‘mdl_rg’.\nSee Semester 1 Lab 3 Q8 for a worked example.\n\n\n\n\n\n\n\n Solution \n\n\nStep 1:\n\nquery_groups <- tibble(music = c(\"None\", \"Pop\", \"Classical\"))\nquery_groups\n\n# A tibble: 3 × 1\n  music    \n  <chr>    \n1 None     \n2 Pop      \n3 Classical\n\n\nStep 2:\n\npredict(mdl_rg, newdata = query_groups)\n\n       1        2        3 \n22.14139 21.89894 24.17414 \n\n\n\nPredicted mean of “None” = \\(\\hat \\mu_\\text{None}\\) = 22.1414\nPredicted mean of “Pop” = \\(\\hat \\mu_\\text{Pop}\\) = 22.1414 - 0.2424 = 21.899\nPredicted mean of “Classical” = \\(\\hat \\mu_\\text{Classical}\\) = 22.1414 + 2.0328 = 24.1742"
  },
  {
    "objectID": "2_02_effects.html#sum-to-zero-coding",
    "href": "2_02_effects.html#sum-to-zero-coding",
    "title": "Effects Coding",
    "section": "Sum to Zero Coding",
    "text": "Sum to Zero Coding\n\nQuestion 7\n\n\nUsing sum-to-zero coding, formally state a linear model to investigate whether there are differences in restaurant spending based on background music conditions.\nDescribe and schematically represent the coding matrix used in the above model.\n\n\n\n\n\n\nHint\n\n\n\n\n\nWhen schematically representing the coding scheme, you should produce a matrix/table of 0s and 1s.\n\n\n\n\n\n\n\n Solution \n\n\nSpecify our model:\n\\[\n\\text{Restaurant Spending} = \\beta_0 + \\beta_1 \\cdot \\text{EffectLevel1} + \\beta_2 \\cdot \\text{EffectLevel2} + \\epsilon\n\\]\nIn words:\n\\[\n\\text{EffectLevel1} = \\begin{cases}\n1  & \\text{if observation is from category 1} \\\\\n0  & \\text{if observation is from category 2} \\\\\n-1 & \\text{otherwise}\n\\end{cases}\n\\]\n\\[\n\\text{EffectLevel2} = \\begin{cases}\n0  & \\text{if observation is from category 1} \\\\\n1  & \\text{if observation is from category 2} \\\\\n-1 & \\text{otherwise}\n\\end{cases}\n\\]\nSchematically:\n\\[\n\\begin{matrix}\n\\textbf{Level}           & \\textbf{EffectLevel1} & \\textbf{EffectLevel2} \\\\\n\\hline\n\\text{None}              & 1   & 0    \\\\\n\\text{Pop}               & 0   & 1    \\\\\n\\text{Classical}         & -1  & -1\n\\end{matrix}\n\\]\n\n\n\n\n\nQuestion 8\n\n\nSet the sum to zero constraint for the factor of background music.\nFit again the linear model, and assign the model the name ‘mdl_stz’.\n\n\n\n\n\n\nHint\n\n\n\n\n\nWe can switch between side-constraints using the following code:\n\n#use dummy coding\ncontrasts(rest_spend$music) <- \"contr.treatment\"\n\n#use sum-to-zero coding\ncontrasts(rest_spend$music) <- \"contr.sum\"\n\n\n\n\n\n\n\n\n Solution \n\n\n\ncontrasts(rest_spend$music) <- \"contr.sum\"\n\n#check coding matches our table above:\ncontrasts(rest_spend$music)\n\n          [,1] [,2]\nNone         1    0\nPop          0    1\nClassical   -1   -1\n\n\n\nmdl_stz <- lm(amount ~ music, data = rest_spend)\nsummary(mdl_stz)\n\n\nCall:\nlm(formula = amount ~ music, data = rest_spend)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-8.433 -1.886  0.127  1.755 11.285 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  22.7382     0.1497 151.856  < 2e-16 ***\nmusic1       -0.5968     0.2118  -2.818   0.0051 ** \nmusic2       -0.8392     0.2118  -3.963 8.94e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.841 on 357 degrees of freedom\nMultiple R-squared:  0.1151,    Adjusted R-squared:  0.1101 \nF-statistic: 23.21 on 2 and 357 DF,  p-value: 3.335e-10\n\n\n\n\n\n\n\nQuestion 9\n\n\nInterpret your coefficients in the context of the study.\n\n\n\n\n\n\nHint\n\n\n\n\n\nRecall that under this constraint the interpretation of the coefficients becomes:\n\n\n\\(\\beta_0\\) represents the grand mean\n\n\\(\\beta_i\\) the effect due to group \\(i\\) — that is, the mean response in group \\(i\\) minus the grand mean\n\n\n\n\n\n\n\n\n Solution \n\n\nThe interpretation is as follows:\n\n\n\n\n\n\n\nCoefficient\nEstimate\nCorresponds to\n\n\n\n(Intercept)\n22.7382\n\\(\\beta_0 = \\frac{\\mu_1 + \\mu_2 + \\mu_3}{3} = \\mu\\)\n\n\nmusic1\n-0.5968\n\\(\\beta_1 = \\mu_1 - \\mu\\)\n\n\nmusic2\n-0.8392\n\\(\\beta_2 = \\mu_2 - \\mu\\)\n\n\n\nThe estimate corresponding to (Intercept) contains \\(\\beta_0 = \\mu = 22.7382\\). This value represents the grand mean of the data. The estimated average spending for customers across background music conditions is approximately £22.74.\nThe next estimate corresponds to music1 and is \\(\\hat \\beta_1 = -0.5968\\). The difference in mean spending between None and the grand mean is estimated to be \\(-0.5968\\). In other words, people with no music playing in the background seem to spend approximately £0.60 less than average.\nThe estimate corresponding to music2 is \\(\\hat \\beta_2 = -0.8392\\). The difference in mean spending between Pop and the grand mean is estimated to be \\(-0.8392\\). In other words, customers with Pop music playing in the background seem to spend approximately £0.84 less than average.\nThe estimate for music3, representing the difference of “Classical” to the grand mean is not shown by summary(). Because of the side-constraint, we know it must be \\(\\beta_3 = -(\\beta_1 + \\beta_2)\\). The difference in mean spending between Classical and the grand mean is estimated to be \\(-(-0.5968 + -0.8392) = 1.436\\). In other words, customers with Classical music playing in the background seem to spend approximately £1.44 more than average."
  },
  {
    "objectID": "2_02_effects.html#comparing-approaches",
    "href": "2_02_effects.html#comparing-approaches",
    "title": "Effects Coding",
    "section": "Comparing Approaches",
    "text": "Comparing Approaches\n\nQuestion 10\n\n\nCompare the the predicted group means across both contrast approaches - do they match?\nIs the model utility \\(F\\)-test still the same across both approaches? Why do you think it’s the case?\n\n\n\n\n Solution \n\n\n\n#note that the below two models and dataset have already been created above, so you can jump straight to adding the predicted values from the two models if you'd prefer \n\n#model with dummy coding\ncontrasts(rest_spend$music) <- contr.treatment\nmdl_rg <- lm(amount ~ music, data = rest_spend)\n\n# model with sum-to-zero coding\ncontrasts(rest_spend$music) <- contr.sum\nmdl_stz <- lm(amount ~ music, data = rest_spend)\n\n#create dataset\nmusic_groups <- tibble(music = c(\"None\", \"Pop\", \"Classical\"))\nmusic_groups\n\n# A tibble: 3 × 1\n  music    \n  <chr>    \n1 None     \n2 Pop      \n3 Classical\n\n#add predicted values from our two models - mdl_rg & mdl_stz - values are the same\nmusic_groups %>%\n  mutate(\n    pred_dummy = predict(mdl_rg, newdata = .),\n    pred_sum_to_zero = predict(mdl_stz, newdata = .)\n  )\n\n# A tibble: 3 × 3\n  music     pred_dummy pred_sum_to_zero\n  <chr>          <dbl>            <dbl>\n1 None            22.1             22.1\n2 Pop             21.9             21.9\n3 Classical       24.2             24.2\n\n\n\n#compare anova() outputs - values are the same\nanova(mdl_rg)\n\nAnalysis of Variance Table\n\nResponse: amount\n           Df Sum Sq Mean Sq F value    Pr(>F)    \nmusic       2  374.7 187.348  23.211 3.335e-10 ***\nResiduals 357 2881.5   8.071                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nanova(mdl_stz)\n\nAnalysis of Variance Table\n\nResponse: amount\n           Df Sum Sq Mean Sq F value    Pr(>F)    \nmusic       2  374.7 187.348  23.211 3.335e-10 ***\nResiduals 357 2881.5   8.071                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nYes, the values from both the dummy coding and sum-to-zero approaches give the same values. This is because, regardless of the coding matrix scheme we use to compare groups, we are still modelling the same group means from our data set. Thus, neither the predicted means nor the model utility \\(F\\)-test depend on the side-constraint that we employ. However, the side-constraint affects the meaning of the parameters in the model."
  },
  {
    "objectID": "2_03_contrasts.html",
    "href": "2_03_contrasts.html",
    "title": "Contrasts",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand how to specify contracts to test specific effects.\nUnderstand different types of study design.\n\n\nBe up to date with lectures\nHave completed previous lab exercises from Week 1 and Week 2\n\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\nkableExtra\nemmeans\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/caffeinedrink.csv"
  },
  {
    "objectID": "2_03_contrasts.html#study-design",
    "href": "2_03_contrasts.html#study-design",
    "title": "Contrasts",
    "section": "Study Design",
    "text": "Study Design\nFor each of the below experiment descriptions, note (1) the design, (2) number of variables of interest, (3) levels of categorical variables, (4) what you think the reference group should be and why.\n\nQuestion 8\n\n\nA group of researchers were interested in whether sleep deprivation influenced reaction time. They hypothesised that sleep deprived individuals would have slower reaction times than non-sleep deprived individuals.\nTo test this, they recruited 60 participants who were matched on a number of demographic variables including age and sex. One member of each pair (e.g., female aged 18) was placed into a different sleep condition - ‘Sleep Deprived’ (4 hours per night) or ‘Non-Sleep Deprived’ (8 hours per night).\n\n\n\n\n Solution \n\n\n\nDesign = Between-person: Matched pairs\nNo of variables of interest = 2 - Sleep Condition and Reaction Time\nLevels of variables = Sleep Condition has 2 levels - Sleep Deprived and Non-Sleep Deprived; Reaction Time is a continuous measure, so has no associated levels\nReference Groups = Sleep Condition - Non-Sleep Deprived because the RQ stated that the researchers were interested in how the sleep deprived group differed from the non-sleep deprived group.\n\n\n\n\n\n\nQuestion 9\n\n\nA group of researchers were interested in replicating an experiment testing the Stroop Effect.\nThey recruited 50 participants who took part in Task A (word colour and meaning are congruent) and Task B (word colour and meaning are incongruent) where they were asked to name the color of the ink instead of reading the word. The order of presentation was counterbalanced across participants. The researchers hypothesised that participants would take significantly more time (‘response time’ measured in seconds) to complete Task B than Task A.\nYou can test yourself here for fun: Stroop Task\n\n\n\n\n Solution \n\n\n\nDesign = Within-person: repeated measures\nNo of variables of interest = 2 - Task and Response Time\nLevels of variables = Task has 2 levels - A and B; Response Time is a continuous measure, so has no associated levels\nReference Groups = Task - A because the RQ stated that the researchers were interested in how response time in Task B differed from the response time in Task A.\n\n\n\n\n\n\nQuestion 10\n\n\nA group of researchers wanted to test a hypothesised theory according to which patients with amnesia will have a deficit in explicit memory but not implicit memory. Huntingtons patients, on the other hand, will display the opposite: they will have no deficit in explicit memory, but will have a deficit in implicit memory.\nTo test this, researchers designed a study that included two variables: ‘Diagnosis’ (Amnesic, Huntingtons, Control) and ‘Task’ (Grammar, Classification, Recognition) where participants were randomly assigned to a Task condition. The first two tasks (Grammar and Classification) are known to reflect implicit memory processes, whereas the Recognition task is known to reflect explicit memory processes.\n\n\n\n\n Solution \n\n\n\nDesign = Between-person: 3×3 factorial design\nNo of variables of interest = 2 - Diagnosis and Task\nLevels of variables = Diagnosis has 3 levels - Amnesic, Huntingtons, and Control; Task has 3 levels - Grammar, Classification, and Recognition\nReference Groups = Diagnosis - Control; Task - Recognition. We have chosen Control since the other two groups have some form of cognitive impairment; and the Recognition task since it measures explicit memory whilst the other two task types implicit."
  },
  {
    "objectID": "2_04_emmeans.html",
    "href": "2_04_emmeans.html",
    "title": "Simple Effects, Pairwise Comparisons, Corrections",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand how to interpret simple effects for experimental designs\nUnderstand how to conduct pairwise comparisons\nUnderstand how to apply corrections available for multiple comparisons\n\n\nBe up to date with lectures\nHave completed previous lab exercises from Week 1, Week 2, and Week 3\n\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npsych\nkableExtra\nstargazer\npatchwork\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/cognitive_experiment.csv. Note, you have already worked with some of this data before - see Semester 1 week 8 lab, but we now have a third Task condition - Classification."
  },
  {
    "objectID": "2_04_emmeans.html#factorial-anova",
    "href": "2_04_emmeans.html#factorial-anova",
    "title": "Simple Effects, Pairwise Comparisons, Corrections",
    "section": "Factorial ANOVA",
    "text": "Factorial ANOVA\n\n Cognitive Exp 3x3 Codebook\n\n\nDescription\nThe researchers designed a study yielding a \\(3 \\times 3\\) factorial design to test whether there are differences in types of memory deficits for those experiencing different cognitive impairment(s).\nThe first factor, “Diagnosis”, classifies the three types of individuals:\n\n1 denotes amnesic patients;\n2 denotes Huntingtons patients; and\n3 denotes a control group of individuals with no known neurological disorder.\n\nThe second factor, “Task”, tells us to which of two tasks each study participant was randomly assigned to:\n\n1 = grammar task, which consists of classifying letter sequences as either following or not following grammatical rules; and\n2 = recognition task, which consists of recognising particular stimuli as stimuli that have previously been presented during the task.\n3 = classification task, which consists of\n\nThe tasks chosen by the researchers have been picked to map onto the theoretical differences between the three types of research participants. The first task (grammar) is known to reflect implicit memory processes, whereas the recognition task is known to reflect explicit memory processes. If the theory is correct, we would expect the difference in scores between the recognition and grammar tasks to be relatively similar for the control and amnesiac groups, but relatively larger for the Huntingtons group compared to controls.\nPreview\nWe have data from the 45 participants (15 amnesiacs, 15 Huntington individuals, and 15 controls). Recall that study involves two factors, now with three levels each. For each combination of factor levels we have 5 observations:\nThe first ten rows of the data are:\n\n\nRows: 45 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (3): Diagnosis, Task, Y\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nAttaching package: 'kableExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\n\nWarning: Values from `Y` are not uniquely identified; output will contain list-cols.\n* Use `values_fn = list` to suppress this warning.\n* Use `values_fn = {summary_fun}` to summarise duplicates.\n* Use the following dplyr code to identify duplicates.\n  {data} %>%\n    dplyr::group_by(Diagnosis, Task) %>%\n    dplyr::summarise(n = dplyr::n(), .groups = \"drop\") %>%\n    dplyr::filter(n > 1L)\n\n\n\n\n\n\n\nTask\n\n\n Diagnosis \n    grammar \n    classification \n    recognition \n  \n\n\n\n amnesic \n    44, 63, 76, 72, 45 \n    72, 66, 55, 82, 75 \n    70, 51, 82, 66, 56 \n  \n\n huntingtons \n    24, 30, 51, 55, 40 \n    53, 59, 33, 37, 43 \n    107, 80, 98, 82, 108 \n  \n\n control \n    76, 98, 71, 70, 85 \n    92, 65, 86, 67, 90 \n    107, 80, 101, 82, 105 \n  \n\n\n\n\nThe five observations are assumed to come from a population having a specific mean. The population means corresponding to each combination of factor levels can be schematically written as:\n\\[\n\\begin{matrix}\n                   &         &         & \\textbf{Task} & \\\\\n                   &         & (j=1)\\text{ grammar} & (j=2)\\text{ classification} & (j=3)\\text{ recognition} \\\\\n                   & (i=1)\\text{ control} & \\mu_{1,1} & \\mu_{1,2} & \\mu_{1,3} \\\\\n\\textbf{Diagnosis} & (i=2)\\text{ amnesic} & \\mu_{2,1} & \\mu_{2,2} & \\mu_{2,3} \\\\\n                   & (i=3)\\text{ huntingtons} & \\mu_{3,1} & \\mu_{3,2} & \\mu_{3,3}\n\\end{matrix}\n\\]"
  },
  {
    "objectID": "2_04_emmeans.html#contrast-analysis",
    "href": "2_04_emmeans.html#contrast-analysis",
    "title": "Simple Effects, Pairwise Comparisons, Corrections",
    "section": "Contrast analysis",
    "text": "Contrast analysis\nWe will now begin by looking at each factor separately.\n\nQuestion 5\n\n\nIn terms of the diagnostic groups, we want to compare the amnesiacs to the Huntington individuals. This corresponds to a contrast with coefficients of 0, 1, and −1, for control, amnesic, and Huntingtons, respectively.\nSimilarly, in terms of the tasks, we want to compare the average of the two implicit memory tasks with the explicit memory task. This corresponds to a contrast with coefficients of 0.5, 0.5, and −1 for the three tasks.\nWhen we are in presence of a significant interaction, the coefficients for a contrast between the means are found by multiplying each row coefficient with all column coefficients as shown below:\n\n\n\n\n\nSpecify the contrast weights in R, and state the null hypothesis of your contrast analysis.\n\n\n\n\n Solution \n\n\nThis can be done in R using:\n\n\nOption 1\nOption 2\n\n\n\n\ndiag_coef  <- c('control' = 0, 'amnesic' = 1, 'huntingtons' = -1)\ntask_coef  <- c('grammar' = 0.5, 'classification' = 0.5, 'recognition' = -1)\ncontr_coef <- outer(diag_coef, task_coef)\ncontr_coef\n\n            grammar classification recognition\ncontrol         0.0            0.0           0\namnesic         0.5            0.5          -1\nhuntingtons    -0.5           -0.5           1\n\n\n\n\n\ndiag_coef  <- c('control' = 0, 'amnesic' = 1, 'huntingtons' = -1)\ntask_coef  <- c('grammar' = 0.5, 'classification' = 0.5, 'recognition' = -1)\ncontr_coef <- diag_coef %o% task_coef\ncontr_coef\n\n            grammar classification recognition\ncontrol         0.0            0.0           0\namnesic         0.5            0.5          -1\nhuntingtons    -0.5           -0.5           1\n\n\n\n\n\nThe above coefficients correspond to testing the null hypothesis\n\\[\nH_0 : \\frac{\\mu_{2,1} + \\mu_{2,2}}{2} - \\mu_{2,3} - \\left( \\frac{\\mu_{3,1} + \\mu_{3,2}}{2} - \\mu_{3,3} \\right) = 0\n\\]\nor, equivalently,\n\\[\nH_0 : \\frac{\\mu_{2,1} + \\mu_{2,2}}{2} - \\mu_{2,3} = \\frac{\\mu_{3,1} + \\mu_{3,2}}{2} - \\mu_{3,3}\n\\]\nwhich says that, in the population, the difference between the mean implicit memory and the explicit memory score is the same for amnesic patients and Huntingtons individuals. Note that the scores for the grammar and classification tasks have been averaged to obtain a single measure of ‘implicit memory’ score.\n\n\n\n\n\nQuestion 6\n\n\nRun contrast analysis, and interpret your output in the context of the research question.\n\n\n\n\n Solution \n\n\nNow that we have the coefficients, let’s firstly call the emmeans function (this is helpful to look at the ordering of the groups):\n\nemm <- emmeans(mdl_int, ~ Diagnosis*Task)\nemm\n\n Diagnosis   Task           emmean   SE df lower.CL upper.CL\n control     recognition        95 5.62 36     83.6    106.4\n amnesic     recognition        65 5.62 36     53.6     76.4\n huntingtons recognition        95 5.62 36     83.6    106.4\n control     grammar            80 5.62 36     68.6     91.4\n amnesic     grammar            60 5.62 36     48.6     71.4\n huntingtons grammar            40 5.62 36     28.6     51.4\n control     classification     80 5.62 36     68.6     91.4\n amnesic     classification     70 5.62 36     58.6     81.4\n huntingtons classification     45 5.62 36     33.6     56.4\n\nConfidence level used: 0.95 \n\n\nNext, from contr_coef, insert the coefficients following the order specified by the rows of emm above. That is, the first one should be for control recognition and have a value of 0, the second for amnesic recognition with a value of -1, and so on…\nWe also give a name to this contrast, such as ‘Research Hyp’.\n\ncomp_res <- contrast(emm, \n                     method = list('Research Hyp' = c(0, -1, 1, 0, 0.5, -0.5, 0, 0.5, -0.5))\n                     )\n\nNext, let’s look at the output via one of two ways:\n\n\nOption 1\nOption 2\n\n\n\n\ncomp_res\n\n contrast     estimate   SE df t.ratio p.value\n Research Hyp     52.5 9.73 36   5.396  <.0001\n\nconfint(comp_res)\n\n contrast     estimate   SE df lower.CL upper.CL\n Research Hyp     52.5 9.73 36     32.8     72.2\n\nConfidence level used: 0.95 \n\n\n\n\n\nsummary(comp_res, infer = TRUE)\n\n contrast     estimate   SE df lower.CL upper.CL t.ratio p.value\n Research Hyp     52.5 9.73 36     32.8     72.2   5.396  <.0001\n\nConfidence level used: 0.95 \n\n\n\n\n\n\n\n\n\n\n\nThe contrast analysis yielded a \\(t\\)-value of 5.4 and a corresponding \\(p\\)-value < .001. Thus, there is evidence that the contrast is not zero in the population. In other words, Amnesics and Huntingtons patients differ in the difference between implicit and explicit recognition memory tasks.\nThe contrast analysis shows that the 95% confidence interval for our contrast stretches from 32.8 to 72.2. This interval does not contain zero. Thus, we can be 95% confident that the task difference is not the same for amnesiacs as for Huntingtons, which is why we can reject the null hypothesis that the difference in differences is zero."
  },
  {
    "objectID": "2_04_emmeans.html#simple-effects",
    "href": "2_04_emmeans.html#simple-effects",
    "title": "Simple Effects, Pairwise Comparisons, Corrections",
    "section": "Simple Effects",
    "text": "Simple Effects\nBy considering the simple effects1, we can identify at which levels of the interacting condition we see different effects.\n\nQuestion 7\n\n\nExamine the simple effects for Task at each level of Diagnosis; and then the simple effects for Diagnosis at each level of Task.\n\n\n\n\n Solution \n\n\n\nmdl_int_simple1 <- pairs(emm, simple = \"Task\")\nmdl_int_simple1\n\nDiagnosis = control:\n contrast                     estimate   SE df t.ratio p.value\n recognition - grammar              15 7.94 36   1.888  0.1567\n recognition - classification       15 7.94 36   1.888  0.1567\n grammar - classification            0 7.94 36   0.000  1.0000\n\nDiagnosis = amnesic:\n contrast                     estimate   SE df t.ratio p.value\n recognition - grammar               5 7.94 36   0.629  0.8050\n recognition - classification       -5 7.94 36  -0.629  0.8050\n grammar - classification          -10 7.94 36  -1.259  0.4273\n\nDiagnosis = huntingtons:\n contrast                     estimate   SE df t.ratio p.value\n recognition - grammar              55 7.94 36   6.923  <.0001\n recognition - classification       50 7.94 36   6.294  <.0001\n grammar - classification           -5 7.94 36  -0.629  0.8050\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\nmdl_int_simple2 <- pairs(emm, simple = \"Diagnosis\")\nmdl_int_simple2\n\nTask = recognition:\n contrast              estimate   SE df t.ratio p.value\n control - amnesic           30 7.94 36   3.776  0.0016\n control - huntingtons        0 7.94 36   0.000  1.0000\n amnesic - huntingtons      -30 7.94 36  -3.776  0.0016\n\nTask = grammar:\n contrast              estimate   SE df t.ratio p.value\n control - amnesic           20 7.94 36   2.518  0.0424\n control - huntingtons       40 7.94 36   5.035  <.0001\n amnesic - huntingtons       20 7.94 36   2.518  0.0424\n\nTask = classification:\n contrast              estimate   SE df t.ratio p.value\n control - amnesic           10 7.94 36   1.259  0.4273\n control - huntingtons       35 7.94 36   4.406  0.0003\n amnesic - huntingtons       25 7.94 36   3.147  0.0091\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\nFrom mdl_int_simple1 we can see the differences between between tasks for each diagnosis group, and from mdl_int_simple2 the differences between diagnoses for each task group.\n\n\n\n\n\nQuestion 8\n\n\nVisualise the interaction, displaying two plots - one with Diagnosis on the x-axis, and the other with Task on the x-axis.\nConsidering the simple effects that we noted above, identify the significant effects and match them to the parts of your interaction plot.\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo visualise the interaction, you can use emmip().\nRecall that the patchwork package allows us to arrange multiple plots using either / or | or +\n\n\n\n\n\n\n\n Solution \n\n\nFirst create our plots:\n\nplt_1 <- emmip(mdl_int, Diagnosis ~ Task, CIs = TRUE)\nplt_2 <- emmip(mdl_int, Task ~ Diagnosis, CIs = TRUE)\nplt_1 / plt_2\n\n\n\n\n\nSimple Effects of Task\n\nFor the simple effects of task (see plt_1), we saw the significant differences (those for which \\(p<.05\\)):\n\nOnly in the Huntingtons group, between recognition & grammar and recognition & classification tasks (top plot: left-most blue point compared to the middle blue point, and then compared to the right-most blue point)\nSimple Effects of Diagnosis\n\nFor the simple effects of Diagnosis (see plt_2), we saw significant differences:\n\nin the recognition task, between control & amnesic\n(bottom plot: left-most red point to middle red-point)\n\nin the recognition task, between amnesic & huntingtons\n(bottom plot: middle red-point to right-most red point)\n\nin the grammar task, between control & huntingtons\n(bottom plot: left-most green point to right-most green point)\nin the classification task, between control & huntingtons\n(bottom plot: left-most blue point to right-most blue point)"
  },
  {
    "objectID": "2_04_emmeans.html#pairwise-comparisons-multiple-corrections",
    "href": "2_04_emmeans.html#pairwise-comparisons-multiple-corrections",
    "title": "Simple Effects, Pairwise Comparisons, Corrections",
    "section": "Pairwise Comparisons & Multiple Corrections",
    "text": "Pairwise Comparisons & Multiple Corrections\n\nQuestion 9\n\n\nConduct exploratory pairwise comparisons to compare all levels of Diagnosis with all levels of Task, applying no correction (note that Tukey will be automatically applied since we are comparing groups of means, so you will need to overwrite this).\nWithout adjusting our \\(\\alpha\\) (or \\(p\\)-value), why might any inferences drawn from your output be problematic?\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can specify the adjustment using adjust = \". Possible options include:\n\nadjust = \"none\"\nadjust =  \"bonferroni\"\nadjust = \"sidak\"\nadjust = \"Tukey\"\nadjust = scheffe\"\n\n\n\n\n\n\n\n\n Solution \n\n\n\npairs_res <- pairs(emm, adjust = \"none\")\npairs_res\n\n contrast                                             estimate   SE df t.ratio\n control recognition - amnesic recognition                  30 7.94 36   3.776\n control recognition - huntingtons recognition               0 7.94 36   0.000\n control recognition - control grammar                      15 7.94 36   1.888\n control recognition - amnesic grammar                      35 7.94 36   4.406\n control recognition - huntingtons grammar                  55 7.94 36   6.923\n control recognition - control classification               15 7.94 36   1.888\n control recognition - amnesic classification               25 7.94 36   3.147\n control recognition - huntingtons classification           50 7.94 36   6.294\n amnesic recognition - huntingtons recognition             -30 7.94 36  -3.776\n amnesic recognition - control grammar                     -15 7.94 36  -1.888\n amnesic recognition - amnesic grammar                       5 7.94 36   0.629\n amnesic recognition - huntingtons grammar                  25 7.94 36   3.147\n amnesic recognition - control classification              -15 7.94 36  -1.888\n amnesic recognition - amnesic classification               -5 7.94 36  -0.629\n amnesic recognition - huntingtons classification           20 7.94 36   2.518\n huntingtons recognition - control grammar                  15 7.94 36   1.888\n huntingtons recognition - amnesic grammar                  35 7.94 36   4.406\n huntingtons recognition - huntingtons grammar              55 7.94 36   6.923\n huntingtons recognition - control classification           15 7.94 36   1.888\n huntingtons recognition - amnesic classification           25 7.94 36   3.147\n huntingtons recognition - huntingtons classification       50 7.94 36   6.294\n control grammar - amnesic grammar                          20 7.94 36   2.518\n control grammar - huntingtons grammar                      40 7.94 36   5.035\n control grammar - control classification                    0 7.94 36   0.000\n control grammar - amnesic classification                   10 7.94 36   1.259\n control grammar - huntingtons classification               35 7.94 36   4.406\n amnesic grammar - huntingtons grammar                      20 7.94 36   2.518\n amnesic grammar - control classification                  -20 7.94 36  -2.518\n amnesic grammar - amnesic classification                  -10 7.94 36  -1.259\n amnesic grammar - huntingtons classification               15 7.94 36   1.888\n huntingtons grammar - control classification              -40 7.94 36  -5.035\n huntingtons grammar - amnesic classification              -30 7.94 36  -3.776\n huntingtons grammar - huntingtons classification           -5 7.94 36  -0.629\n control classification - amnesic classification            10 7.94 36   1.259\n control classification - huntingtons classification        35 7.94 36   4.406\n amnesic classification - huntingtons classification        25 7.94 36   3.147\n p.value\n  0.0006\n  1.0000\n  0.0671\n  0.0001\n  <.0001\n  0.0671\n  0.0033\n  <.0001\n  0.0006\n  0.0671\n  0.5331\n  0.0033\n  0.0671\n  0.5331\n  0.0164\n  0.0671\n  0.0001\n  <.0001\n  0.0671\n  0.0033\n  <.0001\n  0.0164\n  <.0001\n  1.0000\n  0.2162\n  0.0001\n  0.0164\n  0.0164\n  0.2162\n  0.0671\n  <.0001\n  0.0006\n  0.5331\n  0.2162\n  0.0001\n  0.0033\n\n#can also plot if you'd like:\nplot(pairs_res)\n\n\n\n\nFrom the above, we can see comparisons for all different possible pairs of diagnosis-task combinations.\nIn total, there are 9 different estimates, but comparing them all means that we have 36 comparisons being tested! By not adjusting our \\(p\\)-value, we are increasing the experimentwise Type I error rate - we could wrongly reject the null hypothesis at a much higher rate than 5/100 (or 1/20 as is assumed when \\(\\alpha = .05\\)). To overcome this, we might adjust and determine a result to be statistically significant if \\(p < .005\\), as opposed to \\(p < .05\\), depending on how many tests are in our family of tests).\n\n\n\n\n\nQuestion 10\n\n\nSelect an appropriate method to adjust for multiple comparisons, and then obtain confidence intervals.\nComment on how these \\(p\\)-values differ from your raw (i.e., unadjusted) \\(p\\)-values.\n\n\n\n\n Solution \n\n\nNote what the functions in R do is adjust the \\(p\\)-value, rather than the \\(\\alpha\\).\nSince we’re interested in all pairwise comparisons of means, the Tukey adjustment might be a sensible approach. However, we’ll also show the Bonferroni to show how it differs (note, in practice you would only apply one correction and justify this choice based on your design - we are only applying two to note how they differ!)\nLet’s start with Tukey:\n\ncontrast(emm, method = \"pairwise\", adjust=\"Tukey\")\n\n contrast                                             estimate   SE df t.ratio\n control recognition - amnesic recognition                  30 7.94 36   3.776\n control recognition - huntingtons recognition               0 7.94 36   0.000\n control recognition - control grammar                      15 7.94 36   1.888\n control recognition - amnesic grammar                      35 7.94 36   4.406\n control recognition - huntingtons grammar                  55 7.94 36   6.923\n control recognition - control classification               15 7.94 36   1.888\n control recognition - amnesic classification               25 7.94 36   3.147\n control recognition - huntingtons classification           50 7.94 36   6.294\n amnesic recognition - huntingtons recognition             -30 7.94 36  -3.776\n amnesic recognition - control grammar                     -15 7.94 36  -1.888\n amnesic recognition - amnesic grammar                       5 7.94 36   0.629\n amnesic recognition - huntingtons grammar                  25 7.94 36   3.147\n amnesic recognition - control classification              -15 7.94 36  -1.888\n amnesic recognition - amnesic classification               -5 7.94 36  -0.629\n amnesic recognition - huntingtons classification           20 7.94 36   2.518\n huntingtons recognition - control grammar                  15 7.94 36   1.888\n huntingtons recognition - amnesic grammar                  35 7.94 36   4.406\n huntingtons recognition - huntingtons grammar              55 7.94 36   6.923\n huntingtons recognition - control classification           15 7.94 36   1.888\n huntingtons recognition - amnesic classification           25 7.94 36   3.147\n huntingtons recognition - huntingtons classification       50 7.94 36   6.294\n control grammar - amnesic grammar                          20 7.94 36   2.518\n control grammar - huntingtons grammar                      40 7.94 36   5.035\n control grammar - control classification                    0 7.94 36   0.000\n control grammar - amnesic classification                   10 7.94 36   1.259\n control grammar - huntingtons classification               35 7.94 36   4.406\n amnesic grammar - huntingtons grammar                      20 7.94 36   2.518\n amnesic grammar - control classification                  -20 7.94 36  -2.518\n amnesic grammar - amnesic classification                  -10 7.94 36  -1.259\n amnesic grammar - huntingtons classification               15 7.94 36   1.888\n huntingtons grammar - control classification              -40 7.94 36  -5.035\n huntingtons grammar - amnesic classification              -30 7.94 36  -3.776\n huntingtons grammar - huntingtons classification           -5 7.94 36  -0.629\n control classification - amnesic classification            10 7.94 36   1.259\n control classification - huntingtons classification        35 7.94 36   4.406\n amnesic classification - huntingtons classification        25 7.94 36   3.147\n p.value\n  0.0149\n  1.0000\n  0.6257\n  0.0026\n  <.0001\n  0.6257\n  0.0711\n  <.0001\n  0.0149\n  0.6257\n  0.9993\n  0.0711\n  0.6257\n  0.9993\n  0.2575\n  0.6257\n  0.0026\n  <.0001\n  0.6257\n  0.0711\n  <.0001\n  0.2575\n  0.0004\n  1.0000\n  0.9367\n  0.0026\n  0.2575\n  0.2575\n  0.9367\n  0.6257\n  0.0004\n  0.0149\n  0.9993\n  0.9367\n  0.0026\n  0.0711\n\nP value adjustment: tukey method for comparing a family of 9 estimates \n\n\nNote that 8 of the comparisons are no longer significant when using Tukey’s adjustment, suggesting that these might have (when using no adjustment) been type 1 errors!\nNext, lets look at Bonferroni:\n\ncontrast(emm, method = \"pairwise\", adjust=\"bonferroni\")\n\n contrast                                             estimate   SE df t.ratio\n control recognition - amnesic recognition                  30 7.94 36   3.776\n control recognition - huntingtons recognition               0 7.94 36   0.000\n control recognition - control grammar                      15 7.94 36   1.888\n control recognition - amnesic grammar                      35 7.94 36   4.406\n control recognition - huntingtons grammar                  55 7.94 36   6.923\n control recognition - control classification               15 7.94 36   1.888\n control recognition - amnesic classification               25 7.94 36   3.147\n control recognition - huntingtons classification           50 7.94 36   6.294\n amnesic recognition - huntingtons recognition             -30 7.94 36  -3.776\n amnesic recognition - control grammar                     -15 7.94 36  -1.888\n amnesic recognition - amnesic grammar                       5 7.94 36   0.629\n amnesic recognition - huntingtons grammar                  25 7.94 36   3.147\n amnesic recognition - control classification              -15 7.94 36  -1.888\n amnesic recognition - amnesic classification               -5 7.94 36  -0.629\n amnesic recognition - huntingtons classification           20 7.94 36   2.518\n huntingtons recognition - control grammar                  15 7.94 36   1.888\n huntingtons recognition - amnesic grammar                  35 7.94 36   4.406\n huntingtons recognition - huntingtons grammar              55 7.94 36   6.923\n huntingtons recognition - control classification           15 7.94 36   1.888\n huntingtons recognition - amnesic classification           25 7.94 36   3.147\n huntingtons recognition - huntingtons classification       50 7.94 36   6.294\n control grammar - amnesic grammar                          20 7.94 36   2.518\n control grammar - huntingtons grammar                      40 7.94 36   5.035\n control grammar - control classification                    0 7.94 36   0.000\n control grammar - amnesic classification                   10 7.94 36   1.259\n control grammar - huntingtons classification               35 7.94 36   4.406\n amnesic grammar - huntingtons grammar                      20 7.94 36   2.518\n amnesic grammar - control classification                  -20 7.94 36  -2.518\n amnesic grammar - amnesic classification                  -10 7.94 36  -1.259\n amnesic grammar - huntingtons classification               15 7.94 36   1.888\n huntingtons grammar - control classification              -40 7.94 36  -5.035\n huntingtons grammar - amnesic classification              -30 7.94 36  -3.776\n huntingtons grammar - huntingtons classification           -5 7.94 36  -0.629\n control classification - amnesic classification            10 7.94 36   1.259\n control classification - huntingtons classification        35 7.94 36   4.406\n amnesic classification - huntingtons classification        25 7.94 36   3.147\n p.value\n  0.0207\n  1.0000\n  1.0000\n  0.0033\n  <.0001\n  1.0000\n  0.1190\n  <.0001\n  0.0207\n  1.0000\n  1.0000\n  0.1190\n  1.0000\n  1.0000\n  0.5907\n  1.0000\n  0.0033\n  <.0001\n  1.0000\n  0.1190\n  <.0001\n  0.5907\n  0.0005\n  1.0000\n  1.0000\n  0.0033\n  0.5907\n  0.5907\n  1.0000\n  1.0000\n  0.0005\n  0.0207\n  1.0000\n  1.0000\n  0.0033\n  0.1190\n\nP value adjustment: bonferroni method for 36 tests \n\n\nThe first Bonferroni adjusted \\(p\\)-value is 0.0207. The raw (unadjusted) \\(p\\)-value is from the previous question was 0.0005759265 The Bonferroni method simply multiplies the ‘raw’ \\(p\\)-value by the number of the tests.\n\n0.0005759265 * 36\n\n[1] 0.02073335\n\n\nIn terms of differences in Bonferroni to raw \\(p\\)-values, they are thus 36 times the size.\nOne benefit of Bonferroni is that it can be applied to any set of \\(p\\)-values, whereas Tukey only applies when comparing the means of levels of a factor. The downside, however, is that it may be overly conservative (i.e. reduce our power to detect an effect that is truly there).\nWe can actually conduct a Bonferroni adjustment if we have only a set of \\(p\\)-values:\n\n# some random p-values i just made up\np.adjust(c(.004,.033, .135, .567, .001), method = \"bonferroni\")\n\n[1] 0.020 0.165 0.675 1.000 0.005"
  },
  {
    "objectID": "2_04_emmeans.html#why-does-the-number-of-tests-matter",
    "href": "2_04_emmeans.html#why-does-the-number-of-tests-matter",
    "title": "Simple Effects, Pairwise Comparisons, Corrections",
    "section": "Why does the number of tests matter?",
    "text": "Why does the number of tests matter?\n\n refresher on making errors in hypothesis tests\n\n\nThink back to “Type 1 errors” from DAPR1 - when we conduct an hypothesis test, and we set \\(\\alpha=0.05\\), we will reject the null hypothesis \\(H_0\\) when we find a \\(p < .05\\). Now remember what a \\(p\\)-value represents - it is the chance of observing a statistic at least as extreme as the one we do have, assuming the null hypothesis to be true. This means that if \\(H_0\\) is true, then we will still observe a \\(p < .05\\) 5% of the time. So our chance of making this error = the threshold (\\(\\alpha\\)) at which below a p-value results in us rejecting \\(H_0\\).\n\n\n\nBut this error-rate applies to each statistical hypothesis we test. So if we conduct an experiment in which we plan on conducting lots of tests of different comparisons, the chance of an error being made increases substantially. Across the family of tests performed that chance will be much higher than 5%.1\nEach test conducted at \\(\\alpha = 0.05\\) has a 0.05 (or 5%) probability of Type I error (wrongly rejecting the null hypothesis). If we do 9 tests, that experimentwise error rate is \\(\\alpha_{ew} \\leq 9 \\times 0.05\\), where 9 is the number of comparisons made as part of the experiment.\nThus, if nine independent comparisons were made at the \\(\\alpha = 0.05\\) level, the experimentwise Type I error rate \\(\\alpha_{ew}\\) would be at most \\(9 \\times 0.05 = 0.45\\). That is, we could wrongly reject the null hypothesis on average 45 times out of 100. To make this more confusing, many of the tests in a family are not independent (see the lecture slides for the calculation of error rate for dependent tests).\nHere, we go through some of the different options available to us to control, or ‘correct’ for this problem."
  },
  {
    "objectID": "2_04_emmeans.html#bonferroni",
    "href": "2_04_emmeans.html#bonferroni",
    "title": "Simple Effects, Pairwise Comparisons, Corrections",
    "section": "Bonferroni",
    "text": "Bonferroni\n\nQuestion 2\n\n\nLoad the data from last week, and re-acquaint yourself with it.\nProvide a plot of the Diagnosis*Task group mean scores.\nThe data is at https://uoepsy.github.io/data/cognitive_experiment.csv.\n\n\n\n\n Solution \n\n\n\ncog <- read_csv('https://uoepsy.github.io/data/cognitive_experiment.csv')\n# head(df)\n\ncog$Diagnosis <- factor(cog$Diagnosis, \n                       labels = c(\"amnesic\", \"huntingtons\", \"control\"),\n                       ordered = FALSE)\n\ncog$Task <- factor(cog$Task, \n                  labels = c(\"grammar\", \"classification\", \"recognition\"), \n                  ordered = FALSE)\n\ncog$Diagnosis <- fct_relevel(cog$Diagnosis, \"control\")\ncog$Task <- fct_relevel(cog$Task, \"recognition\")\n\ncog <- cog %>%\n    rename(Score = Y)\n\n\n\n\n\nQuestion 3\n\n\nFit the interaction model, using lm(). Pass your model to the anova() function, to remind yourself that there is a significant interaction present.\n\n\n\n\n Solution \n\n\n\nmdl_int <- lm(Score ~ Task*Diagnosis, data = cog)\nanova(mdl_int)\n\nAnalysis of Variance Table\n\nResponse: Score\n               Df Sum Sq Mean Sq F value    Pr(>F)    \nTask            2   5250 2625.00 16.6373  7.64e-06 ***\nDiagnosis       2   5250 2625.00 16.6373  7.64e-06 ***\nTask:Diagnosis  4   5000 1250.00  7.9225 0.0001092 ***\nResiduals      36   5680  157.78                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nQuestion 4\n\n\nThere are various ways to make nice tables in RMarkdown.\nSome of the most well known are:\n\nThe knitr package has kable()\n\nThe pander package has pander()\n\n\nPick one (or find go googling and find a package you like the look of), install the package (if you don’t already have it), then try to create a nice pretty ANOVA table rather than the one given by anova(model).\n\n\n\n\n Solution \n\n\n\nlibrary(knitr)\nkable(anova(mdl_int))\n\n\n\n\n   \n    Df \n    Sum Sq \n    Mean Sq \n    F value \n    Pr(>F) \n  \n\n\n Task \n    2 \n    5250 \n    2625.0000 \n    16.637324 \n    0.0000076 \n  \n\n Diagnosis \n    2 \n    5250 \n    2625.0000 \n    16.637324 \n    0.0000076 \n  \n\n Task:Diagnosis \n    4 \n    5000 \n    1250.0000 \n    7.922535 \n    0.0001092 \n  \n\n Residuals \n    36 \n    5680 \n    157.7778 \n    NA \n    NA \n  \n\n\n\nlibrary(pander)\npander(anova(mdl_int))\n\n\nAnalysis of Variance Table\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(>F)\n\n\n\nTask\n2\n5250\n2625\n16.64\n7.64e-06\n\n\nDiagnosis\n2\n5250\n2625\n16.64\n7.64e-06\n\n\nTask:Diagnosis\n4\n5000\n1250\n7.923\n0.0001092\n\n\nResiduals\n36\n5680\n157.8\nNA\nNA\n\n\n\n\n\n\n\n\n\nQuestion 5\n\n\nAs in the previous week’s exercises, let us suppose that we are specifically interested in comparisons of the mean score across the different diagnosis groups for a given task.\nEdit the code below to obtain the pairwise comparisons of diagnosis groups for each task. Use the Bonferroni method to adjust for multiple comparisons, and then obtain confidence intervals.\n\nlibrary(emmeans)\nemm_task <- emmeans(mdl_int, ? )\ncontr_task <- contrast(emm_task, method = ?, adjust = ? )\n\n\n\n\n\n Solution \n\n\n\n#emm_task <- emmeans(mdl_int, ~ Diagnosis | Task)\n#contr_task <- contrast(emm_task, method = \"pairwise\", adjust=\"bonferroni\")\n#contr_task\n#confint(contr_task)"
  },
  {
    "objectID": "2_04_emmeans.html#šídák",
    "href": "2_04_emmeans.html#šídák",
    "title": "Simple Effects, Pairwise Comparisons, Corrections",
    "section": "Šídák",
    "text": "Šídák\n\nQuestion 7\n\n\nThe Sidak approach is slightly less conservative than the Bonferroni adjustment. Doing this with the emmeans package is easy, can you figure out how?\nHint: you just have to change the adjust argument in contrast() function.\n\n\n\n\n Solution \n\n\n\ncontrast(emm_task, method = \"pairwise\", adjust = \"sidak\")\n\nTask = recognition:\n contrast              estimate   SE df t.ratio p.value\n control - amnesic           30 7.94 36   3.776  0.0017\n control - huntingtons        0 7.94 36   0.000  1.0000\n amnesic - huntingtons      -30 7.94 36  -3.776  0.0017\n\nTask = grammar:\n contrast              estimate   SE df t.ratio p.value\n control - amnesic           20 7.94 36   2.518  0.0484\n control - huntingtons       40 7.94 36   5.035  <.0001\n amnesic - huntingtons       20 7.94 36   2.518  0.0484\n\nTask = classification:\n contrast              estimate   SE df t.ratio p.value\n control - amnesic           10 7.94 36   1.259  0.5185\n control - huntingtons       35 7.94 36   4.406  0.0003\n amnesic - huntingtons       25 7.94 36   3.147  0.0099\n\nP value adjustment: sidak method for 3 tests"
  },
  {
    "objectID": "2_04_emmeans.html#tukey",
    "href": "2_04_emmeans.html#tukey",
    "title": "Simple Effects, Pairwise Comparisons, Corrections",
    "section": "Tukey",
    "text": "Tukey\n\nQuestion 8\n\n\nLike with Šídák, in R we can easily change to Tukey. Conduct pairwise comparisons of the scores of different Diagnosis groups on different Task types (i.e., the interaction), and use the Tukey adjustment.\n\n\n\n\n Solution \n\n\n\nemm_task <- emmeans(mdl_int, ~ Diagnosis*Task)\ncontr_task <- contrast(emm_task, method = \"pairwise\", adjust=\"tukey\")\ncontr_task\n\n contrast                                             estimate   SE df t.ratio\n control recognition - amnesic recognition                  30 7.94 36   3.776\n control recognition - huntingtons recognition               0 7.94 36   0.000\n control recognition - control grammar                      15 7.94 36   1.888\n control recognition - amnesic grammar                      35 7.94 36   4.406\n control recognition - huntingtons grammar                  55 7.94 36   6.923\n control recognition - control classification               15 7.94 36   1.888\n control recognition - amnesic classification               25 7.94 36   3.147\n control recognition - huntingtons classification           50 7.94 36   6.294\n amnesic recognition - huntingtons recognition             -30 7.94 36  -3.776\n amnesic recognition - control grammar                     -15 7.94 36  -1.888\n amnesic recognition - amnesic grammar                       5 7.94 36   0.629\n amnesic recognition - huntingtons grammar                  25 7.94 36   3.147\n amnesic recognition - control classification              -15 7.94 36  -1.888\n amnesic recognition - amnesic classification               -5 7.94 36  -0.629\n amnesic recognition - huntingtons classification           20 7.94 36   2.518\n huntingtons recognition - control grammar                  15 7.94 36   1.888\n huntingtons recognition - amnesic grammar                  35 7.94 36   4.406\n huntingtons recognition - huntingtons grammar              55 7.94 36   6.923\n huntingtons recognition - control classification           15 7.94 36   1.888\n huntingtons recognition - amnesic classification           25 7.94 36   3.147\n huntingtons recognition - huntingtons classification       50 7.94 36   6.294\n control grammar - amnesic grammar                          20 7.94 36   2.518\n control grammar - huntingtons grammar                      40 7.94 36   5.035\n control grammar - control classification                    0 7.94 36   0.000\n control grammar - amnesic classification                   10 7.94 36   1.259\n control grammar - huntingtons classification               35 7.94 36   4.406\n amnesic grammar - huntingtons grammar                      20 7.94 36   2.518\n amnesic grammar - control classification                  -20 7.94 36  -2.518\n amnesic grammar - amnesic classification                  -10 7.94 36  -1.259\n amnesic grammar - huntingtons classification               15 7.94 36   1.888\n huntingtons grammar - control classification              -40 7.94 36  -5.035\n huntingtons grammar - amnesic classification              -30 7.94 36  -3.776\n huntingtons grammar - huntingtons classification           -5 7.94 36  -0.629\n control classification - amnesic classification            10 7.94 36   1.259\n control classification - huntingtons classification        35 7.94 36   4.406\n amnesic classification - huntingtons classification        25 7.94 36   3.147\n p.value\n  0.0149\n  1.0000\n  0.6257\n  0.0026\n  <.0001\n  0.6257\n  0.0711\n  <.0001\n  0.0149\n  0.6257\n  0.9993\n  0.0711\n  0.6257\n  0.9993\n  0.2575\n  0.6257\n  0.0026\n  <.0001\n  0.6257\n  0.0711\n  <.0001\n  0.2575\n  0.0004\n  1.0000\n  0.9367\n  0.0026\n  0.2575\n  0.2575\n  0.9367\n  0.6257\n  0.0004\n  0.0149\n  0.9993\n  0.9367\n  0.0026\n  0.0711\n\nP value adjustment: tukey method for comparing a family of 9 estimates \n\n\nWe can also use the following, which doesn’t require the emmeans package. You might see this when you look online for resources. The aov() function is fitting an ANOVA model, and then TukeyHSD() compares between Diagnosis group; between Task type; and between Diagnosis*Task.\nRun the code below yourself to see the output.\n\nTukeyHSD(aov(Score ~ Diagnosis * Task, data = cog))"
  },
  {
    "objectID": "2_04_emmeans.html#scheffe",
    "href": "2_04_emmeans.html#scheffe",
    "title": "Simple Effects, Pairwise Comparisons, Corrections",
    "section": "Scheffe",
    "text": "Scheffe\n\nQuestion 9\n\n\nRun the same pairwise comparison as above, but this time with the Scheffe adjustment.\n\n\n\n\n Solution \n\n\n\nemm_task <- emmeans(mdl_int, ~ Diagnosis * Task)\ncontr_task <- contrast(emm_task, method = \"pairwise\", adjust=\"scheffe\")\ncontr_task\n\n contrast                                             estimate   SE df t.ratio\n control recognition - amnesic recognition                  30 7.94 36   3.776\n control recognition - huntingtons recognition               0 7.94 36   0.000\n control recognition - control grammar                      15 7.94 36   1.888\n control recognition - amnesic grammar                      35 7.94 36   4.406\n control recognition - huntingtons grammar                  55 7.94 36   6.923\n control recognition - control classification               15 7.94 36   1.888\n control recognition - amnesic classification               25 7.94 36   3.147\n control recognition - huntingtons classification           50 7.94 36   6.294\n amnesic recognition - huntingtons recognition             -30 7.94 36  -3.776\n amnesic recognition - control grammar                     -15 7.94 36  -1.888\n amnesic recognition - amnesic grammar                       5 7.94 36   0.629\n amnesic recognition - huntingtons grammar                  25 7.94 36   3.147\n amnesic recognition - control classification              -15 7.94 36  -1.888\n amnesic recognition - amnesic classification               -5 7.94 36  -0.629\n amnesic recognition - huntingtons classification           20 7.94 36   2.518\n huntingtons recognition - control grammar                  15 7.94 36   1.888\n huntingtons recognition - amnesic grammar                  35 7.94 36   4.406\n huntingtons recognition - huntingtons grammar              55 7.94 36   6.923\n huntingtons recognition - control classification           15 7.94 36   1.888\n huntingtons recognition - amnesic classification           25 7.94 36   3.147\n huntingtons recognition - huntingtons classification       50 7.94 36   6.294\n control grammar - amnesic grammar                          20 7.94 36   2.518\n control grammar - huntingtons grammar                      40 7.94 36   5.035\n control grammar - control classification                    0 7.94 36   0.000\n control grammar - amnesic classification                   10 7.94 36   1.259\n control grammar - huntingtons classification               35 7.94 36   4.406\n amnesic grammar - huntingtons grammar                      20 7.94 36   2.518\n amnesic grammar - control classification                  -20 7.94 36  -2.518\n amnesic grammar - amnesic classification                  -10 7.94 36  -1.259\n amnesic grammar - huntingtons classification               15 7.94 36   1.888\n huntingtons grammar - control classification              -40 7.94 36  -5.035\n huntingtons grammar - amnesic classification              -30 7.94 36  -3.776\n huntingtons grammar - huntingtons classification           -5 7.94 36  -0.629\n control classification - amnesic classification            10 7.94 36   1.259\n control classification - huntingtons classification        35 7.94 36   4.406\n amnesic classification - huntingtons classification        25 7.94 36   3.147\n p.value\n  0.1131\n  1.0000\n  0.8852\n  0.0329\n  0.0001\n  0.8852\n  0.3060\n  0.0003\n  0.1131\n  0.8852\n  0.9999\n  0.3060\n  0.8852\n  0.9999\n  0.6128\n  0.8852\n  0.0329\n  0.0001\n  0.8852\n  0.3060\n  0.0003\n  0.6128\n  0.0080\n  1.0000\n  0.9894\n  0.0329\n  0.6128\n  0.6128\n  0.9894\n  0.8852\n  0.0080\n  0.1131\n  0.9999\n  0.9894\n  0.0329\n  0.3060\n\nP value adjustment: scheffe method with rank 8"
  },
  {
    "objectID": "2_05_writeup_recap.html",
    "href": "2_05_writeup_recap.html",
    "title": "Write Up Example & Block 3 Recap",
    "section": "",
    "text": "At the end of this lab, you will:\n\nUnderstand how to write-up and provide interpretation of a 2x2 factorial ANOVA\n\n\nBe up to date with lectures\nHave completed Labs 1-4\n\nRemember to load all packages within a code chunk at the start of your RMarkdown file using library(). If you do not have a package and need to install, do so within the console using install.packages(\" \"). For further guidance on installing/updating packages, see Section C here.\nFor this lab, you will need to load the following package(s):\n\ntidyverse\npatchwork\nkableExtra\nemmeans\npander\n\nYou can download the data required for this lab here or read it in via this link https://uoepsy.github.io/data/lietraining.csv."
  },
  {
    "objectID": "2_05_writeup_recap.html#study-overview",
    "href": "2_05_writeup_recap.html#study-overview",
    "title": "Write Up Example & Block 3 Recap",
    "section": "Study Overview",
    "text": "Study Overview\n\nResearch Question\nDo Police training materials and the mode of communication influence the accuracy of veracity judgements?\n\n\n Lie detectors: Data Codebook\n\n\nDescription\nA total of 120 participants took part in a study in which they were presented with 100 recordings, and were tasked with guessing whether the speaker in each recording was lying or whether they were telling the truth.\nParticipants scored points every time they correctly identified a truth or a lie, and lost points whenever they mistook a lie for a truth (or vice versa). The maximum possible points to be scored was 100.\nHalf of the participants (\\(n\\) = 60) were shown recordings in audio and video, the other half were presented with only the audio track.\nPrior to taking part in the experiment, participants were given material to read for 10 minutes. Half of the participants in each condition (30 in the audio-only condition, and 30 in the audiovideo condition) were given instructional material used by the Police Force to train detectives to pick up on dishonesty during interrogations via various verbal and non-verbal cues. The remaining 30 participants in each condition were given a series of cartoon strips to read.\nThe data in lietraining.csv contain seven attributes collected from a sample of \\(n=120\\) participants:\n\n\npid: Participant ID\n\nage: Age (in years) of participant\n\ntrained: Whether participants were given instructional material used by the Police Force to train detectives to pick up on dishonesty during interrogations via various verbal and non-verbal cues (yes = y / no = n)\n\naudiovideo: Audio-Video recording condition - either audio+video for those participants shown recordings in audio and video, or ausio-only for those participants presented with only the audio track\n\npoints: Points scored for identifying a truth or a lie (range: 0-100)\n\nPreview\nThe first six rows of the data are:\n\n\n\n\n\n\n\npid\n      age\n      trained\n      audiovideo\n      points\n    \n\n\nppt_1\n26\ny\naudio+video\n36.23952\n\n\nppt_2\n22\ny\naudio+video\n38.46473\n\n\nppt_3\n18\ny\naudio+video\n34.19058\n\n\nppt_4\n22\ny\naudio+video\n52.62804\n\n\nppt_5\n21\ny\naudio+video\n38.89564\n\n\nppt_6\n27\ny\naudio+video\n37.46595\n\n\n\n\n\n\n\n\n\nSetup\n\nSetup\n\n\n\nCreate a new RMarkdown file\nLoad the required package(s)\nRead the lietraining dataset into R, assigning it to an object named liedat\n\n\n\n\n\n\n Solution \n\n\n\nlibrary(tidyverse)\nlibrary(psych) \nlibrary(kableExtra)\nlibrary(emmeans)\nlibrary(pander)\nlibrary(interactions)\n\n#read in data\nliedat <- read_csv(\"https://uoepsy.github.io/data/lietraining.csv\")\n\n\n\n\nAnalysis Code\nTry to answer the research question above without referring to the provided analysis code below, and then check how your script matches up - is there anything you missed or done differently? If so, discuss the differences with a tutor - there are lots of ways to code to the same solution!\n\n Provided Analysis Code\n\n\n\n######Step 1 is always to read in the data, then to explore, check, describe, and visualise it.\n\n#check coding of variables - are they coded as they should be?\nstr(liedat)\n\nspec_tbl_df [120 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ pid       : chr [1:120] \"ppt_1\" \"ppt_2\" \"ppt_3\" \"ppt_4\" ...\n $ age       : num [1:120] 26 22 18 22 21 27 27 26 25 22 ...\n $ trained   : chr [1:120] \"y\" \"y\" \"y\" \"y\" ...\n $ audiovideo: chr [1:120] \"audio+video\" \"audio+video\" \"audio+video\" \"audio+video\" ...\n $ points    : num [1:120] 36.2 38.5 34.2 52.6 38.9 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   pid = col_character(),\n  ..   age = col_double(),\n  ..   trained = col_character(),\n  ..   audiovideo = col_character(),\n  ..   points = col_double()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\nhead(liedat)\n\n# A tibble: 6 × 5\n  pid     age trained audiovideo  points\n  <chr> <dbl> <chr>   <chr>        <dbl>\n1 ppt_1    26 y       audio+video   36.2\n2 ppt_2    22 y       audio+video   38.5\n3 ppt_3    18 y       audio+video   34.2\n4 ppt_4    22 y       audio+video   52.6\n5 ppt_5    21 y       audio+video   38.9\n6 ppt_6    27 y       audio+video   37.5\n\n#make variables factors & label\nliedat$audiovideo <- factor(liedat$audiovideo, labels=c(\"audio\",\"audio+video\"))\nliedat$trained <- factor(liedat$trained, labels = c(\"untrained\",\"trained\"))\n\n#create descriptives table\ndescript <- liedat %>% \n    group_by(audiovideo, trained) %>%\n   summarise(\n       meanpoints = round(mean(points), 2),\n       se = round(sd(points)/sqrt(n()), 2)\n    )\n\n`summarise()` has grouped output by 'audiovideo'. You can override using the\n`.groups` argument.\n\ndescript\n\n# A tibble: 4 × 4\n# Groups:   audiovideo [2]\n  audiovideo  trained   meanpoints    se\n  <fct>       <fct>          <dbl> <dbl>\n1 audio       untrained       52.8  1.27\n2 audio       trained         53.7  1.55\n3 audio+video untrained       49.9  1.01\n4 audio+video trained         40.4  1.12\n\n#plot showing the mean points for each condition\np1 <- ggplot(descript, aes(x = audiovideo, y = meanpoints, color = trained)) + \n  geom_point(size = 3) +\n  geom_linerange(aes(ymin = meanpoints - 2 * se, ymax = meanpoints + 2 * se)) +\n  geom_path(aes(x = as.numeric(audiovideo)))\np1\n\n\n\n######Step 2 is to run your model(s) of interest to answer your research question, and make sure that the data meet the assumptions of your chosen test\n\n#build model\nlie_mdl <- lm(points ~ audiovideo * trained, data = liedat)\n\n#check assumptions\npar(mfrow=c(2,2))\nplot(lie_mdl)\n\n\n\npar(mfrow=c(1,1))\n\n# look at model output - summary() and anova()\nsummary(lie_mdl)\n\n\nCall:\nlm(formula = points ~ audiovideo * trained, data = liedat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.1947  -4.2134  -0.7559   4.5235  21.1755 \n\nCoefficients:\n                                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                           52.7591     1.2576  41.953  < 2e-16 ***\naudiovideoaudio+video                 -2.8367     1.7785  -1.595    0.113    \ntrainedtrained                         0.9759     1.7785   0.549    0.584    \naudiovideoaudio+video:trainedtrained -10.4830     2.5152  -4.168 5.95e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.888 on 116 degrees of freedom\nMultiple R-squared:  0.3768,    Adjusted R-squared:  0.3607 \nF-statistic: 23.38 on 3 and 116 DF,  p-value: 6.591e-12\n\nanova(lie_mdl)\n\nAnalysis of Variance Table\n\nResponse: points\n                    Df Sum Sq Mean Sq F value    Pr(>F)    \naudiovideo           1 1957.7 1957.71  41.263 3.046e-09 ***\ntrained              1  545.8  545.85  11.505   0.00095 ***\naudiovideo:trained   1  824.2  824.20  17.372 5.949e-05 ***\nResiduals          116 5503.6   47.45                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#####Step 3 somewhat depends on the outcomes of step 2. Here, you may need to consider conducting further analyses before writing up / describing your results in relation to the research question. \n\n#Perform a pairwise comparison of the mean accuracy (as measured by points accrued) across the 2×2 factorial design, making sure to adjust for multiple comparisons. \n\nemms_lie <- emmeans(lie_mdl, ~ audiovideo * trained)\n\nlie_con <- contrast(emms_lie, method = \"pairwise\", adjust=\"tukey\")\nlie_con\n\n contrast                                        estimate   SE  df t.ratio\n audio untrained - (audio+video untrained)          2.837 1.78 116   1.595\n audio untrained - audio trained                   -0.976 1.78 116  -0.549\n audio untrained - (audio+video trained)           12.344 1.78 116   6.941\n (audio+video untrained) - audio trained           -3.813 1.78 116  -2.144\n (audio+video untrained) - (audio+video trained)    9.507 1.78 116   5.346\n audio trained - (audio+video trained)             13.320 1.78 116   7.489\n p.value\n  0.3855\n  0.9467\n  <.0001\n  0.1456\n  <.0001\n  <.0001\n\nP value adjustment: tukey method for comparing a family of 4 estimates \n\n# confidence intervals\nconfint(lie_con)\n\n contrast                                        estimate   SE  df lower.CL\n audio untrained - (audio+video untrained)          2.837 1.78 116    -1.80\n audio untrained - audio trained                   -0.976 1.78 116    -5.61\n audio untrained - (audio+video trained)           12.344 1.78 116     7.71\n (audio+video untrained) - audio trained           -3.813 1.78 116    -8.45\n (audio+video untrained) - (audio+video trained)    9.507 1.78 116     4.87\n audio trained - (audio+video trained)             13.320 1.78 116     8.68\n upper.CL\n    7.473\n    3.660\n   16.980\n    0.823\n   14.143\n   17.956\n\nConfidence level used: 0.95 \nConf-level adjustment: tukey method for comparing a family of 4 estimates \n\n#plot\nplot(lie_con)\n\n\n\n\n\n\n\nThe 3-Act Structure: Analysis Strategy, Results, & Discussion\nRecall that we need to present our report in three clear sections - think of your sections like the 3 key parts of a play or story - we need to (1) provide some background and scene setting for the reader, (2) present our results in the context of the research question, and (3) present a resolution to our story - relate our findings back to the question we were asked and provide our answer.\nIf you need a reminder of what to include within each section, refer to Lab 11, and read through the ‘what to include’ sections for Analysis Strategy, Results, and Discussion.\nAct I: Analysis Strategy\n\nQuestion 1\n\n\nAttempt to draft a discussion section based on the above research question and analysis provided.\n\n\n\n\n Example Write-Up of Analysis Strategy Section\n\n\nThe lietraining dataset contained information on 120 participants who took part in a study concerning lie detection. Participants were each presented with 100 recordings (half were shown recordings in audio and video, and the other half audio only), and were tasked with judging whether the speaker in each recording was lying or whether they were telling the truth. Participants scored 1 point each time they correctly identified a truth or a lie, and lost 1 point whenever they mistook a lie for a truth (or vice versa). The maximum score was 100, where higher scores reflected higher levels of accuracy. Prior to taking part in the experiment participants were given materials to read. Half of the participants in each condition were given instructional material used by the Police Force (used to train detectives to pick up on dishonesty during interrogations via various verbal and non-verbal cues) and the remaining 30 participants in each condition were given a series of cartoon strips to read.\nAll participant data was complete, and accuracy scores (points) within range i.e., 0-100. Categorical variables were coded as factors, where audio was designated as the reference level for mode of communication, and untrained as the reference level for training materials.\nTo investigate whether police training materials (trained vs untrained) and the mode of communication (audio vs audiovideo) interacted to influence the accuracy of veracity judgements, a two-way ANOVA model was used. Effects were considered statistically significant at \\(\\alpha = 0.05\\). Using dummy coding, the following model specification was used:\n\\[\n\\begin{aligned}\n\\text{Accuracy Scores} &= \\beta_0 \\\\\n&+ \\beta_1 A_\\text{AudioVideo} + \\beta_2 T_\\text{Trained} \\\\\n&+ \\beta_3 (A_\\text{AudioVideo} * T_\\text{Trained}) \\\\\n&+ \\epsilon\n\\end{aligned}\n\\]\nTo address the research question of whether the interaction between training materials and mode of communication was statistically significant, this formally corresponded to testing whether the interaction coefficient was equal to zero:\n\\[\nH_0: \\beta_3 = 0 \\\\\nH_1: \\beta_3 \\neq 0\n\\]\nThe following assumptions were assessed visually using diagnostic plots: independence (with the previous plot and a plot of residuals vs index; no dependence should be indicated), equal variances (via a scale-location plot; residuals should be evenly spread across the range of fitted values, where the spread should be constant across the range of fitted values), and normality (via a qqplot of the residuals; points should follow along the diagonal line). We also checked if there was any evidence of multicollinearity by checking VIF values, where values > 5 were considered to indicate moderate multicollinearity, and values > 10 severe. Outliers were assessed via Cooks Distance, where values >2 indicated influential points.\n\n\n\nAct II: Results\n\nQuestion 2\n\n\nAttempt to draft a results section based on your detailed analysis strategy and the analysis provided.\n\n\n\n\n Example Write-Up of Results Section\n\n\nDescriptive statistics are displayed in Table 1.\n\n\n\n\n\nTable 1:  Descriptive Statistics \n \n audiovideo \n    trained \n    meanpoints \n    se \n  \n\n\n audio \n    untrained \n    52.76 \n    1.27 \n  \n\n audio \n    trained \n    53.74 \n    1.55 \n  \n\n audio+video \n    untrained \n    49.92 \n    1.01 \n  \n\n audio+video \n    trained \n    40.42 \n    1.12 \n  \n\n\n\n\n\nIn the audio condition, there did not appear to be a difference between trained and non-trained scores. However, untrained scored higher than trained in the audio+video condition. There appeared to be an interaction (see Figure 1).\n\n\n\n\nFigure 1: Interaction Plot\n\n\n\n\nAccuracy of veracity judgements (measured by points scored in lie-detecting game) were analysed with a 2 (audio vs audiovideo) \\(\\times\\) 2 (untrained vs trained) between-subjects ANOVA.\nThe model met assumptions of linearity and independence (see top left panel of Figure 2; residuals were randomly scattered with a mean of zero and there was no clear dependence), homoscedasticity (see bottom left panel of Figure 2; there was a constant spread of residuals), and normality (see top right panel of Figure 2; the QQplot showed very little deviation from the diagonal line).\n\n\n\n\nFigure 2: Diagnostic Plots\n\n\n\n\nThere was a significant interaction between presentation mode and whether or not participants had received training for detecting lies \\(F(1, 116) = 17.37, p <. 001\\) (see Table 2).\n\n\n\n\n\nTable 2:  Model Results \n \n   \n    Df \n    Sum Sq \n    Mean Sq \n    F value \n    Pr(>F) \n  \n\n\n audiovideo \n    1 \n    1957.71 \n    1957.71 \n    41.26 \n    0.00e+00 \n  \n\n trained \n    1 \n    545.85 \n    545.85 \n    11.50 \n    9.50e-04 \n  \n\n audiovideo:trained \n    1 \n    824.20 \n    824.20 \n    17.37 \n    5.95e-05 \n  \n\n Residuals \n    116 \n    5503.63 \n    47.45 \n    NA \n    NA \n  \n\n\n\n\n\nAs displayed in Figure 3, results suggested that the difference in points did not differ significantly in the audio condition regardless of training, but that there were significant differences in the audio video condition.\n\n\n\n\nplt_lie_mdl\n\n\n\nFigure 3: Interaction Plot\n\n\n\n\nTo explore the interaction further, pairwise comparisons were conducted. Tukey’s Honestly Significant Difference comparisons (see Figure 4) indicated that, contrary to what one might expect, participants who were presented with audiovisual recordings scored on average 9.5 points lower when they had read the police training materials compared to when they had received no training (95% CI [4.87 — 14.14]). The presentation mode (audio vs audio-video) was not found to result in a significantly different average score for those who were untrained (95% CI [-1.80 — 7.47]), and nor did training appear to have any effect on detecting lies in the audio-only condition (95% CI [-5.61 — 3.66]).\n\n\n\n\nFigure 4: Tukey HSD Pairwise Comparisons\n\n\n\n\n\n\n\nAct III: Discussion\n\nQuestion 3\n\n\nAttempt to draft a discussion section based on your results and the analysis provided.\n\n\n\n\n Example Write-Up of Discussion Section\n\n\nThe findings indicated that, in general, people were inaccurate when trying to distinguish between a lie and the truth, as the overall mean score was 49.21 out of 100 (SD = 8.61), where a series of completely random guesses expected to score 50/100. The police training materials did not appear to be associated with the ability to accurately detect a lie - trained participants performed more poorly (compared to untrained) in the audio-visual condition. This may indicate that the training materials focus too heavily on visual cues, which perhaps are not actually associated with dishonesty in the appropriate way.\nMAKE STATEMENT IN RELATION TO THE NULL HERE TOO."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Dr Umberto Noe\nDr Josiah King\nDr Emma Waterston\nDepartment of Psychology, The University of Edinburgh"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "Welcome to the Data Analysis for Psychology in R 2 (DAPR2) lab workbook. Using the menu above, you can find lab materials for each week."
  },
  {
    "objectID": "index.html#help-support-feedback",
    "href": "index.html#help-support-feedback",
    "title": "Home",
    "section": "Help, Support & Feedback",
    "text": "Help, Support & Feedback\n\nWithin Lab Workbook\n\nHints, Notes, and Example Write-Up / Interpretation\nHints are shown in a green box, with the title ‘Hint’. If you are unsure what to do, check the collapsible hint provided (note that these are only present for some questions).\n\n\n\n\n\n\nHint\n\n\n\n\n\nThis is an example of a hint.\n\n\n\nNotes are displayed in blue boxes, with the title ‘Note’. These are occasionally used to draw your attention to a specific point.\n\n\n\n\n\n\nNote\n\n\n\nThis is an example of a note.\n\n\nExample write-ups and/or interpretations are shown with a red right border. These are helpful to check your interpretation against, and a useful guide to use in future when interpreting and/or writing up results.\n\n\n\n\n\n\nThis is an example write-up / interpretation block.\n\n\n\n\n\nSolutions\nSolutions are made available immediately below each exercise. To view solutions, click the drop down ‘Solution’ button.\nImportant  Before checking the solution you should attempt the question. You should also avoid copying and pasting code from the solutions. If you do check solutions right away and simply copy the answer, you will struggle to learn from the exercises.\nInstead, you should:\n\nTry to figure out the answer yourself or with your peers (and/or ask for help from a staff member if needed)\nType the code out yourself (and annotate your R code chunks so you know what your code is doing & why - future you will thank you for this).\n\n\n\n\nAsking Questions\n\nDuring labs, if you have a question, please ask one of the tutors for support.\nOutside of labs, we encourage you to use the various support options, details of which can be found on the Course Learn Page."
  },
  {
    "objectID": "index.html#tips-on-googling-statistics-and-r",
    "href": "index.html#tips-on-googling-statistics-and-r",
    "title": "Home",
    "section": "Tips on Googling Statistics and R",
    "text": "Tips on Googling Statistics and R\nSearching online for help with statistics and R can be both a help and a hindrance. If you have an error message in R, copy the error message into Google. The results returned can sometimes just cause more confusion, but sometimes something might jump out at you and help you solve the problem. The same applies with searching the internet for help with statistics - search for “what is a p-value”, and you’ll find many many different articles and forum discussions etc. Some of them you will find too technical, but don’t be scared - the vast majority of people work in statistics will find these too technical too. Some of them you might feel are too simple/not helpful. As a general guide, keep clicking around the search responses, and you may end up finding that someone, somewhere, has provided an explanation at the right level. If you find something during your search which you don’t quite understand, feel free to link it in a post on the discussion forum!"
  },
  {
    "objectID": "index.html#feedback-on-labs",
    "href": "index.html#feedback-on-labs",
    "title": "Home",
    "section": "Feedback on Labs",
    "text": "Feedback on Labs\nIf you wish to make suggestions for improvements to these workbooks (or if you spot any typos!), please email ppls.psych.stats@ed.ac.uk making sure to include the course name in the subject."
  }
]