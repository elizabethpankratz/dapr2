---
title: "<b> Analysing Experiments </b>"
subtitle: "Data Analysis for Psychology in R 2<br><br> "
author: "dapR2 Team"
institute: "Department of Psychology<br>The University of Edinburgh"
date: ""
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    nature:
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```

```{r xaringan-themer, include = FALSE}
library(xaringanthemer)
style_mono_accent(
  #base_color = "#0F4C81", # DAPR1
   base_color = "#BF1932", # DAPR2
  # base_color = "#88B04B", # DAPR3 
  # base_color = "#FCBB06", # USMR
  # base_color = "#a41ae4", # MSMR
  header_color = "#000000",
  header_font_google = google_font("Source Sans Pro"),
  header_font_weight = 400,
  text_font_google = google_font("Source Sans Pro", "400", "400i", "600", "600i"),
  code_font_google = google_font("Source Code Pro")
)
```


```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(kableExtra)
library(emmeans)

hosp_tbl <- read_csv("./data/hospital.csv", col_types = "dff")

```

# Week's Learning Objectives
1. Interpretation of interactions with effects coded variables.
2. Distinguish between interactions, main effect contrasts, and simple effect contrasts.
3. Use contrasts to code specific interaction hypotheses.
4. Apply pairwise tests and corrections.


---


# Hypotheses Testing in Factorial Designs

+ **Interactions (categorical-categorical)**
  + A change in the effect of some condition as a function of another.
  + Does the effect of `Treatment` differ by `Hospital`? 

  <!-- + With effects coding, we can also think of this as a difference in simple effects. -->
  
  
+ Main effects / main effect contrasts (typically not pursued if the interaction is significant).
  + An overall, or average, effect of a condition over combined levels of another.
  + Is there an effect of `Treatment` averaged over `Hospital`? 

+ **Simple Effects**
  + An effect of one condition at a specific level of another.
  + Is there an effect of `Hospital` for those receiving `Treatment A`? (...and so on for all combinations.)
  + In factorial designs with more than two levels of one or more of the conditions, one can also
distinguish between *simple effects* and *simple contrasts*. 
  + A simple contrast is a more focused test that
compares only two cells (or a particular combination of cells).


---
# Our model and coefficients

+ The effects coded model:

$$y_{ijk} = b_0 + \underbrace{(b_1E_1 + b_2E_2)}_{\text{Treatment}} + \underbrace{b_3E_3}_{\text{Hospital}} + \underbrace{b_4E_{13} + b_5E_{23}}_{\text{Interactions}} + \epsilon_{i}$$
+ Where the variables represent the following comparisons: 

```{r, echo=FALSE}
tibble(
  Treatment = c("A", "A", "B", "B", "C", "C"),
  Hospital = rep(c("Hosp1", "Hosp2"),3),
  E1 = c(1,1,0,0,-1,-1),
  E2 = c(0,0,1,1,-1,-1),
  E3 = c(1,-1,1,-1,1,-1),
  E13 = c(1,-1,0,0,-1,1),
  E23 = c(0,0,1,-1,-1,1)
)
```

---
# Our model and coefficients

+ And our model in R:

```{r}
m1 <- lm(SWB ~ Treatment + Hospital + Treatment*Hospital, data = hosp_tbl,
         contrasts = list(Treatment = contr.sum, 
                          Hospital = contr.sum)) # you can code contrasts within lm
```


---
# Table of means

+ Useful to keep in mind the group means:

```{r, echo=FALSE}
knitr::kable(tibble::tribble(
   ~V1, ~V2, ~V3, ~V4,
  "TreatA", "10.80",  "7.85", "9.33",
  "TreatB", "9.43",  "13.11", "11.27",
  "TreatC", "10.10",  "7.98", "9.04", 
  "Marginal","10.11", "9.65", "9.88"
  ), col.names = c("", "Hosp1",  "Hosp2", "Marginal"))
```


---
# Our results
```{r, echo=FALSE}
m1sum <- summary(m1)
summary(m1)
```

---
# Interpretation with effects coding
```{r, echo=FALSE}
round(m1sum$coefficients,2)
```

+ $b_0$ (`Intercept`) = Grand mean.
+ $b_1$ (`Treatment1`) = Difference between row marginal for treatment A and the grand mean. 
+ $b_2$ (`Treatment2`) = Difference between row marginal for treatment B and the grand mean.
+ $b_3$ (`Hospital1`) = Difference between column marginal for Hospital 1 and the grand mean.
+ $b_4$ (`Treatment1:Hospital1`) = Difference between Treatment A and grand mean, in Hospital 1 and Hospital 2.
+ $b_5$ (`Treatment2:Hospital1`) = Difference between Treatment B and grand mean, in Hospital 1 and Hospital 2.


---
# Interpretation with effects coding

.pull-left[
```{r, echo=FALSE}
round(m1sum$coefficients,2)[,1:2]
```
]

.pull-right[
```{r, echo=FALSE}
knitr::kable(tibble::tribble(
   ~V1, ~V2, ~V3, ~V4,
  "TreatA", "10.80",  "7.85", "9.33",
  "TreatB", "9.43",  "13.11", "11.27",
  "TreatC", "10.10",  "7.98", "9.04", 
  "Marginal","10.11", "9.65", "9.88"
  ), col.names = c("", "Hosp1",  "Hosp2", "Marginal"))
```

]

+ $b_0$ (`Intercept`) = Grand mean.
+ $b_1$ (`Treatment1`) = Difference between row marginal for treatment A and the grand mean. 
+ $b_2$ (`Treatment2`) = Difference between row marginal for treatment B and the grand mean.
+ $b_3$ (`Hospital1`) = Difference between column marginal for Hospital 1 and the grand mean.
+ $b_4$ (`Treatment1:Hospital1`) = Difference between Treatment A and grand mean, in Hospital 1 and Hospital 2.
+ $b_5$ (`Treatment2:Hospital1`) = Difference between Treatment B and grand mean, in Hospital 1 and Hospital 2.



---
# Interpretation with effects coding

$$y_{ijk} = b_0 + \underbrace{(b_1E_1 + b_2E_2)}_{\text{Treatment}} + \underbrace{b_3E_3}_{\text{Hospital}} + \underbrace{b_4E_{13} + b_5E_{23}}_{\text{Interactions}} + \epsilon_{i}$$


.pull-left[
```{r, echo=FALSE}
round(m1sum$coefficients,2)[,1:2]
```
]

.pull-right[
```{r, echo=FALSE}
knitr::kable(tibble::tribble(
   ~V1, ~V2, ~V3, ~V4,
  "TreatA", "10.80",  "7.85", "9.33",
  "TreatB", "9.43",  "13.11", "11.27",
  "TreatC", "10.10",  "7.98", "9.04", 
  "Marginal","10.11", "9.65", "9.88"
  ), col.names = c("", "Hosp1",  "Hosp2", "Marginal"))
```

]

```{r, echo=FALSE}
tibble(
  Treatment = c("A", "A", "B", "B", "C", "C"),
  Hospital = rep(c("Hosp1", "Hosp2"),3),
  E1 = c(1,1,0,0,-1,-1),
  E2 = c(0,0,1,1,-1,-1),
  E3 = c(1,-1,1,-1,1,-1),
  E13 = c(1,-1,0,0,-1,1),
  E23 = c(0,0,1,-1,-1,1)
)
```

---
# Interpretation with effects coding

$$y_{ijk} = b_0 + b_1E_1 + b_2E_2 + b_3E_3 + b_4E_{13} + b_5E_{23} + \epsilon_{i}$$

+ $b_0$ (`Intercept`) = Mean of means ("grand mean"): $b_{0} = \mu_{..}$ 
+ $b_1$ (`Treatment1`) = Difference between row marginal for treatment A and the grand mean: $b_1 = \mu_{1.}-\mu_{..}$
+ $b_2$ (`Treatment2`) = Difference between row marginal for treatment B and the grand mean: $b_2 = \mu_{2.}-\mu_{..}$
+ $b_3$ (`Hospital1`) = Difference between column marginal for Hospital 1 and the grand mean: $b_3 = \mu_{.1}-\mu_{..}$
+ $b_4$ (`Treatment1:Hospital1`) = Difference between Treatment A and grand mean, in Hospital 1 and Hospital 2: $b_4 = \mu_{11}-b_0-b_1-b_3$
+ $b_5$ (`Treatment2:Hospital1`) = Difference between Treatment B and grand mean, in Hospital 1 and Hospital 2: $b_5 = \mu_{21}-b_0-b_2-b_3$

.pull-left[
```{r, echo=FALSE}
tibble(
  Treatment = c("A", "A", "B", "B", "C", "C"),
  Hospital = rep(c("Hosp1", "Hosp2"),3),
  E1 = c(1,1,0,0,-1,-1),
  E2 = c(0,0,1,1,-1,-1),
  E3 = c(1,-1,1,-1,1,-1),
  E13 = c(1,-1,0,0,-1,1),
  E23 = c(0,0,1,-1,-1,1)
)
```
]

.pull-right[

```{r, echo=FALSE}
knitr::kable(tibble::tribble(
   ~V1, ~V2, ~V3, ~V4,
  "TreatA", "10.80",  "7.85", "9.33",
  "TreatB", "9.43",  "13.11", "11.27",
  "TreatC", "10.10",  "7.98", "9.04", 
  "Marginal","10.11", "9.65", "9.88"
  ), col.names = c("", "Hosp1",  "Hosp2", "Marginal"))
```
]

---
# Interpretation with effects coding


$$y_{ijk} = b_0 + b_1E_1 + b_2E_2 + b_3E_3 + b_4E_{13} + b_5E_{23} + \epsilon_{i}$$

$$b_{0} = \mu_{..}$$

$$b_1 = \mu_{1.}-\mu_{..}$$

$$b_2 = \mu_{2.}-\mu_{..}$$

$$b_3 = \mu_{.1}-\mu_{..}$$

$$b_4 = \mu_{11}-b_0-b_1-b_3 = (\mu_{11}-\mu_{..}) - (\mu_{1.}-\mu_{..}) - (\mu_{.1}-\mu_{..})$$

$$b_5 = \mu_{21}-b_0-b_2-b_3 = (\mu_{21}-\mu_{..}) - (\mu_{2.}-\mu_{..}) - (\mu_{.1}-\mu_{..})$$



---
class: center, middle
# Questions....

---
# Interacting manual contrasts
+ We can create an interaction based on manual contrasts.

+ Suppose we wanted to test whether there is a difference between Treatment A vs Treatment B and Treatment C across hospitals.

+ Steps:
  + Define the contrasts for each factor.
  + Calculate the product (remember all interactions are products).
  + Create the contrast code.
  + Run the contrast.
  
---
# Interacting manual contrasts in R

+ Step 1: Individual contrasts.

```{r}
treat_con <- c("TreatA" = 1, "TreatB" = -1/2, "TreatC" = -1/2)
hosp_con <- c("Hops1" = 1, "Hosp2" = -1)
```

+ Step 2: Product.

```{r}
contr_prod <- outer(treat_con, hosp_con)
contr_prod
```


---
# Interacting manual contrasts in R

+ Step 3: Create the contrast.

```{r}
m1_emm <- emmeans(m1, ~Treatment*Hospital)
m1_emm
```


```{r}
int_comp <- list("TreatA vs B and C across hospital" = 
                   c(1, -1/2, -1/2, -1, 1/2, 1/2))
```


---
# Interacting manual contrasts in R

+ Step 4: Run.

```{r}
int_comp_test <- contrast(m1_emm, int_comp)
int_comp_test
```


---
class: center, middle
# Questions....


---
# Simple Effects
+ We noted previously that simple effects consider the effect of one condition at a specific level of the other.

  + Is there an effect of `Hospital` for those receiving `Treatment A`? (and so on for all combinations)
  
  + Or, put another way, is there a difference in `SWB` between Hospitals 1 and 2 for people receiving Treatment A?

---
# Simple Effects with `emmeans`

.pull-left[
```{r}
m1_emm <- emmeans(m1, ~Treatment*Hospital)
m1_simple1 <- pairs(m1_emm, 
                    simple = "Hospital")
m1_simple1
```
]

.pull-right[

```{r, echo=FALSE}
knitr::kable(tibble::tribble(
   ~V1, ~V2, ~V3, ~V4,
  "TreatA", "10.80",  "7.85", "9.33",
  "TreatB", "9.43",  "13.11", "11.27",
  "TreatC", "10.10",  "7.98", "9.04", 
  "Marginal","10.11", "9.65", "9.88"
  ), col.names = c("", "Hosp1",  "Hosp2", "Marginal"))
```

]
---
# Simple Effects with `emmeans`

.pull-left[
```{r}
m1_simple2 <- pairs(m1_emm, 
                    simple = "Treatment")
m1_simple2
```
]

.pull-right[

```{r, echo=FALSE}
knitr::kable(tibble::tribble(
   ~V1, ~V2, ~V3, ~V4,
  "TreatA", "10.80",  "7.85", "9.33",
  "TreatB", "9.43",  "13.11", "11.27",
  "TreatC", "10.10",  "7.98", "9.04", 
  "Marginal","10.11", "9.65", "9.88"
  ), col.names = c("", "Hosp1",  "Hosp2", "Marginal"))
```

]

---
# Simple effects with plots

.pull-left[
```{r, echo=FALSE, out.width="90%"}
emmip(m1, Treatment ~ Hospital)
```

]

.pull-right[
```{r}
m1_simple1
```

]

---
# Simple effects with plots

.pull-left[
```{r}
m1_simple2
```

]

.pull-right[
```{r, echo=FALSE, out.width="90%"}
emmip(m1, Hospital ~ Treatment)
```

]


---
# Visualizing the interaction

.pull-left[
```{r, echo=FALSE, warning=FALSE}
emmip(m1, Hospital~Treatment) +
  geom_hline(yintercept = mean(hosp_tbl$SWB))
```
]

.pull-right[
```{r, eval=FALSE, warning=FALSE}
emmip(m1, Hospital~Treatment) +
  geom_hline(yintercept = mean(hosp_tbl$SWB))
```
]


---
class: center, middle
# Questions....



---
# Pairwise comparisons
+ As the name suggests, pairwise comparisons compare all levels of a given predictor variable with all levels of the other.

+ A fully exploratory pairwise analysis.

```{r}
pairs_res <- pairs(m1_emm)
```

---
# Pairwise comparisons

```{r, echo=FALSE}
pairs_res
```



---
# Why do pairwise comparisons?

+ Sometimes we do not have a concrete hypothesis to test.

+ Sometimes we do, but the exploratory analysis is still useful information for the field.

+ Pairwise comparisons throws up a statistical issue, namely the problem of multiple comparisons.
  + When we do lots and lots of tests, the chances of Type I error (false-positives) increase.

+ How we can adjust our inferences to deal with this?

---
# Types of errors

+ Type I error = False positive
  + Reject the null when the null is true. 
  + $\alpha = P(\text{Type I Error})$

+ Type II error = False negative
  + Fail to reject the null when the null is false. 
  + $\beta = P(\text{Type II Error})$
  
---
# A single test
+ If we perform a single test, our Type I error rate is $\alpha$.
  + So if we set $\alpha = 0.05$, the probability of a false positive is 5%.

+ However, what if we do multiple tests ( $m$ ), each with the same $\alpha$ level?

+ What is the probability of a false positive among $m$ tests?

---
# Multiple tests

$$P(\text{Type I error}) = \alpha$$
$$P(\text{not making a Type I error}) = 1 - \alpha$$

$$P(\text{Not making a Type I error in m tests}) = (1 - \alpha)^m$$

$$P(\text{Making a Type I error in m tests}) = 1 - (1-\alpha)^m$$

---
# P(Making a Type I error in m tests)

+ Suppose $m=2$ and $\alpha = 0.05$

```{r}
1 - ((1-0.05)^2)
```

+ Suppose $m=5$ and $\alpha = 0.05$

```{r}
1 - ((1-0.05)^5)
```

+ Suppose $m=10$ and $\alpha = 0.05$

```{r}
1 - ((1-0.05)^10)
```

---
# Why does this matter?

+ The $P(\text{Making a Type I error in m tests}) = 1 - (1-\alpha)^m$ is referred to as the family-wise error rate. 

+ A "family" is a set of related tests. 

+ When we analyse an experimental design, and we look at lots of specific comparisons, we can think of all these tests as a "family". 

+ The larger the family, the more likely we are to find a false positive (see previous slide). 

---
# Corrections
+ There are various methods designed to control for the number of tests.
  + Here control means to keep the Type I Error rate at an intended $\alpha$. 

+ Many options. Some of most common:
  + Bonferroni
  + Sidak
  + Tukey
  + Scheffe

+ Others you may see:
  + Holm's step-down
  + Hochberg's step-up


---
# Bonferroni & Sidak
+ Both are considered "conservative" adjustments.

+ Each treats individual tests within the family as if they are independent.
  + Consider an $\alpha = 0.05$ and $m=\text{number of tests}=15$

+ **Bonferroni**: $\alpha_{Bonferroni} = \frac{\alpha}{m}$

```{r}
0.05/15
```


+ **Sidak**: $\alpha_{Sidak} = 1 - (1- \alpha)^{\frac{1}{m}}$

```{r}
1-((1-0.05)^(1/15))
```

---
# No adjustments

```{r, warning = FALSE, eval=TRUE}
pairs(m1_emm, adjust="none")
```

---
# Bonferroni in action: `emmeans`

```{r, echo=TRUE}
pairs(m1_emm, adjust="bonferroni")
```

---
# Sidak with `emmeans`

```{r}
pairs(m1_emm, adjust = "sidak")
```

---
# What about if there were less tests?

```{r}
pairs(m1_emm, simple="Treatment", adjust="bonferroni")
```


---
# Scheffe & Tukey
+ **Scheffe procedure** involves an adjustment to the critical value of $F$.
  + The adjustment relates to the number of comparisons being made.
  + And makes the critical value of $F$ larger for a fixed $\alpha$. 
  + The more tests, the larger $F$. 

+ The square-root of the adjusted F provides and adjusted $t$. 

--

+ **Tukey's HSD** (Honest significant differences)
  + Compares all pairwise group means. 
  + Each difference is divided by the $SE$ of the sum of means. 
  + This produces a $q$ statistic for each comparison. 
  + And is compared against a studentized range distribution. 


---
# With `emmeans`

```{r}
pairs(m1_emm, adjust = "tukey")
```


---
# With `emmeans`

```{r}
pairs(m1_emm, adjust = "scheffe")
```


---
# Summary
+ We are know finished with discussing testing effects within `lm`.

+ This week we have looked at ways we can code categorical data to test experimental effects.

+ In the next block, we will consider:
  + Non-continuous **dependent** variables
  + Approaches to modelling and modelling issues
  + Power

+ Last week of the course will be all Q&A and discussing exam.


---
class: center, middle
# Thanks for listening!
