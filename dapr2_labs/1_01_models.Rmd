---
title: "Functions and Models"
bibliography: references.bib
biblio-style: apalike
link-citations: yes
params: 
    SHOW_SOLS: TRUE
    TOGGLE: TRUE
---


```{r setup, include=FALSE}
source('assets/setup.R')

# knitr::opts_chunk$set(cache = TRUE)
set.seed(1)
```

:::lo
**LEARNING OBJECTIVES**

1. Review the main concepts from introductory statistics.
1. Understand the concept of a function.
1. Be able to discuss what a statistical model is.
1. Understand the link between models and functions.
:::


# Refresher of basic terminology

`r qbegin(1)`
Provide a short definition for each of these terms. 

- *(Observational) unit*
- *Variable*
- *Categorical variable*
- *Numeric variable*
- *Response/dependent variable*
- *Explanatory/independent variable*
- *Observational study*
- *Experiment*

Check the flashcards in the solution below to compare your definition. If you are not comfortable with one (or more) of the terms, revisit your DAPR1 materials for a refresher.

`r qend()`

`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`

`r optbegin("(Observational) unit", olabel=FALSE,toggle=params$TOGGLE)`
The individual entities on which data are collected.
`r optend()`

`r optbegin("Variable", olabel=FALSE,toggle=params$TOGGLE)`
Any characteristic recorded on the observational units.
`r optend()`

`r optbegin("Categorical variable", olabel=FALSE,toggle=params$TOGGLE)`
A categorical variable places units into one of several groups. Examples are country of birth, dominant hand, and eye colour.
`r optend()`

`r optbegin("Numeric variable", olabel=FALSE,toggle=params$TOGGLE)`
A variable that records a numerical quantity for each case. For such variables standard arithmetic operations make sense. For example, average height, IQ, and weight.
`r optend()`

`r optbegin("Response/dependent variable", olabel=FALSE,toggle=params$TOGGLE)`
A response variable (also called a dependent variable) measures the outcome of interest in a study.
`r optend()`

`r optbegin("Explanatory/independent variable", olabel=FALSE,toggle=params$TOGGLE)`
Explanatory variables (also called independent variables or predictors) are used to explain changes in the response variable.
`r optend()`

`r optbegin("Observational study", olabel=FALSE,toggle=params$TOGGLE)`
An observational study is a study in which the researcher does not manipulate any of the variables involved in the study, but merely records the values as they naturally exist.
`r optend()`

`r optbegin("Experiment", olabel=FALSE,toggle=params$TOGGLE)`
An experiment is a study in which the researcher imposes the values of the explanatory variable on the units before measuring the response variable.
`r optend()`

`r solend()`

# Functions and mathematical models

`r qbegin(2)`
Consider the function $y = 2 + 5 \ x$.

- Identify the dependent variable (DV)
- Identify the independent variable (IV)
- Describe in words what the function does, and compute the output for the following input:

$$
x = \begin{bmatrix}
2 \\
6
\end{bmatrix}
$$

`r qend()`

`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`
The function says that the $y$ value is obtained as a transformation of the $x$ value.

- The dependent variable is $y$
- The independent variable is $x$
- The $y$ value is obtained as five times $x$, plus two.

Example (1): If $x$ equals 2, the corresponding value of $y$ will be $2 + 5 * 2 = 12$.
Example (2): If $x$ equals 6, the corresponding value of $y$ will be $2 + 5 * 6 = 32$.
$$
y = \begin{bmatrix}
2 + 5 * 2 \\
2 + 5 * 6
\end{bmatrix}
= \begin{bmatrix}
12 \\
32
\end{bmatrix}
$$
`r solend()`


`r qbegin(3)`
Write down in words and in symbols the function describing the relationship between the side of a square and its perimeter.

_**Hint:** We are interested in how the perimeter varies as a function of its side. Hence, the perimeter is the dependent variable, and the side is the independent variable._
`r qend()`


`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`
**In words:**

The perimeter of a square is four times the length of its side.

<br />
**In symbols:**

The relationship between side and perimeter of squares is given by:
$$
Perimeter = 4 * Side
$$

If you denote $y$ as the dependent variable _Perimeter_, and $x$ as the independent variable _Side_ we cam write rewrite as: 
$$
y = 4 * x
$$
`r solend()`

## Functions and mathematical models: Plots

In today's lab you will compute the output of functions and plot them. To do so, you will need functionality from the tidyverse package such as `tibble()`, `mutate()`, and `ggplot()`. If  you don't have the package installed, go to the RStudio menu, select Tools, click Install Packages, type `tidyverse` and click install.


`r qbegin(4)`
Load the `tidyverse` package, then create a data set called `squares` containing the perimeter of four squares having sides of length $0, 2, 5, 9$ metres, and then plot the `squares` data as points

_**Hint:** Remember that to combine multiple numbers together we use the function `c()`._
`r qend()`

`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`
```{r}
#Load tidyverse
library(tidyverse)

#Create 'squares' data
squares <- tibble(
  side = c(0, 2, 5, 9),
  perimeter = 4 * side
)

squares
```


```{r}
#Create Plot
ggplot(data = squares, aes(x = side, y = perimeter)) +
  geom_point() +
  labs(x = 'Side (m)', y = 'Perimeter (m)')
```
`r solend()`

`r qbegin(5)`
Now, instead of just four points, we will obtain many more, one hundred, and use them to visualise the relationship between side and perimeter of squares.

Create a sequence of one hundred side lengths (x) going from 0 to 3 metres.

Compute the corresponding perimeters (y).

Plot the side and perimeter data as points on a graph.

Visualise the functional relationship between side and perimeter of squares. To do so, use the function `geom_line()` to connect the computed points with lines.
`r qend()`

`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`
Let's start by creating the side and perimeter data:
```{r}
squares_grid <- tibble(
  side = seq(0, 3, length.out = 100),
  perimeter = 4 * side
)
```

Plot the individual points:
```{r}
ggplot(data = squares_grid, aes(x = side, y = perimeter)) +
  geom_point() +
  labs(x = 'Side (m)', y = 'Perimeter (m)', title = 'Perimeter = 4 Side')
```

Visualise the functional relationship by connecting the individual points with lines:
```{r}
ggplot(data = squares_grid, aes(x = side, y = perimeter)) +
  geom_line(colour = 'blue') +
  labs(x = 'Side (m)', y = 'Perimeter (m)', title = 'Perimeter = 4 Side')
```
`r solend()`


The function $y = 4 \ x$ that you plotted above is an example of a function representing a mathematical model.

We typically validate a model using experimental data. However, we all know how squares work and that two squares with the same side will have the same perimeter (more on this later). 

`r qbegin(6)`
The Scottish National Gallery kindly provided us with measurements of side and perimeter (in metres) for a sample of 10 square paintings.

The data are provided below:
```{r eval=FALSE}
sng <- tibble(
  side = c(1.3, 0.75, 2, 0.5, 0.3, 1.1, 2.3, 0.85, 1.1, 0.2),
  perimeter = c(5.2, 3.0, 8.0, 2.0, 1.2, 4.4, 9.2, 3.4, 4.4, 0.8)
)
```

Plot the mathematical model of the relationship between side and perimeter for squares, and superimpose on top the experimental data from the Scottish National Gallery.
`r qend()`

`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`
```{r squares-scatterplot, fig.cap='The exact relationship between side and perimeter of squares.'}
sng <- tibble(
  side = c(1.3, 0.75, 2, 0.5, 0.3, 1.1, 2.3, 0.85, 1.1, 0.2),
  perimeter = c(5.2, 3.0, 8.0, 2.0, 1.2, 4.4, 9.2, 3.4, 4.4, 0.8)
)

ggplot() +
  geom_line(data = squares_grid, aes(x = side, y = perimeter), colour = 'blue') +
  geom_point(data = sng, aes(x = side, y = perimeter), colour = 'black', 
             alpha = 0.5, size = 3) +
  labs(x = 'Side (m)', y = 'Perimeter (m)')
```

The above plot shows perfect agreement between the observed data and the model.
`r solend()`


`r qbegin(7)`
Use the mathematical model to predict the perimeter of a painting with a side of 1.5 metres.
`r qend()`

`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`
We do not have a painting with a side of 1.5 metres within the random sample of paintings from the Scottish National Gallery.
We predict the perimeter of an unobserved squared painting having a 1.5 metre side using the mathematical model.

You can obtained this prediction either using a visual approach or an algebraic one.

<br>
**Visual approach**

```{r echo=FALSE}
ggplot() +
  geom_line(data = squares_grid, aes(x = side, y = perimeter), colour = 'blue') +
  geom_point(data = sng, aes(x = side, y = perimeter), colour = 'black', 
             alpha = 0.5, size = 3) +
  geom_segment(aes(x = 1.5, xend = 1.5, y = 0, yend = 4 * 1.5), linetype = 2, 
               colour = 'red', arrow = arrow(length = unit(0.5, "cm"))) +
  geom_segment(aes(x = 1.5, xend = 0 , y = 4 * 1.5, yend = 4 * 1.5), linetype = 2, 
               colour = 'red', arrow = arrow(length = unit(0.5, "cm"))) +
  labs(x = 'Side (m)', y = 'Perimeter (m)')
```

Sometimes we can directly read a predicted value from the graph of the functional relationship.

Consider the plot created in the previous question. First, we need to check where x = 1.5. Then, we draw a vertical dashed line until it meets the blue line. The y value corresponding to x = 1.5 can be read off the y-axis.

However, in this case it is not that easy to read it from the drawing... Let's try the next approach.

<br>
**Algebraic approach**

You can substitute the x value in the formula and calculate the corresponding y value.
$$
y = 4 * x = 4 * 1.5 = 6
$$

<br>
We might write this up as:

:::int
The predicted perimeter of squared paintings having a 1.5m side is 6m.
:::

**NOTE**: Don't forget to always include the measurement units when reporting/writing-up results!

`r solend()`

# Statistical models

Consider now the relationship between height (in inches) and handspan (in cm). @Utts2015 provides data for a sample of 167 students which reported their height and handspan as part of a class survey. 

Your task is to investigate how handspan varies as a function of height for the students in the sample.

`r optbegin('Data: handheight.csv.', FALSE, show = TRUE, toggle = params$TOGGLE)`
**Download link**

[Download the data here](https://uoepsy.github.io/data/handheight.csv){target="_blank"}

**Description**

The data set records the height and handspan reported by a random sample of 167 students as part of a class survey [@Utts2015].

The variables are:

- `height`, measured in inches
- `handspan`, measured in centimetres

**Preview**

The first six rows of the data are:

```{r echo=FALSE}
library(kableExtra)
handheight <- read_csv(file = 'https://uoepsy.github.io/data/handheight.csv')
kable(head(handheight), align = 'c') %>%
  kable_styling(full_width = FALSE) %>%
  column_spec(1:2, width = '10em')
```
`r optend()`


`r qbegin(8)`
Read the handheight data into R and name the data set `handheight`. 

Using a scatterplot (since the variables are numeric and continuous) to visualise the relationship between the two numeric variables, comment on any main differences you notice with the relationship between side and perimeter of squares. Note if you detected outliers or points that do not fit with the pattern in the rest of the data.

`r qend()`

`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`
```{r}
handheight <- read_csv(file = 'https://uoepsy.github.io/data/handheight.csv')
head(handheight)
```

We can also add marginal boxplots for each variable using the package `ggExtra`. Before using the package, make sure you have it installed via `install.packages('ggExtra')` in the console and loaded `library(ggExtra)` within an R chunk.

```{r handheight-scatterplot, fig.cap='The statistical relationship between height and handspan.'}
library(ggExtra)

plt <- ggplot(handheight, aes(x = height, y = handspan)) +
  geom_point(size = 3, alpha = 0.5) +
  labs(x = 'Height (in.)', y = 'Handspan (cm)')

ggMarginal(plt, type = 'boxplot')
```

Outliers are extreme observations that are not possible values of a variable or that do not seem to fit with the rest of the data. This could either be:

- *marginally* along one axis: points that have an unusual (too high or too low) x-coordinate or y-coordinate;
- *jointly*: observations that do not fit with the rest of the point cloud.

The boxplots in Figure \@ref(fig:handheight-scatterplot) do not highlight any outliers in the marginal distributions of height and handspan.
Furthermore, from the scatterplot we do not notice any extreme observations or points that do not fit with the rest of the point cloud.

We notice a moderate, positive linear relationship between height and handspan.

Recall Figure \@ref(fig:squares-scatterplot), displaying the relationship between side and perimeters of squares.
In the plot we notice two points on top of each other, reflecting the fact that two squares having the same side will always have the same perimeter.
In fact, the data from the Scottish National Gallery include two squared paintings with a side of 1.1m, both having a measured perimeter of 4.4m.

Figure \@ref(fig:handheight-scatterplot), instead, displays the relationship between height and handspan of a sample of students. The first thing that grabs our attention is the fact that students having the same height do not necessarily have the same handspan. Rather, we clearly see a variety of handspan values for students all having a height of, for example, 70in. To be more precise, the seven students who are 70 in. tall all have differing handspans.
`r solend()`


`r qbegin(9)`
Using the following command, superimpose on top of the scatterplot a best-fit line describing how handspan varies as a function of height.
For the moment, the argument `se = FALSE` tells R to not display uncertainty bands.
```
geom_smooth(method = lm, se = FALSE)
```

Comment on any differences between the lines representing the linear relationship between (a) the side and perimeter of square and (b) height and handspan.
`r qend()`

`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`
```{r handheight-fitted-model, fig.cap='The best-fit line.'}
ggplot(handheight, aes(x = height, y = handspan)) +
  geom_point(size = 3, alpha = 0.5) +
  geom_smooth(method = lm, se = FALSE) +
  labs(x = 'Height (in.)', y = 'Handspan (cm)')
```

The line representing the relationship between side and perimeter of squares is able to predict the actual perimeter value from the measurement of the side of a square.
This is possible because the relationship between side and perimeter is an **exact** one. 
That is, any squares having the same side will have the same perimeter, and there will be no variation in those values.

The line that best fits the relationship between height and handspan, instead, is only able to predict the **average** handspan for a given value of height.
This is because there will be a distribution of handspans at each value of height.
The line will fit the trend/pattern in the values, but there will be individual-to-individual variability that we must accept around that average pattern.
`r solend()`

:::red
## Types of Models: Deterministic vs Statistical

__Deterministic (*Example: Perimeter & Side*)__

The mathematical model 
$$
Perimeter = 4 * Side
$$ 
or, equivalently, 
$$
y = 4 * x
$$
represents the relationship between side and perimeter of squares. This is an example of a _deterministic model_ as it is a model of an *exact relationship* - there can be no deviation.

__Statistical (*Example: Height & Handspan*)__

The relationship between height and handspan shows deviations from the 'average pattern'. Hence, we need to create a model that allows for deviations from the linear relationship - we need a _statistical model_.

A statistical model includes *both* a deterministic function and a random error term:
$$
Handspan = \beta_0 + \beta_1 * Height + \epsilon
$$
or, in short,
$$
y = \underbrace{\beta_0 + \beta_1 * x}_{\text{function of }x} + \underbrace{\epsilon}_{\text{random error}}
$$

The deterministic function need not be linear if the scatterplot displays signs of nonlinearity.
In the equation above, the terms $\beta_0$ and $\beta_1$ are numbers specifying where the line going through the data meets the y-axis and its slope (rate of increase/decrease).

:::

`r qbegin(10)`
```{r eval=FALSE, echo=FALSE}
mdl <- lm(handspan ~ 1 + height, data = handheight)
equatiomatic::extract_eq(mdl, ital_vars = TRUE, use_coefs = TRUE)
```

The line of best-fit is given by:^[Yes, the error term is gone. This is because the line of best-fit gives you the prediction of the average handspan for a given height, and not the individual handspan of a person, which will almost surely be different from the prediction of the line.]

$$
\widehat{Handspan} = -3 + 0.35 \ Height
$$

Calculate the predicted handspan of a student who is (a) 73in tall, and (b) 5in tall. 

`r qend()`

`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`
- The predicted average handspan for students who are 73in tall is $-3 + 0.35 * 73 = 22.55$cm.
- The predicted average handspan for students who are 5in tall is $-3 + 0.35 * 5 = -1.25$cm. 


But wait, handspan can not be negative... This *does not* make any sense!
That's right, we went too far off the range of the available data on heights, which were between 57in and 78in. We extrapolated. This is very dangerous...

```{r, echo=FALSE, fig.cap = 'Source: Randall Munroe, xkcd.com'}
knitr::include_graphics('https://imgs.xkcd.com/comics/extrapolating.png')
```
`r solend()`


# References

<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>