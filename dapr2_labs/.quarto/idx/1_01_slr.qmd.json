{"title":"Simple Linear Regression","markdown":{"yaml":{"title":"Simple Linear Regression","link-citations":true,"params":{"SHOW_SOLS":true,"TOGGLE":true},"editor_options":{"chunk_output_type":"console"}},"headingText":"knitr::opts_chunk$set(cache = TRUE)","containsRefs":false,"markdown":"\n\n```{r setup, include=FALSE}\nsource('assets/setup.R')\n\nset.seed(1)\n```\n\n:::lo\n### <i class=\"fa fa-graduation-cap\"></i> Learning Objectives\nAt the end of this lab, you will:\n\n1. Be able to specify a simple linear model  \n2. Understand what fitted values and residuals are \n3. Be able to interpret the coefficients of a fitted model\n\n### <i class=\"fa fa-check-square-o fa-2\"></i> Requirements\n\n1. Be up to date with lectures  \n2. Have installed R and RStudio on your own computer (unless you have a Chromebook where you may continue to use the PPLS RStudio Server)  \n\n### <i class=\"fab fa-r-project\"></i> Required R Packages\nRemember to load all packages within a code chunk at the start of your RMarkdown file using `library()`. If you do not have a package and need to install, do so within the console using `install.packages(\" \")`. For further guidance on installing/updating packages, see Section C [here](https://uoepsy.github.io/files/install-update-r#update-pkgs). \n\nFor this lab, you will need to load the following package(s):\n\n* **tidyverse** \n* **sjPlot**\n* **kableExtra**\n\n### <i class=\"fa fa-pencil-square-o\" aria-hidden=\"true\"></i> Presenting Results\nAll results should be presented following [APA guidelines](https://apastyle.apa.org/instructional-aids/numbers-statistics-guide.pdf).If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the [rmd bootcamp](https://uoepsy.github.io//rmd-bootcamp/).\n\n### <i class=\"fa fa-file\"></i> Lab Data\nYou can download the data required for this lab [here](https://uoepsy.github.io/data/wellbeing_rural.csv) or read it in via this link https://uoepsy.github.io/data/wellbeing_rural.csv. \n\n:::\n\n# Study Overview \n\n> **Research Question**\n> \n> Does the number of weekly social interactions influence wellbeing scores? \n\n`r optbegin(\"Wellbeing/Rurality data codebook.\", olabel=FALSE, toggle=params$TOGGLE)`  \n\n__Description__\n\nFrom the Edinburgh & Lothians, 100 city/suburb residences and 100 rural residences were chosen at random and contacted to participate in the study. The Warwick-Edinburgh Mental Wellbeing Scale (WEMWBS), was used to measure mental health and well-being. \n\nParticipants filled out a questionnaire including items concerning: estimated average number of hours spent outdoors each week, estimated average number of social interactions each week (whether on-line or in-person), whether a daily routine is followed (yes/no). For those respondents who had an activity tracker app or smart watch, they were asked to provide their average weekly number of steps.  \n  \n  \n__Data Dictionary__\n\nThe data in `wellbeing.csv` contain seven attributes collected from a random sample of $n=200$ hypothetical residents over Edinburgh & Lothians, and include: \n\n```{r echo=FALSE, message=FALSE, warning=FALSE}\nmwdata  <- read_csv(\"https://uoepsy.github.io/data/wellbeing_rural.csv\")\ntibble(\nvariable = names(mwdata),\ndescription = c(\"Age in years of respondent\",\"Self report estimated number of hours per week spent outdoors \", \"Self report estimated number of social interactions per week (both online and in-person)\", \"Binary 1=Yes/0=No response to the question 'Do you follow a daily routine throughout the week?'\", \"Warwick-Edinburgh Mental Wellbeing Scale (WEMWBS), a self-report measure of mental health and well-being. The scale is scored by summing responses to each item, with items answered on a 1 to 5 Likert scale. The minimum scale score is 14 and the maximum is 70\", \"Location of primary residence (City, Suburb, Rural)\", \"Average weekly number of steps in thousands (as given by activity tracker if available)\")\n) %>% gt::gt()\n```\n  \n  \n__Preview__\n\nThe first six rows of the data are:\n\n```{r echo=FALSE, message=FALSE}\nread_csv('https://uoepsy.github.io/data/wellbeing_rural.csv') %>% head %>% gt::gt()\n```\n  \n`r optend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Setup\n\n`r qbegin(\"Setup\", qlabel = FALSE)`  \n\n1. Create a new RMarkdown file\n2. Load the required package(s)\n3. Read the wellbeing dataset into R, assigning it to an object named `mwdata`\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n```{r message=FALSE}\n#Loading the required package(s)\nlibrary(tidyverse)\nlibrary(sjPlot)\nlibrary(kableExtra)\n\n# Reading in data and storing to an object named 'mwdata'\nmwdata <- read_csv(\"https://uoepsy.github.io/data/wellbeing_rural.csv\")\n```\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Exercises \n\n## Data Exploration\n\nThe common first port of call for almost any statistical analysis is to explore the data, and we can do this visually and/or numerically.\n\n+----------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|                |  Marginal Distributions                                                                                                                                         | Bivariate Associations                                                                                                                                                       |\n+================+=================================================================================================================================================================+==============================================================================================================================================================================+\n|**Description** |  The distribution of each variable *without* reference to the values of the other variables                       | Describing the relationship between two numeric variables                                                                                                                    |\n+----------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|**Visually**    | Plot each variable individually.                                                                                                                                | Plot associations among two variables.                                                                                                                                       |\n|  <br>          | <br>                                                                                                                                                            | <br>                                                                                                                                                                         |\n|  <br>          | <br>                                                                                                                                                            | <br>                                                                                                                                                                         |\n|                | You could use, for example, `geom_density()` for a density plot or `geom_histogram()` for a histogram to comment on and/or examine:                             | You could use, for example, `geom_point()` for a scatterplot  to comment on and/or examine:                                                                                                     |\n|  <br>          | <br>                                                                                                                                                            | <br>                                                                                                                                                                         |\n|  <br>          | <br>                                                                                                                                                            | <br>                                                                                                                                                                         |\n|                |<ul><li> The *shape* of the distribution. Look at the shape, centre and spread of the distribution. Is it symmetric or skewed? Is it unimodal or bimodal? </li>  | <li>The *direction* of the association indicates whether there is a positive or negative association  </li>                                                                 \n|                |<li> Identify any *unusual observations*. Do you notice any extreme observations (i.e., outliers)? </li>                                                         | <li>The *form* of association refers to whether the relationship between the variables can be summarized well with a straight line or some more complicated pattern </li>   \n|                |                                                                                                                                                                 | <li>The *strength* of association entails how closely the points fall to a recognizable pattern such as a line  </li>                                                       \n|                |                                                                                                                                                                 | <li>*Unusual observations* that do not fit the pattern of the rest of the observations and which are worth examining in more detail </li></ul>                              |\n+----------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|**Numerically** | Compute and report summary statistics e.g., mean, standard deviation, median, min, max, etc.                                                                    | Compute and report the correlation coefficient.                                                                                                                              |\n|  <br>          | <br>                                                                                                                                                            | <br>                                                                                                                                                                         |\n|  <br>          | <br>                                                                                                                                                            | <br>                                                                                                                                                                         |\n|                | You could, for example, calculate summary statistics such as the mean (`mean()`) and standard deviation (`sd()`), etc. within `summarize()`                     | <br>                                                                                                                                                                         |\n|                |                                                                                                                                                                 | You can use the `cor()` function to calculate this                                                                                                                           |   \n+----------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n### Marginal Distributions\n\n`r qbegin(1)`\n\nVisualise and describe the marginal distributions of wellbeing scores and social interactions.\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint \n\n*Plot interpretation*  \n- The *shape*, *center* and *spread* of the distribution  \n- Whether the distribution is *symmetric* or *skewed*  \n- Whether the distribution is *unimodal* or *bimodal* \n\n*Plotting tips*  \n- Use `\\n` to wrap text in your titles and or axis labels  \n- The **patchwork** package allows us to arrange multiple plots in two ways - `|` arranges the plots adjacent to one another, and `/` arranges the plots on top of one another  \n\n*Table tips*  \n- The **kableExtra** package allows us to produce well formatted tables for our descriptive statistics. To do so, you need to specify the `kable()` and `kable_styling()` arguments  \n- Review the guidance on the [rmd bootcamp](https://uoepsy.github.io//rmd-bootcamp/), particularly Lesson 4\n\n:::\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n\n::: {.panel-tabset}\n\n## Wellbeing (WEMWBS) Scores\n\nVisualisation of distribution:\n```{r}\n#| label: fig-densbox-wb\n#| fig-cap: \"Distribution of Wellbeing (WEMWBS) Scores\"\n#| fig-alt: |\n#|   Density plot of wellbeing scores.\n#|   Unimodal distribution, with most of the wellbeing scores were between roughly 30 and 45. \n#|   All scores within range. \n\nggplot(data = mwdata, aes(x = wellbeing)) +\n  geom_density() +\n  labs(x = \"Wellbeing (WEMWBS) Scores\", \n       y = \"Probability density\")\n```\n\nInitial observations from plot:\n\n+ The distribution of wellbeing scores was unimodal\n+ Most of the wellbeing scores were between roughly 30 and 45\n+ The lowest wellbeing in the sample was approximately 22 and the highest approximately 59. This suggested there was a fair high degree of variation in the data\n+ Scores were within the range of possible values\n\nDescriptive (or summary) statistics for wellbeing scores:\n\n```{r}\n#| label: tbl-w1-desc-wb\n#| tbl-cap: Wellbeing Descriptive Statistics\nmwdata %>% \n  summarize(\n    M = mean(wellbeing), \n    SD = sd(wellbeing)\n    ) %>%\n    kable(caption = \"Wellbeing Descriptive Statistics\", align = \"c\", digits = 2) %>%\n    kable_styling(full_width = FALSE)\n```\n\nFollowing the exploration above, we can describe the wellbeing variable as follows:\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nThe marginal distribution of scores on the WEMWBS was unimodal with a mean of approximately `r round(mean(mwdata$wellbeing),2)`. There was variation in WEMWBS scores (SD = `r round(sd(mwdata$wellbeing),2)`)\n\n:::\n\n## Social Interactions\n\nVisualisation of distribution:\n\n```{r}\n#| label: fig-densbox-socint\n#| fig-cap: \"Distribution of Number of Social Interactions\"\n#| fig-alt: |\n#|   Density plot of number of weekly social interactions.\n#|   Unimodal distribution, with most of the weekly number of social interactions between roughly 8 and 15. \n\nggplot(data = mwdata, aes(x = social_int)) +\n  geom_density() +\n  labs(x = \"Social Interactions (Number per Week)\", \n       y = \"Probability density\")\n```\n\nInitial observations from plot:\n\n+ The distribution of social interactions was unimodal\n+ Most of the participants had between 8 and 15 social interactions per week \n+ The fewest social interactions per week was approximately 3, and the highest approximately 24. This suggested there was a fair high degree of variation in the data\n\nDescriptive (or summary) statistics for the number of weekly social interactions per week:\n\n```{r}\n#| label: tbl-w1-desc-socint\n#| tbl-cap: Social Interactions Descriptive Statistics\nmwdata %>% \n  summarize(\n    M = mean(social_int), \n    SD = sd(social_int)\n    ) %>%\n    kable(caption = \"Social Interactions Descriptive Statistics\", align = \"c\", digits = 2) %>%\n    kable_styling(full_width = FALSE)\n```\n\nFollowing the exploration above, we can describe the social interactions variable as follows:\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nThe marginal distribution of numbers of social interactions per week was unimodal with a mean of approximately `r round(mean(mwdata$social_int),2)`. There was variation in numbers of social interactions (SD = `r round(sd(mwdata$social_int),2)`)\n\n:::\n\n:::\n\n`r solend()`\n\n### Associations among Variables\n\n`r qbegin(2)`\nCreate a scatterplot of wellbeing score and social interactions *before* calculating the correlation between them.  \n\n:::imp\n__Correlation Matrix__  \n\nA table showing the correlation coefficients - $r_{(x,y)}=\\frac{\\mathrm{cov}(x,y)}{s_xs_y}$ - between variables. Each cell in the table shows the association between two variables. The diagonals show the correlation of a variable with itself (and are therefore always equal to 1).  \n\n:::blue\nIn `R`, we can create a correlation matrix by giving the `cor()` function a dataframe. However, we only want to give it 2 columns here. Think about how we select specific columns, either giving the column numbers inside `[]`, or using `select()`. \n:::\n\n:::\n\nMaking reference to both the plot and correlation coefficient, describe the association between wellbeing and social interactions among participants in the Edinburgh & Lothians sample. \n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\n*Plot*  \nWe are trying to investigate how wellbeing varies by varying numbers of weekly social interactions. Hence, wellbeing is the dependent variable (on the y-axis), and social interactions is the independent variable (on the x-axis).\n\n*Correlation*  \nMake sure to round your numbers in-line with APA 7th edition guidelines. The `round()` function will come in handy here, as might this [APA numbers and statistics guide](https://apastyle.apa.org/instructional-aids/numbers-statistics-guide.pdf)! \n\n:::\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n\nLet's produce a scatterplot:\n\n```{r}\n#| label: fig-mwdata-scatterplot\n#| fig-cap: \"Association between Wellbeing and Social Interactions\"\n\nggplot(data = mwdata, aes(x = social_int, y = wellbeing)) +\n  geom_point() +\n  labs(x = \"Social Interactions (Number per Week)\", \n       y = \"Wellbeing (WEMWBS) Scores\")\n```\n\nTo comment on the strength of the linear association we compute the correlation coefficient in either of the following ways:\n\n::: {.panel-tabset}\n\n## Index dataframe (`[]`)\n\n```{r}\n# correlation matrix of the two columns of interest - (check with columns we need, in this case 3 & 5)\nround(cor(mwdata[,c(3,5)]), digits = 2)\n```\n\n## Variable selection (`select()`)\n\n```{r}\n# select only the columns we want by name, and pass this to cor()\nmwdata %>% \n  select(social_int, wellbeing) %>%\n  cor() %>%\n    round(digits = 2)\n```\n\n:::\n\nAnd we can see that via either method, the correlation is \n$$\nr_{\\text({Social~Interactions,~~ Wellbeing})} = .24\n$$\n<br>\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nThere was a weak, positive, linear association between the weekly number of social interactions and WEMWBS scores for the participants in the sample ($r$ = .24). More social interactions were associated, on average, with higher wellbeing scores.\n\n:::\n\n<br>\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n## Model Specification and Fitting\n\nThe scatterplot highlighted a linear relationship, where the data points were scattered around an underlying linear pattern with a roughly-constant spread as x varied.\n\nHence, we will try to fit a simple (i.e., one x variable only) linear regression model:\n\n$$\ny_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i \n\\\\\n\\quad \\text{where} \\quad \\epsilon_i \\sim N(0, \\sigma) \\text{ independently}\n$$\n\n::: {.callout-important icon=false collapse=true}\n# What does $y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i \\quad \\text{where} \\quad \\epsilon_i \\sim N(0, \\sigma) \\text{ independently}$ mean?\nLets break the statement down into smaller parts:\n\n###### $y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i$\n+ $y_i$ is our measured outcome variable (our DV)\n+ $x_i$ is our measured predictor variable (our IV)\n+ $\\beta_0$ is the model intercept\n+ $\\beta_1$ is the model slope\n\n###### $\\epsilon \\sim N(0, \\sigma) \\text{ independently}$\n+ $\\epsilon$ is the residual error \n+ $\\sim$ means 'distributed according to'\n+ $\\sim N(0, \\sigma) \\text{ independently}$ means 'normal distribution with a mean of 0 and a variance of $\\sigma$' \n+ Together, we can say that the errors around the line have a mean of zero and constant spread as x varies. \n\n:::\n\n<br>\n\n`r qbegin(3)`\n\nFirst, write the equation of the fitted line. \n\nNext, using the `lm()` function, fit a simple linear model to predict wellbeing (DV) by social interactions (IV), naming the output `mdl`.\n\nLastly, update your equation of the fitted line to include the estimated coefficients.\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nThe syntax of the `lm()` function is:\n\n```{r eval = FALSE}\n\n[model name] <- lm([response variable i.e., dependent variable] ~ [explanatory variable i.e., independent variable], data = [dataframe])\n```\n\n:::\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n\nFirst, lets specify the fitted model, which can be written either as:\n\n::: {.panel-tabset}\n\n## Option A\n\n$$\n\\widehat{Wellbeing} = \\hat \\beta_0 + \\hat \\beta_1 \\cdot Social~Interactions\n$$\n\n## Option B\n\n$$\n\\widehat{Wellbeing} = \\hat \\beta_0 \\cdot 1 + \\hat \\beta_1 \\cdot Social~Interactions\n$$\n:::\n\nTo fit the model in `R`, as the variables are in the `mwdata` dataframe, we would write:\n\n::: {.panel-tabset}\n\n## Option A\n\n```{r}\nmdl <- lm(wellbeing ~ social_int, data = mwdata)\nmdl\n```\n\n## Option B\n\n```{r}\nmdl <- lm(wellbeing ~ 1 + social_int, data = mwdata)\nmdl\n```\n\n\n:::\n\n::: {.callout-important icon=false collapse=true}\n## Why is there a 1 in the Option B's? \nWhen we specify the linear model in `R`, we include after the tilde sign ($\\sim$), the variables that appear to the right of the $\\hat \\beta$s. The intercept, or $\\beta_0$, is a constant. That is, we could write it as multiplied by 1.\n\nIncluding the 1 explicitly is not necessary because it is included by default (you can check this by comparing the outputs of A & B above with and without the 1 included - the estimates are the same!). After a while, you will find you just want to drop the 1 (i.e., Option B) when calling `lm()` because you know that it’s going to be there, but in these early weeks we tried to keep it explicit to make it clear that you want to the intercept to be estimated. \n:::\n\nNote that by calling the name of the fitted model, `mdl`, you can see the estimated regression coefficients $\\hat \\beta_0$ and $\\hat \\beta_1$. We can add these values to the fitted line: \n\n$$\n\\widehat{Wellbeing} = 32.41 + 0.32 \\cdot Social~Interactions \\\\\n$$\n\n`r solend()`\n\n<br>\n\n`r qbegin(4)`\nExplore the following equivalent ways to obtain the estimated regression coefficients --- that is, $\\hat \\beta_0$ and $\\hat \\beta_1$ --- from the fitted model:\n\n- `mdl`\n- `mdl$coefficients`\n- `coef(mdl)`\n- `coefficients(mdl)`\n- `summary(mdl)`\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n\nThe estimated parameters returned by the below methods are all equivalent. However, `summary()` returns more information.\n\n::: {.panel-tabset}\n\n## mdl()\nSimply invoke the name of the fitted model:\n```{r}\nmdl\n```\n\n## mdl$coefficients\n\n```{r}\nmdl$coefficients\n```\n\n## coef(mdl)\n```{r}\ncoef(mdl)\n```\n\n\n## coefficients(mdl)\n\n```{r}\ncoefficients(mdl)\n```\n\n## summary(mdl)\nLook under the “Estimate” column:\n```{r}\nsummary(mdl)\n```\n\n:::\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nThe estimated intercept is $\\hat \\beta_0 = 32.41$ and the estimated slope is $\\hat \\beta_1 = 0.32$.\n\n:::\n\n`r solend()`\n\n<br>\n\n`r qbegin(5)`\nExplore the following equivalent ways to obtain the estimated standard deviation of the errors --- that is, $\\hat \\sigma$ --- from the fitted model `mdl`:\n\n- `sigma(mdl)`\n- `summary(mdl)`\n\n`r optbegin('Huh? What is $\\\\sigma$?', FALSE)`\nThe standard deviation of the errors, denoted by $\\sigma$, is an important quantity that our model estimates. It represents how much individual data points tend to deviate above and below the regression line. \n\nA small $\\sigma$ indicates that the points hug the line closely and we should expect fairly accurate predictions, while a large $\\sigma$ suggests that, even if we estimate the line perfectly, we can expect individual values to deviate from it by substantial amounts.\n\nThe *estimated* standard deviation of the errors is denoted $\\hat \\sigma$, and is estimated by essentially averaging squared residuals (giving the variance) and taking the square-root: \n\n$$\n\\begin{align}\n& \\hat \\sigma = \\sqrt{\\frac{SS_{Residual}}{n - k - 1}} \\\\\n\\qquad \\\\\n& \\text{where} \\\\\n& SS_{Residual} = \\textrm{Sum of Squared Residuals} = \\sum_{i=1}^n{(\\epsilon_i)^2}\n\\end{align}\n$$\n`r optend()`\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n\nThe estimated standard deviation of the errors can be equivalently obtained by the below methods. However, `summary()` returns more information.\n\n::: {.panel-tabset}\n\n## sigma(mdl)\n\n```{r}\nsigma(mdl)\n```\n\n## summary(mdl)\n\nLook at the \"Residual standard error\" entry of the `summary(mdl)` output:\n```{r}\nsummary(mdl)\n```\n\n:::{.callout-note}\n\nThe term \"Residual standard error\" is a misnomer, as the help page for `sigma` says (check `?sigma`). However, it's hard to get rid of this bad name as it has been used in too many books showing R output.\n\n:::\n\n:::\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\n\nThe estimated standard deviation of the errors is $\\hat \\sigma = `r round(sigma(mdl), 2)`$.\n\n:::\n\n`r solend()`\n\n<br>\n\n`r qbegin(6)`\n\nInterpret the estimated intercept, slope, and standard deviation of the errors in the context of the research question.\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nTo interpret the estimated standard deviation of the errors we can use the fact that about 95\\% of values from a normal distribution fall within two standard deviations of the center.\n\n:::\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n\n::: {.panel-tabset}\n\n## Intercept\n\nThe estimated wellbeing score associated to zero weekly social interactions is 32.41.\n\n## Slope\n\nThe estimated increase in wellbeing associated to one additional weekly social interaction is 0.32.\n\n## Standard deviation of the errors\n\nFor any particular numnber of weekly social interactions, participants' wellbeing scores should be distributed above and below the regression line with standard deviation estimated to be $\\hat \\sigma = `r round(sigma(mdl), 2)`$. Since $2 \\hat \\sigma = `r round((sigma(mdl)*2), 2)`$, we expect most (about 95\\%) of the participants' wellbeing scores to be within about 11 points from the regression line.\n\n:::\n\n`r solend()`\n\n<br>\n\n`r qbegin(7)`\nPlot the data and the fitted regression line. To do so:\n\n- Extract the estimated regression coefficients e.g., via `betas <- coef(mdl)`\n- Extract the first entry of `betas` (i.e., the intercept) via `betas[1]`\n- Extract the second entry of `betas` (i.e., the slope) via `betas[2]`\n- Provide the intercept and slope to the function\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\n*Extracting values*  \nThe function `coef(mdl)` returns a vector (a sequence of numbers all of the same type). To get the first element of the sequence you append `[1]`, and `[2]` for the second.\n\n*Plotting*  \nIn your `ggplot()`, you will need to specify `geom_abline()`. This might help get you started:\n\n```{r eval = FALSE}\ngeom_abline(intercept = <intercept>, slope = <slope>)\n```\n\n:::\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n\nFirst extract the values required:\n```{r}\nbetas <- coef(mdl)\nintercept <- betas[1]\nslope <- betas[2]\n```\n\nWe can plot the model as follows:\n```{r}\nggplot(data = mwdata, aes(x = social_int, y = wellbeing)) +\n  geom_point() +\n  geom_abline(intercept = intercept, slope = slope, color = 'blue') + \n  labs(x = \"Social Interactions (Number per Week)\", y = \"Wellbeing (WEMWBS) Scores\")\n```\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n## Predicted Values & Residuals\n\n:::statbox \n\n### Predicted Values\n\n#### Model predicted values for sample data:\n\nWe can get out the model predicted values for $y$, the \"y hats\" ($\\hat y$), for the data in the sample using various functions:\n\n- `predict(<fitted model>)`\n- `fitted(<fitted model>)`\n- `fitted.values(<fitted model>)`\n- `mdl$fitted.values`\n\nFor example, this will give us the estimated wellbeing score (point on our regression line) for each observed value of social interactions for each of our 200 participants.\n\n```{r}\npredict(mdl)\n```\n\n#### Model predicted values for other (unobserved) data:\n\nTo compute the model-predicted values for unobserved data (i.e., data not contained in the sample), we can use the following function:\n\n- `predict(<fitted model>, newdata = <dataframe>)`\n\nFor this example, we first need to remember that the model predicts `wellbeing` using the independent variable `social_int`. Hence, if we want predictions for new (unobserved) data, we first need to create a tibble with a column called `social_int` containing the number of weekly social interactions for which we want the prediction, and store this as a dataframe.\n\n```{r}\n#Create dataframe 'newdata' containing 2, 25, and 28 weekly social interactions\nnewdata <- tibble(social_int = c(2, 25, 28))\nnewdata\n```\n\nThen we take `newdata` and add a new column called `wellbeing_hat`, computed as the prediction from the fitted `mdl` using the `newdata` above:\n\n```{r}\nnewdata <- newdata %>%\n  mutate(\n    wellbeing_hat = predict(mdl, newdata = newdata)\n  )\nnewdata\n```\n\n### Residuals\n\nThe residuals represent the deviations between the actual responses and the predicted responses and can be obtained either as\n\n- `mdl$residuals`\n- `resid(mdl)`\n- `residuals(mdl)`\n- computing them as the difference between the response ($y_i$) and the predicted response ($\\hat y_i$)\n\n:::\n\n<br>\n\n`r qbegin(8)`\n\nUse `predict(mdl)` to compute the fitted values and residuals. Mutate the `mwdata` dataframe to include the fitted values and residuals as extra columns.\n\nAssign to the following symbols the corresponding numerical values:\n\n- $y_{3}$ (response variable for unit $i = 3$ in the sample data)\n- $\\hat y_{3}$ (fitted value for the third unit)\n- $\\hat \\epsilon_{5}$ (the residual corresponding to the 5th unit, i.e., $y_{5} - \\hat y_{5}$)\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n```{r}\nmwdata_fitted <- mwdata %>%\n  mutate(\n    wellbeing_hat = predict(mdl),\n    resid = wellbeing - wellbeing_hat\n  )\n\nhead(mwdata_fitted)\n```\n\n- $y_{3}$ = `r round(mwdata_fitted[3,5], 2)` (see row 3, column 5)\n- $\\hat y_{3}$ = `r round(mwdata_fitted[3,8], 2)` (see row 3, column 8)\n- $\\hat \\epsilon_{5} = y_{5} - \\hat y_{5}$ = `r round(mwdata_fitted[5,5], 2)` -  `r round(mwdata_fitted[5,8], 2)` = -6.21 (see row 5, columns 5 and 8)\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n## Writing Up & Presenting Results\n\n`r qbegin(9)`\n\nProvide key model results in a formatted table.\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint \n\nUse `tab_model()` from the __sjPlot__ package. \n\nYou can rename your DV and IV labels by specifying `dv.labels` and `pred.labels`. To do so, specify your variable name on the left, and what you would like this to be named in the table on the right. \n\n:::\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n\n```{r}\n#| label: tbl-wb-socint-modresults\n#| tbl-cap: Regression Table for Wellbeing Model\ntab_model(mdl,\n          dv.labels = \"Wellbeing (WEMWBS) Scores\",\n          pred.labels = c(\"social_int\" = \"Social Interactions (Number per Week)\"),\n          title = \"Regression Table for Wellbeing Model\")\n          \n```\n\n`r solend()`\n\n<br>\n\n`r qbegin(10)`\n\nDescribe the design of the study, and the analyses that you undertook. Interpret your results in the context of the research question and report your model results in full.\n\nMake reference to your descriptive plots and/or statistics and regression table. \n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint \n\nMake sure to write your results up following [APA guidelines](https://apastyle.apa.org/instructional-aids/numbers-statistics-guide.pdf)\n\n:::\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nThe `mwdata` dataset contained information on 200 hypothetical participants who lived in Edinburgh & Lothians area. Using a between-subjects design, the researchers collected information on participants' wellbeing (measured via WEMWBS), outdoor time (hours per week), social interactions (number per week), routine (whether or not one was followed), location of residence (City, Suburb, or Rural), average weekly steps (in thousands), and age (in years).\n\nTo visualise the marginal distributions of wellbeing and social interactions, density plots were used. To understand the strength of association between the two variables, the correlation coefficient was estimated. To investigate whether the number of weekly social interactions influences wellbeing (WEMWBS) scores, the following simple linear regression model was used:\n\n$$\n\\text{Wellbeing} = \\beta_0 + \\beta_1 \\cdot \\text{Social Interactions}\n$$\nFrom @fig-densbox-wb and @fig-densbox-socint, we can see that both wellbeing $(M = `r round(mean(mwdata$wellbeing), 2)`, SD = `r round(sd(mwdata$wellbeing), 2)`)$ and social interactions $(M = `r round(mean(mwdata$social_int), 2)`, SD = `r round(sd(mwdata$social_int), 2)`)$ followed unimodal distributions. There was a weak, positive, linear association between WEMWBS scores and the weekly number of social interactions for the participants in the sample $(r = .24)$.\n\nFull regression results are displayed in @tbl-wb-socint-modresults. The estimated wellbeing score with no social interactions per week was `r round(mdl$coefficients[1], 2)`. Each additional social interaction was associated with a `r round(mdl$coefficients[2], 2)` point increase in wellbeing scores. \n\n:::\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Compile Report\n\n`r qbegin(\"Compile Report\", qlabel = FALSE)`  \n\nKnit your report to PDF, and check over your work. To do so, you should:\n\n- Make sure the **tinytex** package is installed\n- Makes sure the ‘yaml’ (bit at the very top of your document) looks something like this:\n\n```{}\n---\ntitle: \"this is my report title\"\nauthor: \"B1234506\"\ndate: \"07/09/2024\"\noutput: bookdown::pdf_document2\n---\n```\n\n::: {.callout-important icon=false collapse=true}\n# What to do if you cannot knit to PDF\nIf you are having issues knitting directly to PDF, try the following:  \n\n- Knit to HTML file  \n- Open your HTML in a web-browser (e.g. Chrome, Firefox)  \n- Print to PDF (Ctrl+P, then choose to save to PDF)  \n- Open file to check formatting\n:::\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\nYou must make sure you have **tinytex** installed in R so that you can “Knit” your Rmd document to a PDF file:\n\n```{r eval = FALSE}\ninstall.packages(\"tinytex\")\ntinytex::install_tinytex()\n```\n\n:::\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n\nYou should end up with a PDF file. If you have followed the above instructions and still have issues with knitting, speak with a tutor. \n\n`r solend()`\n","srcMarkdownNoYaml":"\n\n```{r setup, include=FALSE}\nsource('assets/setup.R')\n\n# knitr::opts_chunk$set(cache = TRUE)\nset.seed(1)\n```\n\n:::lo\n### <i class=\"fa fa-graduation-cap\"></i> Learning Objectives\nAt the end of this lab, you will:\n\n1. Be able to specify a simple linear model  \n2. Understand what fitted values and residuals are \n3. Be able to interpret the coefficients of a fitted model\n\n### <i class=\"fa fa-check-square-o fa-2\"></i> Requirements\n\n1. Be up to date with lectures  \n2. Have installed R and RStudio on your own computer (unless you have a Chromebook where you may continue to use the PPLS RStudio Server)  \n\n### <i class=\"fab fa-r-project\"></i> Required R Packages\nRemember to load all packages within a code chunk at the start of your RMarkdown file using `library()`. If you do not have a package and need to install, do so within the console using `install.packages(\" \")`. For further guidance on installing/updating packages, see Section C [here](https://uoepsy.github.io/files/install-update-r#update-pkgs). \n\nFor this lab, you will need to load the following package(s):\n\n* **tidyverse** \n* **sjPlot**\n* **kableExtra**\n\n### <i class=\"fa fa-pencil-square-o\" aria-hidden=\"true\"></i> Presenting Results\nAll results should be presented following [APA guidelines](https://apastyle.apa.org/instructional-aids/numbers-statistics-guide.pdf).If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the [rmd bootcamp](https://uoepsy.github.io//rmd-bootcamp/).\n\n### <i class=\"fa fa-file\"></i> Lab Data\nYou can download the data required for this lab [here](https://uoepsy.github.io/data/wellbeing_rural.csv) or read it in via this link https://uoepsy.github.io/data/wellbeing_rural.csv. \n\n:::\n\n# Study Overview \n\n> **Research Question**\n> \n> Does the number of weekly social interactions influence wellbeing scores? \n\n`r optbegin(\"Wellbeing/Rurality data codebook.\", olabel=FALSE, toggle=params$TOGGLE)`  \n\n__Description__\n\nFrom the Edinburgh & Lothians, 100 city/suburb residences and 100 rural residences were chosen at random and contacted to participate in the study. The Warwick-Edinburgh Mental Wellbeing Scale (WEMWBS), was used to measure mental health and well-being. \n\nParticipants filled out a questionnaire including items concerning: estimated average number of hours spent outdoors each week, estimated average number of social interactions each week (whether on-line or in-person), whether a daily routine is followed (yes/no). For those respondents who had an activity tracker app or smart watch, they were asked to provide their average weekly number of steps.  \n  \n  \n__Data Dictionary__\n\nThe data in `wellbeing.csv` contain seven attributes collected from a random sample of $n=200$ hypothetical residents over Edinburgh & Lothians, and include: \n\n```{r echo=FALSE, message=FALSE, warning=FALSE}\nmwdata  <- read_csv(\"https://uoepsy.github.io/data/wellbeing_rural.csv\")\ntibble(\nvariable = names(mwdata),\ndescription = c(\"Age in years of respondent\",\"Self report estimated number of hours per week spent outdoors \", \"Self report estimated number of social interactions per week (both online and in-person)\", \"Binary 1=Yes/0=No response to the question 'Do you follow a daily routine throughout the week?'\", \"Warwick-Edinburgh Mental Wellbeing Scale (WEMWBS), a self-report measure of mental health and well-being. The scale is scored by summing responses to each item, with items answered on a 1 to 5 Likert scale. The minimum scale score is 14 and the maximum is 70\", \"Location of primary residence (City, Suburb, Rural)\", \"Average weekly number of steps in thousands (as given by activity tracker if available)\")\n) %>% gt::gt()\n```\n  \n  \n__Preview__\n\nThe first six rows of the data are:\n\n```{r echo=FALSE, message=FALSE}\nread_csv('https://uoepsy.github.io/data/wellbeing_rural.csv') %>% head %>% gt::gt()\n```\n  \n`r optend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Setup\n\n`r qbegin(\"Setup\", qlabel = FALSE)`  \n\n1. Create a new RMarkdown file\n2. Load the required package(s)\n3. Read the wellbeing dataset into R, assigning it to an object named `mwdata`\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n```{r message=FALSE}\n#Loading the required package(s)\nlibrary(tidyverse)\nlibrary(sjPlot)\nlibrary(kableExtra)\n\n# Reading in data and storing to an object named 'mwdata'\nmwdata <- read_csv(\"https://uoepsy.github.io/data/wellbeing_rural.csv\")\n```\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Exercises \n\n## Data Exploration\n\nThe common first port of call for almost any statistical analysis is to explore the data, and we can do this visually and/or numerically.\n\n+----------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|                |  Marginal Distributions                                                                                                                                         | Bivariate Associations                                                                                                                                                       |\n+================+=================================================================================================================================================================+==============================================================================================================================================================================+\n|**Description** |  The distribution of each variable *without* reference to the values of the other variables                       | Describing the relationship between two numeric variables                                                                                                                    |\n+----------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|**Visually**    | Plot each variable individually.                                                                                                                                | Plot associations among two variables.                                                                                                                                       |\n|  <br>          | <br>                                                                                                                                                            | <br>                                                                                                                                                                         |\n|  <br>          | <br>                                                                                                                                                            | <br>                                                                                                                                                                         |\n|                | You could use, for example, `geom_density()` for a density plot or `geom_histogram()` for a histogram to comment on and/or examine:                             | You could use, for example, `geom_point()` for a scatterplot  to comment on and/or examine:                                                                                                     |\n|  <br>          | <br>                                                                                                                                                            | <br>                                                                                                                                                                         |\n|  <br>          | <br>                                                                                                                                                            | <br>                                                                                                                                                                         |\n|                |<ul><li> The *shape* of the distribution. Look at the shape, centre and spread of the distribution. Is it symmetric or skewed? Is it unimodal or bimodal? </li>  | <li>The *direction* of the association indicates whether there is a positive or negative association  </li>                                                                 \n|                |<li> Identify any *unusual observations*. Do you notice any extreme observations (i.e., outliers)? </li>                                                         | <li>The *form* of association refers to whether the relationship between the variables can be summarized well with a straight line or some more complicated pattern </li>   \n|                |                                                                                                                                                                 | <li>The *strength* of association entails how closely the points fall to a recognizable pattern such as a line  </li>                                                       \n|                |                                                                                                                                                                 | <li>*Unusual observations* that do not fit the pattern of the rest of the observations and which are worth examining in more detail </li></ul>                              |\n+----------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|**Numerically** | Compute and report summary statistics e.g., mean, standard deviation, median, min, max, etc.                                                                    | Compute and report the correlation coefficient.                                                                                                                              |\n|  <br>          | <br>                                                                                                                                                            | <br>                                                                                                                                                                         |\n|  <br>          | <br>                                                                                                                                                            | <br>                                                                                                                                                                         |\n|                | You could, for example, calculate summary statistics such as the mean (`mean()`) and standard deviation (`sd()`), etc. within `summarize()`                     | <br>                                                                                                                                                                         |\n|                |                                                                                                                                                                 | You can use the `cor()` function to calculate this                                                                                                                           |   \n+----------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n### Marginal Distributions\n\n`r qbegin(1)`\n\nVisualise and describe the marginal distributions of wellbeing scores and social interactions.\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint \n\n*Plot interpretation*  \n- The *shape*, *center* and *spread* of the distribution  \n- Whether the distribution is *symmetric* or *skewed*  \n- Whether the distribution is *unimodal* or *bimodal* \n\n*Plotting tips*  \n- Use `\\n` to wrap text in your titles and or axis labels  \n- The **patchwork** package allows us to arrange multiple plots in two ways - `|` arranges the plots adjacent to one another, and `/` arranges the plots on top of one another  \n\n*Table tips*  \n- The **kableExtra** package allows us to produce well formatted tables for our descriptive statistics. To do so, you need to specify the `kable()` and `kable_styling()` arguments  \n- Review the guidance on the [rmd bootcamp](https://uoepsy.github.io//rmd-bootcamp/), particularly Lesson 4\n\n:::\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n\n::: {.panel-tabset}\n\n## Wellbeing (WEMWBS) Scores\n\nVisualisation of distribution:\n```{r}\n#| label: fig-densbox-wb\n#| fig-cap: \"Distribution of Wellbeing (WEMWBS) Scores\"\n#| fig-alt: |\n#|   Density plot of wellbeing scores.\n#|   Unimodal distribution, with most of the wellbeing scores were between roughly 30 and 45. \n#|   All scores within range. \n\nggplot(data = mwdata, aes(x = wellbeing)) +\n  geom_density() +\n  labs(x = \"Wellbeing (WEMWBS) Scores\", \n       y = \"Probability density\")\n```\n\nInitial observations from plot:\n\n+ The distribution of wellbeing scores was unimodal\n+ Most of the wellbeing scores were between roughly 30 and 45\n+ The lowest wellbeing in the sample was approximately 22 and the highest approximately 59. This suggested there was a fair high degree of variation in the data\n+ Scores were within the range of possible values\n\nDescriptive (or summary) statistics for wellbeing scores:\n\n```{r}\n#| label: tbl-w1-desc-wb\n#| tbl-cap: Wellbeing Descriptive Statistics\nmwdata %>% \n  summarize(\n    M = mean(wellbeing), \n    SD = sd(wellbeing)\n    ) %>%\n    kable(caption = \"Wellbeing Descriptive Statistics\", align = \"c\", digits = 2) %>%\n    kable_styling(full_width = FALSE)\n```\n\nFollowing the exploration above, we can describe the wellbeing variable as follows:\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nThe marginal distribution of scores on the WEMWBS was unimodal with a mean of approximately `r round(mean(mwdata$wellbeing),2)`. There was variation in WEMWBS scores (SD = `r round(sd(mwdata$wellbeing),2)`)\n\n:::\n\n## Social Interactions\n\nVisualisation of distribution:\n\n```{r}\n#| label: fig-densbox-socint\n#| fig-cap: \"Distribution of Number of Social Interactions\"\n#| fig-alt: |\n#|   Density plot of number of weekly social interactions.\n#|   Unimodal distribution, with most of the weekly number of social interactions between roughly 8 and 15. \n\nggplot(data = mwdata, aes(x = social_int)) +\n  geom_density() +\n  labs(x = \"Social Interactions (Number per Week)\", \n       y = \"Probability density\")\n```\n\nInitial observations from plot:\n\n+ The distribution of social interactions was unimodal\n+ Most of the participants had between 8 and 15 social interactions per week \n+ The fewest social interactions per week was approximately 3, and the highest approximately 24. This suggested there was a fair high degree of variation in the data\n\nDescriptive (or summary) statistics for the number of weekly social interactions per week:\n\n```{r}\n#| label: tbl-w1-desc-socint\n#| tbl-cap: Social Interactions Descriptive Statistics\nmwdata %>% \n  summarize(\n    M = mean(social_int), \n    SD = sd(social_int)\n    ) %>%\n    kable(caption = \"Social Interactions Descriptive Statistics\", align = \"c\", digits = 2) %>%\n    kable_styling(full_width = FALSE)\n```\n\nFollowing the exploration above, we can describe the social interactions variable as follows:\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nThe marginal distribution of numbers of social interactions per week was unimodal with a mean of approximately `r round(mean(mwdata$social_int),2)`. There was variation in numbers of social interactions (SD = `r round(sd(mwdata$social_int),2)`)\n\n:::\n\n:::\n\n`r solend()`\n\n### Associations among Variables\n\n`r qbegin(2)`\nCreate a scatterplot of wellbeing score and social interactions *before* calculating the correlation between them.  \n\n:::imp\n__Correlation Matrix__  \n\nA table showing the correlation coefficients - $r_{(x,y)}=\\frac{\\mathrm{cov}(x,y)}{s_xs_y}$ - between variables. Each cell in the table shows the association between two variables. The diagonals show the correlation of a variable with itself (and are therefore always equal to 1).  \n\n:::blue\nIn `R`, we can create a correlation matrix by giving the `cor()` function a dataframe. However, we only want to give it 2 columns here. Think about how we select specific columns, either giving the column numbers inside `[]`, or using `select()`. \n:::\n\n:::\n\nMaking reference to both the plot and correlation coefficient, describe the association between wellbeing and social interactions among participants in the Edinburgh & Lothians sample. \n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\n*Plot*  \nWe are trying to investigate how wellbeing varies by varying numbers of weekly social interactions. Hence, wellbeing is the dependent variable (on the y-axis), and social interactions is the independent variable (on the x-axis).\n\n*Correlation*  \nMake sure to round your numbers in-line with APA 7th edition guidelines. The `round()` function will come in handy here, as might this [APA numbers and statistics guide](https://apastyle.apa.org/instructional-aids/numbers-statistics-guide.pdf)! \n\n:::\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n\nLet's produce a scatterplot:\n\n```{r}\n#| label: fig-mwdata-scatterplot\n#| fig-cap: \"Association between Wellbeing and Social Interactions\"\n\nggplot(data = mwdata, aes(x = social_int, y = wellbeing)) +\n  geom_point() +\n  labs(x = \"Social Interactions (Number per Week)\", \n       y = \"Wellbeing (WEMWBS) Scores\")\n```\n\nTo comment on the strength of the linear association we compute the correlation coefficient in either of the following ways:\n\n::: {.panel-tabset}\n\n## Index dataframe (`[]`)\n\n```{r}\n# correlation matrix of the two columns of interest - (check with columns we need, in this case 3 & 5)\nround(cor(mwdata[,c(3,5)]), digits = 2)\n```\n\n## Variable selection (`select()`)\n\n```{r}\n# select only the columns we want by name, and pass this to cor()\nmwdata %>% \n  select(social_int, wellbeing) %>%\n  cor() %>%\n    round(digits = 2)\n```\n\n:::\n\nAnd we can see that via either method, the correlation is \n$$\nr_{\\text({Social~Interactions,~~ Wellbeing})} = .24\n$$\n<br>\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nThere was a weak, positive, linear association between the weekly number of social interactions and WEMWBS scores for the participants in the sample ($r$ = .24). More social interactions were associated, on average, with higher wellbeing scores.\n\n:::\n\n<br>\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n## Model Specification and Fitting\n\nThe scatterplot highlighted a linear relationship, where the data points were scattered around an underlying linear pattern with a roughly-constant spread as x varied.\n\nHence, we will try to fit a simple (i.e., one x variable only) linear regression model:\n\n$$\ny_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i \n\\\\\n\\quad \\text{where} \\quad \\epsilon_i \\sim N(0, \\sigma) \\text{ independently}\n$$\n\n::: {.callout-important icon=false collapse=true}\n# What does $y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i \\quad \\text{where} \\quad \\epsilon_i \\sim N(0, \\sigma) \\text{ independently}$ mean?\nLets break the statement down into smaller parts:\n\n###### $y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i$\n+ $y_i$ is our measured outcome variable (our DV)\n+ $x_i$ is our measured predictor variable (our IV)\n+ $\\beta_0$ is the model intercept\n+ $\\beta_1$ is the model slope\n\n###### $\\epsilon \\sim N(0, \\sigma) \\text{ independently}$\n+ $\\epsilon$ is the residual error \n+ $\\sim$ means 'distributed according to'\n+ $\\sim N(0, \\sigma) \\text{ independently}$ means 'normal distribution with a mean of 0 and a variance of $\\sigma$' \n+ Together, we can say that the errors around the line have a mean of zero and constant spread as x varies. \n\n:::\n\n<br>\n\n`r qbegin(3)`\n\nFirst, write the equation of the fitted line. \n\nNext, using the `lm()` function, fit a simple linear model to predict wellbeing (DV) by social interactions (IV), naming the output `mdl`.\n\nLastly, update your equation of the fitted line to include the estimated coefficients.\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nThe syntax of the `lm()` function is:\n\n```{r eval = FALSE}\n\n[model name] <- lm([response variable i.e., dependent variable] ~ [explanatory variable i.e., independent variable], data = [dataframe])\n```\n\n:::\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n\nFirst, lets specify the fitted model, which can be written either as:\n\n::: {.panel-tabset}\n\n## Option A\n\n$$\n\\widehat{Wellbeing} = \\hat \\beta_0 + \\hat \\beta_1 \\cdot Social~Interactions\n$$\n\n## Option B\n\n$$\n\\widehat{Wellbeing} = \\hat \\beta_0 \\cdot 1 + \\hat \\beta_1 \\cdot Social~Interactions\n$$\n:::\n\nTo fit the model in `R`, as the variables are in the `mwdata` dataframe, we would write:\n\n::: {.panel-tabset}\n\n## Option A\n\n```{r}\nmdl <- lm(wellbeing ~ social_int, data = mwdata)\nmdl\n```\n\n## Option B\n\n```{r}\nmdl <- lm(wellbeing ~ 1 + social_int, data = mwdata)\nmdl\n```\n\n\n:::\n\n::: {.callout-important icon=false collapse=true}\n## Why is there a 1 in the Option B's? \nWhen we specify the linear model in `R`, we include after the tilde sign ($\\sim$), the variables that appear to the right of the $\\hat \\beta$s. The intercept, or $\\beta_0$, is a constant. That is, we could write it as multiplied by 1.\n\nIncluding the 1 explicitly is not necessary because it is included by default (you can check this by comparing the outputs of A & B above with and without the 1 included - the estimates are the same!). After a while, you will find you just want to drop the 1 (i.e., Option B) when calling `lm()` because you know that it’s going to be there, but in these early weeks we tried to keep it explicit to make it clear that you want to the intercept to be estimated. \n:::\n\nNote that by calling the name of the fitted model, `mdl`, you can see the estimated regression coefficients $\\hat \\beta_0$ and $\\hat \\beta_1$. We can add these values to the fitted line: \n\n$$\n\\widehat{Wellbeing} = 32.41 + 0.32 \\cdot Social~Interactions \\\\\n$$\n\n`r solend()`\n\n<br>\n\n`r qbegin(4)`\nExplore the following equivalent ways to obtain the estimated regression coefficients --- that is, $\\hat \\beta_0$ and $\\hat \\beta_1$ --- from the fitted model:\n\n- `mdl`\n- `mdl$coefficients`\n- `coef(mdl)`\n- `coefficients(mdl)`\n- `summary(mdl)`\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n\nThe estimated parameters returned by the below methods are all equivalent. However, `summary()` returns more information.\n\n::: {.panel-tabset}\n\n## mdl()\nSimply invoke the name of the fitted model:\n```{r}\nmdl\n```\n\n## mdl$coefficients\n\n```{r}\nmdl$coefficients\n```\n\n## coef(mdl)\n```{r}\ncoef(mdl)\n```\n\n\n## coefficients(mdl)\n\n```{r}\ncoefficients(mdl)\n```\n\n## summary(mdl)\nLook under the “Estimate” column:\n```{r}\nsummary(mdl)\n```\n\n:::\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nThe estimated intercept is $\\hat \\beta_0 = 32.41$ and the estimated slope is $\\hat \\beta_1 = 0.32$.\n\n:::\n\n`r solend()`\n\n<br>\n\n`r qbegin(5)`\nExplore the following equivalent ways to obtain the estimated standard deviation of the errors --- that is, $\\hat \\sigma$ --- from the fitted model `mdl`:\n\n- `sigma(mdl)`\n- `summary(mdl)`\n\n`r optbegin('Huh? What is $\\\\sigma$?', FALSE)`\nThe standard deviation of the errors, denoted by $\\sigma$, is an important quantity that our model estimates. It represents how much individual data points tend to deviate above and below the regression line. \n\nA small $\\sigma$ indicates that the points hug the line closely and we should expect fairly accurate predictions, while a large $\\sigma$ suggests that, even if we estimate the line perfectly, we can expect individual values to deviate from it by substantial amounts.\n\nThe *estimated* standard deviation of the errors is denoted $\\hat \\sigma$, and is estimated by essentially averaging squared residuals (giving the variance) and taking the square-root: \n\n$$\n\\begin{align}\n& \\hat \\sigma = \\sqrt{\\frac{SS_{Residual}}{n - k - 1}} \\\\\n\\qquad \\\\\n& \\text{where} \\\\\n& SS_{Residual} = \\textrm{Sum of Squared Residuals} = \\sum_{i=1}^n{(\\epsilon_i)^2}\n\\end{align}\n$$\n`r optend()`\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n\nThe estimated standard deviation of the errors can be equivalently obtained by the below methods. However, `summary()` returns more information.\n\n::: {.panel-tabset}\n\n## sigma(mdl)\n\n```{r}\nsigma(mdl)\n```\n\n## summary(mdl)\n\nLook at the \"Residual standard error\" entry of the `summary(mdl)` output:\n```{r}\nsummary(mdl)\n```\n\n:::{.callout-note}\n\nThe term \"Residual standard error\" is a misnomer, as the help page for `sigma` says (check `?sigma`). However, it's hard to get rid of this bad name as it has been used in too many books showing R output.\n\n:::\n\n:::\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\n\nThe estimated standard deviation of the errors is $\\hat \\sigma = `r round(sigma(mdl), 2)`$.\n\n:::\n\n`r solend()`\n\n<br>\n\n`r qbegin(6)`\n\nInterpret the estimated intercept, slope, and standard deviation of the errors in the context of the research question.\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nTo interpret the estimated standard deviation of the errors we can use the fact that about 95\\% of values from a normal distribution fall within two standard deviations of the center.\n\n:::\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n\n::: {.panel-tabset}\n\n## Intercept\n\nThe estimated wellbeing score associated to zero weekly social interactions is 32.41.\n\n## Slope\n\nThe estimated increase in wellbeing associated to one additional weekly social interaction is 0.32.\n\n## Standard deviation of the errors\n\nFor any particular numnber of weekly social interactions, participants' wellbeing scores should be distributed above and below the regression line with standard deviation estimated to be $\\hat \\sigma = `r round(sigma(mdl), 2)`$. Since $2 \\hat \\sigma = `r round((sigma(mdl)*2), 2)`$, we expect most (about 95\\%) of the participants' wellbeing scores to be within about 11 points from the regression line.\n\n:::\n\n`r solend()`\n\n<br>\n\n`r qbegin(7)`\nPlot the data and the fitted regression line. To do so:\n\n- Extract the estimated regression coefficients e.g., via `betas <- coef(mdl)`\n- Extract the first entry of `betas` (i.e., the intercept) via `betas[1]`\n- Extract the second entry of `betas` (i.e., the slope) via `betas[2]`\n- Provide the intercept and slope to the function\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\n*Extracting values*  \nThe function `coef(mdl)` returns a vector (a sequence of numbers all of the same type). To get the first element of the sequence you append `[1]`, and `[2]` for the second.\n\n*Plotting*  \nIn your `ggplot()`, you will need to specify `geom_abline()`. This might help get you started:\n\n```{r eval = FALSE}\ngeom_abline(intercept = <intercept>, slope = <slope>)\n```\n\n:::\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n\nFirst extract the values required:\n```{r}\nbetas <- coef(mdl)\nintercept <- betas[1]\nslope <- betas[2]\n```\n\nWe can plot the model as follows:\n```{r}\nggplot(data = mwdata, aes(x = social_int, y = wellbeing)) +\n  geom_point() +\n  geom_abline(intercept = intercept, slope = slope, color = 'blue') + \n  labs(x = \"Social Interactions (Number per Week)\", y = \"Wellbeing (WEMWBS) Scores\")\n```\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n## Predicted Values & Residuals\n\n:::statbox \n\n### Predicted Values\n\n#### Model predicted values for sample data:\n\nWe can get out the model predicted values for $y$, the \"y hats\" ($\\hat y$), for the data in the sample using various functions:\n\n- `predict(<fitted model>)`\n- `fitted(<fitted model>)`\n- `fitted.values(<fitted model>)`\n- `mdl$fitted.values`\n\nFor example, this will give us the estimated wellbeing score (point on our regression line) for each observed value of social interactions for each of our 200 participants.\n\n```{r}\npredict(mdl)\n```\n\n#### Model predicted values for other (unobserved) data:\n\nTo compute the model-predicted values for unobserved data (i.e., data not contained in the sample), we can use the following function:\n\n- `predict(<fitted model>, newdata = <dataframe>)`\n\nFor this example, we first need to remember that the model predicts `wellbeing` using the independent variable `social_int`. Hence, if we want predictions for new (unobserved) data, we first need to create a tibble with a column called `social_int` containing the number of weekly social interactions for which we want the prediction, and store this as a dataframe.\n\n```{r}\n#Create dataframe 'newdata' containing 2, 25, and 28 weekly social interactions\nnewdata <- tibble(social_int = c(2, 25, 28))\nnewdata\n```\n\nThen we take `newdata` and add a new column called `wellbeing_hat`, computed as the prediction from the fitted `mdl` using the `newdata` above:\n\n```{r}\nnewdata <- newdata %>%\n  mutate(\n    wellbeing_hat = predict(mdl, newdata = newdata)\n  )\nnewdata\n```\n\n### Residuals\n\nThe residuals represent the deviations between the actual responses and the predicted responses and can be obtained either as\n\n- `mdl$residuals`\n- `resid(mdl)`\n- `residuals(mdl)`\n- computing them as the difference between the response ($y_i$) and the predicted response ($\\hat y_i$)\n\n:::\n\n<br>\n\n`r qbegin(8)`\n\nUse `predict(mdl)` to compute the fitted values and residuals. Mutate the `mwdata` dataframe to include the fitted values and residuals as extra columns.\n\nAssign to the following symbols the corresponding numerical values:\n\n- $y_{3}$ (response variable for unit $i = 3$ in the sample data)\n- $\\hat y_{3}$ (fitted value for the third unit)\n- $\\hat \\epsilon_{5}$ (the residual corresponding to the 5th unit, i.e., $y_{5} - \\hat y_{5}$)\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n```{r}\nmwdata_fitted <- mwdata %>%\n  mutate(\n    wellbeing_hat = predict(mdl),\n    resid = wellbeing - wellbeing_hat\n  )\n\nhead(mwdata_fitted)\n```\n\n- $y_{3}$ = `r round(mwdata_fitted[3,5], 2)` (see row 3, column 5)\n- $\\hat y_{3}$ = `r round(mwdata_fitted[3,8], 2)` (see row 3, column 8)\n- $\\hat \\epsilon_{5} = y_{5} - \\hat y_{5}$ = `r round(mwdata_fitted[5,5], 2)` -  `r round(mwdata_fitted[5,8], 2)` = -6.21 (see row 5, columns 5 and 8)\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n## Writing Up & Presenting Results\n\n`r qbegin(9)`\n\nProvide key model results in a formatted table.\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint \n\nUse `tab_model()` from the __sjPlot__ package. \n\nYou can rename your DV and IV labels by specifying `dv.labels` and `pred.labels`. To do so, specify your variable name on the left, and what you would like this to be named in the table on the right. \n\n:::\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n\n```{r}\n#| label: tbl-wb-socint-modresults\n#| tbl-cap: Regression Table for Wellbeing Model\ntab_model(mdl,\n          dv.labels = \"Wellbeing (WEMWBS) Scores\",\n          pred.labels = c(\"social_int\" = \"Social Interactions (Number per Week)\"),\n          title = \"Regression Table for Wellbeing Model\")\n          \n```\n\n`r solend()`\n\n<br>\n\n`r qbegin(10)`\n\nDescribe the design of the study, and the analyses that you undertook. Interpret your results in the context of the research question and report your model results in full.\n\nMake reference to your descriptive plots and/or statistics and regression table. \n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint \n\nMake sure to write your results up following [APA guidelines](https://apastyle.apa.org/instructional-aids/numbers-statistics-guide.pdf)\n\n:::\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nThe `mwdata` dataset contained information on 200 hypothetical participants who lived in Edinburgh & Lothians area. Using a between-subjects design, the researchers collected information on participants' wellbeing (measured via WEMWBS), outdoor time (hours per week), social interactions (number per week), routine (whether or not one was followed), location of residence (City, Suburb, or Rural), average weekly steps (in thousands), and age (in years).\n\nTo visualise the marginal distributions of wellbeing and social interactions, density plots were used. To understand the strength of association between the two variables, the correlation coefficient was estimated. To investigate whether the number of weekly social interactions influences wellbeing (WEMWBS) scores, the following simple linear regression model was used:\n\n$$\n\\text{Wellbeing} = \\beta_0 + \\beta_1 \\cdot \\text{Social Interactions}\n$$\nFrom @fig-densbox-wb and @fig-densbox-socint, we can see that both wellbeing $(M = `r round(mean(mwdata$wellbeing), 2)`, SD = `r round(sd(mwdata$wellbeing), 2)`)$ and social interactions $(M = `r round(mean(mwdata$social_int), 2)`, SD = `r round(sd(mwdata$social_int), 2)`)$ followed unimodal distributions. There was a weak, positive, linear association between WEMWBS scores and the weekly number of social interactions for the participants in the sample $(r = .24)$.\n\nFull regression results are displayed in @tbl-wb-socint-modresults. The estimated wellbeing score with no social interactions per week was `r round(mdl$coefficients[1], 2)`. Each additional social interaction was associated with a `r round(mdl$coefficients[2], 2)` point increase in wellbeing scores. \n\n:::\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Compile Report\n\n`r qbegin(\"Compile Report\", qlabel = FALSE)`  \n\nKnit your report to PDF, and check over your work. To do so, you should:\n\n- Make sure the **tinytex** package is installed\n- Makes sure the ‘yaml’ (bit at the very top of your document) looks something like this:\n\n```{}\n---\ntitle: \"this is my report title\"\nauthor: \"B1234506\"\ndate: \"07/09/2024\"\noutput: bookdown::pdf_document2\n---\n```\n\n::: {.callout-important icon=false collapse=true}\n# What to do if you cannot knit to PDF\nIf you are having issues knitting directly to PDF, try the following:  \n\n- Knit to HTML file  \n- Open your HTML in a web-browser (e.g. Chrome, Firefox)  \n- Print to PDF (Ctrl+P, then choose to save to PDF)  \n- Open file to check formatting\n:::\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\nYou must make sure you have **tinytex** installed in R so that you can “Knit” your Rmd document to a PDF file:\n\n```{r eval = FALSE}\ninstall.packages(\"tinytex\")\ntinytex::install_tinytex()\n```\n\n:::\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n\nYou should end up with a PDF file. If you have followed the above instructions and still have issues with knitting, speak with a tutor. \n\n`r solend()`\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":true,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"include-in-header":["assets/toggling.html"],"number-sections":false,"output-file":"1_01_slr.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.340","bibliography":["biblio.bib"],"toc_float":true,"theme":["united","assets/style-labs.scss"],"code-copy":false,"title":"Simple Linear Regression","link-citations":true,"params":{"SHOW_SOLS":true,"TOGGLE":true},"editor_options":{"chunk_output_type":"console"}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}