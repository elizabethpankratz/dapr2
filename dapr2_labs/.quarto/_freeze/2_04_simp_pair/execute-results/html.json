{
  "hash": "e23ba7d11674eeed7d9245df5b55c7a1",
  "result": {
    "markdown": "---\ntitle: \"Simple Effects, Pairwise Comparisons, & Corrections\"\nlink-citations: TRUE\nparams: \n    SHOW_SOLS: TRUE\n    TOGGLE: TRUE\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n:::lo\n\n### <i class=\"fa fa-graduation-cap\"></i> Learning Objectives\nAt the end of this lab, you will:\n\n1. Understand how to interpret simple effects for experimental designs\n2. Understand how to conduct pairwise comparisons\n3. Understand how to apply corrections available for multiple comparisons\n\n### <i class=\"fa fa-check-square-o fa-2\"></i> What You Need\n\n1. Be up to date with lectures\n2. Have completed previous lab exercises from [Semester 1 Week 7](https://uoepsy.github.io/dapr2/2425/labs/1_06_dummy.html), [Semester 1 Week 8](https://uoepsy.github.io/dapr2/2425/labs/1_07_effects.html), [Semester 1 Week 11](https://uoepsy.github.io/dapr2/2425/labs/1_10_writeup_recap2.html), [Semester 2 Week 1](https://uoepsy.github.io/dapr2/2425/labs/2_01_int1_nc.html), [Semester 2 Week 2](https://uoepsy.github.io/dapr2/2425/labs/2_02_int2_nn.html), and [Semester 2 Week 3](https://uoepsy.github.io/dapr2/2425/labs/2_03_int3_cc.html).\n\n### <i class=\"fab fa-r-project\"></i> Required R Packages\nRemember to load all packages within a code chunk at the start of your RMarkdown file using `library()`. If you do not have a package and need to install, do so within the console using `install.packages(\" \")`. For further guidance on installing/updating packages, see Section C [here](https://uoepsy.github.io/files/install-update-r#update-pkgs).  \n\nFor this lab, you will need to load the following package(s):\n\n* **tidyverse** \n* **psych** \n* **kableExtra**\n* **sjPlot**\n* **interactions**\n* **patchwork**\n* **emmeans**\n\n### <i class=\"fa fa-pencil-square-o\" aria-hidden=\"true\"></i> Presenting Results\nAll results should be presented following [APA guidelines](https://apastyle.apa.org/instructional-aids/numbers-statistics-guide.pdf).If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the [rmd bootcamp](https://uoepsy.github.io/scs/rmd-bootcamp/).\n\nThe example write-up sections included as part of the solutions are **not perfect** - they instead should give you a good example of what information you should include and how to structure this. Note that you must **not** copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more [here](https://www.ed.ac.uk/academic-services/students/conduct/academic-misconduct).  \n\n### <i class=\"fa fa-file\"></i> Lab Data\nYou can download the data required for this lab [here](https://uoepsy.github.io/data/cognitive_experiment.csv) or read it in via this link https://uoepsy.github.io/data/cognitive_experiment.csv    \n  \nNote, you have already worked with *some* of this data last week - see [Semester 2 Week 3 lab](https://uoepsy.github.io/dapr2/2425/labs/2_03_int3_cc.html), but we now have a third Task condition - Classification. \n\n:::\n\n# Study Overview\n\n> **Research Question** \n>\n> Are there differences in types of memory deficits for those experiencing different cognitive impairment(s)?\n\nIn this week's exercises, we will further explore questions such as:\n\n- Does level $i$ of the first factor have an effect on the response?\n- Does level $j$ of the second factor have an effect on the response?\n- Is there a combined effect of level $i$ of the first factor and level $j$ of the second factor on the response? In other words, is there interaction of the two factors so that the combined effect is not simply the additive effect of level $i$ of the first factor plus the effect of level $j$ of the second factor?\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-1' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-1', 'opt-start-1')\"> <span class=\"olab\">Cognitive Exp 3x3 data codebook.</span></span></div><div class=\"optional-body\" id = \"opt-body-1\" style=\"display: none;\">\n\n \n  \n__Description__\n\nThe researchers designed a study yielding a $3 \\times 3$ factorial design to test whether there are differences in types of memory deficits for those experiencing different cognitive impairment(s).\n\nThe tasks chosen by the researchers have been picked to map onto the theoretical differences between the three types of research participants. The Grammar and Classification tasks are known to reflect *implicit* memory processes, whereas the recognition task is known to reflect *explicit* memory processes. If the theory is correct, we would expect the difference in scores between the recognition and grammar/classification tasks to be relatively similar for the control and amnesiac groups, but relatively larger for the Huntingtons group compared to controls.\n\n__Data Dictionary__\n\nThe data in `cognitive_experiment.csv` contain three attributes collected from $n=45$ participants, and includes: \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div id=\"ezlgdzhkht\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#ezlgdzhkht table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#ezlgdzhkht thead, #ezlgdzhkht tbody, #ezlgdzhkht tfoot, #ezlgdzhkht tr, #ezlgdzhkht td, #ezlgdzhkht th {\n  border-style: none;\n}\n\n#ezlgdzhkht p {\n  margin: 0;\n  padding: 0;\n}\n\n#ezlgdzhkht .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#ezlgdzhkht .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#ezlgdzhkht .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#ezlgdzhkht .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#ezlgdzhkht .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#ezlgdzhkht .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ezlgdzhkht .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#ezlgdzhkht .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#ezlgdzhkht .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#ezlgdzhkht .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#ezlgdzhkht .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#ezlgdzhkht .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#ezlgdzhkht .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#ezlgdzhkht .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#ezlgdzhkht .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#ezlgdzhkht .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#ezlgdzhkht .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#ezlgdzhkht .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#ezlgdzhkht .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ezlgdzhkht .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#ezlgdzhkht .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#ezlgdzhkht .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#ezlgdzhkht .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ezlgdzhkht .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#ezlgdzhkht .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#ezlgdzhkht .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ezlgdzhkht .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ezlgdzhkht .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#ezlgdzhkht .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ezlgdzhkht .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#ezlgdzhkht .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ezlgdzhkht .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#ezlgdzhkht .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ezlgdzhkht .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#ezlgdzhkht .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ezlgdzhkht .gt_left {\n  text-align: left;\n}\n\n#ezlgdzhkht .gt_center {\n  text-align: center;\n}\n\n#ezlgdzhkht .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#ezlgdzhkht .gt_font_normal {\n  font-weight: normal;\n}\n\n#ezlgdzhkht .gt_font_bold {\n  font-weight: bold;\n}\n\n#ezlgdzhkht .gt_font_italic {\n  font-style: italic;\n}\n\n#ezlgdzhkht .gt_super {\n  font-size: 65%;\n}\n\n#ezlgdzhkht .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#ezlgdzhkht .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#ezlgdzhkht .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#ezlgdzhkht .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#ezlgdzhkht .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#ezlgdzhkht .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#ezlgdzhkht .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    \n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"variable\">variable</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"description\">description</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">Diagnosis</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Diagnosis classifies the three types of individuals: 1 = Amnesic patients, 2 = Huntingtons patients, and 3 = Control group of individuals with no known neurological disorder</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">Task</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Task tells us to which one of three tasks each study participant was randomly assigned to: 1 = Grammar (which consists of classifying letter sequences as either following or not following grammatical rules), 2 = Classification (which consists of classifying stimuli into certain groupings, based on previously indicated information about the groups characteristics), and 3 = Recognition (which consists of recognising particular stimuli as stimuli that have previously been presented during the task)</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">Y</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Score</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n:::\n:::\n\n  \n__Data Overview__\n\nWe have data from the 45 participants (15 amnesiacs, 15 Huntington individuals, and 15 controls). Recall that study involves two factors, now with three levels each. For each combination of factor levels we have 5 observations:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n<tr>\n<th style=\"empty-cells: hide;border-bottom:hidden;\" colspan=\"1\"></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"3\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">Task</div></th>\n</tr>\n  <tr>\n   <th style=\"text-align:left;\"> Diagnosis </th>\n   <th style=\"text-align:left;\"> grammar </th>\n   <th style=\"text-align:left;\"> classification </th>\n   <th style=\"text-align:left;\"> recognition </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> amnesic </td>\n   <td style=\"text-align:left;\"> 44, 63, 76, 72, 45 </td>\n   <td style=\"text-align:left;\"> 72, 66, 55, 82, 75 </td>\n   <td style=\"text-align:left;\"> 70, 51, 82, 66, 56 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> huntingtons </td>\n   <td style=\"text-align:left;\"> 24, 30, 51, 55, 40 </td>\n   <td style=\"text-align:left;\"> 53, 59, 33, 37, 43 </td>\n   <td style=\"text-align:left;\"> 107, 80, 98, 82, 108 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> control </td>\n   <td style=\"text-align:left;\"> 76, 98, 71, 70, 85 </td>\n   <td style=\"text-align:left;\"> 92, 65, 86, 67, 90 </td>\n   <td style=\"text-align:left;\"> 107, 80, 101, 82, 105 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nThe five observations are assumed to come from a population having a specific mean. The population means corresponding to each combination of factor levels can be schematically written as:\n\n$$\n\\begin{matrix}\n                   &         &         & \\textbf{Task} & \\\\\n                   &         &  (j=1) & (j=2) & (j=3) & \\\\\n                   &         &  \\text{ grammar} & \\text{ classification} & \\text{ recognition} \\\\\n                   & (i=1)\\text{ control} & \\mu_{1,1} & \\mu_{1,2} & \\mu_{1,3} \\\\\n\\textbf{Diagnosis} & (i=2)\\text{ amnesic} & \\mu_{2,1} & \\mu_{2,2} & \\mu_{2,3} \\\\\n                   & (i=3)\\text{ huntingtons} & \\mu_{3,1} & \\mu_{3,2} & \\mu_{3,3}\n\\end{matrix}\n$$\n  \n  \n__Preview__\n\nThe first six rows of the data are:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div id=\"jwhphheblm\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#jwhphheblm table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#jwhphheblm thead, #jwhphheblm tbody, #jwhphheblm tfoot, #jwhphheblm tr, #jwhphheblm td, #jwhphheblm th {\n  border-style: none;\n}\n\n#jwhphheblm p {\n  margin: 0;\n  padding: 0;\n}\n\n#jwhphheblm .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#jwhphheblm .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#jwhphheblm .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#jwhphheblm .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#jwhphheblm .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#jwhphheblm .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#jwhphheblm .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#jwhphheblm .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#jwhphheblm .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#jwhphheblm .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#jwhphheblm .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#jwhphheblm .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#jwhphheblm .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#jwhphheblm .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#jwhphheblm .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#jwhphheblm .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#jwhphheblm .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#jwhphheblm .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#jwhphheblm .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#jwhphheblm .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#jwhphheblm .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#jwhphheblm .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#jwhphheblm .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#jwhphheblm .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#jwhphheblm .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#jwhphheblm .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#jwhphheblm .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#jwhphheblm .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#jwhphheblm .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#jwhphheblm .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#jwhphheblm .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#jwhphheblm .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#jwhphheblm .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#jwhphheblm .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#jwhphheblm .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#jwhphheblm .gt_left {\n  text-align: left;\n}\n\n#jwhphheblm .gt_center {\n  text-align: center;\n}\n\n#jwhphheblm .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#jwhphheblm .gt_font_normal {\n  font-weight: normal;\n}\n\n#jwhphheblm .gt_font_bold {\n  font-weight: bold;\n}\n\n#jwhphheblm .gt_font_italic {\n  font-style: italic;\n}\n\n#jwhphheblm .gt_super {\n  font-size: 65%;\n}\n\n#jwhphheblm .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#jwhphheblm .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#jwhphheblm .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#jwhphheblm .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#jwhphheblm .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#jwhphheblm .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#jwhphheblm .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    \n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Diagnosis\">Diagnosis</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Task\">Task</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Y\">Y</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"Diagnosis\" class=\"gt_row gt_right\">1</td>\n<td headers=\"Task\" class=\"gt_row gt_right\">1</td>\n<td headers=\"Y\" class=\"gt_row gt_right\">44</td></tr>\n    <tr><td headers=\"Diagnosis\" class=\"gt_row gt_right\">1</td>\n<td headers=\"Task\" class=\"gt_row gt_right\">1</td>\n<td headers=\"Y\" class=\"gt_row gt_right\">63</td></tr>\n    <tr><td headers=\"Diagnosis\" class=\"gt_row gt_right\">1</td>\n<td headers=\"Task\" class=\"gt_row gt_right\">1</td>\n<td headers=\"Y\" class=\"gt_row gt_right\">76</td></tr>\n    <tr><td headers=\"Diagnosis\" class=\"gt_row gt_right\">1</td>\n<td headers=\"Task\" class=\"gt_row gt_right\">1</td>\n<td headers=\"Y\" class=\"gt_row gt_right\">72</td></tr>\n    <tr><td headers=\"Diagnosis\" class=\"gt_row gt_right\">1</td>\n<td headers=\"Task\" class=\"gt_row gt_right\">1</td>\n<td headers=\"Y\" class=\"gt_row gt_right\">45</td></tr>\n    <tr><td headers=\"Diagnosis\" class=\"gt_row gt_right\">1</td>\n<td headers=\"Task\" class=\"gt_row gt_right\">2</td>\n<td headers=\"Y\" class=\"gt_row gt_right\">72</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n:::\n:::\n\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Setup\n\n\n\n<div class='question-begin'>Setup</div><div class='question-body'>\n\n  \n\n1. Create a new RMarkdown file\n2. Load the required package(s)\n3. Read the cognitive_experiment dataset into R, assigning it to an object named `cog`\n \n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n\n<div class=\"solution-begin\"><span id='sol-start-2' class=\"fa-solid fa-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-2', 'sol-start-2')\">  Solution </span></div><div class=\"solution-body\" id = \"sol-body-2\" style=\"display: none;\">\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#load packages\nlibrary(tidyverse)\nlibrary(psych)\nlibrary(kableExtra)\nlibrary(emmeans)\nlibrary(sjPlot)\nlibrary(interactions)\nlibrary(patchwork)\n\n#read in data\ncog <- read_csv('https://uoepsy.github.io/data/cognitive_experiment.csv')\n```\n:::\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Exercises \n\n## Study & Analysis Plan Overview \n\n\n\n<div class='question-begin'>Question 1</div><div class='question-body'>\n\n\n\nFirstly, examine the dataset, and perform any necessary and appropriate data management steps.\n\nNext, consider what would be the most appropriate coding constraint to apply in order to best address the research question - i.e., are we interested in whether group X (e.g., Amnesic) differed from group Y (e.g., Huntingtons), or whether group X (e.g., Amnesic) differed from the grand mean? \n\nChoose appropriate reference levels for the Diagnosis and Task variables based on your decision above. \n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\n*Data Management*  \n   \n- The `str()` function will return the overall structure of the dataset, this can be quite handy to look at    \n- Convert categorical variables to factors, and if needed, provide better variable names*    \n- Label factors appropriately to aid with your model interpretations if required*      \n- Check that the dataset is complete (i.e., are there any `NA` values?). We can check this using `is.na()`    \n  \nNote that all of these steps can be done in combination - the `mutate()` and `factor()` functions will likely be useful here.   \n  \n*Coding Constraints*  \n  \n- If you think you'd benefit from a refresher on coding constraints, it might be best to revisit the materials from Semester 1 Block 2 (especially the  [dummy vs effects coding flashcard](https://uoepsy.github.io/dapr2/2425/labs/1_b3_reading.html#numeric-outcomes-categorical-predictors)).  \n- If you would like an overview of coding constraints in the context of interaction models, review the [categorical x categorical example > coding constraints flashcard](https://uoepsy.github.io/dapr2/2425/labs/1_b3_reading.html#categorical-x-categorical-example).    \n\n*Reference Levels*  \n  \n- Review the [specifying reference levels flashcard](https://uoepsy.github.io/dapr2/2425/labs/1_b3_reading.html#numeric-outcomes-categorical-predictors).  \n\n  \n*See the [numeric outcomes & categorical predictors flashcard](https://uoepsy.github.io/dapr2/2425/labs/1_b3_reading.html#numeric-outcomes-categorical-predictors).  \n \n:::\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n\n<div class=\"solution-begin\"><span id='sol-start-3' class=\"fa-solid fa-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-3', 'sol-start-3')\">  Solution </span></div><div class=\"solution-body\" id = \"sol-body-3\" style=\"display: none;\">\n\n\n\nLet's have a look at the data to see what we're working with - `str()` or `head()` are a good place to start - and then we should check for any missing data (`NA` values):\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#first look at dataset structure\nstr(cog)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nspc_tbl_ [45 × 3] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Diagnosis: num [1:45] 1 1 1 1 1 1 1 1 1 1 ...\n $ Task     : num [1:45] 1 1 1 1 1 2 2 2 2 2 ...\n $ Y        : num [1:45] 44 63 76 72 45 72 66 55 82 75 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Diagnosis = col_double(),\n  ..   Task = col_double(),\n  ..   Y = col_double()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n```\n:::\n\n```{.r .cell-code}\n#now lets look at top 6 rows (or the head) of the dataset\nhead(cog)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 3\n  Diagnosis  Task     Y\n      <dbl> <dbl> <dbl>\n1         1     1    44\n2         1     1    63\n3         1     1    76\n4         1     1    72\n5         1     1    45\n6         1     2    72\n```\n:::\n\n```{.r .cell-code}\n#check for NAs \ntable(is.na(cog))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nFALSE \n  135 \n```\n:::\n\n```{.r .cell-code}\n# there are none - all FALSE\n```\n:::\n\n\nNext, lets convert `Diagnosis` and `Task` into factors, making the labels of each factor level more meaningful. According to the data description, the encoding of the factor `Diagnosis` is: 1 = amnesic patients, 2 = Huntingtons patients, and 3 = control patients. The encoding for the factor `Task` is: 1 = grammar task, 2 = classification task, and 3 = recognition task.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncog <- cog %>%\n    mutate(\n        Diagnosis = factor(Diagnosis, \n                           levels = c(1, 2, 3),\n                           labels = c('amnesic', 'huntingtons', 'control'),\n                           ordered = FALSE),\n        Task = factor(Task, \n                      levels = c(1, 2, 3),\n                      labels = c('grammar', 'classification', 'recognition'),\n                      ordered = FALSE)) %>%\n    rename(Score = Y)\n```\n:::\n\n\nSince we are interested in comparing groups, we should use dummy coding. By default, `R` uses dummy coding, so we do not need to make any changes to the coding constraint. \n\nHowever, for our reference groups, we're likely to want it to be the Control group for Diagnosis, and recognition for Task: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncog$Diagnosis <- fct_relevel(cog$Diagnosis, \"control\")\ncog$Task <- fct_relevel(cog$Task, \"recognition\")\n```\n:::\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n<br>  \n\n\n\n<div class='question-begin'>Question 2</div><div class='question-body'>\n\n\n\nProvide a brief overview of the study design and data, before detailing your analysis plan to address the research question.\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint \n\n- Give the reader some background on the context of the study (you might be able to re-use some of the content you wrote for [Semester 2 Week 3 lab](https://uoepsy.github.io/dapr2/2425/labs/2_03_int3_cc.html) here, but note that we now have an extra condition within Task)\n- Outline data checks / data cleaning\n- State what type of analysis you will conduct in order to address the research question\n- Specify the model to be fitted to address the research question (note that you will need to specify the reference level of your categorical variables. This will be somewhat similar to last week, but with the addition of Classification in Task, our model will contain a different number of parameters)\n- Specify your chosen significance ($\\alpha$) level\n- State your hypotheses\n\nMuch of the information required can be found in the [Study Overview] codebook.\n\nThe [statistical models](https://uoepsy.github.io/dapr2/2425/labs/1_b3_reading.html#statistical-models) flashcards may also be useful to refer to. Specifically the [interaction models flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b3_reading.html#interaction-models) and [categorical x categorical example flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b3_reading.html#categorical-x-categorical-example) might be of most use.\n\n:::\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n\n<div class=\"solution-begin\"><span id='sol-start-4' class=\"fa-solid fa-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-4', 'sol-start-4')\">  Solution </span></div><div class=\"solution-body\" id = \"sol-body-4\" style=\"display: none;\">\n\n\n\nThe `cog` dataset contained information on 45 hypothetical participants from a between-subjects study. Participants belonged to one of three 'Diagnosis' groups, which had 15 participants in each - Control, Amnesic, or Huntingtons. Participants from each of the Diagnosis groups were equally and randomly assigned to one of three 'Tasks' to measure different memory processes - Grammar, Classification, or Recognition - the former two measuring implicit memory and the latter explicit. This resulted in 5 participants from each Diagnosis group in each of the three Task conditions. \n\nAll participant data was complete, and categorical variables were coded as factors. For the purpose of this analysis, 'Control' was designated as the reference group for Diagnosis, since it was the only group of participants with no known neurological disorder. For Task, the recognition task measures explicit memory whereas the other two measure implicit memory, so this was specified as the reference group.   \n\nBoxplots will be used to visualise the associations among Diagnosis and Task conditions. To address the research question of whether the difference in performance between explicit and implicit memory tasks will be greatest for Huntington patients in comparison to controls, we first need to define the dummy variables for both\n\nDiagnosis:\n\n$$\n\\begin{gather*}\n\\text{D}_\\text{Amnesic} = \\begin{cases}\n1 & \\text{if Diagnosis is Amnesic}\\\\  \n0 & \\text{otherwise}\n\\end{cases}\n\\\\  \n\\\\  \n\\text{D}_\\text{Huntingtons} = \\begin{cases}\n1 & \\text{if Diagnosis is Huntingtons}\\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\quad   \n\\\\  \n\\\\  \n(\\text{Control is base level})  \n\\end{gather*}\n$$\n\nand for Task:  \n  \n$$\n\\begin{gather*}    \n\\text{T}_\\text{Grammar} = \\begin{cases}\n1 & \\text{if Task is Grammar}\\\\\n0 & \\text{otherwise}\\\\  \n\\end{cases}\\\n\\\\  \n\\\\\n\\text{T}_\\text{Classification} = \\begin{cases}  \n1 & \\text{if Task is Classification}\\\\   \n0 & \\text{otherwise}\\\\ \n\\end{cases}\\\\\\  \n\\quad    \n\\\\    \n\\\\  \n(\\text{Recognition is base level})\\\\ \n\\end{gather*}   \n$$\n\nBased on the above dummy coding, we are going to fit the following interaction model:\n\n$$\n\\begin{align}\n\\text{Interaction Model}: \\text{Score} &= \\beta_0  \\\\\n      &+ \\beta_1 \\cdot \\text{D}_\\text{Amnesic} + \\beta_2 \\cdot  \\text{D}_\\text{Huntingtons}  \\\\\n      &+ \\beta_3 \\cdot  \\text{T}_\\text{Grammar}  + \\beta_4 \\cdot  \\text{T}_\\text{Classification}  \\\\\n      &+ \\beta_5 \\cdot  (\\text{D}_\\text{Amnesic} \\cdot  \\text{T}_\\text{Grammar})  \\\\\n      &+ \\beta_6 \\cdot  (\\text{D}_\\text{Huntingtons} \\cdot  \\text{T}_\\text{Grammar})  \\\\\n      &+ \\beta_7 \\cdot  (\\text{D}_\\text{Amnesic} \\cdot  \\text{T}_\\text{Classification})  \\\\\n      &+ \\beta_8 \\cdot  (\\text{D}_\\text{Huntingtons} \\cdot  \\text{T}_\\text{Classification})  \\\\\n      &+ \\epsilon  \n\\end{align}\n$$\n\nEffects will be considered statistically significant at $\\alpha = .05$\n\nOur hypotheses are:\n\n$H_0:$ All $\\beta_j = 0$ (for $j = 5, 6, 7, 8$)\n\nThere are no significant differences in performance between explicit and implicit memory tasks for patients with different cognitive impairment(s). \n\n$H_1:$ At least one $\\beta_j \\neq  0$ (for $j = 5, 6, 7, 8$)\n\nThere are significant differences in performance between explicit and implicit memory tasks for patients with different cognitive impairment(s). \n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n## Descriptive Statistics & Visualisations\n\n\n\n<div class='question-begin'>Question 3</div><div class='question-body'>\n\n\n\nProvide a table of descriptive statistics and visualise your data.\n\nInterpret the descriptive statistics and visualisations in the context of the study (i.e., comment on any observed differences among groups). \n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nReview the many ways to numerically and visually explore your data by reading over the [data exploration flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b3_reading.html#data-exploration).\n  \nFor examples, see flashcards on [descriptives statistics tables - categorical and numeric values examples](https://uoepsy.github.io/dapr2/2425/labs/1_b3_reading.html#data-exploration) and [categorical x categorical example - visualise data](https://uoepsy.github.io/dapr2/2425/labs/1_b3_reading.html#categorical-x-categorical-example).    \n  \nMake sure to comment on any observed differences among the sample means of the different conditions.  \n\n:::\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n\n<div class=\"solution-begin\"><span id='sol-start-5' class=\"fa-solid fa-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-5', 'sol-start-5')\">  Solution </span></div><div class=\"solution-body\" id = \"sol-body-5\" style=\"display: none;\">\n\n\n\n::: {.panel-tabset}\n\n## Numeric\n\nDescriptive statistics presented in a well formatted table:\n\n\n::: {#tbl-cog-descript .cell layout-align=\"center\" tbl-cap='Descriptive Statistics'}\n\n```{.r .cell-code}\ncog_stats <- cog %>% \n    group_by(Diagnosis, Task) %>%\n    summarise(\n        Mean = mean(Score), \n        SD = sd(Score),\n        SE = sd(Score) / sqrt(n()),\n        Min = min(Score),\n        Max = max(Score)) %>%\n    kable(caption = \"Descriptive Statistics of Score\", digits = 2) %>%\n    kable_styling()\n\ncog_stats\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Descriptive Statistics of Score</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Diagnosis </th>\n   <th style=\"text-align:left;\"> Task </th>\n   <th style=\"text-align:right;\"> Mean </th>\n   <th style=\"text-align:right;\"> SD </th>\n   <th style=\"text-align:right;\"> SE </th>\n   <th style=\"text-align:right;\"> Min </th>\n   <th style=\"text-align:right;\"> Max </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> control </td>\n   <td style=\"text-align:left;\"> recognition </td>\n   <td style=\"text-align:right;\"> 95 </td>\n   <td style=\"text-align:right;\"> 12.98 </td>\n   <td style=\"text-align:right;\"> 5.81 </td>\n   <td style=\"text-align:right;\"> 80 </td>\n   <td style=\"text-align:right;\"> 107 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> control </td>\n   <td style=\"text-align:left;\"> grammar </td>\n   <td style=\"text-align:right;\"> 80 </td>\n   <td style=\"text-align:right;\"> 11.68 </td>\n   <td style=\"text-align:right;\"> 5.22 </td>\n   <td style=\"text-align:right;\"> 70 </td>\n   <td style=\"text-align:right;\"> 98 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> control </td>\n   <td style=\"text-align:left;\"> classification </td>\n   <td style=\"text-align:right;\"> 80 </td>\n   <td style=\"text-align:right;\"> 12.98 </td>\n   <td style=\"text-align:right;\"> 5.81 </td>\n   <td style=\"text-align:right;\"> 65 </td>\n   <td style=\"text-align:right;\"> 92 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> amnesic </td>\n   <td style=\"text-align:left;\"> recognition </td>\n   <td style=\"text-align:right;\"> 65 </td>\n   <td style=\"text-align:right;\"> 12.17 </td>\n   <td style=\"text-align:right;\"> 5.44 </td>\n   <td style=\"text-align:right;\"> 51 </td>\n   <td style=\"text-align:right;\"> 82 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> amnesic </td>\n   <td style=\"text-align:left;\"> grammar </td>\n   <td style=\"text-align:right;\"> 60 </td>\n   <td style=\"text-align:right;\"> 14.92 </td>\n   <td style=\"text-align:right;\"> 6.67 </td>\n   <td style=\"text-align:right;\"> 44 </td>\n   <td style=\"text-align:right;\"> 76 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> amnesic </td>\n   <td style=\"text-align:left;\"> classification </td>\n   <td style=\"text-align:right;\"> 70 </td>\n   <td style=\"text-align:right;\"> 10.17 </td>\n   <td style=\"text-align:right;\"> 4.55 </td>\n   <td style=\"text-align:right;\"> 55 </td>\n   <td style=\"text-align:right;\"> 82 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> huntingtons </td>\n   <td style=\"text-align:left;\"> recognition </td>\n   <td style=\"text-align:right;\"> 95 </td>\n   <td style=\"text-align:right;\"> 13.38 </td>\n   <td style=\"text-align:right;\"> 5.98 </td>\n   <td style=\"text-align:right;\"> 80 </td>\n   <td style=\"text-align:right;\"> 108 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> huntingtons </td>\n   <td style=\"text-align:left;\"> grammar </td>\n   <td style=\"text-align:right;\"> 40 </td>\n   <td style=\"text-align:right;\"> 13.25 </td>\n   <td style=\"text-align:right;\"> 5.92 </td>\n   <td style=\"text-align:right;\"> 24 </td>\n   <td style=\"text-align:right;\"> 55 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> huntingtons </td>\n   <td style=\"text-align:left;\"> classification </td>\n   <td style=\"text-align:right;\"> 45 </td>\n   <td style=\"text-align:right;\"> 10.86 </td>\n   <td style=\"text-align:right;\"> 4.86 </td>\n   <td style=\"text-align:right;\"> 33 </td>\n   <td style=\"text-align:right;\"> 59 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n## Visual \n\nSince we have a continuous outcome and 2 categorical predictors - a boxplot would be most appropriate for visualisations:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncog_plt <- ggplot(data = cog, aes(x = Diagnosis, y = Score, color = Task)) +\n  geom_boxplot() +\n  labs(x = 'Diagnosis', y = 'Score')\ncog_plt\n```\n\n::: {.cell-output-display}\n![Association between Task Condition, Diagnosis, and Score](2_04_simp_pair_files/figure-html/fig-cog-desc-1.png){#fig-cog-desc fig-align='center' width=80%}\n:::\n:::\n\n\n:::\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\n+ Control patients consistently performed best across all tasks. They did not appear to differ substantially in their scores between grammar and classification tasks, but they clearly performed better in the recognition task in comparison to both the grammar and classification ones.\n\n+ Amnesic patients appeared to perform better than Huntingtons patients in grammar and classification tasks (reflecting intrinsic memory processes), and performed worse than Huntingtons patients in the recognition task (reflecting extrinsic memory processes).\n\n:::\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n## Model Fitting & Interpretation \n\n\n\n<div class='question-begin'>Question 4</div><div class='question-body'>\n\n\n\nFit the specified model  using `lm()`, and assign it the name \"mdl_int\".\n\nProvide key model results in a formatted table and plot the interaction model before reporting in-text the overall model fit.\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\n*Model Building*  \n  \n- We can fit interaction models using the `lm()` function.  \n- For an overview, see the [interaction models flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b3_reading.html#interaction-models). \n- For an example, review the [interaction models > categorical x categorical example > model building flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b3_reading.html#categorical-x-categorical-example).  \n\n*Results Table*  \n  \n- Use `tab_model()` from the __sjPlot__ package. For a quick guide, review the [tables flashcard](https://uoepsy.github.io/dapr2/2425/labs/1_b3_reading.html#tables).  \n\n*Plot Model*  \n  \n- Using the `cat_plot()` function from the **interactions** package, visualise the interaction effects from your model. \n- For an overview and example, review the [interaction models > categorical x categorical example > model visualisation flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b3_reading.html#categorical-x-categorical-example).   \n\n:::\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n\n<div class=\"solution-begin\"><span id='sol-start-6' class=\"fa-solid fa-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-6', 'sol-start-6')\">  Solution </span></div><div class=\"solution-body\" id = \"sol-body-6\" style=\"display: none;\">\n\n\n\n::: {.panel-tabset}\n\n## Build & Check Model\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#fit interaction model\nmdl_int <- lm(Score ~ Diagnosis * Task, data = cog)\n\n#check model output\nsummary(mdl_int)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Score ~ Diagnosis * Task, data = cog)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n   -16    -12      2     11     18 \n\nCoefficients:\n                                          Estimate Std. Error t value Pr(>|t|)\n(Intercept)                              9.500e+01  5.617e+00  16.912  < 2e-16\nDiagnosisamnesic                        -3.000e+01  7.944e+00  -3.776 0.000576\nDiagnosishuntingtons                     2.960e-14  7.944e+00   0.000 1.000000\nTaskgrammar                             -1.500e+01  7.944e+00  -1.888 0.067085\nTaskclassification                      -1.500e+01  7.944e+00  -1.888 0.067085\nDiagnosisamnesic:Taskgrammar             1.000e+01  1.123e+01   0.890 0.379329\nDiagnosishuntingtons:Taskgrammar        -4.000e+01  1.123e+01  -3.560 0.001063\nDiagnosisamnesic:Taskclassification      2.000e+01  1.123e+01   1.780 0.083490\nDiagnosishuntingtons:Taskclassification -3.500e+01  1.123e+01  -3.115 0.003597\n                                           \n(Intercept)                             ***\nDiagnosisamnesic                        ***\nDiagnosishuntingtons                       \nTaskgrammar                             .  \nTaskclassification                      .  \nDiagnosisamnesic:Taskgrammar               \nDiagnosishuntingtons:Taskgrammar        ** \nDiagnosisamnesic:Taskclassification     .  \nDiagnosishuntingtons:Taskclassification ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.56 on 36 degrees of freedom\nMultiple R-squared:  0.7318,\tAdjusted R-squared:  0.6722 \nF-statistic: 12.28 on 8 and 36 DF,  p-value: 2.844e-08\n```\n:::\n:::\n\n\n## Results Table\n\n\n::: {#tbl-w4-modresults .cell layout-align=\"center\" tbl-cap='Regression Table for Scores Model'}\n\n```{.r .cell-code}\ntab_model(mdl_int,\n          dv.labels = \"Scores\",\n          pred.labels = c(\"Diagnosisamnesic\" = \"Diagnosis - Amnesic\",\n                          \"Diagnosishuntingtons\" = \"Diagnosis - Huntingtons\",\n                          \"Taskgrammar\" = \"Task - Grammar\",\n                          \"Taskclassification\" = \"Task - Classification\",\n                          \"Diagnosisamnesic:Taskgrammar\" = \"Diagnosis - Amnesic : Task - Grammar\",\n                          \"Diagnosishuntingtons:Taskgrammar\" = \"Diagnosis - Huntingtons : Task - Grammar\",\n                          \"Diagnosisamnesic:Taskclassification\" = \"Diagnosis - Amnesic : Task - Classification\",\n                          \"Diagnosishuntingtons:Taskclassification\" = \"Diagnosis - Huntingtons : Task - Classification\"),\n          title = \"Regression Table for Scores Model\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<caption style=\"font-weight: bold; text-align:left;\">Regression Table for Scores Model</caption>\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">Scores</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">95.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">83.61&nbsp;&ndash;&nbsp;106.39</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Diagnosis - Amnesic</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;30.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;46.11&nbsp;&ndash;&nbsp;-13.89</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Diagnosis - Huntingtons</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;16.11&nbsp;&ndash;&nbsp;16.11</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.000</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Task - Grammar</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;15.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;31.11&nbsp;&ndash;&nbsp;1.11</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.067</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Task - Classification</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;15.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;31.11&nbsp;&ndash;&nbsp;1.11</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.067</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Diagnosis - Amnesic :<br>Task - Grammar</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">10.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;12.79&nbsp;&ndash;&nbsp;32.79</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.379</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Diagnosis - Huntingtons :<br>Task - Grammar</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;40.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;62.79&nbsp;&ndash;&nbsp;-17.21</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Diagnosis - Amnesic :<br>Task - Classification</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">20.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;2.79&nbsp;&ndash;&nbsp;42.79</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.083</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Diagnosis - Huntingtons :<br>Task - Classification</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;35.00</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;57.79&nbsp;&ndash;&nbsp;-12.21</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.004</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">45</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> / R<sup>2</sup> adjusted</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.732 / 0.672</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n\n## Interaction Plot\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplt_cog_mdl <- cat_plot(model = mdl_int, \n                  pred = Diagnosis, \n                  modx = Task, \n                  main.title = \"Scores across Diagnosis and Task\",\n                  x.label = \"Diagnosis\",\n                  y.label = \"Score\",\n                  legend.main = \"Task\")\nplt_cog_mdl\n```\n\n::: {.cell-output-display}\n![Interaction Plot](2_04_simp_pair_files/figure-html/fig-cog-4-1.png){#fig-cog-4 fig-align='center' width=80%}\n:::\n:::\n\n\n:::\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nFull regression results including 95% Confidence Intervals are shown in @tbl-w4-modresults, and the interaction model is visually presented in @fig-cog-4. The $F$-test for model utility was significant $(F(8, 36) = 12.28, p < .001)$, and the model explained approximately 67% of the variability in Scores.  \n\n:::\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n## Contrast Analysis\n\nLet's move onto testing differences between specific group means.\n\n\n\n<div class='question-begin'>Question 5</div><div class='question-body'>\n\n\n\nIn terms of the diagnostic groups, we want to compare the individuals with amnesia to those with Huntingtons. This corresponds to a contrast with coefficients of 0, 1, and −1, for control, amnesic, and Huntingtons, respectively. \n\nSimilarly, in terms of the tasks, we want to compare the average of the two implicit memory tasks with the explicit memory task. This corresponds to a contrast with coefficients of 0.5, 0.5, and −1 for the three tasks. \n\nWhen we are in presence of a significant interaction, the coefficients for a contrast between the means are found by multiplying each row coefficient with all column coefficients as shown below:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/contr_interaction.png){fig-align='center' width=100%}\n:::\n:::\n\n\nSpecify the coefficients to be used in the contrast analysis, and present in a table.\n\nNext, formally state the contrast that the researchers were interested in as testable hypotheses. \n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nFor an overview and example, review the [manual contrasts flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b3_reading.html#manual-contrasts).\n\n:::\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n\n<div class=\"solution-begin\"><span id='sol-start-7' class=\"fa-solid fa-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-7', 'sol-start-7')\">  Solution </span></div><div class=\"solution-body\" id = \"sol-body-7\" style=\"display: none;\">\n\n\n\nWe can specify the coefficients to be used in the contrast analysis in `R` using either:\n\n::: {.panel-tabset}\n\n## Option 1\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndiag_coef  <- c('control' = 0, 'amnesic' = 1, 'huntingtons' = -1)\ntask_coef  <- c('grammar' = 0.5, 'classification' = 0.5, 'recognition' = -1)\ncontr_coef <- outer(diag_coef, task_coef)\ncontr_coef\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            grammar classification recognition\ncontrol         0.0            0.0           0\namnesic         0.5            0.5          -1\nhuntingtons    -0.5           -0.5           1\n```\n:::\n:::\n\n\n## Option 2\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndiag_coef  <- c('control' = 0, 'amnesic' = 1, 'huntingtons' = -1)\ntask_coef  <- c('grammar' = 0.5, 'classification' = 0.5, 'recognition' = -1)\ncontr_coef <- diag_coef %o% task_coef\ncontr_coef\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            grammar classification recognition\ncontrol         0.0            0.0           0\namnesic         0.5            0.5          -1\nhuntingtons    -0.5           -0.5           1\n```\n:::\n:::\n\n\n:::\n\nUsing either approach, we can then convert into a well-formatted table:\n\n\n::: {#tbl-q5-weights .cell layout-align=\"center\" tbl-cap='Contrast Weights'}\n\n```{.r .cell-code}\ncontr_coef %>% \n    kable(., caption = \"Contrast Weights\") %>%\n    kable_styling(full_width = FALSE) \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Contrast Weights</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> grammar </th>\n   <th style=\"text-align:right;\"> classification </th>\n   <th style=\"text-align:right;\"> recognition </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> control </td>\n   <td style=\"text-align:right;\"> 0.0 </td>\n   <td style=\"text-align:right;\"> 0.0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> amnesic </td>\n   <td style=\"text-align:right;\"> 0.5 </td>\n   <td style=\"text-align:right;\"> 0.5 </td>\n   <td style=\"text-align:right;\"> -1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> huntingtons </td>\n   <td style=\"text-align:right;\"> -0.5 </td>\n   <td style=\"text-align:right;\"> -0.5 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nThe above coefficients correspond to the following hypotheses:\n\n$$\nH_0: \\quad \\left(\\frac{\\mu_{2,1} + \\mu_{2,2}}{2} - \\mu_{2,3} \\right) - \\left( \\frac{\\mu_{3,1} + \\mu_{3,2}}{2} - \\mu_{3,3} \\right) = 0\n$$\n\n$$\nH_1: \\quad \\left(\\frac{\\mu_{2,1} + \\mu_{2,2}}{2} - \\mu_{2,3} \\right) - \\left( \\frac{\\mu_{3,1} + \\mu_{3,2}}{2} - \\mu_{3,3} \\right) \\neq 0\n$$\n\nwhich can be equivalently specified as:\n\n$$\nH_0: \\quad \\frac{\\mu_{2,1} + \\mu_{2,2}}{2} - \\mu_{2,3} \\quad = \\quad \\frac{\\mu_{3,1} + \\mu_{3,2}}{2} - \\mu_{3,3}\n$$\n\n$$  \nH_1: \\quad \\frac{\\mu_{2,1} + \\mu_{2,2}}{2} - \\mu_{2,3} \\quad \\neq \\quad  \\frac{\\mu_{3,1} + \\mu_{3,2}}{2} - \\mu_{3,3}\n$$\n\nboth statements state that, in the population, the difference between the mean implicit memory and the explicit memory score is the same for individuals with amnesia and Huntingtons. \n\nNote that the scores for the grammar and classification tasks have been averaged to obtain a single measure of 'implicit memory' score.\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n<br>\n\n\n\n<div class='question-begin'>Question 6</div><div class='question-body'>\n\n\n\nFirstly, use `emmeans()` to obtain the estimated means and uncertainties for your factors. \n\nNext, specify the coefficients of the comparison and run the contrast analysis, obtaining 95% confidence intervals. \n\nReport the results of the contrast analysis in full. \n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nFor an overview and example, review the [manual contrasts flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b3_reading.html#manual-contrasts).\n\n:::\n\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n\n<div class=\"solution-begin\"><span id='sol-start-8' class=\"fa-solid fa-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-8', 'sol-start-8')\">  Solution </span></div><div class=\"solution-body\" id = \"sol-body-8\" style=\"display: none;\">\n\n\n\nNow that we have the coefficients, let's firstly call the `emmeans` function to get the estimated means of our groups (this is also helpful to look at the ordering of the groups):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndiag_task_mean <- emmeans(mdl_int, ~ Diagnosis*Task)\ndiag_task_mean\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Diagnosis   Task           emmean   SE df lower.CL upper.CL\n control     recognition        95 5.62 36     83.6    106.4\n amnesic     recognition        65 5.62 36     53.6     76.4\n huntingtons recognition        95 5.62 36     83.6    106.4\n control     grammar            80 5.62 36     68.6     91.4\n amnesic     grammar            60 5.62 36     48.6     71.4\n huntingtons grammar            40 5.62 36     28.6     51.4\n control     classification     80 5.62 36     68.6     91.4\n amnesic     classification     70 5.62 36     58.6     81.4\n huntingtons classification     45 5.62 36     33.6     56.4\n\nConfidence level used: 0.95 \n```\n:::\n:::\n\n\nNext, from `contr_coef`, insert the coefficients **following the order specified by the rows of** `diag_task_mean` above. That is, the first one should be for `control` `recognition` and have a value of 0, the second for `amnesic` `recognition` with a value of -1, and so on...\n\nLet's specify our weights, and give a name to this contrast (in this example 'Research Hyp'):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndiag_task_comp <- contrast(diag_task_mean, \n                     method = list('Research Hyp' = c(0, -1, 1, 0, 0.5, -0.5, 0, 0.5, -0.5))\n                     )\n```\n:::\n\n\nNext, let's look at the output via one of two ways:\n\n::: {.panel-tabset}\n\n## Option 1\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#examine output\ndiag_task_comp\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n contrast     estimate   SE df t.ratio p.value\n Research Hyp     52.5 9.73 36   5.396  <.0001\n```\n:::\n\n```{.r .cell-code}\n#obtain confidence intervals\nconfint(diag_task_comp)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n contrast     estimate   SE df lower.CL upper.CL\n Research Hyp     52.5 9.73 36     32.8     72.2\n\nConfidence level used: 0.95 \n```\n:::\n:::\n\n\n## Option 2\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#examine summary output and state `infer = TRUE` to include confidence intervals\nsummary(diag_task_comp, infer = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n contrast     estimate   SE df lower.CL upper.CL t.ratio p.value\n Research Hyp     52.5 9.73 36     32.8     72.2   5.396  <.0001\n\nConfidence level used: 0.95 \n```\n:::\n:::\n\n\n:::\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nWe performed a test against $H_0: \\quad \\frac{\\mu_{2,1} + \\mu_{2,2}}{2} - \\mu_{2,3} \\quad = \\quad \\frac{\\mu_{3,1} + \\mu_{3,2}}{2} - \\mu_{3,3}$. At the 5\\% significance level, there was evidence that individuals with Amnesia and Huntingtons did differ in the difference between implicit and explicit memory tasks $(t(36) = 5.40, p < .001, \\text{two-sided})$, and this difference was estimated to be 52.50. We are 95\\% confident that the difference in implicit and explicit memory scores between individuals with Amnesia and Huntingtons was between 32.80 to 72.20 points. Therefore, we can reject the null hypothesis that the difference in differences was equal to zero. \n\n:::\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n## Simple Effects\n\n\n\n<div class='question-begin'>Question 7</div><div class='question-body'>\n\n\n\nExamine the simple effects for Task at each level of Diagnosis; and then the simple effects for Diagnosis at each level of Task. \n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nFor an overview and example, review the [simple effects flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b3_reading.html#categorical-x-categorical-example). \n\n:::\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n\n<div class=\"solution-begin\"><span id='sol-start-9' class=\"fa-solid fa-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-9', 'sol-start-9')\">  Solution </span></div><div class=\"solution-body\" id = \"sol-body-9\" style=\"display: none;\">\n\n\n\n\n::: {.panel-tabset}\n\n## Simple Effects of Task\n\nFrom `mdl_int_simple1` we can see the differences between tasks for each diagnosis group:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmdl_int_simple1 <- pairs(diag_task_mean, simple = \"Task\")\nmdl_int_simple1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDiagnosis = control:\n contrast                     estimate   SE df t.ratio p.value\n recognition - grammar              15 7.94 36   1.888  0.1567\n recognition - classification       15 7.94 36   1.888  0.1567\n grammar - classification            0 7.94 36   0.000  1.0000\n\nDiagnosis = amnesic:\n contrast                     estimate   SE df t.ratio p.value\n recognition - grammar               5 7.94 36   0.629  0.8050\n recognition - classification       -5 7.94 36  -0.629  0.8050\n grammar - classification          -10 7.94 36  -1.259  0.4273\n\nDiagnosis = huntingtons:\n contrast                     estimate   SE df t.ratio p.value\n recognition - grammar              55 7.94 36   6.923  <.0001\n recognition - classification       50 7.94 36   6.294  <.0001\n grammar - classification           -5 7.94 36  -0.629  0.8050\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n```\n:::\n:::\n\n\n## Simple Effects of Diagnosis\n\nFrom `mdl_int_simple2` we can see the differences between diagnoses for each task group:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmdl_int_simple2 <- pairs(diag_task_mean, simple = \"Diagnosis\")\nmdl_int_simple2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTask = recognition:\n contrast              estimate   SE df t.ratio p.value\n control - amnesic           30 7.94 36   3.776  0.0016\n control - huntingtons        0 7.94 36   0.000  1.0000\n amnesic - huntingtons      -30 7.94 36  -3.776  0.0016\n\nTask = grammar:\n contrast              estimate   SE df t.ratio p.value\n control - amnesic           20 7.94 36   2.518  0.0424\n control - huntingtons       40 7.94 36   5.035  <.0001\n amnesic - huntingtons       20 7.94 36   2.518  0.0424\n\nTask = classification:\n contrast              estimate   SE df t.ratio p.value\n control - amnesic           10 7.94 36   1.259  0.4273\n control - huntingtons       35 7.94 36   4.406  0.0003\n amnesic - huntingtons       25 7.94 36   3.147  0.0091\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n```\n:::\n:::\n\n\n:::\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n<br>\n\n\n\n<div class='question-begin'>Question 8</div><div class='question-body'>\n\n\n\nVisualise the interaction, displaying two plots - one with Diagnosis on the x-axis, and the other with Task on the x-axis.\n\nConsidering the simple effects that you noted above, identify the significant effects and match them to the corresponding points of your interaction plot.\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nFor an overview and example, review the [simple effects flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b3_reading.html#categorical-x-categorical-example).  \n  \nRecall that the **patchwork** package allows us to arrange multiple plots using either `/` or `|` or `+`.\n\n:::\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n\n<div class=\"solution-begin\"><span id='sol-start-10' class=\"fa-solid fa-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-10', 'sol-start-10')\">  Solution </span></div><div class=\"solution-body\" id = \"sol-body-10\" style=\"display: none;\">\n\n\n\n::: {.panel-tabset}\n\n## Simple Effects of Task\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplt_1 <- emmip(mdl_int, Diagnosis ~ Task, CIs = TRUE)\nplt_1\n```\n\n::: {.cell-output-display}\n![](2_04_simp_pair_files/figure-html/unnamed-chunk-23-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\nFor the simple effects of task (see `plt_1`), we saw the significant differences (those for which $p<.05$):  \n\n+ Only in the Huntingtons group, between recognition & grammar and recognition & classification tasks  \n    + left-most blue point compared to the middle blue point, and then compared to the right-most blue point  \n\n## Simple Effects of Diagnosis\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplt_2 <- emmip(mdl_int, Task ~ Diagnosis, CIs = TRUE)\nplt_2\n```\n\n::: {.cell-output-display}\n![](2_04_simp_pair_files/figure-html/unnamed-chunk-24-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\nFor the simple effects of Diagnosis (see `plt_2`), we saw significant differences (those for which $p<.05$):  \n\n+ in the recognition task, between control & amnesic   \n    + left-most red point to middle red point   \n    \n+ in the recognition task, between amnesic & huntingtons   \n    + middle red-point to right-most red point  \n    \n+ in the grammar task, between control & amnesic  \n    + left-most green point to middle green point  \n    \n+ in the grammar task, between control & huntingtons   \n    + left-most green point to right-most green point  \n    \n+ in the grammar task, between amnesic & huntingtons   \n    + middle green point to right-most green point  \n\n+ in the classification task, between control & huntingtons   \n    + left-most blue point to right-most blue point  \n\n+ in the classification task, between amnesic & huntingtons     \n    + middle blue point to right-most blue point  \n\n:::\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n## Pairwise Comparisons & Multiple Corrections\n\n\n\n<div class='question-begin'>Question 9</div><div class='question-body'>\n\n\n\nConduct exploratory pairwise comparisons to compare all levels of Diagnosis with all levels of Task, applying no correction (note that Tukey will be automatically applied since we are comparing groups of means, so you will need to overwrite this).\n\nWithout adjusting our $\\alpha$ (or $p$-value), why might any inferences drawn from your output be problematic?\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nFor an overview, review the [multiple comparisons flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b3_reading.html#multiple-comparisons).\n\n:::\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n\n<div class=\"solution-begin\"><span id='sol-start-11' class=\"fa-solid fa-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-11', 'sol-start-11')\">  Solution </span></div><div class=\"solution-body\" id = \"sol-body-11\" style=\"display: none;\">\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npairs_res <- pairs(diag_task_mean, adjust = \"none\")\npairs_res\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n contrast                                             estimate   SE df t.ratio\n control recognition - amnesic recognition                  30 7.94 36   3.776\n control recognition - huntingtons recognition               0 7.94 36   0.000\n control recognition - control grammar                      15 7.94 36   1.888\n control recognition - amnesic grammar                      35 7.94 36   4.406\n control recognition - huntingtons grammar                  55 7.94 36   6.923\n control recognition - control classification               15 7.94 36   1.888\n control recognition - amnesic classification               25 7.94 36   3.147\n control recognition - huntingtons classification           50 7.94 36   6.294\n amnesic recognition - huntingtons recognition             -30 7.94 36  -3.776\n amnesic recognition - control grammar                     -15 7.94 36  -1.888\n amnesic recognition - amnesic grammar                       5 7.94 36   0.629\n amnesic recognition - huntingtons grammar                  25 7.94 36   3.147\n amnesic recognition - control classification              -15 7.94 36  -1.888\n amnesic recognition - amnesic classification               -5 7.94 36  -0.629\n amnesic recognition - huntingtons classification           20 7.94 36   2.518\n huntingtons recognition - control grammar                  15 7.94 36   1.888\n huntingtons recognition - amnesic grammar                  35 7.94 36   4.406\n huntingtons recognition - huntingtons grammar              55 7.94 36   6.923\n huntingtons recognition - control classification           15 7.94 36   1.888\n huntingtons recognition - amnesic classification           25 7.94 36   3.147\n huntingtons recognition - huntingtons classification       50 7.94 36   6.294\n control grammar - amnesic grammar                          20 7.94 36   2.518\n control grammar - huntingtons grammar                      40 7.94 36   5.035\n control grammar - control classification                    0 7.94 36   0.000\n control grammar - amnesic classification                   10 7.94 36   1.259\n control grammar - huntingtons classification               35 7.94 36   4.406\n amnesic grammar - huntingtons grammar                      20 7.94 36   2.518\n amnesic grammar - control classification                  -20 7.94 36  -2.518\n amnesic grammar - amnesic classification                  -10 7.94 36  -1.259\n amnesic grammar - huntingtons classification               15 7.94 36   1.888\n huntingtons grammar - control classification              -40 7.94 36  -5.035\n huntingtons grammar - amnesic classification              -30 7.94 36  -3.776\n huntingtons grammar - huntingtons classification           -5 7.94 36  -0.629\n control classification - amnesic classification            10 7.94 36   1.259\n control classification - huntingtons classification        35 7.94 36   4.406\n amnesic classification - huntingtons classification        25 7.94 36   3.147\n p.value\n  0.0006\n  1.0000\n  0.0671\n  0.0001\n  <.0001\n  0.0671\n  0.0033\n  <.0001\n  0.0006\n  0.0671\n  0.5331\n  0.0033\n  0.0671\n  0.5331\n  0.0164\n  0.0671\n  0.0001\n  <.0001\n  0.0671\n  0.0033\n  <.0001\n  0.0164\n  <.0001\n  1.0000\n  0.2162\n  0.0001\n  0.0164\n  0.0164\n  0.2162\n  0.0671\n  <.0001\n  0.0006\n  0.5331\n  0.2162\n  0.0001\n  0.0033\n```\n:::\n\n```{.r .cell-code}\n#can also plot if you'd like:\nplot(pairs_res)\n```\n\n::: {.cell-output-display}\n![](2_04_simp_pair_files/figure-html/unnamed-chunk-25-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\nFrom the above, we can see comparisons for all different possible pairs of diagnosis-task combinations^[the differences between the group means for the comparison as labelled]. \n\nIn total, there are 9 different estimates, but comparing them all means that we have 36 comparisons being tested! By not adjusting our $p$-value, we are increasing the experiment-wise Type I error rate - we could wrongly reject the null hypothesis at a much higher rate than 5/100 (or 1/20 as is assumed when $\\alpha = .05$). To overcome this, we might adjust and determine a result to be statistically significant if $p < .005$, as opposed to $p < .05$, depending on how many tests are in our family of tests.  \n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n<br>\n\n\n\n<div class='question-begin'>Question 10</div><div class='question-body'>\n\n\n\nSelect an appropriate method to adjust for multiple comparisons, and then obtain confidence intervals.\n\nComment on how these $p$-values differ from your raw (i.e., unadjusted) $p$-values.\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nFor an overview, review the [multiple comparisons flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b3_reading.html#multiple-comparisons).\n\n:::\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n\n<div class=\"solution-begin\"><span id='sol-start-12' class=\"fa-solid fa-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-12', 'sol-start-12')\">  Solution </span></div><div class=\"solution-body\" id = \"sol-body-12\" style=\"display: none;\">\n\n\n\nNote what the functions in `R` do is adjust the $p$-value, rather than the $\\alpha$. \n\nSince we're interested in all pairwise comparisons of means, the Tukey adjustment might be a sensible approach. However, we'll also show the Bonferroni to show how it differs (note, in practice you would only apply one correction and justify this choice based on your design - we are only applying two to note how they differ!)\n\n::: {.panel-tabset}\n\n## Tukey\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncontrast(diag_task_mean, method = \"pairwise\", adjust=\"Tukey\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n contrast                                             estimate   SE df t.ratio\n control recognition - amnesic recognition                  30 7.94 36   3.776\n control recognition - huntingtons recognition               0 7.94 36   0.000\n control recognition - control grammar                      15 7.94 36   1.888\n control recognition - amnesic grammar                      35 7.94 36   4.406\n control recognition - huntingtons grammar                  55 7.94 36   6.923\n control recognition - control classification               15 7.94 36   1.888\n control recognition - amnesic classification               25 7.94 36   3.147\n control recognition - huntingtons classification           50 7.94 36   6.294\n amnesic recognition - huntingtons recognition             -30 7.94 36  -3.776\n amnesic recognition - control grammar                     -15 7.94 36  -1.888\n amnesic recognition - amnesic grammar                       5 7.94 36   0.629\n amnesic recognition - huntingtons grammar                  25 7.94 36   3.147\n amnesic recognition - control classification              -15 7.94 36  -1.888\n amnesic recognition - amnesic classification               -5 7.94 36  -0.629\n amnesic recognition - huntingtons classification           20 7.94 36   2.518\n huntingtons recognition - control grammar                  15 7.94 36   1.888\n huntingtons recognition - amnesic grammar                  35 7.94 36   4.406\n huntingtons recognition - huntingtons grammar              55 7.94 36   6.923\n huntingtons recognition - control classification           15 7.94 36   1.888\n huntingtons recognition - amnesic classification           25 7.94 36   3.147\n huntingtons recognition - huntingtons classification       50 7.94 36   6.294\n control grammar - amnesic grammar                          20 7.94 36   2.518\n control grammar - huntingtons grammar                      40 7.94 36   5.035\n control grammar - control classification                    0 7.94 36   0.000\n control grammar - amnesic classification                   10 7.94 36   1.259\n control grammar - huntingtons classification               35 7.94 36   4.406\n amnesic grammar - huntingtons grammar                      20 7.94 36   2.518\n amnesic grammar - control classification                  -20 7.94 36  -2.518\n amnesic grammar - amnesic classification                  -10 7.94 36  -1.259\n amnesic grammar - huntingtons classification               15 7.94 36   1.888\n huntingtons grammar - control classification              -40 7.94 36  -5.035\n huntingtons grammar - amnesic classification              -30 7.94 36  -3.776\n huntingtons grammar - huntingtons classification           -5 7.94 36  -0.629\n control classification - amnesic classification            10 7.94 36   1.259\n control classification - huntingtons classification        35 7.94 36   4.406\n amnesic classification - huntingtons classification        25 7.94 36   3.147\n p.value\n  0.0149\n  1.0000\n  0.6257\n  0.0026\n  <.0001\n  0.6257\n  0.0711\n  <.0001\n  0.0149\n  0.6257\n  0.9993\n  0.0711\n  0.6257\n  0.9993\n  0.2575\n  0.6257\n  0.0026\n  <.0001\n  0.6257\n  0.0711\n  <.0001\n  0.2575\n  0.0004\n  1.0000\n  0.9367\n  0.0026\n  0.2575\n  0.2575\n  0.9367\n  0.6257\n  0.0004\n  0.0149\n  0.9993\n  0.9367\n  0.0026\n  0.0711\n\nP value adjustment: tukey method for comparing a family of 9 estimates \n```\n:::\n:::\n\n\nNote that 8 of the comparisons are no longer significant when using Tukey's adjustment, suggesting that these might have been (when using no adjustment) Type I errors! \n\n\n## Bonferroni\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncontrast(diag_task_mean, method = \"pairwise\", adjust=\"bonferroni\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n contrast                                             estimate   SE df t.ratio\n control recognition - amnesic recognition                  30 7.94 36   3.776\n control recognition - huntingtons recognition               0 7.94 36   0.000\n control recognition - control grammar                      15 7.94 36   1.888\n control recognition - amnesic grammar                      35 7.94 36   4.406\n control recognition - huntingtons grammar                  55 7.94 36   6.923\n control recognition - control classification               15 7.94 36   1.888\n control recognition - amnesic classification               25 7.94 36   3.147\n control recognition - huntingtons classification           50 7.94 36   6.294\n amnesic recognition - huntingtons recognition             -30 7.94 36  -3.776\n amnesic recognition - control grammar                     -15 7.94 36  -1.888\n amnesic recognition - amnesic grammar                       5 7.94 36   0.629\n amnesic recognition - huntingtons grammar                  25 7.94 36   3.147\n amnesic recognition - control classification              -15 7.94 36  -1.888\n amnesic recognition - amnesic classification               -5 7.94 36  -0.629\n amnesic recognition - huntingtons classification           20 7.94 36   2.518\n huntingtons recognition - control grammar                  15 7.94 36   1.888\n huntingtons recognition - amnesic grammar                  35 7.94 36   4.406\n huntingtons recognition - huntingtons grammar              55 7.94 36   6.923\n huntingtons recognition - control classification           15 7.94 36   1.888\n huntingtons recognition - amnesic classification           25 7.94 36   3.147\n huntingtons recognition - huntingtons classification       50 7.94 36   6.294\n control grammar - amnesic grammar                          20 7.94 36   2.518\n control grammar - huntingtons grammar                      40 7.94 36   5.035\n control grammar - control classification                    0 7.94 36   0.000\n control grammar - amnesic classification                   10 7.94 36   1.259\n control grammar - huntingtons classification               35 7.94 36   4.406\n amnesic grammar - huntingtons grammar                      20 7.94 36   2.518\n amnesic grammar - control classification                  -20 7.94 36  -2.518\n amnesic grammar - amnesic classification                  -10 7.94 36  -1.259\n amnesic grammar - huntingtons classification               15 7.94 36   1.888\n huntingtons grammar - control classification              -40 7.94 36  -5.035\n huntingtons grammar - amnesic classification              -30 7.94 36  -3.776\n huntingtons grammar - huntingtons classification           -5 7.94 36  -0.629\n control classification - amnesic classification            10 7.94 36   1.259\n control classification - huntingtons classification        35 7.94 36   4.406\n amnesic classification - huntingtons classification        25 7.94 36   3.147\n p.value\n  0.0207\n  1.0000\n  1.0000\n  0.0033\n  <.0001\n  1.0000\n  0.1190\n  <.0001\n  0.0207\n  1.0000\n  1.0000\n  0.1190\n  1.0000\n  1.0000\n  0.5907\n  1.0000\n  0.0033\n  <.0001\n  1.0000\n  0.1190\n  <.0001\n  0.5907\n  0.0005\n  1.0000\n  1.0000\n  0.0033\n  0.5907\n  0.5907\n  1.0000\n  1.0000\n  0.0005\n  0.0207\n  1.0000\n  1.0000\n  0.0033\n  0.1190\n\nP value adjustment: bonferroni method for 36 tests \n```\n:::\n:::\n\n\nThe first Bonferroni adjusted $p$-value is 0.0207. \n\nThe raw (unadjusted) $p$-value from the previous question was 0.0005759265. \n\nThe Bonferroni method simply multiplies the 'raw' $p$-value by the number of the tests, which we know is 36. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n0.0005759265 * 36\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.02073335\n```\n:::\n:::\n\n\nIn terms of differences in Bonferroni to raw $p$-values, they are thus 36 times the size.  \n\nOne benefit of Bonferroni is that it can be applied to any set of $p$-values, whereas Tukey only applies when comparing the means of levels of a factor. The downside, however, is that it may be overly conservative (i.e. reduce our power to detect an effect that is truly there).  \n\n:::\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Compile Report\n\n\n\n<div class='question-begin'>Compile Report</div><div class='question-body'>\n\n  \n\nKnit your report to PDF, and check over your work. To do so, you should make sure:\n\n- Only the output you want your reader to see is visible (e.g., do you want to hide your code?)\n- Check that the **tinytex** package is installed\n- Ensure that the ‘yaml’ (bit at the very top of your document) looks something like this:\n\n```{}\n---\ntitle: \"this is my report title\"\nauthor: \"B1234506\"\ndate: \"07/09/2024\"\noutput: bookdown::pdf_document2\n---\n```\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n# What to do if you cannot knit to PDF\nIf you are having issues knitting directly to PDF, try the following:  \n\n- Knit to HTML file  \n- Open your HTML in a web-browser (e.g. Chrome, Firefox)  \n- Print to PDF (Ctrl+P, then choose to save to PDF)  \n- Open file to check formatting\n:::\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n# Hiding Code and/or Output\n\n:::{.panel-tabset}\n## Hiding R Code\n\nTo not show the code of an R code chunk, and only show the output, write:\n\n````\n```{{r, echo=FALSE}}\n# code goes here\n```\n````\n\n## Hiding R Output\n\nTo show the code of an R code chunk, but hide the output, write:\n\n````\n```{{r, results='hide'}}\n# code goes here\n```\n````\n\n## Hiding R Code and Output\n\nTo hide both code and output of an R code chunk, write:\n\n````\n```{{r, include=FALSE}}\n# code goes here\n```\n````\n:::\n\n:::\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Tinytex\nYou must make sure you have **tinytex** installed in R so that you can “Knit” your Rmd document to a PDF file:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ninstall.packages(\"tinytex\")\ntinytex::install_tinytex()\n```\n:::\n\n\n:::\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n\n<div class=\"solution-begin\"><span id='sol-start-13' class=\"fa-solid fa-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-13', 'sol-start-13')\">  Solution </span></div><div class=\"solution-body\" id = \"sol-body-13\" style=\"display: none;\">\n\n\n\nYou should end up with a PDF file. If you have followed the above instructions and still have issues with knitting, speak with a Tutor. \n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n",
    "supporting": [
      "2_04_simp_pair_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\r\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}