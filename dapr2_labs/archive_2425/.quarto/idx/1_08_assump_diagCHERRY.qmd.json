{"title":"Assumptions and Diagnostics","markdown":{"yaml":{"title":"Assumptions and Diagnostics","link-citations":true,"params":{"SHOW_SOLS":true,"TOGGLE":true},"editor_options":{"chunk_output_type":"console"}},"headingText":"<i class=\"fa fa-graduation-cap\"></i> Learning Objectives","containsRefs":false,"markdown":"\n\n```{r setup, include=FALSE}\nsource('assets/setup.R')\nlibrary(tidyverse)\nlibrary(plotly)\nlibrary(patchwork)\nlibrary(pander)\nlibrary(car)\nlibrary(performance)\nlibrary(kableExtra)\nset.seed(953)\n```\n\n:::lo\n\nAt the end of this lab, you will:\n\n1. Be able to state the assumptions underlying a linear model\n2. Specify the assumptions underlying a linear model with multiple predictors\n3. Assess if a fitted model satisfies the assumptions of your model\n4. Assess the effect of influential cases on linear model coefficients and overall model evaluations\n\n### <i class=\"fa fa-check-square-o fa-2\"></i> What You Need\n\n1. Be up to date with lectures\n2. Have completed [Week 2](https://uoepsy.github.io/dapr2/2425/labs/1_02_mlr.html) lab exercises\n\n### <i class=\"fab fa-r-project\"></i> Required R Packages\nRemember to load all packages within a code chunk at the start of your RMarkdown file using `library()`. If you do not have a package and need to install, do so within the console using `install.packages(\" \")`. For further guidance on installing/updating packages, see Section C [here](https://uoepsy.github.io/files/install-update-r#update-pkgs). \n\nFor this lab, you will need to load the following package(s):\n\n* **tidyverse** \n* **car**\n* **performance**\n* **kableExtra**\n* **sjPlot**\n\n### <i class=\"fa fa-pencil-square-o\" aria-hidden=\"true\"></i> Presenting Results\nAll results should be presented following [APA guidelines](https://apastyle.apa.org/instructional-aids/numbers-statistics-guide.pdf).If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the [rmd bootcamp](https://uoepsy.github.io/scs/rmd-bootcamp/).\n\nThe example write-up sections included as part of the solutions are **not perfect** - they instead should give you a good example of what information you should include and how to structure this. Note that you must **not** copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more [here](https://www.ed.ac.uk/academic-services/students/conduct/academic-misconduct).\n\n### <i class=\"fa fa-file\"></i> Lab Data\nYou can download the data required for this lab [here](https://uoepsy.github.io/data/wellbeing_rural.csv) or read it in via this link https://uoepsy.github.io/data/wellbeing_rural.csv \n:::\n\n# Lab Overview\n\nIn the previous labs, we have fitted a number of regression models, including some with multiple predictors. In each case, we first specified the model, then visually explored the marginal distributions and associations among variables which would be used in the analysis. Finally, we fit the model, and began to examine the fit by studying what the various parameter estimates represented, and the spread of the residuals.\n\nBut before we draw inferences using our model estimates or use our model to make predictions, we need to be satisfied that our model meets a specific set of assumptions. If these assumptions are not satisfied, the results will not hold.\n\nIn this lab, we will check the assumptions of one of the multiple linear regression models that we have previously fitted in Block 1 using the 'mwdata' dataset (see [Week 2](https://uoepsy.github.io/dapr2/2425/labs/1_02_mlr.html)). \n\n# Study Overview {#sec-studyview}\n\n> **Research Question** \n>\n> Is there an association between wellbeing and time spent outdoors *after* taking into account the association between wellbeing and social interactions? \n\n`r optbegin(\"Wellbeing/Rurality data codebook.\", olabel=FALSE, toggle=params$TOGGLE)`  \n\n__Description__\n\nFrom the Edinburgh & Lothians, 100 city/suburb residences and 100 rural residences were chosen at random and contacted to participate in the study. The Warwick-Edinburgh Mental Wellbeing Scale (WEMWBS), was used to measure mental health and well-being. \n\nParticipants filled out a questionnaire including items concerning: estimated average number of hours spent outdoors each week, estimated average number of social interactions each week (whether on-line or in-person), whether a daily routine is followed (yes/no). For those respondents who had an activity tracker app or smart watch, they were asked to provide their average weekly number of steps.  \n  \n  \n__Data Dictionary__\n\nThe data in `wellbeing_rural.csv` contain seven attributes collected from a random sample of $n=200$ hypothetical residents over Edinburgh & Lothians, and include: \n\n```{r echo=FALSE, message=FALSE, warning=FALSE}\nmwdata  <- read_csv(\"https://uoepsy.github.io/data/wellbeing_rural.csv\")\ntibble(\nvariable = names(mwdata),\ndescription = c(\"Age in years of respondent\",\"Self report estimated number of hours per week spent outdoors \", \"Self report estimated number of social interactions per week (both online and in-person)\", \"Binary 1=Yes/0=No response to the question 'Do you follow a daily routine throughout the week?'\", \"Warwick-Edinburgh Mental Wellbeing Scale (WEMWBS), a self-report measure of mental health and well-being. The scale is scored by summing responses to each item, with items answered on a 1 to 5 Likert scale. The minimum scale score is 14 and the maximum is 70\", \"Location of primary residence (City, Suburb, Rural)\", \"Average weekly number of steps in thousands (as given by activity tracker if available)\")\n) %>% gt::gt()\n```\n  \n  \n__Preview__\n\nThe first six rows of the data are:\n\n```{r echo=FALSE, message=FALSE}\nread_csv('https://uoepsy.github.io/data/wellbeing_rural.csv') %>% head %>% gt::gt()\n```\n  \n`r optend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Setup\n\n`r qbegin(\"Setup\", qlabel = FALSE)`  \n\n1. Create a new RMarkdown file\n2. Load the required package(s)\n3. Read the wellbeing dataset into R, assigning it to an object named `mwdata`\n4. Fit the following model:\n\n$$\n\\text{Wellbeing} = \\beta_0 + \\beta_1 \\cdot \\text{Social Interactions} + \\beta_2 \\cdot \\text{Outdoor Time} + \\epsilon\n$$\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n\n```{r message=FALSE}\n#Loading the required package(s)\nlibrary(tidyverse)\nlibrary(car)\nlibrary(performance)\nlibrary(kableExtra)\nlibrary(sjPlot)\n\n# Reading in data and storing to an object named 'mwdata'\nmwdata <- read_csv(\"https://uoepsy.github.io/data/wellbeing_rural.csv\")\n\n# wellbeing model\nwb_mdl1 <- lm(wellbeing ~ outdoor_time + social_int, data = mwdata) \n```\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Exercises\n\n## Assumptions\n\n`r qbegin(1)`\n\nLet's start by using `check_model()` for our `wb_mdl1` model - we can refer to these plots as a guide as we work through the assumptions questions of the lab.\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nSee the [useful assumptions plots > check_model() flaschard](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#model-assumptions).\n\n:::\n\n:::{.callout-note appearance=\"simple\" collapse=\"true\"}\n\nThese plots **cannot** be used in your reports - they are to be used as a guide only.\n\n:::\n\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\ncheck_model(wb_mdl1)\n```\n\nThe `check_model()` function is a useful way to check the assumptions of models, as it also returns some useful notes to aid your interpretation. There does appear to be evidence that some assumptions may have been violated, **but** to be sure we need to check each assumption individually with plots that are more suitable for a statistics report. \n\n`r solend()`\n\n<br>\n\n`r qbegin(2)`\n\nCheck if the fitted model satisfies the linearity assumption for `wb_mdl1`. \n\nWrite a sentence summarising whether or not you consider the assumption to have been met. Justify your answer with reference to the plots.\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nHow you check this assumption depends on the number of predictors in your model:\n\n+ Single predictor: Use either residual vs fitted values plot (`plot(model, which = 1)`), and/or a scatterplot with loess lines  \n+ Multiple predictors: Use component-residual plots (also known as partial-residual plots) to check the assumption of linearity  \n\nFor more information, as well as tips to aid your interpretation, review the [linearity flashcard](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#model-assumptions).\n\n:::\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r, fig.width = 10, out.width = '85%'}\ncrPlots(wb_mdl1)\n```\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nThe smoother (the pink line) follows quite closely to a linear relationship (the dashed blue line), though there was some deviation. Overall, the evidence suggested that the linearity assumption was met.\n\n:::\n\n`r solend()`\n\n<br>\n\n`r qbegin(3)`\n\nCheck if the fitted model `wb_mdl1` satisfy the equal variance (homoscedasticity) assumption. \n\nWrite a sentence summarising whether or not you consider the assumption to have been met. Justify your answer with reference to the plot.\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nUse `residualPlots()` to plot residuals against the predictor. Since we are only interested in visually assessing our assumption checks, we can suppress the curvature test output by specifying `tests = FALSE`.\n\nFor more information, as well as tips to aid your interpretation, review the [equal variances (homoscedasticity) flashcard](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#model-assumptions).\n\n:::{.callout-hint collapse=\"true\"}\n\n**Quick Tip if plotting using `plot(model)`** \n\nAs the residuals can be positive or negative, we can make it easier to assess equal spread by improving the 'resolution' of the points.\n\nWe can make all residuals positive by discarding the sign (take the absolute value), and then take the square root to make them closer to each other.\n\nA plot of $\\sqrt{|\\text{Standardized residuals}|}$ against the fitted values can be obtained via `plot(model, which = 3)`.\n\n:::\n \n:::\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n\nWe can visually assess by plotting the Pearson residuals against the fitted values:\n\n```{r, fig.width = 8, out.width = '90%'}\nresidualPlots(wb_mdl1, tests = FALSE)\n```\n\nOr by plotting the $\\sqrt{|\\text{Standardized residuals}|}$ against the fitted values:\n\n```{r}\nplot(wb_mdl1, which = 3)\n```\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nPartial residual plots did show non-linear trends between residuals and predictors, hence there is evidence of non-constant variance i.e., heteroscedasticity. Thus, the data did not meet the assumption of equal variance, as the spread of the standardized residuals did not appear to be constant (for the most part) as the fitted values varied.\n\nIn the second plot, all points are above 0, but the majority of the points are not very close to each other. The line does not appear to be relatively flat, and so this also suggested that the error variance does change across the fitted values.\n\n:::\n\n`r solend()`\n\n<br> \n\n`r qbegin(4)`\n\nAssess whether there is autocorrelation in the error terms.\n  \nWrite a sentence summarising whether or not you consider the assumption of independence to have been met (you may have to assume certain aspects of the study design).  \n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nReview the [independence (of errors) flashcard](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#model-assumptions).\n\n:::\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nSince our data were collected from a between-persons study design, we can assume (i.e., based on design, we believe) the errors to be independent.\n:::\n\n`r solend()`\n\n<br>\n\n`r qbegin(5)`\n\nCheck if the fitted model `wb_mdl1` satisfies the normality assumption. \n  \nWrite a sentence summarising whether or not you consider the assumption to have been met. Justify your answer with reference to the plots. \n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nFor more information, as well as tips to aid your interpretation, review the [normality (of errors) flashcard](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#model-assumptions).\n \n:::\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n:::{.panel-tabset}\n\n### Histogram\n\n```{r}\nggplot(data = mwdata, aes(x = wb_mdl1$residuals)) +\n    geom_histogram() \n```\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nThe histogram indicated that the residuals (the differences between observed and predicted values) followed close to a normal distribution. \n\n:::\n\n### QQ Plot\n\n```{r}\nplot(wb_mdl1, which = 2)\n```\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nThe QQplot indicated that the residuals followed close to a normal distribution, as the points followed a linear pattern and there was no substantial skew or departure from normality. There was some evidence of heavier tails, and we may want to examine some observations more closely (i.e., 16, 78, 109).\n\n:::\n\n:::\n\n`r solend()`\n\n<br>\n\n## Multicollinearity \n\n`r qbegin(6)`\n\nFor `wb_mdl1`, calculate the variance inflation factor (VIF) for the predictors in the model.  \n\nWrite a sentence summarising whether or not you consider multicollinearity to be a problem here.  \n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nFor more information, as well as tips to aid your interpretation, review the [multicollinearity flashcard](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#model-assumptions).\n\n:::\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\nvif(wb_mdl1)\n```\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nThe VIF values for all predictors are <5, indicating that multicollinearity is not adversely affecting model estimates. \n\n:::\n\n`r solend()`\n\n## Diagnostics \n\n`r qbegin(7)`\n\nCreate a new tibble which contains:  \n\n1. The original variables from the model (Hint, what does `wb_mdl1$model` give you?)\n2. The fitted values from the model $\\hat y$  \n3. The residuals $\\hat \\epsilon$\n4. The studentised residuals\n5. The hat values\n6. The Cook's Distance values\n\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nFor following will likely be useful to consider when creating your `tibble()`:\n\n1. Think about what `wb_mdl1$model` gives you\n2. `fitted()`\n3. `residuals()`\n4. `rstudent()`\n5. `hatvalues()`\n6. `cooks.distance()`\n\n:::\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\nmdl_diagnost <- \n  tibble(\n  wb_mdl1$model,\n  fitted = fitted(wb_mdl1),\n  resid = residuals(wb_mdl1),\n  studres = rstudent(wb_mdl1),\n  hats = hatvalues(wb_mdl1),\n  cooksd = cooks.distance(wb_mdl1)\n)\n```\n\n\n`r solend()`\n\n<br>\n\n`r qbegin(8)`\n\nFrom the tibble above, comment on the following:\n\n* Looking at the studentised residuals, are there any outliers? \n* Looking at the hat values, are there any observations with high leverage? \n* Looking at the Cook's Distance values, are there any highly influential points?  \n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nAlongside the lecture materials, review the [individual case diagnostics flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#model-assumptions) and consider the commonly used cut-off criteria.\n\n:::\n\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n::: {.panel-tabset}\n\n## Outliers\n\nIn a standard normal distribution, 95% of the values are roughly between -2 and 2. Because of this, studentised residuals of $>2$ or $< -2$ indicate potential outlyingness. \n\nWe can ask `R` how many of the *absolute* values (by specifying `abs()`) are $>2$:\n```{r}\ntable(abs(mdl_diagnost$studres) > 2)\n```\n\nWe have 11 `TRUE` observations, which tells us that they have |studentised residuals| $>2$. \n\nWe can identify which of our observations have these values:\n\n```{r}\nwhich(abs(mdl_diagnost$studres) > 2)\n```\n\nSo we know that observations (or rows) 16, 50, 53, 58, 62, 76, 78, 109, 126, 151, and 163 have absolute values that have studentised residuals of $>2$ or $< -2$.\n\nWe could also *filter* our newly created tibble to these observations to examine the values further:\n\n```{r}\nmwdata %>%\n    mutate(\n    studres = rstudent(wb_mdl1)) %>%\n  dplyr::filter(., studres > 2 | studres < -2) %>%\n  arrange(., desc(studres)) %>%\n  kable(.)  %>%   \n    kable_styling(., full_width = F)\n```\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nThere were `r sum(abs(mdl_diagnost$studres) > 2)` observations identified as potential outliers.\n\n:::\n\n## High Leverage\n\nHat values of more than $2 \\bar{h}$ (2 times the average hat value) are considered high leverage. The average hat value, $\\bar{h}$ is calculated as $\\frac{k + 1}{n}$, where $k$ is the number of predictors, and $n$ is the sample size.\n\nFor our model:\n$$\n\\bar h = \\frac{k+1}{n} = \\frac{2+1}{200} = \\frac{3}{200} = 0.015\n$$\nWe can ask whether any of observations have hat values which are greater than $2 \\bar h$:\n\n```{r}\ntable(mdl_diagnost$hats > (2*0.015))\n```\n\nWe have 16 `TRUE` observations, which tells us that they have high leverage.\n\nWe can identify which of our observations have these values:\n\n```{r}\nwhich(mdl_diagnost$hats > (2*0.015))\n```\n\nSo we know that observations (or rows) 25, 56, 59, 60, 72, 73, 75, 79, 127, 131, 149, 159, 165, 169, 176, and 197 have hat values which are greater than $2 \\bar h$.\n\nWe could also *filter* our newly created tibble to these observations to examine the values further:\n\n```{r}\nmwdata %>%\n    mutate(\n    hats = hatvalues(wb_mdl1)) %>%\n  dplyr::filter(., hats > (2*0.015)) %>%\n  arrange(., desc(hats)) %>%\n  kable(.)  %>%   \n    kable_styling(., full_width = F)\n```\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nThere were `r sum(mdl_diagnost$hats > (2*0.015))` observations that had high leverage (> $2 \\bar h$).  \n\n:::\n\n## Influential Points\n\nWe are using a Cook's Distance cut-off of $\\frac{4}{n-k-1}$, where $k$ is the number of predictors, and $n$ is the sample size.  \n\nFor our model:\n$$\nD_{cutoff} = \\frac{4}{n-k-1} = \\frac{4}{200 - 2 - 1} = \\frac{4}{197} = 0.020\n$$\n\nWe can ask whether any of observations have a high influence on our model estimates:\n\n```{r}\ntable(mdl_diagnost$cooksd > 0.020)\n```\n\nYes, we have 11 `TRUE` observations, which tells us that they are above the $D_{cutoff} = 0.020$.\n\nWe can identify which of our observations have these values:\n\n```{r}\nwhich(mdl_diagnost$cooksd > 0.020)\n```\n\nSo we know that observations (or rows) 16, 53, 58, 76, 78, 109, 125, 126, 149, 151, and 169 have $D > 0.020$. \n\nWe could also *filter* our newly created tibble to these observations to examine the values further:\n\n```{r}\nmwdata %>%\n    mutate(\n    cooksd = cooks.distance(wb_mdl1)) %>%\n  dplyr::filter(., cooksd > 4/(200-2-1)) %>%\n  arrange(., desc(cooksd)) %>%\n  kable(.)  %>%   \n    kable_styling(., full_width = F)\n```\n\nYou can also display the Cook's Distance values themselves using `plot(model, which = 4)`, and add a horizontal line at the $D_{cutoff} = 0.020$ using `abline(h = ???)`:\n\n```{r}\nplot(wb_mdl1, which = 4, abline(h=0.020, col=\"blue\"))\n```\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nThere were `r sum(mdl_diagnost$cooksd > 0.020)` observations that had a high influence on our model estimates.\n\n:::\n\n:::\n\n`r solend()`\n\n<br>\n\n`r qbegin(9)`\n\nUse the function `influence.measures()` to extract these delete-1 measures^[leave-one-out deletion diagnostics] of influence.  \n\nChoose a couple of these measures to focus on, exploring in more detail (you may want to examine values or even try plotting distributions). \n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n \nReview the [individual case diagnostics flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#model-assumptions).  \n\nThe function `influence.measures()` returns an `infl`-type object. To plot this, we need to find a way to extract the actual numbers from it.  \n\nWhat do you think `names(influence.measures(wb_mdl1))` shows you? How can we use `influence.measures(wb_mdl1)$<insert name here>` to extract the matrix of numbers?  \n\n:::\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n::: {.panel-tabset}\n\n## Extracting `influence.measures()`\n\n```{r}\n#extract measures\ninf_mes <- influence.measures(wb_mdl1)\n\n#examine top ten rows, and round to 3 decimal places\nround(inf_mes$infmat[1:10,], 3)\n\n```\n\n\n## Examine `DFBETA` values\n\nDFbeta represents the difference in the beta coefficients when a case is excluded from the model versus when it's included. A large DFbeta value would suggest that a case has a substantial impact on the estimated coefficients, and thus a high influence on the model results; a small DFbeta value would suggest that the case has less influence on the estimated coefficients.\n\nA commonly used cut-off or threshold to compare $|DFBETA|$ values (absolute values) against is $\\frac{2}{\\sqrt{n}}$ (see Belsley et al., (1980) p. 28 for more info)^[Belsley, D. A., Kuh, E., & Welsch, R. E. (2005). Regression diagnostics: Identifying influential data and sources of collinearity. John Wiley & Sons. DOI: 10.1002/0471725153]. \n\nFor our model:\n\n$$\n|DFBETA_{cutoff}| \\quad = \\quad \\frac{2}{\\sqrt{n}} \\quad = \\quad  \\frac{2}{\\sqrt{200}}  = 0.141\n$$\n\nIn order to extract these in order to arrange in descending order, we need to save our delete-1 measures of influence as a dataframe (via `as.data.frame()`). Then we can then arrange our DFBETA values in descending order (via `arrange(desc(???))`). To avoid returning 200 rows of output (i.e., the length of the dataframe), we can ask for the first 15 rows via (`head(., 15)`):\n\n```{r}\n#save as a dataframe\ninf_mes1 <- as.data.frame(inf_mes$infmat)\n\n#arrange dfbeta values in descending order using the absolute value, and show first 10 rows\ninf_mes1 %>%\n    arrange(desc(abs(dfb.1_))) %>%\n    head(., 15)\n```\n\nWe can see that we have `r sum(abs(inf_mes1$dfb.1_) > (2/sqrt(200)))` $|DFBETA|$ values > $\\frac{2}{\\sqrt{200}}$, from observations (or rows) 16, 53, 56, 75, 76, 85, 101, 109, 149, 173, and 179 that we may want to examine further:\n\n```{r}\nwhich(abs(inf_mes1$dfb.1_) > (2/sqrt(200)))\n```\n\n## Plotting COVRATIO statistics\n\nValues which are $>1+\\frac{3(k+1)}{n}$ or $<1-\\frac{3(k+1)}{n}$ are considered as having strong influence.  \n\nFor our model, this is:\n$$\n1 \\pm \\frac{3(k+1)}{n} \\quad = \\quad 1 \\pm\\frac{3(2+1)}{200} \\quad = \\quad 1\\pm \\frac{9}{200} \\quad = \\quad 1\\pm0.045\n$$\n\nThe \"infmat\" bit of an `infl`-type object contains the numbers, as we can see from out output above. To use it with `ggplot()`, we will need to turn it into a dataframe (`as.data.frame()`), or a tibble (`as_tibble()`):   \n\n```{r message=FALSE, warning=FALSE}\ninfdata <- inf_mes$infmat %>%\n  as_tibble()\n```\n\nNow we can build our plot. It would be useful to add vertical lines at the values $\\quad 1\\pm0.045$. To do so, we can use the `geom_vline()` function: \n\n```{r message=FALSE, warning=FALSE}\nggplot(data = infdata, aes(x = cov.r)) + \n  geom_histogram() +\n  geom_vline(aes(xintercept = c(1-0.045), col = \"blue\")) +\n  geom_vline(aes(xintercept = c(1+0.045), col = \"red\")) + \n  theme(legend.position = \"none\")  #remove legend\n```\n\nIt looks like a few observations may be having quite a strong influence on the standard errors here. We can check specifically how many observations are potentially having a having strong influence using the cut off $1\\pm0.045$:\n\n```{r}\ntable(infdata$cov.r < 1 - 0.045 | infdata$cov.r > 1 + 0.045)\n```\n\nWe can identify these 15 observations to investigate further:\n\n```{r}\nwhich(infdata$cov.r < 1 - 0.045 | infdata$cov.r > 1 + 0.045)\n```\n\nWe know that observations (or rows) 16, 25, 50, 58, 62, 72, 73, 78, 79, 109, 127, 151, 159, 165, and 176 have $\\text{COVRATIO  }  1\\pm0.045$. \n\n:::\n\n`r solend()`\n\n<br>\n\n`r qbegin(10)`\n\nWhat approaches would be appropriate to take given the issues highlighted above with the violations of assumptions and case diagnostic results?\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nThere are lots of different options available to us. We may want to consider one of the approaches described in the [next steps: what to do with violations of assumptions / problematic case diagnostic results flashcard](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#model-assumptions). \n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Compile Report\n\n`r qbegin(\"Compile Report\", qlabel = FALSE)`  \n\nKnit your report to PDF, and check over your work. To do so, you should make sure:\n\n- Only the output you want your reader to see is visible (e.g., do you want to hide your code?)\n- Check that the **tinytex** package is installed\n- Ensure that the ‘yaml’ (bit at the very top of your document) looks something like this:\n\n```{}\n---\ntitle: \"this is my report title\"\nauthor: \"B1234506\"\ndate: \"07/09/2024\"\noutput: bookdown::pdf_document2\n---\n```\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n# What to do if you cannot knit to PDF\nIf you are having issues knitting directly to PDF, try the following:  \n\n- Knit to HTML file  \n- Open your HTML in a web-browser (e.g. Chrome, Firefox)  \n- Print to PDF (Ctrl+P, then choose to save to PDF)  \n- Open file to check formatting\n:::\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n# Hiding Code and/or Output\n\n:::{.panel-tabset}\n## Hiding R Code\n\nTo not show the code of an R code chunk, and only show the output, write:\n\n````\n```{{r, echo=FALSE}}\n# code goes here\n```\n````\n\n## Hiding R Output\n\nTo show the code of an R code chunk, but hide the output, write:\n\n````\n```{{r, results='hide'}}\n# code goes here\n```\n````\n\n## Hiding R Code and Output\n\nTo hide both code and output of an R code chunk, write:\n\n````\n```{{r, include=FALSE}}\n# code goes here\n```\n````\n:::\n\n:::\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Tinytex\nYou must make sure you have **tinytex** installed in R so that you can “Knit” your Rmd document to a PDF file:\n\n```{r eval = FALSE}\ninstall.packages(\"tinytex\")\ntinytex::install_tinytex()\n```\n\n:::\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n\nYou should end up with a PDF file. If you have followed the above instructions and still have issues with knitting, speak with a Tutor. \n\n`r solend()`\n\n","srcMarkdownNoYaml":"\n\n```{r setup, include=FALSE}\nsource('assets/setup.R')\nlibrary(tidyverse)\nlibrary(plotly)\nlibrary(patchwork)\nlibrary(pander)\nlibrary(car)\nlibrary(performance)\nlibrary(kableExtra)\nset.seed(953)\n```\n\n:::lo\n\n### <i class=\"fa fa-graduation-cap\"></i> Learning Objectives\nAt the end of this lab, you will:\n\n1. Be able to state the assumptions underlying a linear model\n2. Specify the assumptions underlying a linear model with multiple predictors\n3. Assess if a fitted model satisfies the assumptions of your model\n4. Assess the effect of influential cases on linear model coefficients and overall model evaluations\n\n### <i class=\"fa fa-check-square-o fa-2\"></i> What You Need\n\n1. Be up to date with lectures\n2. Have completed [Week 2](https://uoepsy.github.io/dapr2/2425/labs/1_02_mlr.html) lab exercises\n\n### <i class=\"fab fa-r-project\"></i> Required R Packages\nRemember to load all packages within a code chunk at the start of your RMarkdown file using `library()`. If you do not have a package and need to install, do so within the console using `install.packages(\" \")`. For further guidance on installing/updating packages, see Section C [here](https://uoepsy.github.io/files/install-update-r#update-pkgs). \n\nFor this lab, you will need to load the following package(s):\n\n* **tidyverse** \n* **car**\n* **performance**\n* **kableExtra**\n* **sjPlot**\n\n### <i class=\"fa fa-pencil-square-o\" aria-hidden=\"true\"></i> Presenting Results\nAll results should be presented following [APA guidelines](https://apastyle.apa.org/instructional-aids/numbers-statistics-guide.pdf).If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the [rmd bootcamp](https://uoepsy.github.io/scs/rmd-bootcamp/).\n\nThe example write-up sections included as part of the solutions are **not perfect** - they instead should give you a good example of what information you should include and how to structure this. Note that you must **not** copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more [here](https://www.ed.ac.uk/academic-services/students/conduct/academic-misconduct).\n\n### <i class=\"fa fa-file\"></i> Lab Data\nYou can download the data required for this lab [here](https://uoepsy.github.io/data/wellbeing_rural.csv) or read it in via this link https://uoepsy.github.io/data/wellbeing_rural.csv \n:::\n\n# Lab Overview\n\nIn the previous labs, we have fitted a number of regression models, including some with multiple predictors. In each case, we first specified the model, then visually explored the marginal distributions and associations among variables which would be used in the analysis. Finally, we fit the model, and began to examine the fit by studying what the various parameter estimates represented, and the spread of the residuals.\n\nBut before we draw inferences using our model estimates or use our model to make predictions, we need to be satisfied that our model meets a specific set of assumptions. If these assumptions are not satisfied, the results will not hold.\n\nIn this lab, we will check the assumptions of one of the multiple linear regression models that we have previously fitted in Block 1 using the 'mwdata' dataset (see [Week 2](https://uoepsy.github.io/dapr2/2425/labs/1_02_mlr.html)). \n\n# Study Overview {#sec-studyview}\n\n> **Research Question** \n>\n> Is there an association between wellbeing and time spent outdoors *after* taking into account the association between wellbeing and social interactions? \n\n`r optbegin(\"Wellbeing/Rurality data codebook.\", olabel=FALSE, toggle=params$TOGGLE)`  \n\n__Description__\n\nFrom the Edinburgh & Lothians, 100 city/suburb residences and 100 rural residences were chosen at random and contacted to participate in the study. The Warwick-Edinburgh Mental Wellbeing Scale (WEMWBS), was used to measure mental health and well-being. \n\nParticipants filled out a questionnaire including items concerning: estimated average number of hours spent outdoors each week, estimated average number of social interactions each week (whether on-line or in-person), whether a daily routine is followed (yes/no). For those respondents who had an activity tracker app or smart watch, they were asked to provide their average weekly number of steps.  \n  \n  \n__Data Dictionary__\n\nThe data in `wellbeing_rural.csv` contain seven attributes collected from a random sample of $n=200$ hypothetical residents over Edinburgh & Lothians, and include: \n\n```{r echo=FALSE, message=FALSE, warning=FALSE}\nmwdata  <- read_csv(\"https://uoepsy.github.io/data/wellbeing_rural.csv\")\ntibble(\nvariable = names(mwdata),\ndescription = c(\"Age in years of respondent\",\"Self report estimated number of hours per week spent outdoors \", \"Self report estimated number of social interactions per week (both online and in-person)\", \"Binary 1=Yes/0=No response to the question 'Do you follow a daily routine throughout the week?'\", \"Warwick-Edinburgh Mental Wellbeing Scale (WEMWBS), a self-report measure of mental health and well-being. The scale is scored by summing responses to each item, with items answered on a 1 to 5 Likert scale. The minimum scale score is 14 and the maximum is 70\", \"Location of primary residence (City, Suburb, Rural)\", \"Average weekly number of steps in thousands (as given by activity tracker if available)\")\n) %>% gt::gt()\n```\n  \n  \n__Preview__\n\nThe first six rows of the data are:\n\n```{r echo=FALSE, message=FALSE}\nread_csv('https://uoepsy.github.io/data/wellbeing_rural.csv') %>% head %>% gt::gt()\n```\n  \n`r optend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Setup\n\n`r qbegin(\"Setup\", qlabel = FALSE)`  \n\n1. Create a new RMarkdown file\n2. Load the required package(s)\n3. Read the wellbeing dataset into R, assigning it to an object named `mwdata`\n4. Fit the following model:\n\n$$\n\\text{Wellbeing} = \\beta_0 + \\beta_1 \\cdot \\text{Social Interactions} + \\beta_2 \\cdot \\text{Outdoor Time} + \\epsilon\n$$\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n\n```{r message=FALSE}\n#Loading the required package(s)\nlibrary(tidyverse)\nlibrary(car)\nlibrary(performance)\nlibrary(kableExtra)\nlibrary(sjPlot)\n\n# Reading in data and storing to an object named 'mwdata'\nmwdata <- read_csv(\"https://uoepsy.github.io/data/wellbeing_rural.csv\")\n\n# wellbeing model\nwb_mdl1 <- lm(wellbeing ~ outdoor_time + social_int, data = mwdata) \n```\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Exercises\n\n## Assumptions\n\n`r qbegin(1)`\n\nLet's start by using `check_model()` for our `wb_mdl1` model - we can refer to these plots as a guide as we work through the assumptions questions of the lab.\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nSee the [useful assumptions plots > check_model() flaschard](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#model-assumptions).\n\n:::\n\n:::{.callout-note appearance=\"simple\" collapse=\"true\"}\n\nThese plots **cannot** be used in your reports - they are to be used as a guide only.\n\n:::\n\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\ncheck_model(wb_mdl1)\n```\n\nThe `check_model()` function is a useful way to check the assumptions of models, as it also returns some useful notes to aid your interpretation. There does appear to be evidence that some assumptions may have been violated, **but** to be sure we need to check each assumption individually with plots that are more suitable for a statistics report. \n\n`r solend()`\n\n<br>\n\n`r qbegin(2)`\n\nCheck if the fitted model satisfies the linearity assumption for `wb_mdl1`. \n\nWrite a sentence summarising whether or not you consider the assumption to have been met. Justify your answer with reference to the plots.\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nHow you check this assumption depends on the number of predictors in your model:\n\n+ Single predictor: Use either residual vs fitted values plot (`plot(model, which = 1)`), and/or a scatterplot with loess lines  \n+ Multiple predictors: Use component-residual plots (also known as partial-residual plots) to check the assumption of linearity  \n\nFor more information, as well as tips to aid your interpretation, review the [linearity flashcard](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#model-assumptions).\n\n:::\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r, fig.width = 10, out.width = '85%'}\ncrPlots(wb_mdl1)\n```\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nThe smoother (the pink line) follows quite closely to a linear relationship (the dashed blue line), though there was some deviation. Overall, the evidence suggested that the linearity assumption was met.\n\n:::\n\n`r solend()`\n\n<br>\n\n`r qbegin(3)`\n\nCheck if the fitted model `wb_mdl1` satisfy the equal variance (homoscedasticity) assumption. \n\nWrite a sentence summarising whether or not you consider the assumption to have been met. Justify your answer with reference to the plot.\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nUse `residualPlots()` to plot residuals against the predictor. Since we are only interested in visually assessing our assumption checks, we can suppress the curvature test output by specifying `tests = FALSE`.\n\nFor more information, as well as tips to aid your interpretation, review the [equal variances (homoscedasticity) flashcard](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#model-assumptions).\n\n:::{.callout-hint collapse=\"true\"}\n\n**Quick Tip if plotting using `plot(model)`** \n\nAs the residuals can be positive or negative, we can make it easier to assess equal spread by improving the 'resolution' of the points.\n\nWe can make all residuals positive by discarding the sign (take the absolute value), and then take the square root to make them closer to each other.\n\nA plot of $\\sqrt{|\\text{Standardized residuals}|}$ against the fitted values can be obtained via `plot(model, which = 3)`.\n\n:::\n \n:::\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n\nWe can visually assess by plotting the Pearson residuals against the fitted values:\n\n```{r, fig.width = 8, out.width = '90%'}\nresidualPlots(wb_mdl1, tests = FALSE)\n```\n\nOr by plotting the $\\sqrt{|\\text{Standardized residuals}|}$ against the fitted values:\n\n```{r}\nplot(wb_mdl1, which = 3)\n```\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nPartial residual plots did show non-linear trends between residuals and predictors, hence there is evidence of non-constant variance i.e., heteroscedasticity. Thus, the data did not meet the assumption of equal variance, as the spread of the standardized residuals did not appear to be constant (for the most part) as the fitted values varied.\n\nIn the second plot, all points are above 0, but the majority of the points are not very close to each other. The line does not appear to be relatively flat, and so this also suggested that the error variance does change across the fitted values.\n\n:::\n\n`r solend()`\n\n<br> \n\n`r qbegin(4)`\n\nAssess whether there is autocorrelation in the error terms.\n  \nWrite a sentence summarising whether or not you consider the assumption of independence to have been met (you may have to assume certain aspects of the study design).  \n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nReview the [independence (of errors) flashcard](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#model-assumptions).\n\n:::\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nSince our data were collected from a between-persons study design, we can assume (i.e., based on design, we believe) the errors to be independent.\n:::\n\n`r solend()`\n\n<br>\n\n`r qbegin(5)`\n\nCheck if the fitted model `wb_mdl1` satisfies the normality assumption. \n  \nWrite a sentence summarising whether or not you consider the assumption to have been met. Justify your answer with reference to the plots. \n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nFor more information, as well as tips to aid your interpretation, review the [normality (of errors) flashcard](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#model-assumptions).\n \n:::\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n:::{.panel-tabset}\n\n### Histogram\n\n```{r}\nggplot(data = mwdata, aes(x = wb_mdl1$residuals)) +\n    geom_histogram() \n```\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nThe histogram indicated that the residuals (the differences between observed and predicted values) followed close to a normal distribution. \n\n:::\n\n### QQ Plot\n\n```{r}\nplot(wb_mdl1, which = 2)\n```\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nThe QQplot indicated that the residuals followed close to a normal distribution, as the points followed a linear pattern and there was no substantial skew or departure from normality. There was some evidence of heavier tails, and we may want to examine some observations more closely (i.e., 16, 78, 109).\n\n:::\n\n:::\n\n`r solend()`\n\n<br>\n\n## Multicollinearity \n\n`r qbegin(6)`\n\nFor `wb_mdl1`, calculate the variance inflation factor (VIF) for the predictors in the model.  \n\nWrite a sentence summarising whether or not you consider multicollinearity to be a problem here.  \n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nFor more information, as well as tips to aid your interpretation, review the [multicollinearity flashcard](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#model-assumptions).\n\n:::\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\nvif(wb_mdl1)\n```\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nThe VIF values for all predictors are <5, indicating that multicollinearity is not adversely affecting model estimates. \n\n:::\n\n`r solend()`\n\n## Diagnostics \n\n`r qbegin(7)`\n\nCreate a new tibble which contains:  \n\n1. The original variables from the model (Hint, what does `wb_mdl1$model` give you?)\n2. The fitted values from the model $\\hat y$  \n3. The residuals $\\hat \\epsilon$\n4. The studentised residuals\n5. The hat values\n6. The Cook's Distance values\n\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nFor following will likely be useful to consider when creating your `tibble()`:\n\n1. Think about what `wb_mdl1$model` gives you\n2. `fitted()`\n3. `residuals()`\n4. `rstudent()`\n5. `hatvalues()`\n6. `cooks.distance()`\n\n:::\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\nmdl_diagnost <- \n  tibble(\n  wb_mdl1$model,\n  fitted = fitted(wb_mdl1),\n  resid = residuals(wb_mdl1),\n  studres = rstudent(wb_mdl1),\n  hats = hatvalues(wb_mdl1),\n  cooksd = cooks.distance(wb_mdl1)\n)\n```\n\n\n`r solend()`\n\n<br>\n\n`r qbegin(8)`\n\nFrom the tibble above, comment on the following:\n\n* Looking at the studentised residuals, are there any outliers? \n* Looking at the hat values, are there any observations with high leverage? \n* Looking at the Cook's Distance values, are there any highly influential points?  \n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nAlongside the lecture materials, review the [individual case diagnostics flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#model-assumptions) and consider the commonly used cut-off criteria.\n\n:::\n\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n::: {.panel-tabset}\n\n## Outliers\n\nIn a standard normal distribution, 95% of the values are roughly between -2 and 2. Because of this, studentised residuals of $>2$ or $< -2$ indicate potential outlyingness. \n\nWe can ask `R` how many of the *absolute* values (by specifying `abs()`) are $>2$:\n```{r}\ntable(abs(mdl_diagnost$studres) > 2)\n```\n\nWe have 11 `TRUE` observations, which tells us that they have |studentised residuals| $>2$. \n\nWe can identify which of our observations have these values:\n\n```{r}\nwhich(abs(mdl_diagnost$studres) > 2)\n```\n\nSo we know that observations (or rows) 16, 50, 53, 58, 62, 76, 78, 109, 126, 151, and 163 have absolute values that have studentised residuals of $>2$ or $< -2$.\n\nWe could also *filter* our newly created tibble to these observations to examine the values further:\n\n```{r}\nmwdata %>%\n    mutate(\n    studres = rstudent(wb_mdl1)) %>%\n  dplyr::filter(., studres > 2 | studres < -2) %>%\n  arrange(., desc(studres)) %>%\n  kable(.)  %>%   \n    kable_styling(., full_width = F)\n```\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nThere were `r sum(abs(mdl_diagnost$studres) > 2)` observations identified as potential outliers.\n\n:::\n\n## High Leverage\n\nHat values of more than $2 \\bar{h}$ (2 times the average hat value) are considered high leverage. The average hat value, $\\bar{h}$ is calculated as $\\frac{k + 1}{n}$, where $k$ is the number of predictors, and $n$ is the sample size.\n\nFor our model:\n$$\n\\bar h = \\frac{k+1}{n} = \\frac{2+1}{200} = \\frac{3}{200} = 0.015\n$$\nWe can ask whether any of observations have hat values which are greater than $2 \\bar h$:\n\n```{r}\ntable(mdl_diagnost$hats > (2*0.015))\n```\n\nWe have 16 `TRUE` observations, which tells us that they have high leverage.\n\nWe can identify which of our observations have these values:\n\n```{r}\nwhich(mdl_diagnost$hats > (2*0.015))\n```\n\nSo we know that observations (or rows) 25, 56, 59, 60, 72, 73, 75, 79, 127, 131, 149, 159, 165, 169, 176, and 197 have hat values which are greater than $2 \\bar h$.\n\nWe could also *filter* our newly created tibble to these observations to examine the values further:\n\n```{r}\nmwdata %>%\n    mutate(\n    hats = hatvalues(wb_mdl1)) %>%\n  dplyr::filter(., hats > (2*0.015)) %>%\n  arrange(., desc(hats)) %>%\n  kable(.)  %>%   \n    kable_styling(., full_width = F)\n```\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nThere were `r sum(mdl_diagnost$hats > (2*0.015))` observations that had high leverage (> $2 \\bar h$).  \n\n:::\n\n## Influential Points\n\nWe are using a Cook's Distance cut-off of $\\frac{4}{n-k-1}$, where $k$ is the number of predictors, and $n$ is the sample size.  \n\nFor our model:\n$$\nD_{cutoff} = \\frac{4}{n-k-1} = \\frac{4}{200 - 2 - 1} = \\frac{4}{197} = 0.020\n$$\n\nWe can ask whether any of observations have a high influence on our model estimates:\n\n```{r}\ntable(mdl_diagnost$cooksd > 0.020)\n```\n\nYes, we have 11 `TRUE` observations, which tells us that they are above the $D_{cutoff} = 0.020$.\n\nWe can identify which of our observations have these values:\n\n```{r}\nwhich(mdl_diagnost$cooksd > 0.020)\n```\n\nSo we know that observations (or rows) 16, 53, 58, 76, 78, 109, 125, 126, 149, 151, and 169 have $D > 0.020$. \n\nWe could also *filter* our newly created tibble to these observations to examine the values further:\n\n```{r}\nmwdata %>%\n    mutate(\n    cooksd = cooks.distance(wb_mdl1)) %>%\n  dplyr::filter(., cooksd > 4/(200-2-1)) %>%\n  arrange(., desc(cooksd)) %>%\n  kable(.)  %>%   \n    kable_styling(., full_width = F)\n```\n\nYou can also display the Cook's Distance values themselves using `plot(model, which = 4)`, and add a horizontal line at the $D_{cutoff} = 0.020$ using `abline(h = ???)`:\n\n```{r}\nplot(wb_mdl1, which = 4, abline(h=0.020, col=\"blue\"))\n```\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nThere were `r sum(mdl_diagnost$cooksd > 0.020)` observations that had a high influence on our model estimates.\n\n:::\n\n:::\n\n`r solend()`\n\n<br>\n\n`r qbegin(9)`\n\nUse the function `influence.measures()` to extract these delete-1 measures^[leave-one-out deletion diagnostics] of influence.  \n\nChoose a couple of these measures to focus on, exploring in more detail (you may want to examine values or even try plotting distributions). \n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n \nReview the [individual case diagnostics flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#model-assumptions).  \n\nThe function `influence.measures()` returns an `infl`-type object. To plot this, we need to find a way to extract the actual numbers from it.  \n\nWhat do you think `names(influence.measures(wb_mdl1))` shows you? How can we use `influence.measures(wb_mdl1)$<insert name here>` to extract the matrix of numbers?  \n\n:::\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n::: {.panel-tabset}\n\n## Extracting `influence.measures()`\n\n```{r}\n#extract measures\ninf_mes <- influence.measures(wb_mdl1)\n\n#examine top ten rows, and round to 3 decimal places\nround(inf_mes$infmat[1:10,], 3)\n\n```\n\n\n## Examine `DFBETA` values\n\nDFbeta represents the difference in the beta coefficients when a case is excluded from the model versus when it's included. A large DFbeta value would suggest that a case has a substantial impact on the estimated coefficients, and thus a high influence on the model results; a small DFbeta value would suggest that the case has less influence on the estimated coefficients.\n\nA commonly used cut-off or threshold to compare $|DFBETA|$ values (absolute values) against is $\\frac{2}{\\sqrt{n}}$ (see Belsley et al., (1980) p. 28 for more info)^[Belsley, D. A., Kuh, E., & Welsch, R. E. (2005). Regression diagnostics: Identifying influential data and sources of collinearity. John Wiley & Sons. DOI: 10.1002/0471725153]. \n\nFor our model:\n\n$$\n|DFBETA_{cutoff}| \\quad = \\quad \\frac{2}{\\sqrt{n}} \\quad = \\quad  \\frac{2}{\\sqrt{200}}  = 0.141\n$$\n\nIn order to extract these in order to arrange in descending order, we need to save our delete-1 measures of influence as a dataframe (via `as.data.frame()`). Then we can then arrange our DFBETA values in descending order (via `arrange(desc(???))`). To avoid returning 200 rows of output (i.e., the length of the dataframe), we can ask for the first 15 rows via (`head(., 15)`):\n\n```{r}\n#save as a dataframe\ninf_mes1 <- as.data.frame(inf_mes$infmat)\n\n#arrange dfbeta values in descending order using the absolute value, and show first 10 rows\ninf_mes1 %>%\n    arrange(desc(abs(dfb.1_))) %>%\n    head(., 15)\n```\n\nWe can see that we have `r sum(abs(inf_mes1$dfb.1_) > (2/sqrt(200)))` $|DFBETA|$ values > $\\frac{2}{\\sqrt{200}}$, from observations (or rows) 16, 53, 56, 75, 76, 85, 101, 109, 149, 173, and 179 that we may want to examine further:\n\n```{r}\nwhich(abs(inf_mes1$dfb.1_) > (2/sqrt(200)))\n```\n\n## Plotting COVRATIO statistics\n\nValues which are $>1+\\frac{3(k+1)}{n}$ or $<1-\\frac{3(k+1)}{n}$ are considered as having strong influence.  \n\nFor our model, this is:\n$$\n1 \\pm \\frac{3(k+1)}{n} \\quad = \\quad 1 \\pm\\frac{3(2+1)}{200} \\quad = \\quad 1\\pm \\frac{9}{200} \\quad = \\quad 1\\pm0.045\n$$\n\nThe \"infmat\" bit of an `infl`-type object contains the numbers, as we can see from out output above. To use it with `ggplot()`, we will need to turn it into a dataframe (`as.data.frame()`), or a tibble (`as_tibble()`):   \n\n```{r message=FALSE, warning=FALSE}\ninfdata <- inf_mes$infmat %>%\n  as_tibble()\n```\n\nNow we can build our plot. It would be useful to add vertical lines at the values $\\quad 1\\pm0.045$. To do so, we can use the `geom_vline()` function: \n\n```{r message=FALSE, warning=FALSE}\nggplot(data = infdata, aes(x = cov.r)) + \n  geom_histogram() +\n  geom_vline(aes(xintercept = c(1-0.045), col = \"blue\")) +\n  geom_vline(aes(xintercept = c(1+0.045), col = \"red\")) + \n  theme(legend.position = \"none\")  #remove legend\n```\n\nIt looks like a few observations may be having quite a strong influence on the standard errors here. We can check specifically how many observations are potentially having a having strong influence using the cut off $1\\pm0.045$:\n\n```{r}\ntable(infdata$cov.r < 1 - 0.045 | infdata$cov.r > 1 + 0.045)\n```\n\nWe can identify these 15 observations to investigate further:\n\n```{r}\nwhich(infdata$cov.r < 1 - 0.045 | infdata$cov.r > 1 + 0.045)\n```\n\nWe know that observations (or rows) 16, 25, 50, 58, 62, 72, 73, 78, 79, 109, 127, 151, 159, 165, and 176 have $\\text{COVRATIO  }  1\\pm0.045$. \n\n:::\n\n`r solend()`\n\n<br>\n\n`r qbegin(10)`\n\nWhat approaches would be appropriate to take given the issues highlighted above with the violations of assumptions and case diagnostic results?\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nThere are lots of different options available to us. We may want to consider one of the approaches described in the [next steps: what to do with violations of assumptions / problematic case diagnostic results flashcard](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#model-assumptions). \n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Compile Report\n\n`r qbegin(\"Compile Report\", qlabel = FALSE)`  \n\nKnit your report to PDF, and check over your work. To do so, you should make sure:\n\n- Only the output you want your reader to see is visible (e.g., do you want to hide your code?)\n- Check that the **tinytex** package is installed\n- Ensure that the ‘yaml’ (bit at the very top of your document) looks something like this:\n\n```{}\n---\ntitle: \"this is my report title\"\nauthor: \"B1234506\"\ndate: \"07/09/2024\"\noutput: bookdown::pdf_document2\n---\n```\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n# What to do if you cannot knit to PDF\nIf you are having issues knitting directly to PDF, try the following:  \n\n- Knit to HTML file  \n- Open your HTML in a web-browser (e.g. Chrome, Firefox)  \n- Print to PDF (Ctrl+P, then choose to save to PDF)  \n- Open file to check formatting\n:::\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n# Hiding Code and/or Output\n\n:::{.panel-tabset}\n## Hiding R Code\n\nTo not show the code of an R code chunk, and only show the output, write:\n\n````\n```{{r, echo=FALSE}}\n# code goes here\n```\n````\n\n## Hiding R Output\n\nTo show the code of an R code chunk, but hide the output, write:\n\n````\n```{{r, results='hide'}}\n# code goes here\n```\n````\n\n## Hiding R Code and Output\n\nTo hide both code and output of an R code chunk, write:\n\n````\n```{{r, include=FALSE}}\n# code goes here\n```\n````\n:::\n\n:::\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Tinytex\nYou must make sure you have **tinytex** installed in R so that you can “Knit” your Rmd document to a PDF file:\n\n```{r eval = FALSE}\ninstall.packages(\"tinytex\")\ntinytex::install_tinytex()\n```\n\n:::\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n\nYou should end up with a PDF file. If you have followed the above instructions and still have issues with knitting, speak with a Tutor. \n\n`r solend()`\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":true,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"include-in-header":["assets/toggling.html",{"text":"<link rel=\"stylesheet\" href=\"https://uoepsy.github.io/assets/css/ccfooter.css\" />\n"}],"number-sections":false,"output-file":"1_08_assump_diagCHERRY.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.57","bibliography":["biblio.bib"],"toc_float":true,"code-annotations":"hover","link-citations":true,"theme":["united","assets/style-labs.scss"],"title":"Assumptions and Diagnostics","params":{"SHOW_SOLS":true,"TOGGLE":true},"editor_options":{"chunk_output_type":"console"}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}