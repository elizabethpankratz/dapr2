{"title":"Simple Effects, Pairwise Comparisons, & Corrections","markdown":{"yaml":{"title":"Simple Effects, Pairwise Comparisons, & Corrections","link-citations":true,"params":{"SHOW_SOLS":true,"TOGGLE":true},"editor_options":{"chunk_output_type":"console"}},"headingText":"<i class=\"fa fa-graduation-cap\"></i> Learning Objectives","containsRefs":false,"markdown":"\n\n```{r setup, include=FALSE}\nsource('assets/setup.R')\n\nset.seed(3)\n\nlibrary(DT)\nlibrary(tidyverse)\n```\n\n:::lo\n\nAt the end of this lab, you will:\n\n1. Understand how to interpret simple effects for experimental designs\n2. Understand how to conduct pairwise comparisons\n3. Understand how to apply corrections available for multiple comparisons\n\n### <i class=\"fa fa-check-square-o fa-2\"></i> What You Need\n\n1. Be up to date with lectures\n2. Have completed previous lab exercises from [Semester 1 Week 7](https://uoepsy.github.io/dapr2/2425/labs/1_06_dummy.html), [Semester 1 Week 8](https://uoepsy.github.io/dapr2/2425/labs/1_07_effects.html), [Semester 1 Week 11](https://uoepsy.github.io/dapr2/2425/labs/1_10_writeup_recap2.html), [Semester 2 Week 1](https://uoepsy.github.io/dapr2/2425/labs/2_01_int1_nc.html), [Semester 2 Week 2](https://uoepsy.github.io/dapr2/2425/labs/2_02_int2_nn.html), and [Semester 2 Week 3](https://uoepsy.github.io/dapr2/2425/labs/2_03_int3_cc.html).\n\n### <i class=\"fab fa-r-project\"></i> Required R Packages\nRemember to load all packages within a code chunk at the start of your RMarkdown file using `library()`. If you do not have a package and need to install, do so within the console using `install.packages(\" \")`. For further guidance on installing/updating packages, see Section C [here](https://uoepsy.github.io/files/install-update-r#update-pkgs).  \n\nFor this lab, you will need to load the following package(s):\n\n* **tidyverse** \n* **psych** \n* **kableExtra**\n* **sjPlot**\n* **interactions**\n* **patchwork**\n* **emmeans**\n\n### <i class=\"fa fa-pencil-square-o\" aria-hidden=\"true\"></i> Presenting Results\nAll results should be presented following [APA guidelines](https://apastyle.apa.org/instructional-aids/numbers-statistics-guide.pdf).If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the [rmd bootcamp](https://uoepsy.github.io/scs/rmd-bootcamp/).\n\nThe example write-up sections included as part of the solutions are **not perfect** - they instead should give you a good example of what information you should include and how to structure this. Note that you must **not** copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more [here](https://www.ed.ac.uk/academic-services/students/conduct/academic-misconduct).  \n\n### <i class=\"fa fa-file\"></i> Lab Data\nYou can download the data required for this lab [here](https://uoepsy.github.io/data/cognitive_experiment.csv) or read it in via this link https://uoepsy.github.io/data/cognitive_experiment.csv    \n  \nNote, you have already worked with *some* of this data last week - see [Semester 2 Week 3 lab](https://uoepsy.github.io/dapr2/2425/labs/2_03_int3_cc.html), but we now have a third Task condition - Classification. \n\n:::\n\n# Study Overview\n\n> **Research Question** \n>\n> Are there differences in types of memory deficits for those experiencing different cognitive impairment(s)?\n\nIn this week's exercises, we will further explore questions such as:\n\n- Does level $i$ of the first factor have an effect on the response?\n- Does level $j$ of the second factor have an effect on the response?\n- Is there a combined effect of level $i$ of the first factor and level $j$ of the second factor on the response? In other words, is there interaction of the two factors so that the combined effect is not simply the additive effect of level $i$ of the first factor plus the effect of level $j$ of the second factor?\n\n`r optbegin(\"Cognitive Exp 3x3 data codebook.\", olabel=FALSE, toggle=params$TOGGLE)` \n  \n__Description__\n\nThe researchers designed a study yielding a $3 \\times 3$ factorial design to test whether there are differences in types of memory deficits for those experiencing different cognitive impairment(s).\n\nThe tasks chosen by the researchers have been picked to map onto the theoretical differences between the three types of research participants. The Grammar and Classification tasks are known to reflect *implicit* memory processes, whereas the recognition task is known to reflect *explicit* memory processes. If the theory is correct, we would expect the difference in scores between the recognition and grammar/classification tasks to be relatively similar for the control and amnesiac groups, but relatively larger for the Huntingtons group compared to controls.\n\n__Data Dictionary__\n\nThe data in `cognitive_experiment.csv` contain three attributes collected from $n=45$ participants, and includes: \n\n```{r echo=FALSE, message=FALSE, warning=FALSE}\ncog <- read_csv(\"https://uoepsy.github.io/data/cognitive_experiment.csv\")\ntibble(\nvariable = names(cog),\ndescription = c(\"Diagnosis classifies the three types of individuals: 1 = Amnesic patients, 2 = Huntingtons patients, and 3 = Control group of individuals with no known neurological disorder\", \"Task tells us to which one of three tasks each study participant was randomly assigned to: 1 = Grammar (which consists of classifying letter sequences as either following or not following grammatical rules), 2 = Classification (which consists of classifying stimuli into certain groupings, based on previously indicated information about the groups characteristics), and 3 = Recognition (which consists of recognising particular stimuli as stimuli that have previously been presented during the task)\", \"Score\")) %>% gt::gt()\n```\n  \n__Data Overview__\n\nWe have data from the 45 participants (15 amnesiacs, 15 Huntington individuals, and 15 controls). Recall that study involves two factors, now with three levels each. For each combination of factor levels we have 5 observations:\n\n```{r echo=FALSE, message=FALSE}\nlibrary(tidyverse)\ndf <- read_csv('https://uoepsy.github.io/data/cognitive_experiment.csv')\n# head(df)\n\ndf$Diagnosis <- factor(df$Diagnosis, \n                       labels = c(\"amnesic\", \"huntingtons\", \"control\"),\n                       ordered = FALSE)\n\ndf$Task <- factor(df$Task, \n                  labels = c(\"grammar\", \"classification\", \"recognition\"), \n                  ordered = FALSE)\n\nlibrary(kableExtra)\n\ndf %>% \n    pivot_wider(names_from = 'Task', values_from = 'Y', values_fn = list) %>% \n    kable() %>%\n    kable_styling(full_width = FALSE) %>%\n    add_header_above(c(\" \" = 1, \"Task\" = 3))\n```\n\nThe five observations are assumed to come from a population having a specific mean. The population means corresponding to each combination of factor levels can be schematically written as:\n\n$$\n\\begin{matrix}\n                   &         &         & \\textbf{Task} & \\\\\n                   &         &  (j=1) & (j=2) & (j=3) & \\\\\n                   &         &  \\text{ grammar} & \\text{ classification} & \\text{ recognition} \\\\\n                   & (i=1)\\text{ control} & \\mu_{1,1} & \\mu_{1,2} & \\mu_{1,3} \\\\\n\\textbf{Diagnosis} & (i=2)\\text{ amnesic} & \\mu_{2,1} & \\mu_{2,2} & \\mu_{2,3} \\\\\n                   & (i=3)\\text{ huntingtons} & \\mu_{3,1} & \\mu_{3,2} & \\mu_{3,3}\n\\end{matrix}\n$$\n  \n  \n__Preview__\n\nThe first six rows of the data are:\n\n```{r echo=FALSE, message=FALSE}\nread_csv('https://uoepsy.github.io/data/cognitive_experiment.csv') %>% head %>% gt::gt()\n```\n\n`r optend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Setup\n\n`r qbegin(\"Setup\", qlabel = FALSE)`  \n\n1. Create a new RMarkdown file\n2. Load the required package(s)\n3. Read the cognitive_experiment dataset into R, assigning it to an object named `cog`\n \n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r message=FALSE}\n#load packages\nlibrary(tidyverse)\nlibrary(psych)\nlibrary(kableExtra)\nlibrary(emmeans)\nlibrary(sjPlot)\nlibrary(interactions)\nlibrary(patchwork)\n\n#read in data\ncog <- read_csv('https://uoepsy.github.io/data/cognitive_experiment.csv')\n```\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Exercises \n\n## Study & Analysis Plan Overview \n\n`r qbegin(1)`\n\nFirstly, examine the dataset, and perform any necessary and appropriate data management steps.\n\nNext, consider what would be the most appropriate coding constraint to apply in order to best address the research question - i.e., are we interested in whether group X (e.g., Amnesic) differed from group Y (e.g., Huntingtons), or whether group X (e.g., Amnesic) differed from the grand mean? \n\nChoose appropriate reference levels for the Diagnosis and Task variables based on your decision above. \n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\n*Data Management*  \n   \n- The `str()` function will return the overall structure of the dataset, this can be quite handy to look at    \n- Convert categorical variables to factors, and if needed, provide better variable names*    \n- Label factors appropriately to aid with your model interpretations if required*      \n- Check that the dataset is complete (i.e., are there any `NA` values?). We can check this using `is.na()`    \n  \nNote that all of these steps can be done in combination - the `mutate()` and `factor()` functions will likely be useful here.   \n  \n*Coding Constraints*  \n  \n- If you think you'd benefit from a refresher on coding constraints, it might be best to revisit the materials from Semester 1 Block 2 (especially the  [dummy vs effects coding flashcard](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#numeric-outcomes-categorical-predictors)).  \n- If you would like an overview of coding constraints in the context of interaction models, review the [categorical x categorical example > coding constraints flashcard](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#categorical-x-categorical-example).    \n\n*Reference Levels*  \n  \n- Review the [specifying reference levels flashcard](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#numeric-outcomes-categorical-predictors).  \n\n  \n*See the [numeric outcomes & categorical predictors flashcard](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#numeric-outcomes-categorical-predictors).  \n \n:::\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nLet's have a look at the data to see what we're working with - `str()` or `head()` are a good place to start - and then we should check for any missing data (`NA` values):\n```{r}\n#first look at dataset structure\nstr(cog)\n\n#now lets look at top 6 rows (or the head) of the dataset\nhead(cog)\n\n#check for NAs \ntable(is.na(cog))\n# there are none - all FALSE\n```\n\nNext, lets convert `Diagnosis` and `Task` into factors, making the labels of each factor level more meaningful. According to the data description, the encoding of the factor `Diagnosis` is: 1 = amnesic patients, 2 = Huntingtons patients, and 3 = control patients. The encoding for the factor `Task` is: 1 = grammar task, 2 = classification task, and 3 = recognition task.\n\n```{r}\ncog <- cog %>%\n    mutate(\n        Diagnosis = factor(Diagnosis, \n                           levels = c(1, 2, 3),\n                           labels = c('amnesic', 'huntingtons', 'control'),\n                           ordered = FALSE),\n        Task = factor(Task, \n                      levels = c(1, 2, 3),\n                      labels = c('grammar', 'classification', 'recognition'),\n                      ordered = FALSE)) %>%\n    rename(Score = Y)\n```\n\nSince we are interested in comparing groups, we should use dummy coding. By default, `R` uses dummy coding, so we do not need to make any changes to the coding constraint. \n\nHowever, for our reference groups, we're likely to want it to be the Control group for Diagnosis, and recognition for Task: \n\n```{r}\ncog$Diagnosis <- fct_relevel(cog$Diagnosis, \"control\")\ncog$Task <- fct_relevel(cog$Task, \"recognition\")\n```\n\n`r solend()`\n\n<br>  \n\n`r qbegin(2)`\n\nProvide a brief overview of the study design and data, before detailing your analysis plan to address the research question.\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint \n\n- Give the reader some background on the context of the study (you might be able to re-use some of the content you wrote for [Semester 2 Week 3 lab](https://uoepsy.github.io/dapr2/2425/labs/2_03_int3_cc.html) here, but note that we now have an extra condition within Task)\n- Outline data checks / data cleaning\n- State what type of analysis you will conduct in order to address the research question\n- Specify the model to be fitted to address the research question (note that you will need to specify the reference level of your categorical variables. This will be somewhat similar to last week, but with the addition of Classification in Task, our model will contain a different number of parameters)\n- Specify your chosen significance ($\\alpha$) level\n- State your hypotheses\n\nMuch of the information required can be found in the [Study Overview] codebook.\n\nThe [statistical models](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#statistical-models) flashcards may also be useful to refer to. Specifically the [interaction models flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#interaction-models) and [categorical x categorical example flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#categorical-x-categorical-example) might be of most use.\n\n:::\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nThe `cog` dataset contained information on 45 hypothetical participants from a between-subjects study. Participants belonged to one of three 'Diagnosis' groups, which had 15 participants in each - Control, Amnesic, or Huntingtons. Participants from each of the Diagnosis groups were equally and randomly assigned to one of three 'Tasks' to measure different memory processes - Grammar, Classification, or Recognition - the former two measuring implicit memory and the latter explicit. This resulted in 5 participants from each Diagnosis group in each of the three Task conditions. \n\nAll participant data was complete, and categorical variables were coded as factors. For the purpose of this analysis, 'Control' was designated as the reference group for Diagnosis, since it was the only group of participants with no known neurological disorder. For Task, the recognition task measures explicit memory whereas the other two measure implicit memory, so this was specified as the reference group.   \n\nBoxplots will be used to visualise the associations among Diagnosis and Task conditions. To address the research question of whether the difference in performance between explicit and implicit memory tasks will be greatest for Huntington patients in comparison to controls, we first need to define the dummy variables for both\n\nDiagnosis:\n\n$$\n\\begin{gather*}\n\\text{D}_\\text{Amnesic} = \\begin{cases}\n1 & \\text{if Diagnosis is Amnesic}\\\\  \n0 & \\text{otherwise}\n\\end{cases}\n\\\\  \n\\\\  \n\\text{D}_\\text{Huntingtons} = \\begin{cases}\n1 & \\text{if Diagnosis is Huntingtons}\\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\quad   \n\\\\  \n\\\\  \n(\\text{Control is base level})  \n\\end{gather*}\n$$\n\nand for Task:  \n  \n$$\n\\begin{gather*}    \n\\text{T}_\\text{Grammar} = \\begin{cases}\n1 & \\text{if Task is Grammar}\\\\\n0 & \\text{otherwise}\\\\  \n\\end{cases}\\\n\\\\  \n\\\\\n\\text{T}_\\text{Classification} = \\begin{cases}  \n1 & \\text{if Task is Classification}\\\\   \n0 & \\text{otherwise}\\\\ \n\\end{cases}\\\\\\  \n\\quad    \n\\\\    \n\\\\  \n(\\text{Recognition is base level})\\\\ \n\\end{gather*}   \n$$\n\nBased on the above dummy coding, we are going to fit the following interaction model:\n\n$$\n\\begin{align}\n\\text{Interaction Model}: \\text{Score} &= \\beta_0  \\\\\n      &+ \\beta_1 \\cdot \\text{D}_\\text{Amnesic} + \\beta_2 \\cdot  \\text{D}_\\text{Huntingtons}  \\\\\n      &+ \\beta_3 \\cdot  \\text{T}_\\text{Grammar}  + \\beta_4 \\cdot  \\text{T}_\\text{Classification}  \\\\\n      &+ \\beta_5 \\cdot  (\\text{D}_\\text{Amnesic} \\cdot  \\text{T}_\\text{Grammar})  \\\\\n      &+ \\beta_6 \\cdot  (\\text{D}_\\text{Huntingtons} \\cdot  \\text{T}_\\text{Grammar})  \\\\\n      &+ \\beta_7 \\cdot  (\\text{D}_\\text{Amnesic} \\cdot  \\text{T}_\\text{Classification})  \\\\\n      &+ \\beta_8 \\cdot  (\\text{D}_\\text{Huntingtons} \\cdot  \\text{T}_\\text{Classification})  \\\\\n      &+ \\epsilon  \n\\end{align}\n$$\n\nEffects will be considered statistically significant at $\\alpha = .05$\n\nOur hypotheses are:\n\n$H_0:$ All $\\beta_j = 0$ (for $j = 5, 6, 7, 8$)\n\nThere are no significant differences in performance between explicit and implicit memory tasks for patients with different cognitive impairment(s). \n\n$H_1:$ At least one $\\beta_j \\neq  0$ (for $j = 5, 6, 7, 8$)\n\nThere are significant differences in performance between explicit and implicit memory tasks for patients with different cognitive impairment(s). \n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n## Descriptive Statistics & Visualisations\n\n`r qbegin(3)`\n\nProvide a table of descriptive statistics and visualise your data.\n\nInterpret the descriptive statistics and visualisations in the context of the study (i.e., comment on any observed differences among groups). \n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nReview the many ways to numerically and visually explore your data by reading over the [data exploration flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#data-exploration).\n  \nFor examples, see flashcards on [descriptives statistics tables - categorical and numeric values examples](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#data-exploration) and [categorical x categorical example - visualise data](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#categorical-x-categorical-example).    \n  \nMake sure to comment on any observed differences among the sample means of the different conditions.  \n\n:::\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n::: {.panel-tabset}\n\n## Numeric\n\nDescriptive statistics presented in a well formatted table:\n\n```{r message=FALSE, warning=FALSE}\n#| label: tbl-cog-descript\n#| tbl-cap: Descriptive Statistics\ncog_stats <- cog %>% \n    group_by(Diagnosis, Task) %>%\n    summarise(\n        Mean = mean(Score), \n        SD = sd(Score),\n        SE = sd(Score) / sqrt(n()),\n        Min = min(Score),\n        Max = max(Score)) %>%\n    kable(caption = \"Descriptive Statistics of Score\", digits = 2) %>%\n    kable_styling()\n\ncog_stats\n```\n\n## Visual \n\nSince we have a continuous outcome and 2 categorical predictors - a boxplot would be most appropriate for visualisations:\n\n```{r}\n#| label: fig-cog-desc\n#| fig-cap: \"Association between Task Condition, Diagnosis, and Score\"\ncog_plt <- ggplot(data = cog, aes(x = Diagnosis, y = Score, color = Task)) +\n  geom_boxplot() +\n  labs(x = 'Diagnosis', y = 'Score')\ncog_plt\n```\n\n:::\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\n+ Control patients consistently performed best across all tasks. They did not appear to differ substantially in their scores between grammar and classification tasks, but they clearly performed better in the recognition task in comparison to both the grammar and classification ones.\n\n+ Amnesic patients appeared to perform better than Huntingtons patients in grammar and classification tasks (reflecting intrinsic memory processes), and performed worse than Huntingtons patients in the recognition task (reflecting extrinsic memory processes).\n\n:::\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n## Model Fitting & Interpretation \n\n`r qbegin(4)`\n\nFit the specified model  using `lm()`, and assign it the name \"mdl_int\".\n\nProvide key model results in a formatted table and plot the interaction model before reporting in-text the overall model fit.\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\n*Model Building*  \n  \n- We can fit interaction models using the `lm()` function.  \n- For an overview, see the [interaction models flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#interaction-models). \n- For an example, review the [interaction models > categorical x categorical example > model building flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#categorical-x-categorical-example).  \n\n*Results Table*  \n  \n- Use `tab_model()` from the __sjPlot__ package. For a quick guide, review the [tables flashcard](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#tables).  \n\n*Plot Model*  \n  \n- Using the `cat_plot()` function from the **interactions** package, visualise the interaction effects from your model. \n- For an overview and example, review the [interaction models > categorical x categorical example > model visualisation flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#categorical-x-categorical-example).   \n\n:::\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n::: {.panel-tabset}\n\n## Build & Check Model\n\n```{r}\n#fit interaction model\nmdl_int <- lm(Score ~ Diagnosis * Task, data = cog)\n\n#check model output\nsummary(mdl_int)\n```\n\n## Results Table\n\n```{r}\n#| label: tbl-w4-modresults\n#| tbl-cap: Regression Table for Scores Model\ntab_model(mdl_int,\n          dv.labels = \"Scores\",\n          pred.labels = c(\"Diagnosisamnesic\" = \"Diagnosis - Amnesic\",\n                          \"Diagnosishuntingtons\" = \"Diagnosis - Huntingtons\",\n                          \"Taskgrammar\" = \"Task - Grammar\",\n                          \"Taskclassification\" = \"Task - Classification\",\n                          \"Diagnosisamnesic:Taskgrammar\" = \"Diagnosis - Amnesic : Task - Grammar\",\n                          \"Diagnosishuntingtons:Taskgrammar\" = \"Diagnosis - Huntingtons : Task - Grammar\",\n                          \"Diagnosisamnesic:Taskclassification\" = \"Diagnosis - Amnesic : Task - Classification\",\n                          \"Diagnosishuntingtons:Taskclassification\" = \"Diagnosis - Huntingtons : Task - Classification\"),\n          title = \"Regression Table for Scores Model\")\n```\n\n## Interaction Plot\n\n```{r}\n#| label: fig-cog-4\n#| fig-cap: \"Interaction Plot\"\nplt_cog_mdl <- cat_plot(model = mdl_int, \n                  pred = Diagnosis, \n                  modx = Task, \n                  main.title = \"Scores across Diagnosis and Task\",\n                  x.label = \"Diagnosis\",\n                  y.label = \"Score\",\n                  legend.main = \"Task\")\nplt_cog_mdl\n```\n\n:::\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nFull regression results including 95% Confidence Intervals are shown in @tbl-w4-modresults, and the interaction model is visually presented in @fig-cog-4. The $F$-test for model utility was significant $(F(8, 36) = 12.28, p < .001)$, and the model explained approximately 67% of the variability in Scores.  \n\n:::\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n## Contrast Analysis\n\nLet's move onto testing differences between specific group means.\n\n`r qbegin(5)`\n\nIn terms of the diagnostic groups, we want to compare the individuals with amnesia to those with Huntingtons. This corresponds to a contrast with coefficients of 0, 1, and −1, for control, amnesic, and Huntingtons, respectively. \n\nSimilarly, in terms of the tasks, we want to compare the average of the two implicit memory tasks with the explicit memory task. This corresponds to a contrast with coefficients of 0.5, 0.5, and −1 for the three tasks. \n\nWhen we are in presence of a significant interaction, the coefficients for a contrast between the means are found by multiplying each row coefficient with all column coefficients as shown below:\n\n```{r echo=FALSE, out.width = '100%'}\nknitr::include_graphics('images/contr_interaction.png')\n```\n\nSpecify the coefficients to be used in the contrast analysis, and present in a table.\n\nNext, formally state the contrast that the researchers were interested in as testable hypotheses. \n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nFor an overview and example, review the [manual contrasts flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#manual-contrasts).\n\n:::\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nWe can specify the coefficients to be used in the contrast analysis in `R` using either:\n\n::: {.panel-tabset}\n\n## Option 1\n\n```{r}\ndiag_coef  <- c('control' = 0, 'amnesic' = 1, 'huntingtons' = -1)\ntask_coef  <- c('grammar' = 0.5, 'classification' = 0.5, 'recognition' = -1)\ncontr_coef <- outer(diag_coef, task_coef)\ncontr_coef\n```\n\n## Option 2\n\n```{r}\ndiag_coef  <- c('control' = 0, 'amnesic' = 1, 'huntingtons' = -1)\ntask_coef  <- c('grammar' = 0.5, 'classification' = 0.5, 'recognition' = -1)\ncontr_coef <- diag_coef %o% task_coef\ncontr_coef\n```\n\n:::\n\nUsing either approach, we can then convert into a well-formatted table:\n\n```{r}\n#| label: tbl-q5-weights\n#| tbl-cap: Contrast Weights\ncontr_coef %>% \n    kable(., caption = \"Contrast Weights\") %>%\n    kable_styling(full_width = FALSE) \n```\n\nThe above coefficients correspond to the following hypotheses:\n\n$$\nH_0: \\quad \\left(\\frac{\\mu_{2,1} + \\mu_{2,2}}{2} - \\mu_{2,3} \\right) - \\left( \\frac{\\mu_{3,1} + \\mu_{3,2}}{2} - \\mu_{3,3} \\right) = 0\n$$\n\n$$\nH_1: \\quad \\left(\\frac{\\mu_{2,1} + \\mu_{2,2}}{2} - \\mu_{2,3} \\right) - \\left( \\frac{\\mu_{3,1} + \\mu_{3,2}}{2} - \\mu_{3,3} \\right) \\neq 0\n$$\n\nwhich can be equivalently specified as:\n\n$$\nH_0: \\quad \\frac{\\mu_{2,1} + \\mu_{2,2}}{2} - \\mu_{2,3} \\quad = \\quad \\frac{\\mu_{3,1} + \\mu_{3,2}}{2} - \\mu_{3,3}\n$$\n\n$$  \nH_1: \\quad \\frac{\\mu_{2,1} + \\mu_{2,2}}{2} - \\mu_{2,3} \\quad \\neq \\quad  \\frac{\\mu_{3,1} + \\mu_{3,2}}{2} - \\mu_{3,3}\n$$\n\nboth statements state that, in the population, the difference between the mean implicit memory and the explicit memory score is the same for individuals with amnesia and Huntingtons. \n\nNote that the scores for the grammar and classification tasks have been averaged to obtain a single measure of 'implicit memory' score.\n\n`r solend()`\n\n<br>\n\n`r qbegin(6)`\n\nFirstly, use `emmeans()` to obtain the estimated means and uncertainties for your factors. \n\nNext, specify the coefficients of the comparison and run the contrast analysis, obtaining 95% confidence intervals. \n\nReport the results of the contrast analysis in full. \n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nFor an overview and example, review the [manual contrasts flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#manual-contrasts).\n\n:::\n\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nNow that we have the coefficients, let's firstly call the `emmeans` function to get the estimated means of our groups (this is also helpful to look at the ordering of the groups):\n\n```{r}\ndiag_task_mean <- emmeans(mdl_int, ~ Diagnosis*Task)\ndiag_task_mean\n```\n\nNext, from `contr_coef`, insert the coefficients **following the order specified by the rows of** `diag_task_mean` above. That is, the first one should be for `control` `recognition` and have a value of 0, the second for `amnesic` `recognition` with a value of -1, and so on...\n\nLet's specify our weights, and give a name to this contrast (in this example 'Research Hyp'):\n\n```{r}\ndiag_task_comp <- contrast(diag_task_mean, \n                     method = list('Research Hyp' = c(0, -1, 1, 0, 0.5, -0.5, 0, 0.5, -0.5))\n                     )\n```\n\nNext, let's look at the output via one of two ways:\n\n::: {.panel-tabset}\n\n## Option 1\n\n```{r}\n#examine output\ndiag_task_comp\n\n#obtain confidence intervals\nconfint(diag_task_comp)\n```\n\n## Option 2\n\n```{r}\n#examine summary output and state `infer = TRUE` to include confidence intervals\nsummary(diag_task_comp, infer = TRUE)\n```\n\n:::\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nWe performed a test against $H_0: \\quad \\frac{\\mu_{2,1} + \\mu_{2,2}}{2} - \\mu_{2,3} \\quad = \\quad \\frac{\\mu_{3,1} + \\mu_{3,2}}{2} - \\mu_{3,3}$. At the 5\\% significance level, there was evidence that individuals with Amnesia and Huntingtons did differ in the difference between implicit and explicit memory tasks $(t(36) = 5.40, p < .001, \\text{two-sided})$, and this difference was estimated to be 52.50. We are 95\\% confident that the difference in implicit and explicit memory scores between individuals with Amnesia and Huntingtons was between 32.80 to 72.20 points. Therefore, we can reject the null hypothesis that the difference in differences was equal to zero. \n\n:::\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n## Simple Effects\n\n`r qbegin(7)`\n\nExamine the simple effects for Task at each level of Diagnosis; and then the simple effects for Diagnosis at each level of Task. \n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nFor an overview and example, review the [simple effects flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#categorical-x-categorical-example). \n\n:::\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n\n::: {.panel-tabset}\n\n## Simple Effects of Task\n\nFrom `mdl_int_simple1` we can see the differences between tasks for each diagnosis group:\n\n```{r}\nmdl_int_simple1 <- pairs(diag_task_mean, simple = \"Task\")\nmdl_int_simple1\n```\n\n## Simple Effects of Diagnosis\n\nFrom `mdl_int_simple2` we can see the differences between diagnoses for each task group:\n\n```{r}\nmdl_int_simple2 <- pairs(diag_task_mean, simple = \"Diagnosis\")\nmdl_int_simple2\n```\n\n:::\n\n`r solend()`\n\n<br>\n\n`r qbegin(8)`\n\nVisualise the interaction, displaying two plots - one with Diagnosis on the x-axis, and the other with Task on the x-axis.\n\nConsidering the simple effects that you noted above, identify the significant effects and match them to the corresponding points of your interaction plot.\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nFor an overview and example, review the [simple effects flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#categorical-x-categorical-example).  \n  \nRecall that the **patchwork** package allows us to arrange multiple plots using either `/` or `|` or `+`.\n\n:::\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n::: {.panel-tabset}\n\n## Simple Effects of Task\n\n```{r}\nplt_1 <- emmip(mdl_int, Diagnosis ~ Task, CIs = TRUE)\nplt_1\n```\n\nFor the simple effects of task (see `plt_1`), we saw the significant differences (those for which $p<.05$):  \n\n+ Only in the Huntingtons group, between recognition & grammar and recognition & classification tasks  \n    + left-most blue point compared to the middle blue point, and then compared to the right-most blue point  \n\n## Simple Effects of Diagnosis\n\n```{r}\nplt_2 <- emmip(mdl_int, Task ~ Diagnosis, CIs = TRUE)\nplt_2\n```\n\n\nFor the simple effects of Diagnosis (see `plt_2`), we saw significant differences (those for which $p<.05$):  \n\n+ in the recognition task, between control & amnesic   \n    + left-most red point to middle red point   \n    \n+ in the recognition task, between amnesic & huntingtons   \n    + middle red-point to right-most red point  \n    \n+ in the grammar task, between control & amnesic  \n    + left-most green point to middle green point  \n    \n+ in the grammar task, between control & huntingtons   \n    + left-most green point to right-most green point  \n    \n+ in the grammar task, between amnesic & huntingtons   \n    + middle green point to right-most green point  \n\n+ in the classification task, between control & huntingtons   \n    + left-most blue point to right-most blue point  \n\n+ in the classification task, between amnesic & huntingtons     \n    + middle blue point to right-most blue point  \n\n:::\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n## Pairwise Comparisons & Multiple Corrections\n\n`r qbegin(9)`\n\nConduct exploratory pairwise comparisons to compare all levels of Diagnosis with all levels of Task, applying no correction (note that Tukey will be automatically applied since we are comparing groups of means, so you will need to overwrite this).\n\nWithout adjusting our $\\alpha$ (or $p$-value), why might any inferences drawn from your output be problematic?\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nFor an overview, review the [multiple comparisons flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#multiple-comparisons).\n\n:::\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\npairs_res <- pairs(diag_task_mean, adjust = \"none\")\npairs_res\n\n#can also plot if you'd like:\nplot(pairs_res)\n```\n\nFrom the above, we can see comparisons for all different possible pairs of diagnosis-task combinations^[the differences between the group means for the comparison as labelled]. \n\nIn total, there are 9 different estimates, but comparing them all means that we have 36 comparisons being tested! By not adjusting our $p$-value, we are increasing the experiment-wise Type I error rate - we could wrongly reject the null hypothesis at a much higher rate than 5/100 (or 1/20 as is assumed when $\\alpha = .05$). To overcome this, we might adjust and determine a result to be statistically significant if $p < .005$, as opposed to $p < .05$, depending on how many tests are in our family of tests.  \n\n`r solend()`\n\n<br>\n\n`r qbegin(10)`\n\nSelect an appropriate method to adjust for multiple comparisons, and then obtain confidence intervals.\n\nComment on how these $p$-values differ from your raw (i.e., unadjusted) $p$-values.\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nFor an overview, review the [multiple comparisons flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#multiple-comparisons).\n\n:::\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nNote what the functions in `R` do is adjust the $p$-value, rather than the $\\alpha$. \n\nSince we're interested in all pairwise comparisons of means, the Tukey adjustment might be a sensible approach. However, we'll also show the Bonferroni to show how it differs (note, in practice you would only apply one correction and justify this choice based on your design - we are only applying two to note how they differ!)\n\n::: {.panel-tabset}\n\n## Tukey\n\n```{r}\ncontrast(diag_task_mean, method = \"pairwise\", adjust=\"Tukey\")\n```\n\nNote that 8 of the comparisons are no longer significant when using Tukey's adjustment, suggesting that these might have been (when using no adjustment) Type I errors! \n\n\n## Bonferroni\n\n```{r}\ncontrast(diag_task_mean, method = \"pairwise\", adjust=\"bonferroni\")\n```\n\nThe first Bonferroni adjusted $p$-value is 0.0207. \n\nThe raw (unadjusted) $p$-value from the previous question was 0.0005759265. \n\nThe Bonferroni method simply multiplies the 'raw' $p$-value by the number of the tests, which we know is 36. \n\n```{r}\n0.0005759265 * 36\n```\n\nIn terms of differences in Bonferroni to raw $p$-values, they are thus 36 times the size.  \n\nOne benefit of Bonferroni is that it can be applied to any set of $p$-values, whereas Tukey only applies when comparing the means of levels of a factor. The downside, however, is that it may be overly conservative (i.e. reduce our power to detect an effect that is truly there).  \n\n:::\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Compile Report\n\n`r qbegin(\"Compile Report\", qlabel = FALSE)`  \n\nKnit your report to PDF, and check over your work. To do so, you should make sure:\n\n- Only the output you want your reader to see is visible (e.g., do you want to hide your code?)\n- Check that the **tinytex** package is installed\n- Ensure that the ‘yaml’ (bit at the very top of your document) looks something like this:\n\n```{}\n---\ntitle: \"this is my report title\"\nauthor: \"B1234506\"\ndate: \"07/09/2024\"\noutput: bookdown::pdf_document2\n---\n```\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n# What to do if you cannot knit to PDF\nIf you are having issues knitting directly to PDF, try the following:  \n\n- Knit to HTML file  \n- Open your HTML in a web-browser (e.g. Chrome, Firefox)  \n- Print to PDF (Ctrl+P, then choose to save to PDF)  \n- Open file to check formatting\n:::\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n# Hiding Code and/or Output\n\n:::{.panel-tabset}\n## Hiding R Code\n\nTo not show the code of an R code chunk, and only show the output, write:\n\n````\n```{{r, echo=FALSE}}\n# code goes here\n```\n````\n\n## Hiding R Output\n\nTo show the code of an R code chunk, but hide the output, write:\n\n````\n```{{r, results='hide'}}\n# code goes here\n```\n````\n\n## Hiding R Code and Output\n\nTo hide both code and output of an R code chunk, write:\n\n````\n```{{r, include=FALSE}}\n# code goes here\n```\n````\n:::\n\n:::\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Tinytex\nYou must make sure you have **tinytex** installed in R so that you can “Knit” your Rmd document to a PDF file:\n\n```{r eval = FALSE}\ninstall.packages(\"tinytex\")\ntinytex::install_tinytex()\n```\n\n:::\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n\nYou should end up with a PDF file. If you have followed the above instructions and still have issues with knitting, speak with a Tutor. \n\n`r solend()`\n\n","srcMarkdownNoYaml":"\n\n```{r setup, include=FALSE}\nsource('assets/setup.R')\n\nset.seed(3)\n\nlibrary(DT)\nlibrary(tidyverse)\n```\n\n:::lo\n\n### <i class=\"fa fa-graduation-cap\"></i> Learning Objectives\nAt the end of this lab, you will:\n\n1. Understand how to interpret simple effects for experimental designs\n2. Understand how to conduct pairwise comparisons\n3. Understand how to apply corrections available for multiple comparisons\n\n### <i class=\"fa fa-check-square-o fa-2\"></i> What You Need\n\n1. Be up to date with lectures\n2. Have completed previous lab exercises from [Semester 1 Week 7](https://uoepsy.github.io/dapr2/2425/labs/1_06_dummy.html), [Semester 1 Week 8](https://uoepsy.github.io/dapr2/2425/labs/1_07_effects.html), [Semester 1 Week 11](https://uoepsy.github.io/dapr2/2425/labs/1_10_writeup_recap2.html), [Semester 2 Week 1](https://uoepsy.github.io/dapr2/2425/labs/2_01_int1_nc.html), [Semester 2 Week 2](https://uoepsy.github.io/dapr2/2425/labs/2_02_int2_nn.html), and [Semester 2 Week 3](https://uoepsy.github.io/dapr2/2425/labs/2_03_int3_cc.html).\n\n### <i class=\"fab fa-r-project\"></i> Required R Packages\nRemember to load all packages within a code chunk at the start of your RMarkdown file using `library()`. If you do not have a package and need to install, do so within the console using `install.packages(\" \")`. For further guidance on installing/updating packages, see Section C [here](https://uoepsy.github.io/files/install-update-r#update-pkgs).  \n\nFor this lab, you will need to load the following package(s):\n\n* **tidyverse** \n* **psych** \n* **kableExtra**\n* **sjPlot**\n* **interactions**\n* **patchwork**\n* **emmeans**\n\n### <i class=\"fa fa-pencil-square-o\" aria-hidden=\"true\"></i> Presenting Results\nAll results should be presented following [APA guidelines](https://apastyle.apa.org/instructional-aids/numbers-statistics-guide.pdf).If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the [rmd bootcamp](https://uoepsy.github.io/scs/rmd-bootcamp/).\n\nThe example write-up sections included as part of the solutions are **not perfect** - they instead should give you a good example of what information you should include and how to structure this. Note that you must **not** copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more [here](https://www.ed.ac.uk/academic-services/students/conduct/academic-misconduct).  \n\n### <i class=\"fa fa-file\"></i> Lab Data\nYou can download the data required for this lab [here](https://uoepsy.github.io/data/cognitive_experiment.csv) or read it in via this link https://uoepsy.github.io/data/cognitive_experiment.csv    \n  \nNote, you have already worked with *some* of this data last week - see [Semester 2 Week 3 lab](https://uoepsy.github.io/dapr2/2425/labs/2_03_int3_cc.html), but we now have a third Task condition - Classification. \n\n:::\n\n# Study Overview\n\n> **Research Question** \n>\n> Are there differences in types of memory deficits for those experiencing different cognitive impairment(s)?\n\nIn this week's exercises, we will further explore questions such as:\n\n- Does level $i$ of the first factor have an effect on the response?\n- Does level $j$ of the second factor have an effect on the response?\n- Is there a combined effect of level $i$ of the first factor and level $j$ of the second factor on the response? In other words, is there interaction of the two factors so that the combined effect is not simply the additive effect of level $i$ of the first factor plus the effect of level $j$ of the second factor?\n\n`r optbegin(\"Cognitive Exp 3x3 data codebook.\", olabel=FALSE, toggle=params$TOGGLE)` \n  \n__Description__\n\nThe researchers designed a study yielding a $3 \\times 3$ factorial design to test whether there are differences in types of memory deficits for those experiencing different cognitive impairment(s).\n\nThe tasks chosen by the researchers have been picked to map onto the theoretical differences between the three types of research participants. The Grammar and Classification tasks are known to reflect *implicit* memory processes, whereas the recognition task is known to reflect *explicit* memory processes. If the theory is correct, we would expect the difference in scores between the recognition and grammar/classification tasks to be relatively similar for the control and amnesiac groups, but relatively larger for the Huntingtons group compared to controls.\n\n__Data Dictionary__\n\nThe data in `cognitive_experiment.csv` contain three attributes collected from $n=45$ participants, and includes: \n\n```{r echo=FALSE, message=FALSE, warning=FALSE}\ncog <- read_csv(\"https://uoepsy.github.io/data/cognitive_experiment.csv\")\ntibble(\nvariable = names(cog),\ndescription = c(\"Diagnosis classifies the three types of individuals: 1 = Amnesic patients, 2 = Huntingtons patients, and 3 = Control group of individuals with no known neurological disorder\", \"Task tells us to which one of three tasks each study participant was randomly assigned to: 1 = Grammar (which consists of classifying letter sequences as either following or not following grammatical rules), 2 = Classification (which consists of classifying stimuli into certain groupings, based on previously indicated information about the groups characteristics), and 3 = Recognition (which consists of recognising particular stimuli as stimuli that have previously been presented during the task)\", \"Score\")) %>% gt::gt()\n```\n  \n__Data Overview__\n\nWe have data from the 45 participants (15 amnesiacs, 15 Huntington individuals, and 15 controls). Recall that study involves two factors, now with three levels each. For each combination of factor levels we have 5 observations:\n\n```{r echo=FALSE, message=FALSE}\nlibrary(tidyverse)\ndf <- read_csv('https://uoepsy.github.io/data/cognitive_experiment.csv')\n# head(df)\n\ndf$Diagnosis <- factor(df$Diagnosis, \n                       labels = c(\"amnesic\", \"huntingtons\", \"control\"),\n                       ordered = FALSE)\n\ndf$Task <- factor(df$Task, \n                  labels = c(\"grammar\", \"classification\", \"recognition\"), \n                  ordered = FALSE)\n\nlibrary(kableExtra)\n\ndf %>% \n    pivot_wider(names_from = 'Task', values_from = 'Y', values_fn = list) %>% \n    kable() %>%\n    kable_styling(full_width = FALSE) %>%\n    add_header_above(c(\" \" = 1, \"Task\" = 3))\n```\n\nThe five observations are assumed to come from a population having a specific mean. The population means corresponding to each combination of factor levels can be schematically written as:\n\n$$\n\\begin{matrix}\n                   &         &         & \\textbf{Task} & \\\\\n                   &         &  (j=1) & (j=2) & (j=3) & \\\\\n                   &         &  \\text{ grammar} & \\text{ classification} & \\text{ recognition} \\\\\n                   & (i=1)\\text{ control} & \\mu_{1,1} & \\mu_{1,2} & \\mu_{1,3} \\\\\n\\textbf{Diagnosis} & (i=2)\\text{ amnesic} & \\mu_{2,1} & \\mu_{2,2} & \\mu_{2,3} \\\\\n                   & (i=3)\\text{ huntingtons} & \\mu_{3,1} & \\mu_{3,2} & \\mu_{3,3}\n\\end{matrix}\n$$\n  \n  \n__Preview__\n\nThe first six rows of the data are:\n\n```{r echo=FALSE, message=FALSE}\nread_csv('https://uoepsy.github.io/data/cognitive_experiment.csv') %>% head %>% gt::gt()\n```\n\n`r optend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Setup\n\n`r qbegin(\"Setup\", qlabel = FALSE)`  \n\n1. Create a new RMarkdown file\n2. Load the required package(s)\n3. Read the cognitive_experiment dataset into R, assigning it to an object named `cog`\n \n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r message=FALSE}\n#load packages\nlibrary(tidyverse)\nlibrary(psych)\nlibrary(kableExtra)\nlibrary(emmeans)\nlibrary(sjPlot)\nlibrary(interactions)\nlibrary(patchwork)\n\n#read in data\ncog <- read_csv('https://uoepsy.github.io/data/cognitive_experiment.csv')\n```\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Exercises \n\n## Study & Analysis Plan Overview \n\n`r qbegin(1)`\n\nFirstly, examine the dataset, and perform any necessary and appropriate data management steps.\n\nNext, consider what would be the most appropriate coding constraint to apply in order to best address the research question - i.e., are we interested in whether group X (e.g., Amnesic) differed from group Y (e.g., Huntingtons), or whether group X (e.g., Amnesic) differed from the grand mean? \n\nChoose appropriate reference levels for the Diagnosis and Task variables based on your decision above. \n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\n*Data Management*  \n   \n- The `str()` function will return the overall structure of the dataset, this can be quite handy to look at    \n- Convert categorical variables to factors, and if needed, provide better variable names*    \n- Label factors appropriately to aid with your model interpretations if required*      \n- Check that the dataset is complete (i.e., are there any `NA` values?). We can check this using `is.na()`    \n  \nNote that all of these steps can be done in combination - the `mutate()` and `factor()` functions will likely be useful here.   \n  \n*Coding Constraints*  \n  \n- If you think you'd benefit from a refresher on coding constraints, it might be best to revisit the materials from Semester 1 Block 2 (especially the  [dummy vs effects coding flashcard](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#numeric-outcomes-categorical-predictors)).  \n- If you would like an overview of coding constraints in the context of interaction models, review the [categorical x categorical example > coding constraints flashcard](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#categorical-x-categorical-example).    \n\n*Reference Levels*  \n  \n- Review the [specifying reference levels flashcard](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#numeric-outcomes-categorical-predictors).  \n\n  \n*See the [numeric outcomes & categorical predictors flashcard](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#numeric-outcomes-categorical-predictors).  \n \n:::\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nLet's have a look at the data to see what we're working with - `str()` or `head()` are a good place to start - and then we should check for any missing data (`NA` values):\n```{r}\n#first look at dataset structure\nstr(cog)\n\n#now lets look at top 6 rows (or the head) of the dataset\nhead(cog)\n\n#check for NAs \ntable(is.na(cog))\n# there are none - all FALSE\n```\n\nNext, lets convert `Diagnosis` and `Task` into factors, making the labels of each factor level more meaningful. According to the data description, the encoding of the factor `Diagnosis` is: 1 = amnesic patients, 2 = Huntingtons patients, and 3 = control patients. The encoding for the factor `Task` is: 1 = grammar task, 2 = classification task, and 3 = recognition task.\n\n```{r}\ncog <- cog %>%\n    mutate(\n        Diagnosis = factor(Diagnosis, \n                           levels = c(1, 2, 3),\n                           labels = c('amnesic', 'huntingtons', 'control'),\n                           ordered = FALSE),\n        Task = factor(Task, \n                      levels = c(1, 2, 3),\n                      labels = c('grammar', 'classification', 'recognition'),\n                      ordered = FALSE)) %>%\n    rename(Score = Y)\n```\n\nSince we are interested in comparing groups, we should use dummy coding. By default, `R` uses dummy coding, so we do not need to make any changes to the coding constraint. \n\nHowever, for our reference groups, we're likely to want it to be the Control group for Diagnosis, and recognition for Task: \n\n```{r}\ncog$Diagnosis <- fct_relevel(cog$Diagnosis, \"control\")\ncog$Task <- fct_relevel(cog$Task, \"recognition\")\n```\n\n`r solend()`\n\n<br>  \n\n`r qbegin(2)`\n\nProvide a brief overview of the study design and data, before detailing your analysis plan to address the research question.\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint \n\n- Give the reader some background on the context of the study (you might be able to re-use some of the content you wrote for [Semester 2 Week 3 lab](https://uoepsy.github.io/dapr2/2425/labs/2_03_int3_cc.html) here, but note that we now have an extra condition within Task)\n- Outline data checks / data cleaning\n- State what type of analysis you will conduct in order to address the research question\n- Specify the model to be fitted to address the research question (note that you will need to specify the reference level of your categorical variables. This will be somewhat similar to last week, but with the addition of Classification in Task, our model will contain a different number of parameters)\n- Specify your chosen significance ($\\alpha$) level\n- State your hypotheses\n\nMuch of the information required can be found in the [Study Overview] codebook.\n\nThe [statistical models](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#statistical-models) flashcards may also be useful to refer to. Specifically the [interaction models flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#interaction-models) and [categorical x categorical example flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#categorical-x-categorical-example) might be of most use.\n\n:::\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nThe `cog` dataset contained information on 45 hypothetical participants from a between-subjects study. Participants belonged to one of three 'Diagnosis' groups, which had 15 participants in each - Control, Amnesic, or Huntingtons. Participants from each of the Diagnosis groups were equally and randomly assigned to one of three 'Tasks' to measure different memory processes - Grammar, Classification, or Recognition - the former two measuring implicit memory and the latter explicit. This resulted in 5 participants from each Diagnosis group in each of the three Task conditions. \n\nAll participant data was complete, and categorical variables were coded as factors. For the purpose of this analysis, 'Control' was designated as the reference group for Diagnosis, since it was the only group of participants with no known neurological disorder. For Task, the recognition task measures explicit memory whereas the other two measure implicit memory, so this was specified as the reference group.   \n\nBoxplots will be used to visualise the associations among Diagnosis and Task conditions. To address the research question of whether the difference in performance between explicit and implicit memory tasks will be greatest for Huntington patients in comparison to controls, we first need to define the dummy variables for both\n\nDiagnosis:\n\n$$\n\\begin{gather*}\n\\text{D}_\\text{Amnesic} = \\begin{cases}\n1 & \\text{if Diagnosis is Amnesic}\\\\  \n0 & \\text{otherwise}\n\\end{cases}\n\\\\  \n\\\\  \n\\text{D}_\\text{Huntingtons} = \\begin{cases}\n1 & \\text{if Diagnosis is Huntingtons}\\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\quad   \n\\\\  \n\\\\  \n(\\text{Control is base level})  \n\\end{gather*}\n$$\n\nand for Task:  \n  \n$$\n\\begin{gather*}    \n\\text{T}_\\text{Grammar} = \\begin{cases}\n1 & \\text{if Task is Grammar}\\\\\n0 & \\text{otherwise}\\\\  \n\\end{cases}\\\n\\\\  \n\\\\\n\\text{T}_\\text{Classification} = \\begin{cases}  \n1 & \\text{if Task is Classification}\\\\   \n0 & \\text{otherwise}\\\\ \n\\end{cases}\\\\\\  \n\\quad    \n\\\\    \n\\\\  \n(\\text{Recognition is base level})\\\\ \n\\end{gather*}   \n$$\n\nBased on the above dummy coding, we are going to fit the following interaction model:\n\n$$\n\\begin{align}\n\\text{Interaction Model}: \\text{Score} &= \\beta_0  \\\\\n      &+ \\beta_1 \\cdot \\text{D}_\\text{Amnesic} + \\beta_2 \\cdot  \\text{D}_\\text{Huntingtons}  \\\\\n      &+ \\beta_3 \\cdot  \\text{T}_\\text{Grammar}  + \\beta_4 \\cdot  \\text{T}_\\text{Classification}  \\\\\n      &+ \\beta_5 \\cdot  (\\text{D}_\\text{Amnesic} \\cdot  \\text{T}_\\text{Grammar})  \\\\\n      &+ \\beta_6 \\cdot  (\\text{D}_\\text{Huntingtons} \\cdot  \\text{T}_\\text{Grammar})  \\\\\n      &+ \\beta_7 \\cdot  (\\text{D}_\\text{Amnesic} \\cdot  \\text{T}_\\text{Classification})  \\\\\n      &+ \\beta_8 \\cdot  (\\text{D}_\\text{Huntingtons} \\cdot  \\text{T}_\\text{Classification})  \\\\\n      &+ \\epsilon  \n\\end{align}\n$$\n\nEffects will be considered statistically significant at $\\alpha = .05$\n\nOur hypotheses are:\n\n$H_0:$ All $\\beta_j = 0$ (for $j = 5, 6, 7, 8$)\n\nThere are no significant differences in performance between explicit and implicit memory tasks for patients with different cognitive impairment(s). \n\n$H_1:$ At least one $\\beta_j \\neq  0$ (for $j = 5, 6, 7, 8$)\n\nThere are significant differences in performance between explicit and implicit memory tasks for patients with different cognitive impairment(s). \n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n## Descriptive Statistics & Visualisations\n\n`r qbegin(3)`\n\nProvide a table of descriptive statistics and visualise your data.\n\nInterpret the descriptive statistics and visualisations in the context of the study (i.e., comment on any observed differences among groups). \n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nReview the many ways to numerically and visually explore your data by reading over the [data exploration flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#data-exploration).\n  \nFor examples, see flashcards on [descriptives statistics tables - categorical and numeric values examples](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#data-exploration) and [categorical x categorical example - visualise data](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#categorical-x-categorical-example).    \n  \nMake sure to comment on any observed differences among the sample means of the different conditions.  \n\n:::\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n::: {.panel-tabset}\n\n## Numeric\n\nDescriptive statistics presented in a well formatted table:\n\n```{r message=FALSE, warning=FALSE}\n#| label: tbl-cog-descript\n#| tbl-cap: Descriptive Statistics\ncog_stats <- cog %>% \n    group_by(Diagnosis, Task) %>%\n    summarise(\n        Mean = mean(Score), \n        SD = sd(Score),\n        SE = sd(Score) / sqrt(n()),\n        Min = min(Score),\n        Max = max(Score)) %>%\n    kable(caption = \"Descriptive Statistics of Score\", digits = 2) %>%\n    kable_styling()\n\ncog_stats\n```\n\n## Visual \n\nSince we have a continuous outcome and 2 categorical predictors - a boxplot would be most appropriate for visualisations:\n\n```{r}\n#| label: fig-cog-desc\n#| fig-cap: \"Association between Task Condition, Diagnosis, and Score\"\ncog_plt <- ggplot(data = cog, aes(x = Diagnosis, y = Score, color = Task)) +\n  geom_boxplot() +\n  labs(x = 'Diagnosis', y = 'Score')\ncog_plt\n```\n\n:::\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\n+ Control patients consistently performed best across all tasks. They did not appear to differ substantially in their scores between grammar and classification tasks, but they clearly performed better in the recognition task in comparison to both the grammar and classification ones.\n\n+ Amnesic patients appeared to perform better than Huntingtons patients in grammar and classification tasks (reflecting intrinsic memory processes), and performed worse than Huntingtons patients in the recognition task (reflecting extrinsic memory processes).\n\n:::\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n## Model Fitting & Interpretation \n\n`r qbegin(4)`\n\nFit the specified model  using `lm()`, and assign it the name \"mdl_int\".\n\nProvide key model results in a formatted table and plot the interaction model before reporting in-text the overall model fit.\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\n*Model Building*  \n  \n- We can fit interaction models using the `lm()` function.  \n- For an overview, see the [interaction models flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#interaction-models). \n- For an example, review the [interaction models > categorical x categorical example > model building flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#categorical-x-categorical-example).  \n\n*Results Table*  \n  \n- Use `tab_model()` from the __sjPlot__ package. For a quick guide, review the [tables flashcard](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#tables).  \n\n*Plot Model*  \n  \n- Using the `cat_plot()` function from the **interactions** package, visualise the interaction effects from your model. \n- For an overview and example, review the [interaction models > categorical x categorical example > model visualisation flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#categorical-x-categorical-example).   \n\n:::\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n::: {.panel-tabset}\n\n## Build & Check Model\n\n```{r}\n#fit interaction model\nmdl_int <- lm(Score ~ Diagnosis * Task, data = cog)\n\n#check model output\nsummary(mdl_int)\n```\n\n## Results Table\n\n```{r}\n#| label: tbl-w4-modresults\n#| tbl-cap: Regression Table for Scores Model\ntab_model(mdl_int,\n          dv.labels = \"Scores\",\n          pred.labels = c(\"Diagnosisamnesic\" = \"Diagnosis - Amnesic\",\n                          \"Diagnosishuntingtons\" = \"Diagnosis - Huntingtons\",\n                          \"Taskgrammar\" = \"Task - Grammar\",\n                          \"Taskclassification\" = \"Task - Classification\",\n                          \"Diagnosisamnesic:Taskgrammar\" = \"Diagnosis - Amnesic : Task - Grammar\",\n                          \"Diagnosishuntingtons:Taskgrammar\" = \"Diagnosis - Huntingtons : Task - Grammar\",\n                          \"Diagnosisamnesic:Taskclassification\" = \"Diagnosis - Amnesic : Task - Classification\",\n                          \"Diagnosishuntingtons:Taskclassification\" = \"Diagnosis - Huntingtons : Task - Classification\"),\n          title = \"Regression Table for Scores Model\")\n```\n\n## Interaction Plot\n\n```{r}\n#| label: fig-cog-4\n#| fig-cap: \"Interaction Plot\"\nplt_cog_mdl <- cat_plot(model = mdl_int, \n                  pred = Diagnosis, \n                  modx = Task, \n                  main.title = \"Scores across Diagnosis and Task\",\n                  x.label = \"Diagnosis\",\n                  y.label = \"Score\",\n                  legend.main = \"Task\")\nplt_cog_mdl\n```\n\n:::\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nFull regression results including 95% Confidence Intervals are shown in @tbl-w4-modresults, and the interaction model is visually presented in @fig-cog-4. The $F$-test for model utility was significant $(F(8, 36) = 12.28, p < .001)$, and the model explained approximately 67% of the variability in Scores.  \n\n:::\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n## Contrast Analysis\n\nLet's move onto testing differences between specific group means.\n\n`r qbegin(5)`\n\nIn terms of the diagnostic groups, we want to compare the individuals with amnesia to those with Huntingtons. This corresponds to a contrast with coefficients of 0, 1, and −1, for control, amnesic, and Huntingtons, respectively. \n\nSimilarly, in terms of the tasks, we want to compare the average of the two implicit memory tasks with the explicit memory task. This corresponds to a contrast with coefficients of 0.5, 0.5, and −1 for the three tasks. \n\nWhen we are in presence of a significant interaction, the coefficients for a contrast between the means are found by multiplying each row coefficient with all column coefficients as shown below:\n\n```{r echo=FALSE, out.width = '100%'}\nknitr::include_graphics('images/contr_interaction.png')\n```\n\nSpecify the coefficients to be used in the contrast analysis, and present in a table.\n\nNext, formally state the contrast that the researchers were interested in as testable hypotheses. \n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nFor an overview and example, review the [manual contrasts flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#manual-contrasts).\n\n:::\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nWe can specify the coefficients to be used in the contrast analysis in `R` using either:\n\n::: {.panel-tabset}\n\n## Option 1\n\n```{r}\ndiag_coef  <- c('control' = 0, 'amnesic' = 1, 'huntingtons' = -1)\ntask_coef  <- c('grammar' = 0.5, 'classification' = 0.5, 'recognition' = -1)\ncontr_coef <- outer(diag_coef, task_coef)\ncontr_coef\n```\n\n## Option 2\n\n```{r}\ndiag_coef  <- c('control' = 0, 'amnesic' = 1, 'huntingtons' = -1)\ntask_coef  <- c('grammar' = 0.5, 'classification' = 0.5, 'recognition' = -1)\ncontr_coef <- diag_coef %o% task_coef\ncontr_coef\n```\n\n:::\n\nUsing either approach, we can then convert into a well-formatted table:\n\n```{r}\n#| label: tbl-q5-weights\n#| tbl-cap: Contrast Weights\ncontr_coef %>% \n    kable(., caption = \"Contrast Weights\") %>%\n    kable_styling(full_width = FALSE) \n```\n\nThe above coefficients correspond to the following hypotheses:\n\n$$\nH_0: \\quad \\left(\\frac{\\mu_{2,1} + \\mu_{2,2}}{2} - \\mu_{2,3} \\right) - \\left( \\frac{\\mu_{3,1} + \\mu_{3,2}}{2} - \\mu_{3,3} \\right) = 0\n$$\n\n$$\nH_1: \\quad \\left(\\frac{\\mu_{2,1} + \\mu_{2,2}}{2} - \\mu_{2,3} \\right) - \\left( \\frac{\\mu_{3,1} + \\mu_{3,2}}{2} - \\mu_{3,3} \\right) \\neq 0\n$$\n\nwhich can be equivalently specified as:\n\n$$\nH_0: \\quad \\frac{\\mu_{2,1} + \\mu_{2,2}}{2} - \\mu_{2,3} \\quad = \\quad \\frac{\\mu_{3,1} + \\mu_{3,2}}{2} - \\mu_{3,3}\n$$\n\n$$  \nH_1: \\quad \\frac{\\mu_{2,1} + \\mu_{2,2}}{2} - \\mu_{2,3} \\quad \\neq \\quad  \\frac{\\mu_{3,1} + \\mu_{3,2}}{2} - \\mu_{3,3}\n$$\n\nboth statements state that, in the population, the difference between the mean implicit memory and the explicit memory score is the same for individuals with amnesia and Huntingtons. \n\nNote that the scores for the grammar and classification tasks have been averaged to obtain a single measure of 'implicit memory' score.\n\n`r solend()`\n\n<br>\n\n`r qbegin(6)`\n\nFirstly, use `emmeans()` to obtain the estimated means and uncertainties for your factors. \n\nNext, specify the coefficients of the comparison and run the contrast analysis, obtaining 95% confidence intervals. \n\nReport the results of the contrast analysis in full. \n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nFor an overview and example, review the [manual contrasts flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#manual-contrasts).\n\n:::\n\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nNow that we have the coefficients, let's firstly call the `emmeans` function to get the estimated means of our groups (this is also helpful to look at the ordering of the groups):\n\n```{r}\ndiag_task_mean <- emmeans(mdl_int, ~ Diagnosis*Task)\ndiag_task_mean\n```\n\nNext, from `contr_coef`, insert the coefficients **following the order specified by the rows of** `diag_task_mean` above. That is, the first one should be for `control` `recognition` and have a value of 0, the second for `amnesic` `recognition` with a value of -1, and so on...\n\nLet's specify our weights, and give a name to this contrast (in this example 'Research Hyp'):\n\n```{r}\ndiag_task_comp <- contrast(diag_task_mean, \n                     method = list('Research Hyp' = c(0, -1, 1, 0, 0.5, -0.5, 0, 0.5, -0.5))\n                     )\n```\n\nNext, let's look at the output via one of two ways:\n\n::: {.panel-tabset}\n\n## Option 1\n\n```{r}\n#examine output\ndiag_task_comp\n\n#obtain confidence intervals\nconfint(diag_task_comp)\n```\n\n## Option 2\n\n```{r}\n#examine summary output and state `infer = TRUE` to include confidence intervals\nsummary(diag_task_comp, infer = TRUE)\n```\n\n:::\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nWe performed a test against $H_0: \\quad \\frac{\\mu_{2,1} + \\mu_{2,2}}{2} - \\mu_{2,3} \\quad = \\quad \\frac{\\mu_{3,1} + \\mu_{3,2}}{2} - \\mu_{3,3}$. At the 5\\% significance level, there was evidence that individuals with Amnesia and Huntingtons did differ in the difference between implicit and explicit memory tasks $(t(36) = 5.40, p < .001, \\text{two-sided})$, and this difference was estimated to be 52.50. We are 95\\% confident that the difference in implicit and explicit memory scores between individuals with Amnesia and Huntingtons was between 32.80 to 72.20 points. Therefore, we can reject the null hypothesis that the difference in differences was equal to zero. \n\n:::\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n## Simple Effects\n\n`r qbegin(7)`\n\nExamine the simple effects for Task at each level of Diagnosis; and then the simple effects for Diagnosis at each level of Task. \n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nFor an overview and example, review the [simple effects flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#categorical-x-categorical-example). \n\n:::\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n\n::: {.panel-tabset}\n\n## Simple Effects of Task\n\nFrom `mdl_int_simple1` we can see the differences between tasks for each diagnosis group:\n\n```{r}\nmdl_int_simple1 <- pairs(diag_task_mean, simple = \"Task\")\nmdl_int_simple1\n```\n\n## Simple Effects of Diagnosis\n\nFrom `mdl_int_simple2` we can see the differences between diagnoses for each task group:\n\n```{r}\nmdl_int_simple2 <- pairs(diag_task_mean, simple = \"Diagnosis\")\nmdl_int_simple2\n```\n\n:::\n\n`r solend()`\n\n<br>\n\n`r qbegin(8)`\n\nVisualise the interaction, displaying two plots - one with Diagnosis on the x-axis, and the other with Task on the x-axis.\n\nConsidering the simple effects that you noted above, identify the significant effects and match them to the corresponding points of your interaction plot.\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nFor an overview and example, review the [simple effects flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#categorical-x-categorical-example).  \n  \nRecall that the **patchwork** package allows us to arrange multiple plots using either `/` or `|` or `+`.\n\n:::\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n::: {.panel-tabset}\n\n## Simple Effects of Task\n\n```{r}\nplt_1 <- emmip(mdl_int, Diagnosis ~ Task, CIs = TRUE)\nplt_1\n```\n\nFor the simple effects of task (see `plt_1`), we saw the significant differences (those for which $p<.05$):  \n\n+ Only in the Huntingtons group, between recognition & grammar and recognition & classification tasks  \n    + left-most blue point compared to the middle blue point, and then compared to the right-most blue point  \n\n## Simple Effects of Diagnosis\n\n```{r}\nplt_2 <- emmip(mdl_int, Task ~ Diagnosis, CIs = TRUE)\nplt_2\n```\n\n\nFor the simple effects of Diagnosis (see `plt_2`), we saw significant differences (those for which $p<.05$):  \n\n+ in the recognition task, between control & amnesic   \n    + left-most red point to middle red point   \n    \n+ in the recognition task, between amnesic & huntingtons   \n    + middle red-point to right-most red point  \n    \n+ in the grammar task, between control & amnesic  \n    + left-most green point to middle green point  \n    \n+ in the grammar task, between control & huntingtons   \n    + left-most green point to right-most green point  \n    \n+ in the grammar task, between amnesic & huntingtons   \n    + middle green point to right-most green point  \n\n+ in the classification task, between control & huntingtons   \n    + left-most blue point to right-most blue point  \n\n+ in the classification task, between amnesic & huntingtons     \n    + middle blue point to right-most blue point  \n\n:::\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n## Pairwise Comparisons & Multiple Corrections\n\n`r qbegin(9)`\n\nConduct exploratory pairwise comparisons to compare all levels of Diagnosis with all levels of Task, applying no correction (note that Tukey will be automatically applied since we are comparing groups of means, so you will need to overwrite this).\n\nWithout adjusting our $\\alpha$ (or $p$-value), why might any inferences drawn from your output be problematic?\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nFor an overview, review the [multiple comparisons flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#multiple-comparisons).\n\n:::\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\npairs_res <- pairs(diag_task_mean, adjust = \"none\")\npairs_res\n\n#can also plot if you'd like:\nplot(pairs_res)\n```\n\nFrom the above, we can see comparisons for all different possible pairs of diagnosis-task combinations^[the differences between the group means for the comparison as labelled]. \n\nIn total, there are 9 different estimates, but comparing them all means that we have 36 comparisons being tested! By not adjusting our $p$-value, we are increasing the experiment-wise Type I error rate - we could wrongly reject the null hypothesis at a much higher rate than 5/100 (or 1/20 as is assumed when $\\alpha = .05$). To overcome this, we might adjust and determine a result to be statistically significant if $p < .005$, as opposed to $p < .05$, depending on how many tests are in our family of tests.  \n\n`r solend()`\n\n<br>\n\n`r qbegin(10)`\n\nSelect an appropriate method to adjust for multiple comparisons, and then obtain confidence intervals.\n\nComment on how these $p$-values differ from your raw (i.e., unadjusted) $p$-values.\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Hint\n\nFor an overview, review the [multiple comparisons flashcards](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#multiple-comparisons).\n\n:::\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nNote what the functions in `R` do is adjust the $p$-value, rather than the $\\alpha$. \n\nSince we're interested in all pairwise comparisons of means, the Tukey adjustment might be a sensible approach. However, we'll also show the Bonferroni to show how it differs (note, in practice you would only apply one correction and justify this choice based on your design - we are only applying two to note how they differ!)\n\n::: {.panel-tabset}\n\n## Tukey\n\n```{r}\ncontrast(diag_task_mean, method = \"pairwise\", adjust=\"Tukey\")\n```\n\nNote that 8 of the comparisons are no longer significant when using Tukey's adjustment, suggesting that these might have been (when using no adjustment) Type I errors! \n\n\n## Bonferroni\n\n```{r}\ncontrast(diag_task_mean, method = \"pairwise\", adjust=\"bonferroni\")\n```\n\nThe first Bonferroni adjusted $p$-value is 0.0207. \n\nThe raw (unadjusted) $p$-value from the previous question was 0.0005759265. \n\nThe Bonferroni method simply multiplies the 'raw' $p$-value by the number of the tests, which we know is 36. \n\n```{r}\n0.0005759265 * 36\n```\n\nIn terms of differences in Bonferroni to raw $p$-values, they are thus 36 times the size.  \n\nOne benefit of Bonferroni is that it can be applied to any set of $p$-values, whereas Tukey only applies when comparing the means of levels of a factor. The downside, however, is that it may be overly conservative (i.e. reduce our power to detect an effect that is truly there).  \n\n:::\n\n`r solend()`\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Compile Report\n\n`r qbegin(\"Compile Report\", qlabel = FALSE)`  \n\nKnit your report to PDF, and check over your work. To do so, you should make sure:\n\n- Only the output you want your reader to see is visible (e.g., do you want to hide your code?)\n- Check that the **tinytex** package is installed\n- Ensure that the ‘yaml’ (bit at the very top of your document) looks something like this:\n\n```{}\n---\ntitle: \"this is my report title\"\nauthor: \"B1234506\"\ndate: \"07/09/2024\"\noutput: bookdown::pdf_document2\n---\n```\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n# What to do if you cannot knit to PDF\nIf you are having issues knitting directly to PDF, try the following:  \n\n- Knit to HTML file  \n- Open your HTML in a web-browser (e.g. Chrome, Firefox)  \n- Print to PDF (Ctrl+P, then choose to save to PDF)  \n- Open file to check formatting\n:::\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n# Hiding Code and/or Output\n\n:::{.panel-tabset}\n## Hiding R Code\n\nTo not show the code of an R code chunk, and only show the output, write:\n\n````\n```{{r, echo=FALSE}}\n# code goes here\n```\n````\n\n## Hiding R Output\n\nTo show the code of an R code chunk, but hide the output, write:\n\n````\n```{{r, results='hide'}}\n# code goes here\n```\n````\n\n## Hiding R Code and Output\n\nTo hide both code and output of an R code chunk, write:\n\n````\n```{{r, include=FALSE}}\n# code goes here\n```\n````\n:::\n\n:::\n\n:::{.callout-tip appearance=\"simple\" collapse=\"true\"}\n\n### Tinytex\nYou must make sure you have **tinytex** installed in R so that you can “Knit” your Rmd document to a PDF file:\n\n```{r eval = FALSE}\ninstall.packages(\"tinytex\")\ntinytex::install_tinytex()\n```\n\n:::\n\n`r qend()`\n\n`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`\n\nYou should end up with a PDF file. If you have followed the above instructions and still have issues with knitting, speak with a Tutor. \n\n`r solend()`\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":true,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"include-in-header":["assets/toggling.html",{"text":"<link rel=\"stylesheet\" href=\"https://uoepsy.github.io/assets/css/ccfooter.css\" />\n"}],"number-sections":false,"output-file":"2_04_simp_pair.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.57","bibliography":["biblio.bib"],"toc_float":true,"code-annotations":"hover","link-citations":true,"theme":["united","assets/style-labs.scss"],"title":"Simple Effects, Pairwise Comparisons, & Corrections","params":{"SHOW_SOLS":true,"TOGGLE":true},"editor_options":{"chunk_output_type":"console"}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}