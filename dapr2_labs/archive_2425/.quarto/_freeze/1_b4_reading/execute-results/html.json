{
  "hash": "6f628042d1b150640f03c7faffad9913",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Blocks 1, 2, 3, & 4 Flash Cards\"\nlink-citations: true\ncode-annotations: hover\nparams: \n    SHOW_SOLS: TRUE\n    TOGGLE: TRUE\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n\n\n:::lo\n### <i class=\"fa fa-graduation-cap\"></i> Flash Card Aims\n\nThe purpose of these flashcards is to complement your Semester 1 and 2 core learning materials i.e., your lecture and lab materials, by offering additional guidance and examples on key concepts/topics. It’s designed to deepen your understanding, clarify complex concepts, and help you make connections between different areas of study. Think of it as an extra resource that supports what you’re learning in the classroom. \n\nYou may want to consider using the below as a supporting document whilst your work through lab exercises, and/or refer to in order to aid revision. \n\n### <i class=\"fab fa-r-project\"></i> R Packages\n\nWithin this reading, the following packages are used:\n\n* **tidyverse** \n* **sjPlot**\n* **kableExtra**\n* **psych**\n* **emmeans**\n* **performance**\n* **car**\n* **interactions**\n* **pwr**\n\n### <i class=\"fa fa-pencil-square-o\" aria-hidden=\"true\"></i> Presenting Results\nNote that you must **not** copy any of the write-ups included below for future reports - if you do, you will be committing plagiarism, and this type of academic misconduct is taken very seriously by the University. You can find out more [here](https://www.ed.ac.uk/academic-services/students/conduct/academic-misconduct).\n\n:::\n\n# Back to Basics\n\n\nFor an overview of basic statistical tests and core concepts (e.g., $p$-values), please revisit the [DAPR1 materials](https://uoepsy.github.io/dapr1/2324/) for a refresher (also accessible via the DAPR1 Learn page).\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-1' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-1', 'opt-start-1')\"> <span class=\"olab\">Terminology</span></span></div><div class=\"optional-body\" id = \"opt-body-1\" style=\"display: none;\">\n\n\n\nLet's spend some time to remind ourselves of some key terminology, specifically related to types of variables and study designs:\n\n\n| Term           | Definition       |\n|----------------|------------------|\n| (Observational) unit | The individual entities on which data are collected |  \n| Variable | Any characteristic recorded on the observational units |  \n| Numeric variable | A variable that records a numerical quantity for each case. For such variables standard arithmetic operations make sense. For example: height, IQ, and weight |  \n| Categorical variable | A categorical variable places units into one of several groups. For example: country of birth, dominant hand, and eye colour |  \n| Binary variable | A special case of categorical variable with only 2 possible levels. For example: handedness (left or right), smoking status (smoker or non-smoker), pass test (yes or no) |  \n| Response variable (also more commonly called a dependent variable, or outcome variable) | Measures the outcome of interest in a study |  \n| Explanatory/independent variable (also called predictors) | Are used to explain differences/changes in the response variable |  \n| Observational study | An observational study is a study in which the researcher does not manipulate any of the variables involved in the study, but merely records the values as they naturally exist | \n| Experimental study | An experiment is a study in which the researcher imposes the values of the explanatory variable on the units before measuring the response variable |  \n\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Data Exploration\n\nThe common first port of call for almost any statistical analysis is to explore the data, and we can do this visually and/or numerically.\n\n<table cellspacing=\"3\">\n<tr style=\"border-bottom: 1px solid\"><th></th><th style=\"border-right: 1px solid\">Marginal Distributions</th><th>Bivariate Associations</th></tr>\n<tr style=\"border-bottom: 1px solid\">\n<td style=\"vertical-align:top\">**Description**</td>\n<td style=\"vertical-align:top;border-right: 1px solid\">The distribution of each variable individually (i.e., *without* reference to the values of the other variables).</td>\n<td style=\"vertical-align:top\">Describing the association between two numeric variables.</td>\n</tr>\n<tr style=\"border-bottom: 1px solid\">\n<td style=\"vertical-align:top\">**Visually**</td>\n<td style=\"vertical-align:top;border-right: 1px solid\">Plot each variable individually.<br><br>You could use, for example, `geom_density()` for a density plot or `geom_histogram()` for a histogram to comment on and/or examine:<br><ul><li> The *shape* of the distribution. Look at the shape, centre and spread of the distribution. Is it symmetric or skewed? Is it unimodal or bimodal? </li><li> Identify any *unusual observations*. Do you notice any extreme observations (i.e., outliers)? </li></ul></td>\n<td style=\"vertical-align:top\">Plot associations among two variables.<br><br>You could use, for example, `geom_point()` for a scatterplot  to comment on and/or examine:<br><ul><li>The *direction* of the association indicates whether there is a positive or negative association</li><li>The *form* of association refers to whether the relationship between the variables can be summarized well with a straight line or some more complicated pattern </li><li>The *strength* of association entails how closely the points fall to a recognizable pattern such as a line  </li><li>*Unusual observations* that do not fit the pattern of the rest of the observations and which are worth examining in more detail </li></ul></td>\n</tr>\n<tr style=\"border-bottom: 1px solid\">\n<td style=\"vertical-align:top\">**Numerically**&nbsp;&nbsp;&nbsp;</td>\n<td style=\"vertical-align:top;border-right: 1px solid\">Compute and report summary statistics e.g., mean, standard deviation, median, min, max, etc.<br><br>You could, for example, calculate summary statistics such as the mean (`mean()`) and standard deviation (`sd()`), etc. within `summarize()`</td>\n<td style=\"vertical-align:top\">Compute and report the correlation coefficient.<br><br>You can use the `cor()` function to calculate this</td>\n</tr>\n</table>\n\n\n\n## Numeric Exploration\n\nNumeric exploration of data involves examining key statistics like mean, median, and standard deviation via descriptives tables; and assessing the associations among variables through correlation coefficients. Exploring our data numerically helps us to identify patterns and associations in the data.\n\n### Descriptives \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-2' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-2', 'opt-start-2')\"> <span class=\"olab\">Descriptives Tables</span></span></div><div class=\"optional-body\" id = \"opt-body-2\" style=\"display: none;\">\n\n\n\nThere are numerous packages available that allow us to pull out descriptive statistics from our dataset such as **tidyverse** and **psych**.\n\nWhen we pull out descriptive statistics, it is useful to present these in a well formatted table for your reader. There are lots of different ways of doing this, but one of the most common (and straightforward!) is to use the `kable()` function from the package **kableExtra**. \n\nThis allows us to give our table a clear caption (via `caption = \"insert caption here\"`, align values within columns e.g., center aligned via `align = \"??\"`), and we can also round to however many decimal places we desire (standard for APA is 2 dp; via `digits = ??`). \n\nWe can also add in the function `kable_styling()`. This is really helpful for customising your table e.g., the font size, position, and whether or not you want the table full width (as well as lots of other things - check out the helper function!). \n\nFor an overview of how to make tables in RMarkdown, see [Lesson 4 of the RMD bootcamp](https://uoepsy.github.io/scs/rmd-bootcamp/04-prettytab.html)\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-3' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-3', 'opt-start-3')\"> <span class=\"olab\">Descriptives Tables - Examples</span></span></div><div class=\"optional-body\" id = \"opt-body-3\" style=\"display: none;\">\n\n\n\n::: {.panel-tabset}\n\n##### The **tidyverse** way\n\nWe can use the `summarise()` function to numerically summarise/describe our data. Some key values we may want to consider extracting are (though not limited to): the mean (via `mean()`, standard deviation (via `sd()`), minimum value (via `min()`), maximum value (via `max()`), standard error (via `se()`), and skewness (via `skew()`). \n\n::: {.panel-tabset}\n\n## Numeric values only example:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(kableExtra)\n\n# using the pre-loaded iris dataset\n# taking the mean and standard deviation of sepal length via the summarize function\n# returning a table with a caption, where numbers are rounded to 2 dp\n# asking for a table that is not the full width of the window display\niris %>%\n    summarize(\n        M_Length = mean(Sepal.Length),\n        SD_Length = sd(Sepal.Length)\n    ) %>%\n    kable(caption = \"Sepal Length Descriptives (in cm)\", digits = 2) %>%\n    kable_styling(full_width = FALSE)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Sepal Length Descriptives (in cm)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> M_Length </th>\n   <th style=\"text-align:right;\"> SD_Length </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 5.84 </td>\n   <td style=\"text-align:right;\"> 0.83 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n\n## Categorical and numeric values example:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(kableExtra)\n\n# using the pre-loaded iris dataset\n# grouping by Species. NOTE: we can group by 2 variables - we would just separate by a comma within group_by( , )\n# taking the mean and standard deviation of sepal length via the summarize function\n# returning a table of sepal length grouped by species with a caption, where numbers are rounded to 2 dp\n# asking for a table that is not the full width of the window display\niris %>%\n    group_by(Species) %>%\n    summarize(\n        M_Length = mean(Sepal.Length),\n        SD_Length = sd(Sepal.Length)\n    ) %>%\n    kable(caption = \"Sepal Length (in cm) Grouped by Species Descriptives Table\", digits = 2) %>%\n    kable_styling(full_width = FALSE)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Sepal Length (in cm) Grouped by Species Descriptives Table</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Species </th>\n   <th style=\"text-align:right;\"> M_Length </th>\n   <th style=\"text-align:right;\"> SD_Length </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> setosa </td>\n   <td style=\"text-align:right;\"> 5.01 </td>\n   <td style=\"text-align:right;\"> 0.35 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> versicolor </td>\n   <td style=\"text-align:right;\"> 5.94 </td>\n   <td style=\"text-align:right;\"> 0.52 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> virginica </td>\n   <td style=\"text-align:right;\"> 6.59 </td>\n   <td style=\"text-align:right;\"> 0.64 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n:::\n\n##### The **psych** way\n\nThe `describe()` function will produce a table of descriptive statistics. If you would like only a subset of this output (e.g., mean, sd), you can use `select()` after calling `describe()` e.g., `describe() %>% select(mean, sd)`.\n\n::: {.panel-tabset}\n\n## Numeric values only example:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(psych)\nlibrary(kableExtra)\n\n# using the pre-loaded iris dataset\n# we want to get descriptive statistics of the iris dataset, specifically the sepal length column\n# we specifically want to select the mean and standard deviation from the descriptive statistics available (try this without including this argument to see what values you all get out)\n# returning a table with a caption, where numbers are rounded to 2 dp\n# asking for a table that is not the full width of the window display\ndescribe(iris$Sepal.Length) %>%\n    select(mean, sd) %>%\n    kable(caption = \"Sepal Length Descriptives (in cm)\", digits = 2) %>%\n    kable_styling(full_width = FALSE)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Sepal Length Descriptives (in cm)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">  </th>\n   <th style=\"text-align:right;\"> mean </th>\n   <th style=\"text-align:right;\"> sd </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> X1 </td>\n   <td style=\"text-align:right;\"> 5.84 </td>\n   <td style=\"text-align:right;\"> 0.83 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n\n## Categorical and numeric values options:\n\n*Note that this is quite an overly complex way to return these summary statistics - using the `tidyverse()` way is much more intuitive and straightforward!*\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(psych)\nlibrary(kableExtra)\n\n# using the pre-loaded iris dataset\n# we want to get descriptive statistics of the iris dataset, specifically the sepal length column by Species\n# we want to return a matrix (hence mat = TRUE), then convert this to a dataframe\n# we specifically want to select the mean and standard deviation from the descriptive statistics available (try this without including this argument to see what values you all get out)\n# returning a table with a new column names of Group, Mean, SD; adding a caption; numbers are rounded to 2 dp\n# asking for a table that is not the full width of the window display\n\n\ndescribeBy(Sepal.Length ~ Species, data = iris, mat = TRUE, digits = 2) %>%\n  as.data.frame() %>%\n  rownames_to_column() %>% \n  select(group1, mean, sd) %>%\n    kable(col.names = c(\"Group\", \"Mean\", \"SD\"), caption = \"Sepal Length Descriptives (in cm)\", digits = 2) %>%\n    kable_styling(full_width = FALSE)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Sepal Length Descriptives (in cm)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Group </th>\n   <th style=\"text-align:right;\"> Mean </th>\n   <th style=\"text-align:right;\"> SD </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> setosa </td>\n   <td style=\"text-align:right;\"> 5.01 </td>\n   <td style=\"text-align:right;\"> 0.35 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> versicolor </td>\n   <td style=\"text-align:right;\"> 5.94 </td>\n   <td style=\"text-align:right;\"> 0.52 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> virginica </td>\n   <td style=\"text-align:right;\"> 6.59 </td>\n   <td style=\"text-align:right;\"> 0.64 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n:::\n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n#### Correlation\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-4' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-4', 'opt-start-4')\"> <span class=\"olab\">Correlation Coefficient</span></span></div><div class=\"optional-body\" id = \"opt-body-4\" style=\"display: none;\">\n\n\n\nThe correlation coefficient is a standardised number which quantifies the strength and direction of the linear association between two variables. In a population it is denoted by $\\rho$, and in a sample it is denoted by $r$. \n\nValues of $r$ fall between $-1$ and $1$. How to interpret:\n\n+ Size: More extreme values (i.e., the The closer $r$ is to $+/- 1$) the stronger the linear association, and the closer to $0$ a weak/no association. Commonly used cut-offs are:\n    + Weak = $.1 < |r| < .3$\n    + Moderate = $.3 < |r| < .5$\n    + Strong = $|r| > .5$\n    \n+ Direction: The sign of $r$ says nothing about the strength of the association, but its nature and direction:\n    + Positive association means that values of one variable tend to be higher when values of the other variable are higher\n    + Negative association means that values of one variable tend to be lower when values of the other variable are higher\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-5' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-5', 'opt-start-5')\"> <span class=\"olab\">Correlation Matrix</span></span></div><div class=\"optional-body\" id = \"opt-body-5\" style=\"display: none;\">\n\n\n\nA correlation matrix is a table showing the correlation coefficients - $r_{(x,y)}=\\frac{\\mathrm{cov}(x,y)}{s_xs_y}$ - between variables. Each cell in the table shows the association between two variables. The diagonals show the correlation of a variable with itself (and are therefore always equal to 1).  \n\n:::blue\n**In R**\n\nWe can create a correlation matrix by giving the `cor()` function a dataframe. It is important to remember that all variables **must** be numeric.\n:::\n\nLet's check the structure of the iris dataset to ensure that all variables are numeric:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstr(iris)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n```\n\n\n:::\n:::\n\n\n\n\nWe can see that the variable *Species* in column 5 is a factor - this means that we cannot include this in our correlation matrix. Therefore, we need to *subset*, or, in other words, select specific columns. We can do this either giving the column numbers inside `[]`, or using `select()`. In our case, we want the variables in columns 1 - 4, just not 5.\n\nIf you had `NA` values within your dataset, you could choose to remove these `NA`s using `na.rm = TRUE` inside the `cor()` function.\n\n::: {.panel-tabset}\n\n## Index dataframe (`[]`)\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nround(cor(iris[,c(1:4)]), digits = 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             Sepal.Length Sepal.Width Petal.Length Petal.Width\nSepal.Length         1.00       -0.12         0.87        0.82\nSepal.Width         -0.12        1.00        -0.43       -0.37\nPetal.Length         0.87       -0.43         1.00        0.96\nPetal.Width          0.82       -0.37         0.96        1.00\n```\n\n\n:::\n:::\n\n\n\n\n## Variable selection (`select()`)\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# select only the columns we want by variable name, and pass this to cor()\niris %>% \n  select(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width) %>%\n  cor() %>%\n  round(digits = 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             Sepal.Length Sepal.Width Petal.Length Petal.Width\nSepal.Length         1.00       -0.12         0.87        0.82\nSepal.Width         -0.12        1.00        -0.43       -0.37\nPetal.Length         0.87       -0.43         1.00        0.96\nPetal.Width          0.82       -0.37         0.96        1.00\n```\n\n\n:::\n:::\n\n\n\n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-6' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-6', 'opt-start-6')\"> <span class=\"olab\">Correlation - Hypothesis Testing</span></span></div><div class=\"optional-body\" id = \"opt-body-6\" style=\"display: none;\">\n\n\n\nThe hypotheses of the correlation test are, as always, statements about the _population_ parameter (in this case the correlation between the two variables in the population - i.e., $\\rho$).  \n\nIf we are conducting a two tailed test, then... \n\n- $H_0: \\rho = 0$. There is _no_ linear association between $x$ and $y$ in the population.  \n- $H_1: \\rho \\neq 0$ There is a linear association between $x$ and $y$.  \n  \nIf we instead conduct a one-tailed test, then we are testing either...\n\n- $H_0: \\rho \\leq 0$ There is a negative or no linear association between $x$ and $y$   \n- $H_1: \\rho > 0$ There is a positive linear association between $x$ and $y$.\n\n**OR**\n\n- $H_0: \\rho \\geq 0$ There is a positive or no linear association between $x$ and $y$   \n- $H_1: \\rho < 0$ There is a negative linear association between $x$ and $y$.  \n\n__Test Statistic__  \n\nThe  test statistic for this test is the $t$ statistic, the formula for which depends on both the observed correlation ($r$) and the sample size ($n$):\n\n$$t = r \\sqrt{\\frac{n-2}{1-r^2}}$$\n\n\n__p-value__  \n\nWe calculate the $p$-value for our $t$-statistic as the long-run probability of a $t$-statistic with $n-2$ degrees of freedom being less than, greater than, or more extreme in either direction (depending on the direction of our alternative hypothesis) than our observed $t$-statistic.  \n\n__Assumptions__  \n\nFor a test of Pearson's correlation coefficient $r$, we need to make sure a few conditions are met:  \n\n+ Both variables are quantitative (i.e., numeric)\n+ Both variables are drawn from normally distributed populations\n+ The association between the two variables is linear  \n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-7' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-7', 'opt-start-7')\"> <span class=\"olab\">Correlation - Hypothesis Testing in R</span></span></div><div class=\"optional-body\" id = \"opt-body-7\" style=\"display: none;\">\n\n\n\n:::blue\n**In R**\n\nWe can test the significance of the correlation coefficient really easily with the function `cor.test()`:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncor.test(iris$Sepal.Length, iris$Petal.Length)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's product-moment correlation\n\ndata:  iris$Sepal.Length and iris$Petal.Length\nt = 21.646, df = 148, p-value < 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.8270363 0.9055080\nsample estimates:\n      cor \n0.8717538 \n```\n\n\n:::\n:::\n\n\n\n\nNote, by default, `cor.test()` will include only observations that have no missing data on either variable. \n\nWe can specify whether we want to conduct a one- or two-tailed test by adding the argument `alternative = ` and specifying `alternative = \"less\"`, `alternative = \"greater\"`, or `alternative = \"two.sided\"` (the latter being the default).  \n\n:::\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\n**Example Interpretation**\n\nThere was a strong positive association between sepal length and petal length $(r = .87, t(148) = 21.65, p < .001)$. These results suggested that a greater sepal length was positively associated with a greater petal length. \n\n:::\n\n:::{.callout-note}\n\nFor a detailed recap of all things correlation (including further details and examples), revisit the [Correlation lecture from DAPR1](https://uoepsy.github.io/dapr1/2324/lectures/dapR1_lec20_Correlation.pdf).\n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n## Visual Exploration\n\nVisual exploration of our data allows us to visualize the distributions of our data, and to identify potential associations between variables.\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-8' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-8', 'opt-start-8')\"> <span class=\"olab\">How to Visualise Data</span></span></div><div class=\"optional-body\" id = \"opt-body-8\" style=\"display: none;\">\n\n\n\nTo visualise (i.e., plot) our data, we can use `ggplot()` from the **tidyverse** package. Note the key components of the `ggplot()` code:\n\n+ `data =` where we provide the name of the dataframe.\n+ `aes =` where we provide the aesthetics. These are things which we map from the data to the graph. For instance, the $x$-axis, or if we wanted to colour the columns/bars according to some aspect of the data.\n+ `+ geom_...` = where we add (using +) some geometry. These are the shapes (e.g., bars, points, etc.), which will be put in the correct place according to what we specified in `aes()`.\n+ `labs()` = where we provide labels for our plot (e.g., the $x$- and $y$-axis)\n\n\n:::{.callout-note}\n\nThere are lots of arguments that you can further customise, some of which are specified in the examples below e.g., `bins = `, `alpha = `, `fill = `, `linewidth = `. `linetype = `, `size = ` etc. For these, you can look up the helper function to see the range of arguments they can take using `?` - e.g., `?fill`\n\nIf you'd like to read more about `ggplot()`, there is a handy [cheatsheet](https://rstudio.github.io/cheatsheets/data-visualization.pdf).\n\n:::\n\nOne other thing to consider when visualising your data is how you are going to arrange your plots. Some handy tips on this:  \n  \n- Use \\n to wrap text in your titles and or axis labels  \n- The **patchwork** package allows us to arrange multiple plots in two ways - `|` arranges the plots adjacent to one another, and `/` arranges the plots on top of one another  \n\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-9' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-9', 'opt-start-9')\"> <span class=\"olab\">Data Visualisation - Marginal Examples</span></span></div><div class=\"optional-body\" id = \"opt-body-9\" style=\"display: none;\">\n\n\n\n::: {.panel-tabset}\n\n#### Histogram\n\nA histogram shows the frequency of values which fall within bins of an equal width. \n\n**Basic:**\n\n- x-axis: possible values of some variable, grouped into bins\n- y-axis: frequency of a given value or values within bins\n- *What are bins?*: A bin represents a range of scores\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_histogram() +\n    labs(x = \"Sepal Length (in cm)\")\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-9-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n\n**Updating Bins:**\n\nWithin `geom_histogram()`, we can specify `bins = ` to specify the number of columns we want (for this example, lets say we want 10):\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_histogram(bins = 10) +\n    labs(x = \"Sepal Length (in cm)\")\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-10-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\nAlternatively, we can specify `binwidth = ` to specify the width of each bin (it is very helpful to be aware of the scale of your variable here!):\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_histogram(binwidth = 0.1) +\n    labs(x = \"Sepal Length (in cm)\")\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-11-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n\n**Outline columns with color:**\n\nWithin `geom_histogram()`, we can specify `color = ` to set a colored outline of the columns:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_histogram(color = \"red\") +\n    labs(x = \"Sepal Length (in cm)\")\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-12-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n\n**Fill columns with color:**\n\nWithin `geom_histogram()`, we can specify `fill = ` to fill the columns with a color:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_histogram(fill = \"purple\") +\n    labs(x = \"Sepal Length (in cm)\")\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-13-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n#### Density\n\nA visualization of the distribution of a numeric variable. \n\n**Basic:**\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_density() +\n    labs(x = \"Sepal Length (in cm)\")\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-14-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n**Filled:**\n\nWe can fill our plot with colour by specifying `fill = ` within `geom_density()`:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_density(fill = \"lightblue\") +\n    labs(x = \"Sepal Length (in cm)\")\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-15-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n**Line Type & Width:**\n\nWe can change the type and width of the line by specifying `linetype = ` and `linewidth = ` within `geom_density()`:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = iris, aes(x = Sepal.Length)) +\n    geom_density(linetype = 6, linewidth = 3) +\n    labs(x = \"Sepal Length (in cm)\")\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-16-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-10' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-10', 'opt-start-10')\"> <span class=\"olab\">Data Visualisation - Bivariate Examples</span></span></div><div class=\"optional-body\" id = \"opt-body-10\" style=\"display: none;\">\n\n\n\nUnlike in our marginal plots where we specified our x-axis variable within `aes()`, to visualise bivariate associations, we need to specify what variables we want on both our x- and y-axis. \n\n::: {.panel-tabset}\n\n#### Scatterplot\n\nWe can use a scatterplot (since the variables are numeric and continuous) to visualise the association between the two numeric variables - these will be our x- and y-axis values. \n\nWe plot these values for each row of our dataset, and we should end up with a *cloud* of scattered points. \n\nHere we will want to comment on any key observations that we notice, including if we detect outliers or points that do not fit with the pattern in the rest of the data. Outliers are extreme observations that are not possible values of a variable or that do not seem to fit with the rest of the data. This could either be:\n\n+ *marginally* along one axis: points that have an unusual (too high or too low) x-coordinate or y-coordinate;\n+ *jointly*: observations that do not fit with the rest of the point cloud \n\n**Basic:**\n\nWe need to specify `+ geom_point()` to get a scatterplot: \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = iris, aes(x = Petal.Length, y = Sepal.Length)) +\n    geom_point() +\n    labs(x = \"Petal Length (in cm)\", y = \"Sepal Length (in cm)\")\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-17-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n**Fill points with color:**\n\nWithin `geom_point()`, we can specify `color = ` to fill the points with a color:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = iris, aes(x = Petal.Length, y = Sepal.Length)) +\n    geom_point(color = \"orange\") +\n    labs(x = \"Petal Length (in cm)\", y = \"Sepal Length (in cm)\")\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-18-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n**Change size and opacity:**\n\nWe can change the size (using `size =`) and the opacity (using `alpha =`) of our geom elements on the plot. Let’s include this below:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = iris, aes(x = Petal.Length, y = Sepal.Length)) +\n    geom_point(size = 3, alpha = 0.5) +\n    labs(x = \"Petal Length (in cm)\", y = \"Sepal Length (in cm)\")\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-19-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n**Add a line of best fit:**\n\nWe can superimpose (i.e., add) a line of best fit by including the argument `+ geom_smooth()`. Since we want to fit a straight line, we want to use `method = \"lm\"`. We can also specify whether we want to display confidence intervals around our line by specifying `se = TRUE / FALSE`. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = iris, aes(x = Petal.Length, y = Sepal.Length)) +\n    geom_point() +\n    geom_smooth(method = \"lm\", se = FALSE) +\n    labs(x = \"Petal Length (in cm)\", y = \"Sepal Length (in cm)\")\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-20-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n#### Boxplot\n\nWe can use a boxplot to visualise the association between one numeric variable and one categorical variable - these will be our y- and x-axis values respectively.\n\n**Basic:**\n\nWe need to specify `+ geom_boxplot()` to get a boxplot: \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = iris, aes(x = Species, y = Sepal.Length)) +\n    geom_boxplot() +\n    labs(x = \"Species\", y = \"Sepal Length (in cm)\")\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-21-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n**Change boxplot fill colours by group:**\n\nWithin `aes()`, we can specify `fill = ` to fill the boxes with a color:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = iris, aes(x = Species, y = Sepal.Length, fill = Species)) +\n    geom_boxplot() +\n    labs(x = \"Species\", y = \"Sepal Length (in cm)\")\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-22-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n**Change boxplot line colours by group:**\n\nWithin `aes()`, we can specify `color = ` to colour the lines with a color:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = iris, aes(x = Species, y = Sepal.Length, color = Species)) +\n    geom_boxplot() +\n    labs(x = \"Species\", y = \"Sepal Length (in cm)\")\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-23-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n**Adding jitter:**\n\nWe can add jittered points to a boxplot to better see the underlying distribution of the data (by adding a little random variation to each data point) via `geom_jitter()`: \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = iris, aes(x = Species, y = Sepal.Length, color = Species)) +\n    geom_boxplot() +\n    geom_jitter() + \n    labs(x = \"Species\", y = \"Sepal Length (in cm)\")\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-24-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n**Change legend position:**\n\nWe can add the argument `+ theme(legend.position = )` to move (or even remove) the legend by specifying, for example, ` \"right\" `, ` \"left\" `, ` \"top\" `, ` \"bottom\" `, or  `\"none\" ` to remove. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# legend at bottom of plot\nggplot(data = iris, aes(x = Species, y = Sepal.Length, color = Species)) +\n    geom_boxplot() +\n    labs(x = \"Species\", y = \"Sepal Length (in cm)\") + \n    theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-25-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n#### Facets\n\nWhen we have two numeric variables, as well as categorical variables, we can use `facet_wrap()` / `facet_grid()` to help divide/arrange our plots. If we had two categorical variables, by simply stringing them together to further group our plots by specifying `facet_wrap( ~ cat_variable1 + cat_variable2)`\n\n**Basic:**\n\nWe need to specify `+ geom_point()` to get a scatterplot, and *either* `+ facet_wrap()` or  `+ facet_grid()` to separate by your categorical variable: \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = iris, aes(x = Petal.Length, y = Sepal.Length)) +\n    geom_point() +\n    facet_wrap(~Species) + \n    labs(x = \"Petal Length (in cm)\", y = \"Sepal Length (in cm)\")\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-26-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n**Add a line of best fit:**\n\nWe can superimpose (i.e., add) a line of best fit by including the argument `+ geom_smooth()`. Since we want to fit a straight line, we want to use `method = \"lm\"`. We can also specify whether we want to display confidence intervals around our line by specifying `se = TRUE / FALSE`. Note that a line is fitted for every level of your categorical variable:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = iris, aes(x = Petal.Length, y = Sepal.Length)) +\n    geom_point() +\n    geom_smooth(method = \"lm\", se = FALSE) +\n        facet_wrap(~Species) + \n    labs(x = \"Petal Length (in cm)\", y = \"Sepal Length (in cm)\")\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-27-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n**Subplot layout:**\n\nYou can change the overall layout of the subplots by specifying `dir = ` within the `facet_wrap()` argument, where `“h”` will return a horizontal layout (this is the default) and `“v”` for vertical.\n\nYou can also change the layout of the subplot labels by specifying `strip.position = ` within the `facet_wrap()` argument, where labels can be arranged to display at the `“top”` (this is the default), `“bottom”`, `“left”` or `“right”`. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = iris, aes(x = Petal.Length, y = Sepal.Length)) +\n    geom_point() +\n    facet_wrap(~Species, dir = \"v\", strip.position = \"right\") + \n    labs(x = \"Petal Length (in cm)\", y = \"Sepal Length (in cm)\")\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-28-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Functions and Mathematical Models\n\nBasic functions and mathematical models are foundational tools used to describe and predict associations between variables.\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-11' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-11', 'opt-start-11')\"> <span class=\"olab\">Identification & Specification</span></span></div><div class=\"optional-body\" id = \"opt-body-11\" style=\"display: none;\">\n\n\n\nConsider the function $y = 2 + 5 \\ x$. From this, we can do the following:\n\n- Identify the dependent variable (DV)\n- Identify the independent variable (IV)\n- Describe in words what the function does, and compute the output for the following input:\n\n$$\nx = \\begin{bmatrix}\n2 \\\\\n6\n\\end{bmatrix}\n$$\n\nThe function says that the $y$ value is obtained as a transformation of the $x$ value.\n\n- The dependent variable is $y$\n- The independent variable is $x$\n- The $y$ value is obtained as five times $x$, plus two.\n\n<br />\nExample (1): If $x$ equals 2, the corresponding value of $y$ will be $2 + 5 * 2 = 12$.\n<br />\nExample (2): If $x$ equals 6, the corresponding value of $y$ will be $2 + 5 * 6 = 32$.\n\n$$\ny = \\begin{bmatrix}\n2 + 5 * 2 \\\\\n2 + 5 * 6\n\\end{bmatrix}\n= \\begin{bmatrix}\n12 \\\\\n32\n\\end{bmatrix}\n$$\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-12' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-12', 'opt-start-12')\"> <span class=\"olab\">Deterministic Models - Description & Specification</span></span></div><div class=\"optional-body\" id = \"opt-body-12\" style=\"display: none;\">\n\n\n\nWe come across functions *a lot* in daily life, and probably don't think much about it. In a slightly more mathematical setting, we can write down in words and in symbols the function describing the association between the side of a square and its perimeter (e.g., to capture *how* the perimeter *varies* as a function of its side). In this case, the perimeter is the dependent variable, and the side is the independent variable.\n\nThis is what we would refer to as a *deterministic model*, as it is a model of an *exact relationship* - there can be no deviation.\n\n**Model Specification**\n\n::: {.panel-tabset}\n\n## In words\n\nThe perimeter of a square is four times the length of its side.\n\n\n## In symbols\n\nThe relationship between side and perimeter of squares is given by:\n\n$$\nPerimeter = 4 * Side\n$$\n\nIf you denote $y$ as the dependent variable _Perimeter_, and $x$ as the independent variable _Side_ we can rewrite as: \n\n$$\ny = 4 * x\n$$\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-13' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-13', 'opt-start-13')\"> <span class=\"olab\">Deterministic Models - Visualisation</span></span></div><div class=\"optional-body\" id = \"opt-body-13\" style=\"display: none;\">\n\n\n\nLet's create a dataset called `squares`, containing the perimeter of four squares having sides of length $0, 2, 5, 9$ meters, and then plot the `squares` data as points on a scatterplot. \n\nFirst, let's make our squares data. Here we will use two important functions - `tibble()` and `c()`. The `tibble()` function allows us to construct a data frame. To store a sequence of numbers into R, we can **c**ombine the values using `c()`. A sequence of elements all of the same type is called a *vector*.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#create data frame named squares\nsquares <- tibble(\n  side = c(0, 2, 5, 9), \n  perimeter = 4 * side\n)\n\n#check that our values are contained within squares\nsquares\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 2\n   side perimeter\n  <dbl>     <dbl>\n1     0         0\n2     2         8\n3     5        20\n4     9        36\n```\n\n\n:::\n:::\n\n\n\n\nNow we know how `ggplot()` works, we can start to build our plot. First we specify our data (we want to use the *squares* data frame), and then our aesthetics. Since the perimeter varies as a function of side, we want side on the $x$-axis, and perimeter on the $y$-axis. We want to create a scatterplot, so we need to specify our `geom_...` argument as `geom_point()`. Lastly, we will provide clearer axis labels, and include the units of measurement. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = squares, aes(x = side, y = perimeter)) +\n  geom_point() +  \n  labs(x = 'Side (m)', y = 'Perimeter (m)',  title = 'Perimeter = 4*Side')  \n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/fig-squares1-1.png){#fig-squares1 fig-align='center' width=80%}\n:::\n:::\n\n\n\n\nWe could also visualise the functional relationship by connecting the individual points with a line. To do so, we need to add a new argument - `geom_line()`. If you would like to change the colour of the line from the default, you can specify `geom_line(colour = \"insert colour name\")`. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = squares, aes(x = side, y = perimeter)) +\n  geom_point() +\n  geom_line(colour = \"blue\") + \n  labs(x = 'Side (m)', y = 'Perimeter (m)',  title = 'Perimeter = 4*Side')  \n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-31-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-14' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-14', 'opt-start-14')\"> <span class=\"olab\">Deterministic Models - Predicted Values</span></span></div><div class=\"optional-body\" id = \"opt-body-14\" style=\"display: none;\">\n\n\n\nSometimes we can directly read a predicted value from the graph of the functional relationship.\n\nConsider the plot created above. For example, first we need to check where x = 2.5. Then, we draw a vertical dashed line until it meets the blue line. The y value corresponding to x = 2.5 can be read off the y-axis. In our case, we would say a side of 2.5m corresponds to a perimeter of 10m. \n\nHowever, in this case it is not that easy to read it from the drawing... This leads us to the algebraic approach:\n\nWe can substitute the x value in the formula and calculate the corresponding y value where we would conclude that the predicted perimeter of squared paintings having a 2.5m side is 10m:\n\n$$\ny = 4 \\cdot x  \\\\    \n$$\n\n$$\ny = 4 \\cdot 2.5 \\\\  \n$$\n\n$$\ny = 10  \\\\\n$$\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Statistical Models\n\nStatistical models are used to understand the associations among variables.\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-15' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-15', 'opt-start-15')\"> <span class=\"olab\">Specifying Hypotheses</span></span></div><div class=\"optional-body\" id = \"opt-body-15\" style=\"display: none;\">\n\n\n\nWe need to specify our hypotheses when testing a model as this not only defines what we are testing, but also sets the direction for statistical inference. By specifying a null hypothesis (typically stating no effect or no association) and an alternative hypothesis (indicating the presence of an association), we create a structured approach for determining the statistical significance of model parameters. Without specifying hypotheses, the interpretation of results would lack focus, making it difficult to assess the validity and relevance of the model's findings.\n\nIn regression analysis, hypothesis testing for beta coefficients is used to assess whether (each) predictor variable significantly contributes to the model. \n\nThe way we specify hypotheses is similar across simple and multiple regression models.\n\nFor each regression coefficient $\\beta_j$ (for predictor $X_j$):\n\n+ Null hypothesis ($H_0$) = $\\beta_j = 0$: The predictor variable ($X_j$) is not associated with the DV  \n+ Alternative hypothesis ($H_1$) = $\\beta_j \\neq 0$: The predictor variable ($X_j$) is associated with the DV  \n  \n  \nBased on the $p$-value or comparison of the $t$-statistic with the critical value, you can conclude whether the predictor variable is significant or not (see the simple & multiple regression Models - extracting information > model coefficients flashcard below):\n\n+ Reject $H_0$ if $|t_j|$ > critical value or $p$-value $< \\alpha$ \n+ Fail to reject $H_0$ if $|t_j|$ $\\leq$ critical value or $p$-value $\\geq \\alpha$ \n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-16' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-16', 'opt-start-16')\"> <span class=\"olab\">Simple Linear Regression Models - Description & Specification</span></span></div><div class=\"optional-body\" id = \"opt-body-16\" style=\"display: none;\">\n\n\n\nThe association between two variables (e.g., recall accuracy and age) will show deviations from the 'average pattern'. Hence, we need to create a model that allows for deviations from the linear relationship - we need a _statistical model_.\n\nA statistical model includes *both* a deterministic function and a random error term. We typically refer to the outcome (‘dependent’) variable with the letter $y$ and to our predictor (‘explanatory’/‘independent’) variables with the letter $x$. A simple (i.e., one x variable only) linear regression model thus takes the following form (where the terms $\\beta_0$ and $\\beta_1$ are numbers specifying where the line going through the data meets the y-axis (i.e., the intercept - where $x$ = 0; $\\beta_0$) and its slope (direction and gradient of line; $\\beta_1$):\n\n**Model Specification**\n\n$$\ny_i = \\beta_0 + \\beta_1 \\cdot x_i + \\epsilon_i    \n$$\n\n**Model Specification: Annotated**\n\n$$\ny_i = \\underbrace{\\beta_0 + \\beta_1 \\cdot x_i}_{\\text{function of }x} + \\underbrace{\\epsilon_i}_{\\text{random error}}  \n\\\\\n$$\n\n$$\n\\quad \\text{where} \\quad \\epsilon_i \\sim N(0, \\sigma) \\text{ independently}\n$$\n\n\n**Model Specification: Explained**\n\nLet's break down what $y_i = \\beta_0 + \\beta_1 \\cdot x_i + \\epsilon_i \\quad \\text{where} \\quad \\epsilon_i \\sim N(0, \\sigma) \\text{ independently}$ actually means by considering the statement in smaller parts:\n\n+ *$y_i = \\beta_0 + \\beta_1 \\cdot x_i$*  \n  \n    + $y_i$ is our measured outcome variable (our DV)  \n    + $x_i$ is our measured predictor variable (our IV)  \n    + $\\beta_0$ is the model intercept  \n    + $\\beta_1$ is the model slope  \n\n+ *$\\epsilon \\sim N(0, \\sigma) \\text{ independently}$*   \n  \n    + $\\epsilon$ is the residual error   \n    + $\\sim$ means 'distributed according to'    \n    + $N(0, \\sigma) \\text{ independently}$ means 'normal distribution with a mean of 0 and a variance of $\\sigma$'   \n    + Together, we can say that the errors around the line have a mean of zero and constant spread as x varies    \n\n\n:::blue\n**In R**\n\nThere are basically two pieces of information that we need to pass to the `lm()` function:\n\n1. The formula: The regression formula should be specified in the form `y ~ x` where $y$ is the dependent variable (DV) and $x$ the independent variable (IV).\n2. The data: Specify which dataframe contains the variables specified in the formula.\n\nIn `R`, the syntax of the `lm()` function can be specified as follows (where DV = dependent variable, IV = independent variable, and dataframe_name = the name of your dataset):\n\n::: {.panel-tabset}\n\n## Option A\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel_name <- lm(DV ~ IV, data = data_name) \n```\n:::\n\n\n\n\n## Option B\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel_name <- lm(data_name$DV ~ data_name$IV)\n```\n:::\n\n\n\n\n\n:::\n\nyou can also specify as: \n\n::: {.panel-tabset}\n\n## Option A\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel_name <- lm(DV ~ 1 + IV, data = data_name) \n```\n:::\n\n\n\n\n## Option B\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel_name <- lm(data_name$DV ~ 1 + data_name$IV)\n```\n:::\n\n\n\n\n:::\n\n::: {.callout-important icon=false collapse=true}\n## Why is there a 1 in the two bottom options? \n\nWhen we specify the linear model in `R`, we include after the tilde sign ($\\sim$), the variables that appear to the right of the $\\hat \\beta$s. The intercept, or $\\beta_0$, is a constant. That is, we could write it as multiplied by 1.\n\nIncluding the 1 explicitly is not necessary because it is included by default (you can check this by comparing the outputs of A & B above with and without the 1 included - the estimates are the same!). After a while, you will find you just want to drop the 1 when calling `lm()` because you know that it’s going to be there, but in these early weeks we tried to keep it explicit to make it clear that you want the intercept to be estimated. \n:::\n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n## Numeric Outcomes & Predictors\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-17' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-17', 'opt-start-17')\"> <span class=\"olab\">Simple Linear Regression Models - Example</span></span></div><div class=\"optional-body\" id = \"opt-body-17\" style=\"display: none;\">\n\n\n\nImagine that you were tasked to investigate whether there was an association between recall accuracy and age. You have been provided with data from twenty participants who studied passages of text (c500 words long), and were tested a week later. The testing phase presented participants with 100 statements about the text. They had to answer whether each statement was true or false, as well as rate their confidence in each answer (on a sliding scale from 0 to 100). The dataset contains, for each participant, the percentage of items correctly answered, their age (in years), and their average confidence rating. \n\nThe data are available at [https://uoepsy.github.io/data/recalldata.csv](https://uoepsy.github.io/data/recalldata.csv)\n\nWe could specify our model as:\n\n$$\n\\text{Recall Accuracy}_i = \\beta_0 + \\beta_1 \\cdot \\text{Age}_i + \\epsilon_i    \n$$\n\nand fit our model in `R` as\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#specify model\nrecall_simp <- lm(recall_accuracy ~ age, data = recalldata)\n\n#look at model coefficients\nrecall_simp\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = recall_accuracy ~ age, data = recalldata)\n\nCoefficients:\n(Intercept)          age  \n    84.0153      -0.3026  \n```\n\n\n:::\n:::\n\n\n\n\nWhen we call the name of the fitted model, `recall_simp`, you can see the estimated regression coefficients $\\hat \\beta_0$ and $\\hat \\beta_1$. The line of best-fit is thus given by:^[Yes, the error term is gone. This is because the line of best-fit gives you the prediction of the average recall accuracy for a given age, and not the individual recall accuracy of an individual person, which will almost surely be different from the prediction of the line.] \n\n$$\n\\widehat{Recall~Accuracy} = 84.02 - 0.31 \\cdot \\text{Age}\n$$\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-18' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-18', 'opt-start-18')\"> <span class=\"olab\">Multiple Linear Regression Models - Description & Specification</span></span></div><div class=\"optional-body\" id = \"opt-body-18\" style=\"display: none;\">\n\n\n\nMultiple linear regression involves looking at one continuous outcome (i.e., DV), with two or more independent variables (i.e., IVs). \n\nA multiple linear regression model takes the following form:\n\n$$\ny_i = \\beta_0 + \\beta_1 \\cdot x_1 + \\beta_2 \\cdot x_2 + \\epsilon_i\n$$\n$$\n\\quad \\text{where} \\quad \\epsilon_i \\sim N(0, \\sigma) \\text{ independently}\n$$\nSo, for example, we could extend our recall accuracy model to include recall confidence as a predictor:\n\n$$\n\\text{Recall Accuracy}_i = \\beta_0 + \\beta_1 \\cdot \\text{Recall Confidence}_i + \\beta_2 \\cdot \\text{Age}_i + \\epsilon_i    \n$$\n\n:::blue\n\nIn **R**\n\nMultiple and simple linear regression follow the same structure within the `lm()` function - the logic scales up to however many predictor variables we want to include in our model. You simply add (using the `+` sign) more independent variables. For example, if we wanted to build a multiple linear regression that included three independent variables, we could fit one of the following via the `lm()` function:\n\n::: {.panel-tabset}\n\n## Option A\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel_name <- lm(DV ~ IV1 + IV2 + IV3, data = data_name)\n```\n:::\n\n\n\n\n## Option B\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel_name <- lm(data_name$DV ~ data_name$IV1 + data_name$IV2 + data_name$IV3)\n```\n:::\n\n\n\n\n:::\n\n:::\n\n**Interpretation of Multiple Regression Coefficients**\n\nYou'll hear a lot of different ways that people explain multiple regression coefficients.  \n\nFor the model $y = \\beta_0 + \\beta_1 \\cdot x_1 + \\beta_2 \\cdot x_2 + \\epsilon$, the estimate $\\hat \\beta_1$ will often be reported as:  \n  \n\"the increase in $y$ for a one unit increase in $x_1$ when...\"\n\n- \"holding the effect of $x_2$ constant.\"\n- \"controlling for differences in $x_2$.\"\n- \"partialling out the effects of $x_2$.\"\n- \"holding $x_2$ equal.\"\n- \"accounting for effects of $x_2$.\" \n\nFor models with 3+ predictors, just like building the model in `R`, the logic of the above simply extends. \n\nFor example “the increase in [outcome] for a one unit increase in [predictor] when...”\n\n- “holding [other predictors] constant.”  \n- “accounting for [other predictors].”  \n- “controlling for differences in [other predictors].”  \n- “partialling out the effects of [other predictors].”  \n- “holding [other predictors] equal.”  \n- “accounting for effects of [other predictors].”  \n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-19' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-19', 'opt-start-19')\"> <span class=\"olab\">Simple Linear Regression Models - Visualisation</span></span></div><div class=\"optional-body\" id = \"opt-body-19\" style=\"display: none;\">\n\n\n\nAs we saw above, the line representing the relationship between side and perimeter of squares is able to predict the actual perimeter value from the measurement of the side of a square.  \n\nThis is possible because the association between side and perimeter is an **exact** one. That is, any squares having the same side will have the same perimeter, and there will be no variation in those values.\n\nThe line that best fits the association between recall accuracy and age (see @fig-recallage-fitted-model), instead, is only able to predict the **average** accuracy for a given value of age.\n\nThis is because there will be a distribution of recall accuracy at each value of age. The line will fit the trend/pattern in the values, but there will be individual-to-individual variability that we must accept around that average pattern.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(recalldata, aes(x = age, y = recall_accuracy)) + \n    geom_point(size = 3, alpha = 0.5) +\n    geom_smooth(method = lm, se = FALSE) + \n    labs(x = \"Age (in years)\", y = \"Recall Accuracy (%)\")\n```\n\n::: {.cell-output-display}\n![Association between Recall Accuracy and Age](1_b4_reading_files/figure-html/fig-recallage-fitted-model-1.png){#fig-recallage-fitted-model fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-20' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-20', 'opt-start-20')\"> <span class=\"olab\">Multiple Linear Regression Models - Visualisation</span></span></div><div class=\"optional-body\" id = \"opt-body-20\" style=\"display: none;\">\n\n\n\nWhen we have 2+ predictors, we can’t just plot our data an add `geom_smooth(method=lm)`, because that would give a visualisation of a linear model with just one predictor (whichever one is on the x-axis).  \n\nInstead, we can use the function `plot_model()` from **sjPlot**. Here's an example with our recall accuracy model, with two predictors (recall confidence and age):\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot_model(recall_mdl,\n           type = \"eff\",\n           terms = \"recall_confidence\",\n           show.data = TRUE)\n\nplot_model(recall_mdl,\n           type = \"eff\",\n           terms = \"age\",\n           show.data = TRUE)\n```\n\n::: {.cell-output-display}\n![Association between Recall Accuracy, Recall Confidence and Age](1_b4_reading_files/figure-html/fig-recalmod-1.png){#fig-recalmod-1 fig-align='center' width=80%}\n:::\n\n::: {.cell-output-display}\n![Association between Recall Accuracy, Recall Confidence and Age](1_b4_reading_files/figure-html/fig-recalmod-2.png){#fig-recalmod-2 fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n## Numeric Outcomes & Categorical Predictors\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-21' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-21', 'opt-start-21')\"> <span class=\"olab\">Overview</span></span></div><div class=\"optional-body\" id = \"opt-body-21\" style=\"display: none;\">\n\n\n\nWe can include categorical predictors in a linear regression, but the interpretation of the coefficients is very specific. Whereas we talked about coefficients being interpreted as “the change in $y$ associated with a 1-unit increase in $x$”, for categorical explanatory variables, coefficients can be considered to examine differences in group means. \n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-22' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-22', 'opt-start-22')\"> <span class=\"olab\">Coding Variables as Factors</span></span></div><div class=\"optional-body\" id = \"opt-body-22\" style=\"display: none;\">\n\n\n\nWhen we have categorical predictors, it is important that we tell `R` specifically to code them appropriately as *factors*.  \n\n:::blue\n\nIn **R**\n\nWe can use various functions to convert between different types of data, such as:\n\n+ `factor()` / `as_factor()` - to turn a variable into a factor  \n+ `as.numeric()` - to turn a variable into numbers\n\n:::\n\n\n\nAs a first step, it is a good idea to look at the structure of the dataset you are working with. For the purpose of this example, our dataset is called \"tips\" (you might recall this from DAPR1):\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstr(tips)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nspc_tbl_ [157 × 7] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Bill  : num [1:157] 23.7 36.1 32 17.4 15.4 ...\n $ Tip   : num [1:157] 10 7 5.01 3.61 3 2.5 3.44 2.42 3 2 ...\n $ Credit: chr [1:157] \"n\" \"n\" \"y\" \"y\" ...\n $ Guests: num [1:157] 2 3 2 2 2 2 2 2 2 2 ...\n $ Day   : chr [1:157] \"f\" \"f\" \"f\" \"f\" ...\n $ Server: chr [1:157] \"A\" \"B\" \"A\" \"B\" ...\n $ PctTip: num [1:157] 42.2 19.4 15.7 20.8 19.5 13.4 16 12.4 12.7 10.7 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Bill = col_double(),\n  ..   Tip = col_double(),\n  ..   Credit = col_character(),\n  ..   Guests = col_double(),\n  ..   Day = col_character(),\n  ..   Server = col_character(),\n  ..   PctTip = col_double()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n```\n\n\n:::\n:::\n\n\n\n\nFrom the output, we can see that `Credit` (whether guests paid with a credit card; n/y responses) was coded as a `<chr>` or character variable. If we wanted to set this as a factor so that `R` recognises it as a categorical variable, we can use on of the following:\n\n::: {.panel-tabset}\n\n### `as_factor()`\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntips <- tips %>% \n  mutate(Credit = as_factor(Credit))\n```\n:::\n\n\n\n\n### `factor()`\n\nWe could also use the `factor()` function, and at the same time label factors appropriately to aid reader interpretation (it may not be immediately clear to some that *n* represents 'No' and *y* represents 'Yes'). To do so, we list the all levels of `Credit`, and provide a new label corresponding to each level:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntips$Credit <- factor(tips$Credit, \n                      levels = c(\"n\", \"y\"),\n                      labels = c(\"No\", \"Yes\"))\n```\n:::\n\n\n\n\n:::\n\nUsing either of the above approaches, if we now run `str(tips)` again, you should see that `Credit` is now coded as a factor with 2 levels:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstr(tips)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntibble [157 × 7] (S3: tbl_df/tbl/data.frame)\n $ Bill  : num [1:157] 23.7 36.1 32 17.4 15.4 ...\n $ Tip   : num [1:157] 10 7 5.01 3.61 3 2.5 3.44 2.42 3 2 ...\n $ Credit: Factor w/ 2 levels \"n\",\"y\": 1 1 2 2 1 1 1 1 1 1 ...\n $ Guests: num [1:157] 2 3 2 2 2 2 2 2 2 2 ...\n $ Day   : chr [1:157] \"f\" \"f\" \"f\" \"f\" ...\n $ Server: chr [1:157] \"A\" \"B\" \"A\" \"B\" ...\n $ PctTip: num [1:157] 42.2 19.4 15.7 20.8 19.5 13.4 16 12.4 12.7 10.7 ...\n```\n\n\n:::\n:::\n\n\n\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-23' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-23', 'opt-start-23')\"> <span class=\"olab\">Binary Predictors</span></span></div><div class=\"optional-body\" id = \"opt-body-23\" style=\"display: none;\">\n\n\n\nBinary variables have two categories (more commonly referred to as levels), and these levels (e.g., Yes/No, Dog/Cat, Right/Left, Smoker/Non-Smoker) are simply entered in the model as a series of 0s and 1s. Numeric variables that represent categorical data are typically referred to as __dummy variables__.  \n\nOur coefficients are just the same as before. The intercept is where our predictor equals zero, and the slope is the change in our outcome variable associated with a 1-unit change in our predictor.\n\nHowever, “zero” for this predictor variable now corresponds to a whole level. This is known as the “reference level”. Accordingly, the 1-unit change in our predictor (the move from “zero” to “one”) corresponds to the difference between the two levels. \n\nWhen used as predictors in multiple regression models, binary variables behave much the same way. The coefficient will give us the estimated change in $y$ when moving from one level to the other, whilst holding other predictors constant (for more info, see the **Multiple Linear Regression Models - Description & Specification** flashcard, specifically the section on interpretation of multiple regression coefficients).\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-24' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-24', 'opt-start-24')\"> <span class=\"olab\">Categorical Predictors with k levels</span></span></div><div class=\"optional-body\" id = \"opt-body-24\" style=\"display: none;\">\n\n\n\nWhen we have a _categorical_ explanatory variable with __more than 2 levels__, our model gets a bit more complex - it needs not just one, but _a number of_ dummy variables. For a categorical variable with $k$ levels, we can express it in $k-1$ dummy variables.  \n\nFor example, the \"species\" column below has three levels, and can be expressed by the two variables \"species_dog\" and \"species_parrot\": \n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n  species species_dog species_parrot\n1     cat           0              0\n2     cat           0              0\n3     dog           1              0\n4  parrot           0              1\n5     dog           1              0\n6     cat           0              0\n7     ...         ...            ...\n```\n\n\n:::\n:::\n\n\n\n\n+ The \"cat\" level is expressed whenever both the \"species_dog\" and \"species_parrot\" variables are 0.\n+ The \"dog\" level is expressed whenever the \"species_dog\" variable is 1 and the \"species_parrot\" variable is 0.\n+ The \"parrot\" level is expressed whenever the \"species_dog\" variable is 0 and the \"species_parrot\" variable is 1.  \n\n`R` will do all of this re-expression for us. If we include in our model a categorical explanatory variable with 3 different levels, the model will estimate 2 parameters - one for each dummy variable. We can interpret the parameter estimates (the coefficients we obtain using `coefficients()`,`coef()` or `summary()`) as the estimated increase in the outcome variable associated with an increase of one in each dummy variable (holding all other variables equal).  \n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n-----------------------------------------------------------------\n      &nbsp;         Estimate   Std. Error   t value   Pr(>|t|)  \n------------------- ---------- ------------ --------- -----------\n  **(Intercept)**     60.28       1.209       49.86    5.273e-39 \n\n  **speciesdog**      -11.47       1.71      -6.708    3.806e-08 \n\n **speciesparrot**    -4.916       1.71      -2.875    0.006319  \n-----------------------------------------------------------------\n\n\n:::\n:::\n\n\n\n\nRecall that the intercept is the estimated outcome when all predictors are zero. In our example then, this represents the cat. We think of the \"cat\" category in this example as the _reference level_ - it is the category against which other categories are compared against. Therefore, in the above example, an increase in 1 of \"species_dog\" is the difference between a \"cat\" and a \"dog\". An increase in one of \"species_parrot\" is the difference between a \"cat\" and a \"parrot\". \n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-48-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-25' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-25', 'opt-start-25')\"> <span class=\"olab\">Dummy vs Effects Coding</span></span></div><div class=\"optional-body\" id = \"opt-body-25\" style=\"display: none;\">\n\n\n\n\nPossible side-constraints on the parameters are:\n\n|       Name      |             Constraint            |             Meaning of $\\beta_0$            |         R         |\n|:---------------:|:---------------------------------:|:-------------------------------------------:|:-----------------:|\n| Sum to zero (Effects Coding) | $\\beta_1 + \\beta_2 + \\beta_3 = 0$ | $\\beta_0 = \\mu$   |    `contr.sum`    |\n| Reference group (Dummy Coding) |           $\\beta_1 = 0$           | $\\beta_0 = \\mu_1$ | `contr.treatment` |\n\n\n**Dummy Coding**\n\nBy default `R` uses the reference group constraint - i.e., dummy coding  (sometimes called treatment contrast coding). If your factor has $g$ levels, your regression model will have $g-1$ dummy variables (`R` creates them for you, as we've seen in the examples above). \n\nWhen we use this approach, the intercept is the estimated $y$ when all predictors (i.e., $x$'s) are zero. Because the reference level is kind of like “0” in our contrast matrix, this is part of the intercept estimate. We get out a coefficient for each subsequent level, which are the estimated differences from each level to the reference group.\n\n\n**Effects Coding**\n\nEffects coding (sometimes called sum-to-zero coding) is the next most commonly used in psychological research. These are a way of comparing each level to the overall (or grand) mean. This involves a bit of trickery that uses -1s and 1s rather than 0s and 1s, in order to make “0” be mid-way between all the levels - the average of the levels.\n\nWhen we use this approach, the intercept is the estimated average $y$ when averaged across all levels of the predictor variable. In other words, it is the estimated grand mean of $y$. The coefficients represent the estimated difference for that level from the overall grand mean.\n\n:::blue\n\nIn **R**\n\nIf we want to use effects coding, we can apply:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncontrasts(iris$Species) <- \"contr.sum\"\n```\n:::\n\n\n\n\nWe can switch back to the default reference group constraint by applying either of these:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Option 1\ncontrasts(iris$Species) <- NULL\n\n# Option 2\ncontrasts(iris$Species) <- \"contr.treatment\"\n```\n:::\n\n\n\n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-26' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-26', 'opt-start-26')\"> <span class=\"olab\">Categorical Predictors - Interpretation</span></span></div><div class=\"optional-body\" id = \"opt-body-26\" style=\"display: none;\">\n\n\n\nLet's apply this to a different example - the iris dataset, and specifically, the Species categorical variable:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#check what levels we have\nlevels(iris$Species)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"setosa\"     \"versicolor\" \"virginica\" \n```\n\n\n:::\n:::\n\n\n\n\n\n::: {.panel-tabset}\n\n### Dummy Coding\n\nFrom the above, we can see that Species has 3 levels - \"setosa\", \"versicolor\", and \"virginica\". If we put these into a model, assuming `R`'s default ordering, we know that `R` will automatically apply dummy (or treatment coding), and \"setosa\" will be taken as our reference group:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#fit model\nspec_model <- lm(Sepal.Length ~ Species, data = iris)\nsummary(spec_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Sepal.Length ~ Species, data = iris)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.6880 -0.3285 -0.0060  0.3120  1.3120 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         5.0060     0.0728  68.762  < 2e-16 ***\nSpeciesversicolor   0.9300     0.1030   9.033 8.77e-16 ***\nSpeciesvirginica    1.5820     0.1030  15.366  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5148 on 147 degrees of freedom\nMultiple R-squared:  0.6187,\tAdjusted R-squared:  0.6135 \nF-statistic: 119.3 on 2 and 147 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n\nLet's first map our coefficients and estimates:\n\n| Coefficient | Estimate | Corresponds to |\n|:-:|:-:|:-:|\n| (Intercept)   |  5.0060 | $\\beta_0 = \\hat \\mu_1$\n| Speciesversicolor      | 0.9300  | $\\beta_0 + \\beta_1 = \\hat \\mu_2$ |\n| Speciesvirginica         | 1.5820  | $\\beta_0 + \\beta_2 = \\hat \\mu_3$ |\n\n+ The estimate corresponding to (Intercept) contains $\\hat \\beta_0 = \\hat \\mu_1 = 5.01$. The estimated average sepal length for the species setosa was approximately 5.01.\n\n+ The second estimate corresponds to `Speciesversicolor` and was $\\hat \\beta_1 = 0.93$. The difference in mean sepal length between `setosa` and `versicolor` species was estimated to be $0.93~cm$. Thus, $\\hat \\mu_2 = 5.01 + 0.93 = 5.94$. We could say - the species iris versicolor had a sepal length of approximately 5.94cm, and this was approximately 0.93cm longer than the iris setosa. This difference was statistically significant $(p < .001)$.\n\n+ The third estimate corresponds to `Speciesvirginica` and was $\\hat \\beta_2 = 1.58$. The difference in mean sepal length between `setosa` and `virginica` species was estimated to be $1.58~cm$. Thus, $\\hat \\mu_2 = 5.01 + 1.58 = 6.59$. We could say - the species iris virginica had a sepal length of approximately 6.59cm, and this was approximately 1.58cm longer than the iris setosa. This difference was statistically significant $(p < .001)$.\n\n### Effects Coding\n\nFirst we need to tell `R` to apply effects (or sum-to-zero) coding and check the ordering of the levels:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncontrasts(iris$Species) <- \"contr.sum\"\ncontrasts(iris$Species) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           [,1] [,2]\nsetosa        1    0\nversicolor    0    1\nvirginica    -1   -1\n```\n\n\n:::\n:::\n\n\n\n\nThen we can run our model:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#fit model\nspec_model2 <- lm(Sepal.Length ~ Species, data = iris)\nsummary(spec_model2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Sepal.Length ~ Species, data = iris)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.6880 -0.3285 -0.0060  0.3120  1.3120 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  5.84333    0.04203 139.020   <2e-16 ***\nSpecies1    -0.83733    0.05944 -14.086   <2e-16 ***\nSpecies2     0.09267    0.05944   1.559    0.121    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5148 on 147 degrees of freedom\nMultiple R-squared:  0.6187,\tAdjusted R-squared:  0.6135 \nF-statistic: 119.3 on 2 and 147 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n           versicolor virginica\nsetosa              0         0\nversicolor          1         0\nvirginica           0         1\n```\n\n\n:::\n:::\n\n\n\n\nLet's first map our coefficients and estimates:\n\n| Coefficient | Estimate | Corresponds to |\n|:-:|:-:|:-:|\n| (Intercept)   |  5.84333  | $\\beta_0 = \\frac{\\mu_1 + \\mu_2 + \\mu_3}{3} = \\mu$\n| Species1      | -0.83733  | $\\beta_1 = \\mu_1 - \\mu$|\n| Species2      | 0.09267   | $\\beta_2 = \\mu_2 - \\mu$ |\n\n+ The first estimate corresponding to (Intercept) contains $\\hat \\beta_0 = \\hat \\mu = 5.84$. The estimated average sepal length across iris species was approximately $5.84~cm$.\n\n+ The second estimate corresponds to `Species1` and was $\\hat \\beta_1 = -0.84$. The difference in mean sepal length between `setosa` $(\\hat \\mu_1)$ and the grand mean $(\\hat \\mu_0)$  was estimated to be $0.84~cm$. In other words, the iris species of setosa had a sepal length $0.84~cm$ shorter than average, where its length was estimated to be $5.84333 + (-0.83733) = 5~cm$. This difference in length was statistically significant $(p < .001)$.\n\n+ The third estimate corresponds to `Species2` and was $\\hat \\beta_2 = 0.09$. The difference in mean sepal length between `versicolor` $(\\hat \\mu_2)$ and the grand mean $(\\hat \\mu_0)$  was estimated to be $0.09~cm$. In other words, the iris species of versicolor had a sepal length $0.09~cm$ longer than average, where its length was estimated to be $5.84333 + 0.09267 = 5.94~cm$. This difference in length was not statistically significant $(p = .121)$.\n\n+ The estimate for `Species3`, representing the difference of “virginica” to the grand mean is *not shown* by `summary()`. Because of the side-constraint, we know that $\\mu_3 = \\beta_0 - (\\beta_1 + \\beta_2)$. The difference in sepal length between `virginica` and the grand mean was estimated to be $-(-0.83733 + 0.09267) = 0.74466$. In other words, the virginica iris species had a sepal length $0.74~cm$ longer than average, where its length was estimated to be $5.84333 - (-0.83733  + 0.09267) = 6.59~cm$.  \n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br>   \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-27' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-27', 'opt-start-27')\"> <span class=\"olab\">Specifying Reference Levels</span></span></div><div class=\"optional-body\" id = \"opt-body-27\" style=\"display: none;\">\n\n\n\nWhen you have a categorical variable coded as a factor, `R` will default to using alphabetical ordering - hence in our example above \"cat\" was the reference level (as opposed to \"dog\" or \"parrot\"), and in the other \"setosa\" was the reference level (as opposed to \"versicolor\" or \"virginica\").\n\nWe could override this by making it a factor with an ordering to it’s levels (see the use of `factor()` and `levels()`). Functions like `fct_relevel()` might be handy too. \n\nFor example, let's say we wanted to change the reference level in our \"spec_model\" above, there are a few different ways that we can do this.\n\nFirst we should check the current ordering of the levels:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlevels(iris$Species)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"setosa\"     \"versicolor\" \"virginica\" \n```\n\n\n:::\n:::\n\n\n\n\nWe can then change the reference level to be versicolor (using one of the below methods):\n\n::: {.panel-tabset}\n\n### `fct_relevel()`\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\niris <- iris %>% \n  mutate(\n    Species = fct_relevel(Species, \"versicolor\")\n  )\n```\n:::\n\n\n\n\n\n### `relevel()`\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\niris$Species <- relevel(iris$Species, \"versicolor\")\n```\n:::\n\n\n\n\n### `factor()`\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\niris$Species <- iris$Species %>% \n  factor(., levels = c(\"versicolor\", \"setosa\", \"virginica\"))\n```\n:::\n\n\n\n\n:::\n\nAnd then re-run our model:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#fit model\nspec_model2 <- lm(Sepal.Length ~ Species, data = iris)\nsummary(spec_model2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Sepal.Length ~ Species, data = iris)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.6880 -0.3285 -0.0060  0.3120  1.3120 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(>|t|)    \n(Intercept)        5.9360     0.0728  81.536  < 2e-16 ***\nSpeciessetosa     -0.9300     0.1030  -9.033 8.77e-16 ***\nSpeciesvirginica   0.6520     0.1030   6.333 2.77e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5148 on 147 degrees of freedom\nMultiple R-squared:  0.6187,\tAdjusted R-squared:  0.6135 \nF-statistic: 119.3 on 2 and 147 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n\n## Interaction Models\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-28' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-28', 'opt-start-28')\"> <span class=\"olab\">Specifying Interaction Models</span></span></div><div class=\"optional-body\" id = \"opt-body-28\" style=\"display: none;\">\n\n\n\nInteraction models allow us to model the idea of “the association between $x_1$ and $y$ differs depending on the level of $x_2$” by including a product (multiplication) term between the two predictors.\n\n**Formula:**  \n\n$$\ny = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 (x_1 \\cdot x_2) + \\epsilon\n$$\n\n\nIf we fit the interaction `x1:x2`, we almost always want to also fit the separate effects `x1` and `x2`:\n\n:::quote\n\"Except in special circumstances, a model including a product term for interaction between two explanatory variables should also include terms with each of the explanatory variables individually, even though their coefficients may not be significantly different from zero. Following this rule avoids the logical inconsistency of saying that the effect of $X_1$ depends on the level of $X_2$ but that there is no effect of $X_1$.\"  \n--- @Ramsey2012\n:::\n\n\n:::blue\n\n\nIn **R**\n\nThere are basically two pieces of information that we need to pass to the `lm()` function:\n\n1. The formula: The regression formula should be specified in the form `y ~ x` where $y$ is the dependent variable (DV), $x_1$ the first independent variable (IV1), and $x_2$ the second independent variable (IV2). We then also need to include the interaction term between $x_1$ and $x_2$.\n\n2. The data: Specify which dataframe (`data = `) contains the variables specified in the formula.\n\n+ run interaction model via `lm()` function\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel_name <- lm(DV ~ IV1*IV2, data = data_name)\n```\n:::\n\n\n\n\n**OR**\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel_name <- lm(DV ~ IV1 + IV2 + IV1:IV2, data = data_name)\n```\n:::\n\n\n\n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br>\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-29' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-29', 'opt-start-29')\"> <span class=\"olab\">Interpreting Coefficients</span></span></div><div class=\"optional-body\" id = \"opt-body-29\" style=\"display: none;\">\n\n\n\n::: {.panel-tabset}\n\n#### Interpreting coefficients for A and B in the presence of an interaction A:B\n\nWhen you include an interaction between $x_1$ and $x_2$ in a regression model, you are estimating the extent to which the effect of $x_1$ on $y$ is different across the values of $x_2$.  \n\nWhat this means is that the effect of $x_1$ on $y$ *depends on/is conditional upon* the value of $x_2$ (and vice versa, the effect of $x_2$ on $y$ is different across the values of $x_1$).  \n  \nThis means that we can no longer talk about the \"effect of $x_1$ _holding $x_2$ constant_\". Instead we can talk about a _marginal effect_ of $x_1$ on $y$ at a specific value of $x_2$. \n\n:::frame\nWhen we fit the model $y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 (x_1 \\cdot x_2) + \\epsilon$ using `lm()`:  \n\n- the parameter estimate $\\hat \\beta_1$ is the _marginal effect_ of $x_1$ on $y$ where $x_2 = 0$  \n- the parameter estimate $\\hat \\beta_2$ is the _marginal effect_ of $x_2$ on $y$ where $x_1 = 0$ \nIn other words, when we fit a model with an interaction in R, we get out coefficients for both predictors, and for the interaction. The coefficients for each individual predictor reflect the effect on the outcome when the other predictor is zero.\n\n:::\n\n<div style=\"margin-left: 15px\">\n<small>\n__N.B.__ Regardless of whether or not there is an interaction term in our model, all parameter estimates in multiple regression are \"conditional\" in the sense that they are dependent upon the inclusion of other variables in the model. For instance, in $y = \\beta_0 + \\beta_1 \\cdot x_1 + \\beta_2 \\cdot x_2 + \\epsilon$ the coefficient $\\hat \\beta_1$ is conditional upon holding $x_2$ constant. \n</small>\n</div>\n\n#### Interpreting the interaction term A:B \n\nThe coefficient for an interaction term can be thought of as providing an _adjustment to the slope._   \n\nLet's take the following model as an example:\n\n```\nlm(formula = y ~ x1 * x2, data = df)\n...\n\n...\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)  \n(Intercept)  ...        ....       ...      ...  \nx1           ...        ....       ...      ...  \nx2           ...        ....       ...      ...  \nx1:x2        ...        ....       ...      ...  \n---\n```\n\nThese coefficients can be interpreted, in turn as:  \n\n| Coefficient      | Interpretation |\n| ----------- | ----------- |\n| `(Intercept)` | the estimated $y$ when all predictors ($x_1$ and $x_2$) are zero is [*estimate*] |\n| `x1`  | **when $x_2$ is zero,** a 1 unit increase in $x_1$ is associated with a [*estimate*] change in $y$ |\n| `x2`  | **when $x_1$ is zero,** a 1 unit increase in $x_2$ is associated with a [*estimate*] change in $y$. |\n| `x1:x2`  | as $x_2$ increases by 1, the association between $x_1$ and $y$ changes by [*estimate*]<br>_**or**_<br>as $x_1$ increases by 1, the association between $x_2$ and $y$ changes by [*estimate*] |\n\n:::\n\n::: {.callout-note}\n#### What if there are other things (e.g., other predictors/covatiates) in the model too?\n\nNote that the interaction `x1:x2` changes how we interpret the individual coefficients for `x1` and `x2`.  \n\nIt does __*not*__ change how we interpret coefficients for other predictors that might be in our model. For variables that **aren't** involved in the interaction term, these are still held constant.  \n\nFor example, suppose we _also_ had another predictor $c_1$ in our model: \n\n```\nlm(y ~ c1 + x1 + x2 + x1:x2)\n```\n\n| Coefficient      | Interpretation |\n| ----------- | ----------- |\n| `(Intercept)` | the estimated $y$ when all predictors ($c_1$, $x_1$ and $x_2$) are zero is [*estimate*] |\n| `c1` | a 1 unit increase in $c_1$ is associated with a [*estimate*] increase in $y$, holding constant all other variables in the model ($x_1$ and $x_2$) |\n| `x1`  | holding $c_1$ constant, **when $x_2$ is zero,** a 1 unit increase in $x_1$ is associated with a [*estimate*] change in $y$ |\n| `x2`  | holding $c_1$ constant, **when $x_1$ is zero,** a 1 unit increase in $x_2$ is associated with a [*estimate*] change in $y$. |\n| `x1:x2`  | holding $c_1$ constant, as $x_2$ increases by 1, the association between $x_1$ and $y$ changes by [*estimate*]<br>_**or**_<br>holding $c_1$ constant, as $x_1$ increases by 1, the association between $x_2$ and $y$ changes by [*estimate*] |\n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-30' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-30', 'opt-start-30')\"> <span class=\"olab\">Example Data</span></span></div><div class=\"optional-body\" id = \"opt-body-30\" style=\"display: none;\">\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\nFor the examples in this section , we are going to use the *palmer penguins* dataset^[Horst, A. M., Hill, A. P., & Gorman, K. B. (2020). palmerpenguins: Palmer Archipelago (Antarctica) penguin data. R package version 0.1.0. https://allisonhorst.github.io/palmerpenguins/ doi: 10.5281/zenodo.3960218]. We can have a concise overview of the dataset using `str()` (to see the structure) and `head()` (and to view the first 6 rows):\n\n::: {.panel-tabset}\n\n#### `str()`\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstr(penguins)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntibble [344 × 8] (S3: tbl_df/tbl/data.frame)\n $ species          : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island           : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex              : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year             : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n```\n\n\n:::\n:::\n\n\n\n\n#### `head()`\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhead(penguins)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  <fct>   <fct>              <dbl>         <dbl>             <int>       <int>\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 2 more variables: sex <fct>, year <int>\n```\n\n\n:::\n:::\n\n\n\n\n:::\n\nEach of the three examples has a different research question, but the same process is followed.\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n\n### Numeric x Categorical Example\n\n> **Research Question** \n>\n> Does the association between body mass and flipper length differ between species of penguin?  \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-31' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-31', 'opt-start-31')\"> <span class=\"olab\">Visualise Data</span></span></div><div class=\"optional-body\" id = \"opt-body-31\" style=\"display: none;\">\n\n \n\nSince we have a continuous DV, one continuous IV and one categorical (with 3 levels) IV, one of the most appropriate visualisations would be a scatterplot where we have a separate line of best fit mapped for each level of species:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npenguins %>%\n  ggplot(., aes(x = flipper_length_mm, y = body_mass_g, colour = species)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) + \n  labs(x = \"Flipper Length (in mm)\", y = \"Body Mass (in g)\")\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-66-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\nAlternatively, we could create the same above scatterplot, and then divide into different facets by species:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npenguins %>%\n  ggplot(., aes(x = flipper_length_mm, y = body_mass_g, colour = species)) +\n  geom_point() +\n  facet_wrap(~species) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  labs(x = \"Flipper Length (in mm)\", y = \"Body Mass (in g)\")\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-67-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br>\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-32' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-32', 'opt-start-32')\"> <span class=\"olab\">Model Specification</span></span></div><div class=\"optional-body\" id = \"opt-body-32\" style=\"display: none;\">\n\n\n\nBefore we specify our model, we must select (and provide justification for this choice) the reference group(s) for our categorical variable(s). In this specific example, there is no natural reference category, nor one that maps to our RQ, so we will go with `R`'s default coding and have Adelie as our reference group for species. \n$$\n\\begin{align}\n\\text{Body Mass} ~=~ & \\beta_0 + \\beta_1 \\cdot \\text{Flipper Length} + \\beta_2 \\cdot \\text{Species}_\\text{Chinstrap} + \\beta_3 \\cdot \\text{Species}_\\text{Gentoo} \\\\\n& + \\beta_4 \\cdot (\\text{Flipper Length} \\cdot \\text{Species}_\\text{Chinstrap}) \\\\\n& + \\beta_5 \\cdot (\\text{Flipper Length} \\cdot \\text{Species}_\\text{Gentoo}) + \\epsilon \\\\\n\\end{align}\n\\quad \n$$\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br>\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-33' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-33', 'opt-start-33')\"> <span class=\"olab\">Model Building</span></span></div><div class=\"optional-body\" id = \"opt-body-33\" style=\"display: none;\">\n\n \n\nNo penguins in our dataset had a flipper length of zero mm. We might want to mean centre this predictor variable so that we can consider the difference in body mass between penguin species with average flipper lengths. Before we build our model, we should mean centre this IV:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npenguins <- penguins %>%\n    mutate(\n   mc_flipper_length_mm = scale(flipper_length_mm, scale = FALSE)\n   )\n```\n:::\n\n\n\n\nRecall that the default in `R` is to apply dummy coding, and thus `R` computes the dummy variables for us! Since we are using the default reference group, we can simply run our model (with our newly created mean centered flipper length variable): \n \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmdl_nc <- lm(body_mass_g ~ mc_flipper_length_mm * species, data = penguins)\n```\n:::\n\n\n\n\nEach row in the `summary()` output of the model will correspond to one of the estimated $\\beta$’s in the equation above.  \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(mdl_nc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = body_mass_g ~ mc_flipper_length_mm * species, data = penguins)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-911.18 -251.93  -31.77  197.82 1144.81 \n\nCoefficients:\n                                      Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                           4060.549     59.010  68.811  < 2e-16 ***\nmc_flipper_length_mm                    32.832      4.627   7.095 7.69e-12 ***\nspeciesChinstrap                      -151.424     80.912  -1.871  0.06215 .  \nspeciesGentoo                          126.662    108.104   1.172  0.24216    \nmc_flipper_length_mm:speciesChinstrap    1.742      7.856   0.222  0.82467    \nmc_flipper_length_mm:speciesGentoo      21.791      6.941   3.139  0.00184 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 370.6 on 336 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.7896,\tAdjusted R-squared:  0.7864 \nF-statistic: 252.2 on 5 and 336 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br>\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-34' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-34', 'opt-start-34')\"> <span class=\"olab\">Results Interpretation</span></span></div><div class=\"optional-body\" id = \"opt-body-34\" style=\"display: none;\">\n\n \n\n::: {.panel-tabset}\n\n## `(Intercept)`   \n\n$\\beta_0$ = `(Intercept)` = 4060.55  \n\n+ The intercept, or predicted body mass when flipper length was average and species was Adelie.  \n    - An Adelie penguin with an average flipper length was expected to have a body mass of $4060.55g$.  \n    \n## `mc_flipper_length_mm`   \n\n$\\beta_1$ = `mc_flipper_length_mm` = 32.83  \n\n+ The simple slope of flipper length (in mm) for species reference group (Adelie).   \n    - For an Adelie penguin, every 1 additional mm in flipper length was associated with a significant $32.83g$ increase in their body mass $(p < .001)$.\n    \n## `speciesChinstrap`   \n\n$\\beta_2$ = `speciesChinstrap` = -151.42  \n\n+ The simple effect of species (or the difference in body mass between Adelie and Chinstrap penguins) when flipper length was average.\n    - A Chinstrap penguin with an average flipper length had a body mass $151.42g$ lighter than an Adelie penguin with the same flipper length. Note that this difference was not statistically different from zero $(p = .062)$.\n\n## `speciesGentoo`   \n\n$\\beta_3$ = `speciesGentoo` = 126.66  \n\n+ The simple effect of species (or the difference in body mass between Adelie and Gentoo penguins) when flipper length was average. \n    - A Gentoo penguin with an average flipper length had a body mass $126.66g$ heavier than an Adelie penguin with the same flipper length. Note that this difference was not statistically different from zero $(p = .242)$.  \n\n## `mc_flipper_length_mm:speciesChinstrap`   \n\n$\\beta_4$ = `mc_flipper_length_mm:speciesChinstrap` = 1.74  \n\n+  The interaction between flipper length (in mm; mean centered) and species (levels: Adelie/Chinstrap). This is the estimated difference in simple slopes of flipper length for Adelie vs. Chinstrap penguins.  \n    - In comparison to Adelie penguins, for a Chinstrap penguin every 1 additional mm in flipper length was associated with a $1.74g$ point greater change in their body mass. Note that this adjustment was not statistically different from zero $(p = .825)$.  \n\n## `mc_flipper_length_mm:speciesGentoo`   \n\n$\\beta_5$ = `mc_flipper_length_mm:speciesGentoo` = 21.79  \n\n+  The interaction between flipper length (in mm; mean centered) and species (levels: Adelie/Gentoo). This is the estimated difference in simple slopes of flipper length for Adelie vs. Gentoo penguins.  \n    - In comparison to Adelie penguins, for a Gentoo penguin every 1 additional mm in flipper length was associated with a $21.79g$ greater increase in their body mass. Note that this adjustment was statistically significant $(p = .002)$.  \n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br>\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-35' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-35', 'opt-start-35')\"> <span class=\"olab\">Model Visualisation</span></span></div><div class=\"optional-body\" id = \"opt-body-35\" style=\"display: none;\">\n\n \n\nWe can do this using the `probe_interaction()` function from the **interactions** package.  \n\nIn terms of of specification, it might be useful to look up the helper function (i.e., `?probe_interaction`). As a quick guide:\n\n- `model = `: The name model to be used  \n- `pred = `: The continuous predictor variable that will appear on the x-axis  \n- `modx = `: The categorical moderator variable  \n- `interval = `: If we say `TRUE`, then confidence/prediction intervals will be plotted around the line   \n\nRemember to give your plot informative titles/labels. You, for example, likely want to give your plot:\n\n- a clear and concise title (specify `main.title = `)  \n- axis labels with units or scale included (specify `x.label = ` and `y.label = `)  \n- a legend title (specify `legend.main = `)  \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(interactions)\n\nplt_mdl_nc <- probe_interaction(model = mdl_nc,\n                                pred = mc_flipper_length_mm,\n                                modx = species,\n                                interval = T,\n                                main.title = \"Predicted Body Mass across Flipper Length by Species\",\n                                x.label = \"Flipper Length (in mm; Mean Centered)\",\n                                y.label = \"Body Mass (in g)\",\n                                legend.main = \"Penguin Species\")\nplt_mdl_nc$interactplot\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-71-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n### Numeric x Numeric Example\n\n> **Research Question** \n>\n> Does the influence of bill length on body mass vary depending on flipper length?\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-36' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-36', 'opt-start-36')\"> <span class=\"olab\">Visualise Data</span></span></div><div class=\"optional-body\" id = \"opt-body-36\" style=\"display: none;\">\n\n \n\nUsing `pairs.panels()` is likely the most useful way to visualise the associations among numeric variables. It returns a scatterplot of matrices (SPLOM) returning you (1) the marginal distribution of each variable via a histogram, (2) the correlation between variables, and (3) bivariate scatterplots. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npenguins %>%\n    select(body_mass_g, flipper_length_mm, bill_length_mm) %>%\n    pairs.panels()\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-72-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\nIf you *really* wanted to, you could create a 3D plot showing the associations among all three variables at once. We wouldn't really recommend doing this - they can be very difficult to interpret correctly, and given their interactive nature, definitely NOT something that you'd want to include in a stats report. But, for demonstration purposes only, we could create one using the **plotly** package:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(plotly)\nplot_ly(penguins, x = ~flipper_length_mm, y = ~body_mass_g, z = ~bill_length_mm, type = 'scatter3d', mode = 'markers+lines')\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"plotly html-widget html-fill-item\" id=\"htmlwidget-3178203cca97f77c3c47\" style=\"width:80%;height:480px;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-3178203cca97f77c3c47\">{\"x\":{\"visdat\":{\"2c871087017\":[\"function () \",\"plotlyVisDat\"]},\"cur_data\":\"2c871087017\",\"attrs\":{\"2c871087017\":{\"x\":{},\"y\":{},\"z\":{},\"mode\":\"markers+lines\",\"alpha_stroke\":1,\"sizes\":[10,100],\"spans\":[1,20],\"type\":\"scatter3d\"}},\"layout\":{\"margin\":{\"b\":40,\"l\":60,\"t\":25,\"r\":10},\"scene\":{\"xaxis\":{\"title\":\"flipper_length_mm\"},\"yaxis\":{\"title\":\"body_mass_g\"},\"zaxis\":{\"title\":\"bill_length_mm\"}},\"hovermode\":\"closest\",\"showlegend\":false},\"source\":\"A\",\"config\":{\"modeBarButtonsToAdd\":[\"hoverclosest\",\"hovercompare\"],\"showSendToCloud\":false},\"data\":[{\"x\":[181,186,195,null,193,190,181,195,193,190,186,180,182,191,198,185,195,197,184,194,174,180,189,185,180,187,183,187,172,180,178,178,188,184,195,196,190,180,181,184,182,195,186,196,185,190,182,179,190,191,186,188,190,200,187,191,186,193,181,194,185,195,185,192,184,192,195,188,190,198,190,190,196,197,190,195,191,184,187,195,189,196,187,193,191,194,190,189,189,190,202,205,185,186,187,208,190,196,178,192,192,203,183,190,193,184,199,190,181,197,198,191,193,197,191,196,188,199,189,189,187,198,176,202,186,199,191,195,191,210,190,197,193,199,187,190,191,200,185,193,193,187,188,190,192,185,190,184,195,193,187,201,211,230,210,218,215,210,211,219,209,215,214,216,214,213,210,217,210,221,209,222,218,215,213,215,215,215,216,215,210,220,222,209,207,230,220,220,213,219,208,208,208,225,210,216,222,217,210,225,213,215,210,220,210,225,217,220,208,220,208,224,208,221,214,231,219,230,214,229,220,223,216,221,221,217,216,230,209,220,215,223,212,221,212,224,212,228,218,218,212,230,218,228,212,224,214,226,216,222,203,225,219,228,215,228,216,215,210,219,208,209,216,229,213,230,217,230,217,222,214,null,215,222,212,213,192,196,193,188,197,198,178,197,195,198,193,194,185,201,190,201,197,181,190,195,181,191,187,193,195,197,200,200,191,205,187,201,187,203,195,199,195,210,192,205,210,187,196,196,196,201,190,212,187,198,199,201,193,203,187,197,191,203,202,194,206,189,195,207,202,193,210,198],\"y\":[3750,3800,3250,null,3450,3650,3625,4675,3475,4250,3300,3700,3200,3800,4400,3700,3450,4500,3325,4200,3400,3600,3800,3950,3800,3800,3550,3200,3150,3950,3250,3900,3300,3900,3325,4150,3950,3550,3300,4650,3150,3900,3100,4400,3000,4600,3425,2975,3450,4150,3500,4300,3450,4050,2900,3700,3550,3800,2850,3750,3150,4400,3600,4050,2850,3950,3350,4100,3050,4450,3600,3900,3550,4150,3700,4250,3700,3900,3550,4000,3200,4700,3800,4200,3350,3550,3800,3500,3950,3600,3550,4300,3400,4450,3300,4300,3700,4350,2900,4100,3725,4725,3075,4250,2925,3550,3750,3900,3175,4775,3825,4600,3200,4275,3900,4075,2900,3775,3350,3325,3150,3500,3450,3875,3050,4000,3275,4300,3050,4000,3325,3500,3500,4475,3425,3900,3175,3975,3400,4250,3400,3475,3050,3725,3000,3650,4250,3475,3450,3750,3700,4000,4500,5700,4450,5700,5400,4550,4800,5200,4400,5150,4650,5550,4650,5850,4200,5850,4150,6300,4800,5350,5700,5000,4400,5050,5000,5100,4100,5650,4600,5550,5250,4700,5050,6050,5150,5400,4950,5250,4350,5350,3950,5700,4300,4750,5550,4900,4200,5400,5100,5300,4850,5300,4400,5000,4900,5050,4300,5000,4450,5550,4200,5300,4400,5650,4700,5700,4650,5800,4700,5550,4750,5000,5100,5200,4700,5800,4600,6000,4750,5950,4625,5450,4725,5350,4750,5600,4600,5300,4875,5550,4950,5400,4750,5650,4850,5200,4925,4875,4625,5250,4850,5600,4975,5500,4725,5500,4700,5500,4575,5500,5000,5950,4650,5500,4375,5850,4875,6000,4925,null,4850,5750,5200,5400,3500,3900,3650,3525,3725,3950,3250,3750,4150,3700,3800,3775,3700,4050,3575,4050,3300,3700,3450,4400,3600,3400,2900,3800,3300,4150,3400,3800,3700,4550,3200,4300,3350,4100,3600,3900,3850,4800,2700,4500,3950,3650,3550,3500,3675,4450,3400,4300,3250,3675,3325,3950,3600,4050,3350,3450,3250,4050,3800,3525,3950,3650,3650,4000,3400,3775,4100,3775],\"z\":[39.100000000000001,39.5,40.299999999999997,null,36.700000000000003,39.299999999999997,38.899999999999999,39.200000000000003,34.100000000000001,42,37.799999999999997,37.799999999999997,41.100000000000001,38.600000000000001,34.600000000000001,36.600000000000001,38.700000000000003,42.5,34.399999999999999,46,37.799999999999997,37.700000000000003,35.899999999999999,38.200000000000003,38.799999999999997,35.299999999999997,40.600000000000001,40.5,37.899999999999999,40.5,39.5,37.200000000000003,39.5,40.899999999999999,36.399999999999999,39.200000000000003,38.799999999999997,42.200000000000003,37.600000000000001,39.799999999999997,36.5,40.799999999999997,36,44.100000000000001,37,39.600000000000001,41.100000000000001,37.5,36,42.299999999999997,39.600000000000001,40.100000000000001,35,42,34.5,41.399999999999999,39,40.600000000000001,36.5,37.600000000000001,35.700000000000003,41.299999999999997,37.600000000000001,41.100000000000001,36.399999999999999,41.600000000000001,35.5,41.100000000000001,35.899999999999999,41.799999999999997,33.5,39.700000000000003,39.600000000000001,45.799999999999997,35.5,42.799999999999997,40.899999999999999,37.200000000000003,36.200000000000003,42.100000000000001,34.600000000000001,42.899999999999999,36.700000000000003,35.100000000000001,37.299999999999997,41.299999999999997,36.299999999999997,36.899999999999999,38.299999999999997,38.899999999999999,35.700000000000003,41.100000000000001,34,39.600000000000001,36.200000000000003,40.799999999999997,38.100000000000001,40.299999999999997,33.100000000000001,43.200000000000003,35,41,37.700000000000003,37.799999999999997,37.899999999999999,39.700000000000003,38.600000000000001,38.200000000000003,38.100000000000001,43.200000000000003,38.100000000000001,45.600000000000001,39.700000000000003,42.200000000000003,39.600000000000001,42.700000000000003,38.600000000000001,37.299999999999997,35.700000000000003,41.100000000000001,36.200000000000003,37.700000000000003,40.200000000000003,41.399999999999999,35.200000000000003,40.600000000000001,38.799999999999997,41.5,39,44.100000000000001,38.5,43.100000000000001,36.799999999999997,37.5,38.100000000000001,41.100000000000001,35.600000000000001,40.200000000000003,37,39.700000000000003,40.200000000000003,40.600000000000001,32.100000000000001,40.700000000000003,37.299999999999997,39,39.200000000000003,36.600000000000001,36,37.799999999999997,36,41.5,46.100000000000001,50,48.700000000000003,50,47.600000000000001,46.5,45.399999999999999,46.700000000000003,43.299999999999997,46.799999999999997,40.899999999999999,49,45.5,48.399999999999999,45.799999999999997,49.299999999999997,42,49.200000000000003,46.200000000000003,48.700000000000003,50.200000000000003,45.100000000000001,46.5,46.299999999999997,42.899999999999999,46.100000000000001,44.5,47.799999999999997,48.200000000000003,50,47.299999999999997,42.799999999999997,45.100000000000001,59.600000000000001,49.100000000000001,48.399999999999999,42.600000000000001,44.399999999999999,44,48.700000000000003,42.700000000000003,49.600000000000001,45.299999999999997,49.600000000000001,50.5,43.600000000000001,45.5,50.5,44.899999999999999,45.200000000000003,46.600000000000001,48.5,45.100000000000001,50.100000000000001,46.5,45,43.799999999999997,45.5,43.200000000000003,50.399999999999999,45.299999999999997,46.200000000000003,45.700000000000003,54.299999999999997,45.799999999999997,49.799999999999997,46.200000000000003,49.5,43.5,50.700000000000003,47.700000000000003,46.399999999999999,48.200000000000003,46.5,46.399999999999999,48.600000000000001,47.5,51.100000000000001,45.200000000000003,45.200000000000003,49.100000000000001,52.5,47.399999999999999,50,44.899999999999999,50.799999999999997,43.399999999999999,51.299999999999997,47.5,52.100000000000001,47.5,52.200000000000003,45.5,49.5,44.5,50.799999999999997,49.399999999999999,46.899999999999999,48.399999999999999,51.100000000000001,48.5,55.899999999999999,47.200000000000003,49.100000000000001,47.299999999999997,46.799999999999997,41.700000000000003,53.399999999999999,43.299999999999997,48.100000000000001,50.5,49.799999999999997,43.5,51.5,46.200000000000003,55.100000000000001,44.5,48.799999999999997,47.200000000000003,null,46.799999999999997,50.399999999999999,45.200000000000003,49.899999999999999,46.5,50,51.299999999999997,45.399999999999999,52.700000000000003,45.200000000000003,46.100000000000001,51.299999999999997,46,51.299999999999997,46.600000000000001,51.700000000000003,47,52,45.899999999999999,50.5,50.299999999999997,58,46.399999999999999,49.200000000000003,42.399999999999999,48.5,43.200000000000003,50.600000000000001,46.700000000000003,52,50.5,49.5,46.399999999999999,52.799999999999997,40.899999999999999,54.200000000000003,42.5,51,49.700000000000003,47.5,47.600000000000001,52,46.899999999999999,53.5,49,46.200000000000003,50.899999999999999,45.5,50.899999999999999,50.799999999999997,50.100000000000001,49,51.5,49.799999999999997,48.100000000000001,51.399999999999999,45.700000000000003,50.700000000000003,42.5,52.200000000000003,45.200000000000003,49.299999999999997,50.200000000000003,45.600000000000001,51.899999999999999,46.799999999999997,45.700000000000003,55.799999999999997,43.5,49.600000000000001,50.799999999999997,50.200000000000003],\"mode\":\"markers+lines\",\"type\":\"scatter3d\",\"marker\":{\"color\":\"rgba(31,119,180,1)\",\"line\":{\"color\":\"rgba(31,119,180,1)\"}},\"error_y\":{\"color\":\"rgba(31,119,180,1)\"},\"error_x\":{\"color\":\"rgba(31,119,180,1)\"},\"line\":{\"color\":\"rgba(31,119,180,1)\"},\"frame\":null}],\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.20000000000000001,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br>\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-37' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-37', 'opt-start-37')\"> <span class=\"olab\">Model Specification</span></span></div><div class=\"optional-body\" id = \"opt-body-37\" style=\"display: none;\">\n\n \n\n$$\n\\begin{align}\n\\text{Body Mass} ~=~ & \\beta_0 + \\beta_1 \\cdot \\text{Flipper Length} + \\beta_2 \\cdot \\text{Bill Length} \\\\  \n& + \\beta_3 \\cdot (\\text{Flipper Length} \\cdot \\text{Bill Length}) + \\epsilon\n\\end{align}\n$$ \n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br>\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-38' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-38', 'opt-start-38')\"> <span class=\"olab\">Model Building</span></span></div><div class=\"optional-body\" id = \"opt-body-38\" style=\"display: none;\">\n\n \n\nNo penguins in our dataset had zero mm flipper or bill lengths. We might want to mean centre both of these predictor variables so that we can consider the difference in body mass between penguins with average flipper lengths and average bill lengths. Before we build our model, we should mean centre our two IVs:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npenguins <- penguins %>%\n    mutate(\n   mc_flipper_length_mm = scale(flipper_length_mm, scale = FALSE),\n   mc_bill_length_mm = scale(bill_length_mm, scale = FALSE)\n   )\n```\n:::\n\n\n\n\nWe can then specify our model using these two mean centred IVs: \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmdl_nn <- lm(body_mass_g ~ mc_flipper_length_mm * mc_bill_length_mm, data = penguins)\nsummary(mdl_nn)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = body_mass_g ~ mc_flipper_length_mm * mc_bill_length_mm, \n    data = penguins)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1040.18  -283.07   -23.94   241.93  1241.40 \n\nCoefficients:\n                                        Estimate Std. Error t value Pr(>|t|)\n(Intercept)                            4141.4879    26.4532 156.559  < 2e-16\nmc_flipper_length_mm                     45.3910     2.1082  21.531  < 2e-16\nmc_bill_length_mm                        11.8249     5.3161   2.224 0.026785\nmc_flipper_length_mm:mc_bill_length_mm    1.1998     0.3224   3.721 0.000232\n                                          \n(Intercept)                            ***\nmc_flipper_length_mm                   ***\nmc_bill_length_mm                      *  \nmc_flipper_length_mm:mc_bill_length_mm ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 386.8 on 338 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.7694,\tAdjusted R-squared:  0.7674 \nF-statistic: 375.9 on 3 and 338 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br>\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-39' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-39', 'opt-start-39')\"> <span class=\"olab\">Results Interpretation</span></span></div><div class=\"optional-body\" id = \"opt-body-39\" style=\"display: none;\">\n\n \n\n::: {.panel-tabset}\n\n## `(Intercept)`   \n\n$\\beta_0$ = `(Intercept)` = 4141.49  \n\n+ The intercept, or predicted body mass of penguins for average flipper and bill length.  \n    - A penguin with average flipper and bill length was expected to have a body mass of $4141.49g$.  \n    \n## `mc_flipper_length_mm`   \n\n$\\beta_1$ = `mc_flipper_length_mm` = 45.39  \n\n+ The simple slope of flipper length (in mm) when bill length was average.     \n    - For a penguin with an average bill length, every 1mm increase in flipper length was associated with a significant $(p < .001)$ increase of $45.39g$ in their body mass.\n    \n## `mc_bill_length_mm`   \n\n$\\beta_2$ = `mc_bill_length_mm` = 11.82  \n\n+ The simple slope of bill length (in mm) when flipper length was average.     \n    - For a penguin with an average flipper length, every 1mm increase in bill length was associated with a significant $(p < .05)$ increase in their body mass by $11.82g$. \n\n## `mc_flipper_length_mm:mc_bill_length_mm`   \n\n$\\beta_3$ = `mc_flipper_length_mm:mc_bill_length_mm` = 1.2  \n\n+ The interaction between flipper and bill length on body mass - the change in the slope of flipper length as a function of bill length.    \n    - For every 1mm increase in bill length, when flipper length increased by 1mm, the slope with body mass was adjusted by 1.20 $(\\beta = 1.2,~p < .001)$. \n    \n    \n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br>\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-40' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-40', 'opt-start-40')\"> <span class=\"olab\">Model Visualisation</span></span></div><div class=\"optional-body\" id = \"opt-body-40\" style=\"display: none;\">\n\n\n\nWe can do this using the `probe_interaction()` function from the **interactions** package.  \n\nIn terms of of specification, it might be useful to look up the helper function (i.e., `?probe_interaction`). As a quick guide:\n\n- `model = `: The name model to be used  \n- `pred = `: The continuous predictor variable that will appear on the x-axis  \n- `modx = `: The continuous moderator variable  \n- `interval = `: If we say `TRUE`, then confidence/prediction intervals will be plotted around the line   \n- `jnplot = `: Since we are looking at a numeric x numeric interaction, we want to specify that this is `TRUE`\n\nRemember to give your plot informative titles/labels. You, for example, likely want to give your plot:\n\n- a clear and concise title (specify `main.title = `)  \n- axis labels with units or scale included (specify `x.label = ` and `y.label = `)  \n- a legend title (specify `legend.main = `)  \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(interactions)\n\nplt_mdl_nn <- probe_interaction(model = mdl_nn,\n                                pred = mc_flipper_length_mm,\n                                modx = mc_bill_length_mm,\n                                cond.int = T,\n                                interval = T,\n                                jnplot = T,\n                                main.title = \"Bill Length Moderating the Effect of Flipper Length on Body Mass\",\n                                x.label = \"Flipper Length (in mm; Mean Centered)\",\n                                y.label = \"Body Mass (in g)\",\n                                legend.main = \"Bill Length (in mm; Mean Centered)\")\n```\n:::\n\n\n\n\nFrom the above, we can choose to extract different information/visualisations of simple slopes (this will likely be dependent upon the question(s) you are trying to answer) - the interaction plot, simple slopes analysis only, johnson-neyman plot only, or both simple slopes and johnson-neyman plot: \n\n::: {.panel-tabset}\n\n# Interaction Plot\n\nThe default simple slopes analysis selects $z$-values for us at which to test the slope. The defaults are: the mean of $Z$, and $+1~SD$ and $-1~SD$ from the mean:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplt_mdl_nn$interactplot\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-77-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n# Simple Slopes Only\n\nHere we can look a the significance of each slope:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplt_mdl_nn$simslopes$slopes\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Value of mc_bill_length_mm     Est.     S.E.     2.5%    97.5%   t val.\n1              -5.459584e+00 38.84037 3.185723 32.57403 45.10672 12.19201\n2               1.018029e-15 45.39104 2.108209 41.24417 49.53790 21.53061\n3               5.459584e+00 51.94170 2.222151 47.57071 56.31269 23.37452\n             p\n1 1.379943e-28\n2 2.378006e-65\n3 1.402468e-72\n```\n\n\n:::\n:::\n\n\n\n\n# Johnson-Neyman Plot Only\n\nThe Johnson-Neyman plot allows us to visualise the regions of significance - i.e., it identifies the range of the moderator variable $(Z)$ where the effect of the independent variable $(X)$ on the dependent variable $(Y)$ is statistically significant (e.g., $p < .05$). Outwith these regions, the effect of the independent variable is not significant.\n\nPointers to help with interpretation of the plot:\n\n+ x-axis = Values of moderator variable $(Z)$  \n+ y-axis = The conditional effect (slope) of the independent variable $(X)$ on the dependent variable $(Y)$  \n+ Bold black line (range of observed data) = The actual range of the moderator variable $(Z)$ values within the dataset. This helps with interpretation of results, and more importantly, avoid extrapolation - i.e., should help to ensure that the interpretations of the plot are data-driven and based on the actually observed data  \n+ Zero line = The horizontal line at $y = 0$ indicates the point where the effect of the IV $(X)$ on the DV $(Y)$ is neither positive or negative  \n+ Shaded areas = Regions where the effect is significant (e.g., *outside* the bounds of 95% confidence intervals that include zero) are highlighted in blue. Regions where the effect is non-significant (e.g., crosses the zero line, *inside* the bounds of the 95% confidence intervals that include zero) are highlighted in red  \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplt_mdl_nn$simslopes$jnplot\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-79-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n# Both Simple Slopes & Johnson-Neyman Plot\n\nWhen we return both the simple slopes analysis and Johnson-Neyman plot, we can see that some text is also provided to aid our interpretation of the plot:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplt_mdl_nn$simslopes\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nJOHNSON-NEYMAN INTERVAL\n\nWhen mc_bill_length_mm is OUTSIDE the interval [-83.07, -23.71], the slope\nof mc_flipper_length_mm is p < .05.\n\nNote: The range of observed values of mc_bill_length_mm is [-11.82, 15.68]\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-80-1.png){fig-align='center' width=80%}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSIMPLE SLOPES ANALYSIS\n\nWhen mc_bill_length_mm = -5.459584e+00 (- 1 SD): \n\n                                         Est.    S.E.   t val.      p\n----------------------------------- --------- ------- -------- ------\nSlope of mc_flipper_length_mm           38.84    3.19    12.19   0.00\nConditional intercept                 4076.93   42.62    95.65   0.00\n\nWhen mc_bill_length_mm =  1.018029e-15 (Mean): \n\n                                         Est.    S.E.   t val.      p\n----------------------------------- --------- ------- -------- ------\nSlope of mc_flipper_length_mm           45.39    2.11    21.53   0.00\nConditional intercept                 4141.49   26.45   156.56   0.00\n\nWhen mc_bill_length_mm =  5.459584e+00 (+ 1 SD): \n\n                                         Est.    S.E.   t val.      p\n----------------------------------- --------- ------- -------- ------\nSlope of mc_flipper_length_mm           51.94    2.22    23.37   0.00\nConditional intercept                 4206.05   35.60   118.14   0.00\n```\n\n\n:::\n:::\n\n\n\n\nIn our example, we could say:\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\n**Example Interpretation**\n\nThe association between body mass (in g) and flipper length (in mm; mean centered) was significant when bill length (in mm; mean centered) was more than 83.07mm below the mean or greater than -23.71mm above the mean.\n\n:::\n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n\n### Categorical x Categorical Example\n\n> **Research Question** \n>\n> Do differences in body mass between species differ by sex?\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-41' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-41', 'opt-start-41')\"> <span class=\"olab\">Visualise Data</span></span></div><div class=\"optional-body\" id = \"opt-body-41\" style=\"display: none;\">\n\n \n\nSince we have a continuous DV, and we have two categorical IVs, one of the most appropriate visualisations would be a boxplot:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npenguins %>%\n    drop_na() %>% #we need this here as we have some missing data for this particular example!\n    ggplot(., aes(x = species, y = body_mass_g, fill = sex)) +\n    geom_boxplot() +\n  labs(x = \"Species\", y = \"Body Mass (in g)\")\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-81-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br>\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-42' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-42', 'opt-start-42')\"> <span class=\"olab\">Model Specification</span></span></div><div class=\"optional-body\" id = \"opt-body-42\" style=\"display: none;\">\n\n \n\nBefore we specify our model, we must select (and provide justification for this choice) the reference group(s) for our categorical variable(s). In this specific example, there is no natural reference category, nor one that maps to our RQ, so we will go with `R`'s default coding and have Adelie as our reference group for species, and female for sex.\n\n$$\n\\begin{aligned}\n\\text{Body Mass} &= \\beta_0 + \\beta_1 \\cdot \\text{Species}_\\text{Chinstrap} + \\beta_2 \\text{Species}_\\text{Gentoo} + \\beta_3 \\cdot \\text{Sex}_\\text{Male}  \\\\\n      &+ \\beta_4 \\cdot (\\text{Species}_\\text{Chinstrap} \\cdot \\text{Sex}_\\text{Male}) + \\beta_5 \\cdot (\\text{Species}_\\text{Gentoo} \\cdot \\text{Sex}_\\text{Male}) + \\epsilon\n\\end{aligned}\n$$\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br>\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-43' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-43', 'opt-start-43')\"> <span class=\"olab\">Model Building</span></span></div><div class=\"optional-body\" id = \"opt-body-43\" style=\"display: none;\">\n\n \n\nRecall that the default in `R` is to apply dummy coding, and thus `R` computes the dummy variables for us! Since we are using the default reference group, we can simply run our model.   \n  \nEach row in the `summary()` output of the model will correspond to one of the estimated $\\beta$’s in the equation above.  \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmdl_cc <- lm(body_mass_g ~ species * sex, data = penguins)\nsummary(mdl_cc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = body_mass_g ~ species * sex, data = penguins)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-827.21 -213.97   11.03  206.51  861.03 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(>|t|)    \n(Intercept)               3368.84      36.21  93.030  < 2e-16 ***\nspeciesChinstrap           158.37      64.24   2.465  0.01420 *  \nspeciesGentoo             1310.91      54.42  24.088  < 2e-16 ***\nsexmale                    674.66      51.21  13.174  < 2e-16 ***\nspeciesChinstrap:sexmale  -262.89      90.85  -2.894  0.00406 ** \nspeciesGentoo:sexmale      130.44      76.44   1.706  0.08886 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 309.4 on 327 degrees of freedom\n  (11 observations deleted due to missingness)\nMultiple R-squared:  0.8546,\tAdjusted R-squared:  0.8524 \nF-statistic: 384.3 on 5 and 327 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br>\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-44' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-44', 'opt-start-44')\"> <span class=\"olab\">Results Interpretation</span></span></div><div class=\"optional-body\" id = \"opt-body-44\" style=\"display: none;\">\n\n \n\n::: {.panel-tabset}\n\n## `(Intercept)`   \n\n$\\beta_0$ = `(Intercept)` = 3368.84  \n\n+ The intercept, or predicted body mass of a female Adelie (i.e., when both predictor variables are at their reference levels).  \n    - A female Adelie penguin was expected to have a body mass of $3368.84g$.  \n    \n## `speciesChinstrap`   \n\n$\\beta_1$ = `speciesChinstrap` = 158.37  \n\n+ The difference in body mass between female Adelie and Chinstrap penguins.  \n    - In comparison to female Adelie penguins, Chinstrap penguins of the same sex were significantly $(p < .05)$ heavier by $158.37g$.\n\n## `speciesGentoo`   \n\n$\\beta_2$ = `speciesGentoo` = 1310.91  \n\n+ The difference in body mass between female Adelie and Gentoo penguins.  \n    - In comparison to female Adelie penguins, Gentoo penguins of the same sex were significantly $(p < .001)$ heavier by $1310.91g$.\n\n## `sexmale`   \n\n$\\beta_3$ = `sexmale` = 674.66  \n\n+ The difference in body mass between female and male Adelie penguins.  \n    - In comparison to female Adelie penguins, male Adelie penguins were significantly heavier by $674.66g$  $(p < .001)$.\n\n## `speciesChinstrap:sexmale`  \n\n$\\beta_4$ = `speciesChinstrap:sexmale` = -262.89  \n\n+ The difference in body mass for Adelie and Chinstrap penguins between females and males differed by $-262.89g$. \n    - The difference in body mass between female and male penguins was $262.89g$ less for Chinstrap penguins in comparison to Adele penguins. This difference was statistically significant $p < .05$. \n    - The difference in body mass between female and male penguins was significantly less for the Chinstrap species in comparison to Adelie (where there was an additional $262.89g$ lesser difference between the two sexes).  \n    \n    \n## `speciesGentoo:sexmale`  \n    \n$\\beta_5$ = `speciesGentoo:sexmale` = 130.44  \n\n+ The difference in body mass for Adelie and Gentoo penguins between females and males differed by $130.44g$. \n    - The difference in body mass between female and male penguins was $130.45g$ more for Gentoo penguins in comparison to Adele penguins. This difference was not statistically significant $p = .089$.   \n    - The difference in body mass between female and male penguins was more for the Gentoo species in comparison to Adelie (where there was an additional $130.45g$ greater difference between the two sexes), though this difference was not statistically significant.  \n    \n:::\n\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br>\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-45' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-45', 'opt-start-45')\"> <span class=\"olab\">Model Visualisation</span></span></div><div class=\"optional-body\" id = \"opt-body-45\" style=\"display: none;\">\n\n\n\nWe can do this using the `cat_plot()` function from the **interactions** package.\n\nIn terms of of specification, it might be useful to look up the helper function  (i.e., `?cat_plot`). As a quick guide:\n\n- `model = `: The name model to be used  \n- `pred = `: The categorical predictor variable that will appear on the x-axis  \n- `modx = `: The categorical moderator variable  \n\nRemember to give your plot informative titles/labels. You, for example, likely want to give your plot:\n\n- a clear and concise title (specify `main.title = `)  \n- axis labels with units or scale included (specify `x.label = ` and `y.label = `)  \n- a legend title (specify `legend.main = `)  \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(interactions)\n\nplt_mdl_cc <- cat_plot(model = mdl_cc,\n                                pred = species,\n                                modx = sex,\n                                main.title = \"Body Mass across Species and Sex\",\n                                x.label = \"Species\",\n                                y.label = \"Body Mass (in g)\",\n                                legend.main = \"Sex\")\nplt_mdl_cc\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-83-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-46' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-46', 'opt-start-46')\"> <span class=\"olab\">Coding Constraints</span></span></div><div class=\"optional-body\" id = \"opt-body-46\" style=\"display: none;\">\n\n\n\n\n\n\n\n\n\n\n\nWhen we have categorical predictors, our choice of contrasts coding changes the bits that we're getting our of our model.  \n\nSuppose we have a 2x2 design (condition A and B, in groups 1 and 2):  \n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Categorical x Categorical Interaction plot](1_b4_reading_files/figure-html/fig-sumplot-1.png){#fig-sumplot fig-align='center' width=80%}\n:::\n:::\n\n\n\n\nWhen we are using the default contrasts coding (i.e., treatment or dummy) in `R`, then our coefficients for the individual predictors represent moving between the dots in @fig-sumplot.  \n\n```\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)            1.9098     0.1759  10.855  < 2e-16 ***\nconditionB             1.1841     0.2488   4.759 5.65e-06 ***\ngrouping2             -1.6508     0.2488  -6.635 1.09e-09 ***\nconditionB:grouping2  -2.1627     0.3519  -6.146 1.15e-08 ***\n---\n```\n\n- The intercept is the red circle in @fig-sumplot.  \n- The coefficient for condition is the difference between the red circle and the red triangle in @fig-sumplot.  \n- The coefficient for grouping is the difference between the red circle and the blue circle in @fig-sumplot.  \n- The interaction coefficient is the difference from the slope of the red line to the slope of the blue line.  \n\n\nHowever, when we change to using effects (or sum-to-zero) coding, we're switching where zero is in our model. So if we change to sum contrasts (here we've changed __both__ predictors to using sum-to-zero coding), then we end up estimating the effect of each predictor averaged across the other.  \n\n```\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)           1.13577    0.08796  12.912  < 2e-16 ***\nconditionB            0.05141    0.08796   0.584     0.56    \ngrouping2            -1.36607    0.08796 -15.530  < 2e-16 ***\nconditionB:grouping2 -0.54066    0.08796  -6.146 1.15e-08 ***\n---\n```\n\n- The intercept is the grey X in @fig-sumplot2.  \n- The coefficient for condition is the difference between the grey X and the grey triangle in @fig-sumplot2.  \n- The coefficient for grouping is the difference between the grey X and the blue line in @fig-sumplot2.  \n- The interaction coefficient is the difference from the slope of the grey line to slope of the blue line.  \n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Visualisation of sum-to-zero for categorical x categorical interaction plot](1_b4_reading_files/figure-html/fig-sumplot2-1.png){#fig-sumplot2 fig-align='center' width=80%}\n:::\n:::\n\n\n\n\nIt can get quite confusing when we start switching up the contrasts, but it's all just because we're changing what \"zero\" means, and what \"moving 1\" means:  \n\n::: {.panel-tabset}\n\n#### Dummy/Treatment Coding\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-87-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n#### Effects/Sum-to-Zero Coding\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-88-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-47' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-47', 'opt-start-47')\"> <span class=\"olab\">Simple Effects</span></span></div><div class=\"optional-body\" id = \"opt-body-47\" style=\"display: none;\">\n\n\n\nSimple effects involve examining the effect of one independent variable at a specific level of a second independent variable. This can allow us to better understand the nature of the interaction as we can examine group differences within one level of one of the independent variables. \n\nGoing back to our penguins example, we could ask:\n\n+ Is there an effect of sex for chinstrap penguins? Or in other words, is there a difference in body mass between male and female chinstrap penguins?\n\nTo test simple effects, we can use the **emmeans** package. \n\n:::blue\n\nIn **R**\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#load the emmeans package\nlibrary(emmeans)\n\n#obtain estimates of simple comparisons of cell means\nmdl_cc_emm <- emmeans(mdl_cc, ~species*sex)\n\n#return cell means\nmdl_cc_emm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n species   sex    emmean   SE  df lower.CL upper.CL\n Adelie    female   3369 36.2 327     3298     3440\n Chinstrap female   3527 53.1 327     3423     3632\n Gentoo    female   4680 40.6 327     4600     4760\n Adelie    male     4043 36.2 327     3972     4115\n Chinstrap male     3939 53.1 327     3835     4043\n Gentoo    male     5485 39.6 327     5407     5563\n\nConfidence level used: 0.95 \n```\n\n\n:::\n\n```{.r .cell-code}\n#specify that we want to compare sex for each species\nmdl_cc_simple <- pairs(mdl_cc_emm, simple = \"sex\")\n\n#return comparison \nmdl_cc_simple\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nspecies = Adelie:\n contrast      estimate   SE  df t.ratio p.value\n female - male     -675 51.2 327 -13.174  <.0001\n\nspecies = Chinstrap:\n contrast      estimate   SE  df t.ratio p.value\n female - male     -412 75.0 327  -5.487  <.0001\n\nspecies = Gentoo:\n contrast      estimate   SE  df t.ratio p.value\n female - male     -805 56.7 327 -14.188  <.0001\n```\n\n\n:::\n:::\n\n\n\n\n:::\n\n\nWe can also visualise the interaction using `emmip()`. Here we need to specify the model object, what we want on the x- and y-axis, and whether we want 95% CIs to be displayed.\n\n:::blue\n\nIn **R**\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n## first argument is the model object we need to use to visualise the slopes\n## species is on the x axis\n## separate lines for each level of sex\n## return 95% CIs is set to true (default is false)\n\nemmip(mdl_cc, sex ~ species,\n      CIs = TRUE,\n      ylab = \"Predicted Weight (g)\",\n      xlab = \"Species\")\n```\n\n::: {.cell-output-display}\n![Predicted Penguin Weight by Species and Sex](1_b4_reading_files/figure-html/fig-penguin-simp-1.png){#fig-penguin-simp fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n:::\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\n**Example Interpretation**\n\nA simple effects analysis examined the whether there was a difference in body mass between male and female chinstrap penguins. Males $(M = 3939~g)$ were estimated to be heavier than females $(M = 3527~g)$ with an estimated difference of $412~g$, and this difference was statistically significant $p < .001$. This difference is visually presented in  @fig-penguin-simp. \n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n## General\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-48' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-48', 'opt-start-48')\"> <span class=\"olab\">Extracting Information</span></span></div><div class=\"optional-body\" id = \"opt-body-48\" style=\"display: none;\">\n\n\n\n::: {.panel-tabset}\n\n## Model Call\n\n\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![Multiple regression output in R, model formula highlighted](images/recall_mdl_call.PNG){fig-align='left' width=80%}\n:::\n:::\n\n\n\n\nThe call section at the very top of the `summary()` output shows us the formula that was specified in `R` to fit the regression model.\n\nIn the above, we can see that recall accuracy is our DV, recall confidence and age were our two IVs, and our dataset was named recalldata.\n\n## Residuals\n\n\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![Multiple regression output in R, residuals highlighted](images/recall_mdl_residuals.PNG){fig-align='left' width=80%}\n:::\n:::\n\n\n\n\nResiduals are the difference between the observed values and model predicted values of the DV. \n\nIdeally, for the model to be unbiased, we want our median value to be around 0, as this would show that the errors are random fluctuations around the true line. When this is the case, we know that our model is doing a good job predicting values at the high and low ends of our dataset, and that our residuals were somewhat symmetrical. \n\n## Model Coefficients\n\n\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![Multiple regression output in R, model coefficients highlighted](images/recall_mdl_coefficients.PNG){fig-align='left' width=80%}\n:::\n:::\n\n\n\n\n::: {.panel-tabset}\n\n### Estimates\n\nOur model estimates help us to build our best fitting equation of the line that represents the association between our DV and our IV(s). \n\nIn the above example, we can build our equation for our model from this information:\n\n$$\n\\text{Recall Accuracy}_i = \\beta_0 + \\beta_1 \\cdot \\text{Recall Confidence}_i + \\beta_2 \\cdot \\text{Age}_i + \\epsilon_i\n$$\n$$\n\\widehat{\\text{Recall Accuracy}} = 36.16 + 0.90 \\cdot \\text{Recall Confidence} - 0.34 \\cdot \\text{Age} \n$$\n\n:::blue\n**In R**\n\nThere are numerous equivalent ways to obtain the estimated regression coefficients --- that is, $\\hat \\beta_0$, $\\hat \\beta_1$, ...., $\\hat \\beta_k$ --- from the fitted model (for this below example, our fitted model has been named `mdl`):\n\n- `mdl`\n- `mdl$coefficients`\n- `coef(mdl)`\n- `coefficients(mdl)`\n\n:::\n\n### Std. Error\n\nThe standard error of the coefficient is an estimate of the standard deviation of the coefficient (i.e., how much uncertainty there is in our estimated coefficient).\n\n:::blue\n**In R**\n\nIf you wanted to obtain just the standard error for each estimated regression coefficient, you could do the following (for this below example, our fitted model has been named `mdl`):\n\n- `summary(mdl)$coefficients[,2]` \n\n:::\n\nUsing the standard error, we can create confidence intervals to estimate a plausible range of values for the true population parameter. Recall the formula for obtaining a confidence interval for the population slope is:\n\n$$\n\\hat \\beta_j \\pm t^* \\cdot SE(\\hat \\beta_j)\n$$\nwhere $t^*$ denotes the critical value chosen from t-distribution with $n-k-1$ degrees of freedom (where $k$ = number of predictors and $n$ = sample size) for a desired $\\alpha$ level of confidence. \n\n:::blue\n**In R**\n\nWe can obtain the confidence intervals for the regression coefficients using the command `confint()`\n:::\n\n\n### t value\n\nThe t-statistic is the $\\beta$ coefficient divided by the standard error: \n\n$$\nt = \\frac{\\hat \\beta_j - 0}{SE(\\hat \\beta_j)}\n$$\n\nwhich follows a $t$-distribution with $n-k-1$ degrees of freedom (where $k$ = number of predictors and $n$ = sample size).\n\nWith this, we can test the the null hypothesis $H_0: \\beta_j = 0$. \n\nGenerally speaking, you want your model coefficients to have large $t$-statistics as this would indicate that the standard error was small in comparison to the coefficient. The larger our $t$-statistic, the more confident we can be that the coefficient is not 0. \n\n:::blue\n**In R**\n\nIf you wanted to obtain just the $t$-values for each estimated regression coefficient, you could do the following (for this below example, our fitted model has been named `mdl`):\n\n- `coef(summary(mdl))[, \"t value\"]`\n- `summary(mdl)$coefficients[,3]` \n\n:::\n\n### Pr(>|t|)\n\nFrom our $t$-value, we can compute our $p$-value. The $p$-value help us to understand whether our coefficient(s) are statistically significant (i.e., that the coefficient is statistically different from 0). The $p$-value of each estimate indicates the probability of observing a $t$-value at least as extreme as, or more extreme than, the one calculated from the sample data when assuming the null hypothesis to be true.\n\nIn Psychology, a $p$-value < .05 is usually used to make statements regarding statistical significance (it is important that you always state your $\\alpha$ level to help your reader understand any statements regarding statistical significance).\n\nThe number of asterisks marks corresponds with the significance of the coefficient (see the 'Signif. codes' legend just under the coefficients section). \n\n:::blue\n**In R**\n\nIf you wanted to obtain just the $p$-values for each estimated regression coefficient, you could do the following (for this below example, our fitted model has been named `mdl`):\n\n- `summary(mdl)$coefficients[,4]` \n\n:::\n\n:::\n\n## $\\sigma$\n\n\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![Multiple regression output in R, model standard deviation of the errors highlighted](images/recall_mdl_residerror.PNG){fig-align='left' width=80%}\n:::\n:::\n\n\n\n\nThe standard deviation of the errors, denoted by $\\sigma$, is an important quantity that our model estimates. It represents how much individual data points tend to deviate above and below the regression line - in other words, it tells us how well the model fits the data. \n\nA small $\\sigma$ indicates that the points hug the line closely and we should expect fairly accurate predictions, while a large $\\sigma$ suggests that, even if we estimate the line perfectly, we can expect individual values to deviate from it by substantial amounts.\n\nThe *estimated* standard deviation of the errors is denoted $\\hat \\sigma$, and is estimated by essentially averaging squared residuals (giving the variance) and taking the square-root: \n\n$$\n\\begin{align}\n& \\hat \\sigma = \\sqrt{\\frac{SS_{Residual}}{n - k - 1}} \\\\\n\\qquad \\\\\n& \\text{where} \\\\\n& SS_{Residual} = \\textrm{Sum of Squared Residuals} = \\sum_{i=1}^n{(\\epsilon_i)^2}\n\\end{align}\n$$\n\n:::blue\n**In R**\n\nThere are a couple of equivalent ways to obtain the estimated standard deviation of the errors --- that is, $\\hat \\sigma$ --- from the fitted model (for this example, our fitted model has been named `mdl`):\n\n- `sigma(mdl)`\n- `summary(mdl)`\n\n::: \n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n## Manual Contrasts\n\nDummy and effects coding allow us to  test the significance of the difference between means of groups and some other mean (either reference group or grand mean respectively). However, in some cases, we may want to test more specific hypotheses that require us to test the difference between particular *combinations* of groups. In such cases, we can use manual contrasts.\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-49' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-49', 'opt-start-49')\"> <span class=\"olab\">Rules</span></span></div><div class=\"optional-body\" id = \"opt-body-49\" style=\"display: none;\">\n\n\n\nThere are some rules that we need to follow when using manual contrasts:\n\n+ **Rule 1**: Weights are -1 $\\geq$ x $\\leq$ 1\n+ **Rule 2**: The group(s) in one chunk are given negative weights, the group(s) in the other get positive weights\n+ **Rule 3**: The sum of the weights of the comparison must be 0\n+ **Rule 4**: If a group is not involved in the comparison, weight is 0\n+ **Rule 5**: For a given comparison, weights assigned to group(s) are equal to 1 divided by the number of groups in that chunk.\n+ **Rule 6**: Restrict yourself to running $k$ - 1 comparisons (where $k$ = number of groups)\n+ **Rule 7**: Each contrast can only compare 2 chunks of variance\n+ **Rule 8**: Once a group singled out, it can not enter other contrasts \n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-50' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-50', 'opt-start-50')\"> <span class=\"olab\">In R - Additive Model</span></span></div><div class=\"optional-body\" id = \"opt-body-50\" style=\"display: none;\">\n\n\n\nAfter specifying our hypotheses, to test our contrasts, we can use the **emmeans** package and follow the below structure:\n\n+ **Step 1**: Fit and run the model using `lm()`\n+ **Step 2**: Use the `emmeans()` function to obtain the estimated means of each group. You can visualise these by using `plot()` on the obtained  estimated means of the groups\n+ **Step 3**: Check the order of your levels via `levels()`\n+ **Step 4**: Define the contrast by specifying the weights following the rules outlined above (as well as paying attention to the ordering of the levels)\n+ **Step 5**: Test the pre-specified group contrast(s) via `contrast()` \n+ **Step 6**: Obtain confidence intervals via `confint()`\n\nAfter completing these steps, the last task would be to interpret the results of the contrast analysis in the context of the hypothesis. \n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-51' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-51', 'opt-start-51')\"> <span class=\"olab\">Example - Additive Model</span></span></div><div class=\"optional-body\" id = \"opt-body-51\" style=\"display: none;\">\n\n\n\nSuppose we wanted to address the following question:\n\n> **Research Question** \n>\n> Does the sepal length of an iris grown in Western states (i.e., iris setosa) differ from the sepal length of an Iris grown in Eastern states (i.e., iris versicolor and virginica)?\n\n\nWe could specify our hypothesis as:\n\n$$\n\\begin{aligned}\n    \\quad H_0 &: \\mu_\\text{Western} = \\mu_\\text{Eastern} \\\\\n    \\quad H_0 &: \\mu_\\text{Setosa} = \\frac{1}{2} (\\mu_\\text{Versicolor} + \\mu_\\text{Virginica}) \\\\\n\\\\\n    \\quad H_1 &: \\mu_\\text{Western} \\neq \\mu_\\text{Eastern} \\\\\n    \\quad H_1 &: \\mu_\\text{Setosa} \\neq \\frac{1}{2} (\\mu_\\text{Versicolor} + \\mu_\\text{Virginica}) \\\\\n\\\\ \n\\end{aligned}\n$$\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\nAnd then conduct our manual contrast analysis:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Step 1: Fit and run the model \nspec_model <- lm(Sepal.Length ~ Species, data = iris)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Step 2: Use`emmeans()`& `plot()`\nseplength_mean <- emmeans(spec_model, ~ Species)\nseplength_mean \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Species    emmean     SE  df lower.CL upper.CL\n setosa       5.01 0.0728 147     4.86     5.15\n versicolor   5.94 0.0728 147     5.79     6.08\n virginica    6.59 0.0728 147     6.44     6.73\n\nConfidence level used: 0.95 \n```\n\n\n:::\n\n```{.r .cell-code}\nplot(seplength_mean)\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-93-1.png){fig-align='center' width=80%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Step 3: Check levels order via `levels()`\nlevels(iris$Species)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"setosa\"     \"versicolor\" \"virginica\" \n```\n\n\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Step 4: Define contrast & weights - want to compare Iris setosa to iris versicolor and iris virginica\nseplength_comp <- list(\"Western State Iris - Eastern State Iris\" = c(-1, 1/2, 1/2))\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Step 5: run contrast analysis\nseplength_comp_test <- contrast(seplength_mean, method = seplength_comp)\nseplength_comp_test\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n contrast                                estimate     SE  df t.ratio p.value\n Western State Iris - Eastern State Iris     1.26 0.0892 147  14.086  <.0001\n```\n\n\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Step 6: confidence intervals\nconfint(seplength_comp_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n contrast                                estimate     SE  df lower.CL upper.CL\n Western State Iris - Eastern State Iris     1.26 0.0892 147     1.08     1.43\n\nConfidence level used: 0.95 \n```\n\n\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Bonus Step: Run inferential test and return CIs in one command\nsummary(seplength_comp_test, infer = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n contrast                                estimate     SE  df lower.CL upper.CL\n Western State Iris - Eastern State Iris     1.26 0.0892 147     1.08     1.43\n t.ratio p.value\n  14.086  <.0001\n\nConfidence level used: 0.95 \n```\n\n\n:::\n:::\n\n\n\n\nAnd write up our findings in the context of the hypothesis / research question:\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\n**Example Interpretation**\n\nWe performed a test against $H_0: \\mu_1 - \\frac{1}{2}(\\mu_2 + \\mu_3) = 0$. At the 5\\% significance level, there was evidence that iris sepal length was significantly different between Western and Eastern states in the US $(t(147) = 14.09, p < .001, \\text{two-sided})$, and this difference was estimated to be 1.26cm. We are 95\\% confident that an Iris grown in an Eastern state, on average, would be between 1.08cm and 1.43cm longer than those grown in a Western state $(CI_{95}[1.08, 1.43])$.\n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br>\n \n\n\n<div class=\"optional-begin\"><span id='opt-start-52' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-52', 'opt-start-52')\"> <span class=\"olab\">In R - Interaction Model</span></span></div><div class=\"optional-body\" id = \"opt-body-52\" style=\"display: none;\">\n\n\n\nAfter specifying our hypotheses, to test our contrasts, we can use the **emmeans** package and follow the below structure:\n\n+ **Step 1**: Fit and run the model using `lm()`\n+ **Step 2**: Specify the coefficients to be used in the contrast analysis and present in a table\n+ **Step 3**: Use the `emmeans()` function to obtain the estimated means of each group. You can visualise these by using `plot()` on the obtained  estimated means of the groups\n+ **Step 4**: Define the contrast by specifying the weights following the rules outlined above (as well as paying attention to the ordering of the groups as specified in the output of Step 3)\n+ **Step 5**: Test the pre-specified group contrast(s) via `contrast()` \n+ **Step 6**: Obtain confidence intervals via `confint()`\n\nAfter completing these steps, the last task would be to interpret the results of the contrast analysis in the context of the hypothesis. \n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br>\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-53' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-53', 'opt-start-53')\"> <span class=\"olab\">Example - Interaction Model</span></span></div><div class=\"optional-body\" id = \"opt-body-53\" style=\"display: none;\">\n\n\n\nSuppose we wanted to address the following question:\n\n> **Research Question** \n>\n> Does the difference in body mass between male and female penguins differ between those residing exclusively on the Antarctic Continent (i.e., Adelie) and those living in both Antarctica and the sub-Antarctic islands (i.e., Gentoo and Chinstrap)?  \n\nWe could specify our hypothesis as:\n\n$$\n\\begin{aligned}\n    H_0 &: \\mu_\\text{(Male, Antarctic Continent)} - \\mu_\\text{(Female, Antarctic Continent)} = \\\\\n    &\\mu_\\text{(Male, Northern Antarctica | sub-Antarctic islands)} - \\mu_\\text{(Female, Northern Antarctica | sub-Antarctic islands)} \n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n    H_1 &: \\mu_\\text{(Male, Antarctic Continent)} - \\mu_\\text{(Female, Antarctic Continent)} \\neq \\\\\n    &\\mu_\\text{(Male, Northern Antarctica | sub-Antarctic islands)}) - (\\mu_\\text{(Female, Northern Antarctica | sub-Antarctic islands)})\n\\end{aligned}\n$$\n\nOr equivalently as:\n\n$$\n\\begin{aligned}\nH_0 &: \\mu_\\text{(Male, Adelie)} - \\mu_\\text{(Female, Adelie)} = \\\\\n   & \\frac{1}{2} (\\mu_\\text{(Male, Gentoo)} + \\mu_\\text{(Male, Chinstrap)}) - \\frac{1}{2}(\\mu_\\text{(Female, Gentoo)} + \\mu_\\text{(Female, Chinstrap)}) \\\\\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\nH_1 &: \\mu_\\text{(Male, Adelie)} - \\mu_\\text{(Female, Adelie)} \\neq \\\\\n    &\\frac{1}{2} (\\mu_\\text{(Male, Gentoo)} + \\mu_\\text{(Male, Chinstrap)}) - \\frac{1}{2}(\\mu_\\text{(Female, Gentoo)} + \\mu_\\text{(Female, Chinstrap)}) \\\\\n\\end{aligned}\n$$\n\n\nAnd then conduct our manual contrast analysis:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Step 1: Fit and run the model \nmdl_cc <- lm(body_mass_g ~ species * sex, data = penguins)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Step 2: Specify the coefficients to be used in the contrast analysis, and present in a formatted table\n\n#TWO EQUALLY VALID WAYS TO DO THIS - SELECT ONLY ONE:\n#Option 1:\nspecies_coef  <- c('Adelie' = -1, 'chinstrap' = 0.5, 'Gentoo' = 0.5)\nsex_coef  <- c('male' = -1, 'female' = 1)\ncontr_coef <- outer(species_coef, sex_coef)\ncontr_coef\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          male female\nAdelie     1.0   -1.0\nchinstrap -0.5    0.5\nGentoo    -0.5    0.5\n```\n\n\n:::\n\n```{.r .cell-code}\n#Option 2:\nspecies_coef  <- c('Adelie' = -1, 'chinstrap' = 0.5, 'Gentoo' = 0.5)\nsex_coef  <- c('male' = -1, 'female' = 1)\ncontr_coef_2 <- species_coef %o% sex_coef\ncontr_coef_2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          male female\nAdelie     1.0   -1.0\nchinstrap -0.5    0.5\nGentoo    -0.5    0.5\n```\n\n\n:::\n\n```{.r .cell-code}\n#Convert into a well-formatted table:\ncontr_coef %>% \n    kable(., caption = \"Penguin Contrast Weights\") %>%\n    kable_styling(full_width = FALSE) \n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Penguin Contrast Weights</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">  </th>\n   <th style=\"text-align:right;\"> male </th>\n   <th style=\"text-align:right;\"> female </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Adelie </td>\n   <td style=\"text-align:right;\"> 1.0 </td>\n   <td style=\"text-align:right;\"> -1.0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> chinstrap </td>\n   <td style=\"text-align:right;\"> -0.5 </td>\n   <td style=\"text-align:right;\"> 0.5 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Gentoo </td>\n   <td style=\"text-align:right;\"> -0.5 </td>\n   <td style=\"text-align:right;\"> 0.5 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Step 3: Use`emmeans()`& `plot()`\nspecies_sex_mean <- emmeans(mdl_cc, ~ species*sex)\nspecies_sex_mean\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n species   sex    emmean   SE  df lower.CL upper.CL\n Adelie    female   3369 36.2 327     3298     3440\n Chinstrap female   3527 53.1 327     3423     3632\n Gentoo    female   4680 40.6 327     4600     4760\n Adelie    male     4043 36.2 327     3972     4115\n Chinstrap male     3939 53.1 327     3835     4043\n Gentoo    male     5485 39.6 327     5407     5563\n\nConfidence level used: 0.95 \n```\n\n\n:::\n\n```{.r .cell-code}\nplot(species_sex_mean)\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-101-1.png){fig-align='center' width=80%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Step 4/5: Define contrast & weights, and give a name to this contrast \nspecies_sex_comp <- contrast(species_sex_mean,\n                             method = list('Penguin Hyp' = c(-1, 0.5, 0.5, 1, -0.5, -0.5))\n                     )\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Step 6: examine output and return inferential stats - CIs, t-ratio, p-value\n\n#OPTION 1:\n#examine output\nspecies_sex_comp\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n contrast    estimate   SE  df t.ratio p.value\n Penguin Hyp     66.2 69.5 327   0.952  0.3416\n```\n\n\n:::\n\n```{.r .cell-code}\n#obtain confidence intervals\nconfint(species_sex_comp)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n contrast    estimate   SE  df lower.CL upper.CL\n Penguin Hyp     66.2 69.5 327    -70.6      203\n\nConfidence level used: 0.95 \n```\n\n\n:::\n\n```{.r .cell-code}\n#OPTION 2:\nsummary(species_sex_comp, infer = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n contrast    estimate   SE  df lower.CL upper.CL t.ratio p.value\n Penguin Hyp     66.2 69.5 327    -70.6      203   0.952  0.3416\n\nConfidence level used: 0.95 \n```\n\n\n:::\n:::\n\n\n\n\n\nAnd write up our findings in the context of the hypothesis / research question:\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\n**Example Interpretation**\n\nAt the 5\\% significance level, there was no evidence that the difference in body weight between male and female penguins differed by where the species was based geographically $(t(327) = 0.95, p = .342, \\text{two-sided})$.\n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n## Multiple Comparisons\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-54' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-54', 'opt-start-54')\"> <span class=\"olab\">Pairwise Comparisons</span></span></div><div class=\"optional-body\" id = \"opt-body-54\" style=\"display: none;\">\n\n\n\nWe can use pairwise comparisons when we want to compare *all* levels of an independent variable with *all* the levels of the other. In other words, we can compare all *pairwise* means between groups to determine whether there is a statistical difference between each pair of groups compared. \n\nFor example, let's say that you had 2 categorical variables - `Day` (5 levels: Mon, Tue, Wed, Thurs, and Fri) and `Time` (3 levels: Morning, Afternoon, and Evening) where your outcome variable was `productivity` level (scored on a scale 0-50). If we were to conduct all possible pairwise comparisons, this would lead to the following pairs of groups being compared on productivity:\n\n+ Mon - Morning  \n+ Mon - Afternoon   \n+ Mon - Evening  \n+ Tue - Morning  \n+ Tue - Afternoon   \n+ Tue - Evening  \n+ Wed - Morning  \n+ Wed - Afternoon   \n+ Wed - Evening  \n+ Thurs - Morning  \n+ Thurs - Afternoon   \n+ Thurs - Evening  \n+ Fri - Morning  \n+ Fri - Afternoon   \n+ Fri - Evening  \n\n:::blue\n\nIn **R**\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#run comparisons\npair_comp <- pairs(<INSERT OBJECT NAME>)\n\n#examine output\npair_comp\n\n#plot comparisons\nplot(pair_comp)\n```\n:::\n\n\n\n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br>\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-55' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-55', 'opt-start-55')\"> <span class=\"olab\">Why does the Number of Tests Matter?</span></span></div><div class=\"optional-body\" id = \"opt-body-55\" style=\"display: none;\">\n\n \n\nIf we are conducting all possible pairwise comparisons, we can calculate how many tests are being conducted via the following rule:\n\n$$\n_nC_r = \\frac{n!}{r!(n-r)!} \\\\\n$$\n$$\n\\begin{align} \\\\\n& \\text{Where:} \\\\\n& n = \\text{total number in the set} \\\\\n& r = \\text{number chosen} \\\\\n& _nC_r = \\text{number of combinations of r from n} \\\\\n\\end{align}\n$$\n\nSo, why does the number of tests matter? First, think back to [\"Type 1 errors\" from DAPR1](https://uoepsy.github.io/dapr1/2324/lectures/dapr1_2_05_errorspower.pdf) - when we conduct an hypothesis test, and we set $\\alpha = .05$, we will reject the null hypothesis $H_0$ when we find a $p < .05$. Now remember what a $p$-value represents - it is the chance of observing a statistic at least as extreme as the one we do have, assuming the null hypothesis to be true. This means that *if* $H_0$ **is** true, then we will still observe a $p < .05$ 5\\% of the time. So our chance of making this error = the threshold ($\\alpha$) at which below a $p$-value results in us rejecting $H_0$. \n\nBut this error-rate applies to each statistical hypothesis we test. So if we conduct an experiment in which we plan on conducting lots of tests of different comparisons, the chance of an error being made increases substantially. Across the family of tests performed that chance will be much higher than 5\\%.^[what defines a 'family' of tests is debatable.]\n\nEach test conducted at $\\alpha = .05$ has a .05 (or 5%) probability of Type I error (wrongly rejecting the null hypothesis). If we do 9 tests, that experiment-wise error rate is $\\alpha_{ew} \\leq 9 \\times .05$, where 9 is the number of comparisons made as part of the experiment.\n\nThus, if nine **independent** comparisons were made at the $\\alpha = .05$ level, the experiment-wise Type I error rate $\\alpha_{ew}$ would be at most $9 \\times .05 = 0.45$. That is, we could wrongly reject the null hypothesis on average 45 times out of 100.  \n  \nTo make this more confusing, many of the tests in a family are not **independent** (see the lecture slides for the calculation of error rate for dependent tests).  \n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br>  \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-56' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-56', 'opt-start-56')\"> <span class=\"olab\">When to use Which Correction</span></span></div><div class=\"optional-body\" id = \"opt-body-56\" style=\"display: none;\">\n\n\n\n**Bonferroni**  \n\n- Use Bonferroni’s method when you are interested in a small number of planned contrasts (or pairwise comparisons).\n- Bonferroni's method is to divide alpha by the number of tests/confidence intervals.\n- Assumes that all comparisons are independent of one another.  \n- It sacrifices slightly more power than Tukey’s method (discussed below), but it can be applied to any set of contrasts or linear combinations (i.e., it is useful in more situations than Tukey).\n- It is usually better than Tukey if we want to do a small number of planned comparisons.  \n\n**Šídák**  \n\n- (A bit) more powerful than the Bonferroni method.\n- Assumes that all comparisons are independent of one another. \n- Less common than Bonferroni method, largely because it is more difficult to calculate (not a problem now we have computers).  \n\n**Tukey**\n\n- It specifies an exact family significance level for comparing all pairs of treatment means.  \n- Use Tukey’s method when you are interested in all (or most) pairwise comparisons of means.  \n\n**Scheffe**\n\n- It is the most conservative (least powerful) of all tests.\n- It controls the family alpha level for testing all possible contrasts.\n- It should be used if you have not planned contrasts in advance.\n- For testing pairs of treatment means it is too conservative (you should use Bonferroni or Šídák).\n\n**Others**  \n  \n- In the wider literature, Holm's step-down and Hochberg's step-up mentioned. Do feel free to read about these in your spare time - there are lots of resources online.  \n\n:::blue\n\nIn **R**\n\nYou can easily change which correction you are using via the `adjust = ` argument. For example, using our categorical x categorical interaction model (`mdl_cc`) using the penguins dataset: \n\n::: {.panel-tabset}\n\n### Bonferroni\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nbonf_pair_comp <- pairs(mdl_cc_emm, adjust = \"bonferroni\")\n\nbonf_pair_comp\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n contrast                          estimate   SE  df t.ratio p.value\n Adelie female - Chinstrap female      -158 64.2 327  -2.465  0.2131\n Adelie female - Gentoo female        -1311 54.4 327 -24.088  <.0001\n Adelie female - Adelie male           -675 51.2 327 -13.174  <.0001\n Adelie female - Chinstrap male        -570 64.2 327  -8.875  <.0001\n Adelie female - Gentoo male          -2116 53.7 327 -39.425  <.0001\n Chinstrap female - Gentoo female     -1153 66.8 327 -17.246  <.0001\n Chinstrap female - Adelie male        -516 64.2 327  -8.037  <.0001\n Chinstrap female - Chinstrap male     -412 75.0 327  -5.487  <.0001\n Chinstrap female - Gentoo male       -1958 66.2 327 -29.564  <.0001\n Gentoo female - Adelie male            636 54.4 327  11.691  <.0001\n Gentoo female - Chinstrap male         741 66.8 327  11.085  <.0001\n Gentoo female - Gentoo male           -805 56.7 327 -14.188  <.0001\n Adelie male - Chinstrap male           105 64.2 327   1.627  1.0000\n Adelie male - Gentoo male            -1441 53.7 327 -26.855  <.0001\n Chinstrap male - Gentoo male         -1546 66.2 327 -23.345  <.0001\n\nP value adjustment: bonferroni method for 15 tests \n```\n\n\n:::\n\n```{.r .cell-code}\nplot(bonf_pair_comp)\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-105-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n### Šídák\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsidak_pair_comp <- pairs(mdl_cc_emm, adjust = \"sidak\")\n\nsidak_pair_comp\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n contrast                          estimate   SE  df t.ratio p.value\n Adelie female - Chinstrap female      -158 64.2 327  -2.465  0.1931\n Adelie female - Gentoo female        -1311 54.4 327 -24.088  <.0001\n Adelie female - Adelie male           -675 51.2 327 -13.174  <.0001\n Adelie female - Chinstrap male        -570 64.2 327  -8.875  <.0001\n Adelie female - Gentoo male          -2116 53.7 327 -39.425  <.0001\n Chinstrap female - Gentoo female     -1153 66.8 327 -17.246  <.0001\n Chinstrap female - Adelie male        -516 64.2 327  -8.037  <.0001\n Chinstrap female - Chinstrap male     -412 75.0 327  -5.487  <.0001\n Chinstrap female - Gentoo male       -1958 66.2 327 -29.564  <.0001\n Gentoo female - Adelie male            636 54.4 327  11.691  <.0001\n Gentoo female - Chinstrap male         741 66.8 327  11.085  <.0001\n Gentoo female - Gentoo male           -805 56.7 327 -14.188  <.0001\n Adelie male - Chinstrap male           105 64.2 327   1.627  0.8096\n Adelie male - Gentoo male            -1441 53.7 327 -26.855  <.0001\n Chinstrap male - Gentoo male         -1546 66.2 327 -23.345  <.0001\n\nP value adjustment: sidak method for 15 tests \n```\n\n\n:::\n\n```{.r .cell-code}\nplot(sidak_pair_comp)\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-106-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n### Tukey\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntukey_pair_comp <- pairs(mdl_cc_emm, adjust = \"tukey\")\n\ntukey_pair_comp\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n contrast                          estimate   SE  df t.ratio p.value\n Adelie female - Chinstrap female      -158 64.2 327  -2.465  0.1376\n Adelie female - Gentoo female        -1311 54.4 327 -24.088  <.0001\n Adelie female - Adelie male           -675 51.2 327 -13.174  <.0001\n Adelie female - Chinstrap male        -570 64.2 327  -8.875  <.0001\n Adelie female - Gentoo male          -2116 53.7 327 -39.425  <.0001\n Chinstrap female - Gentoo female     -1153 66.8 327 -17.246  <.0001\n Chinstrap female - Adelie male        -516 64.2 327  -8.037  <.0001\n Chinstrap female - Chinstrap male     -412 75.0 327  -5.487  <.0001\n Chinstrap female - Gentoo male       -1958 66.2 327 -29.564  <.0001\n Gentoo female - Adelie male            636 54.4 327  11.691  <.0001\n Gentoo female - Chinstrap male         741 66.8 327  11.085  <.0001\n Gentoo female - Gentoo male           -805 56.7 327 -14.188  <.0001\n Adelie male - Chinstrap male           105 64.2 327   1.627  0.5812\n Adelie male - Gentoo male            -1441 53.7 327 -26.855  <.0001\n Chinstrap male - Gentoo male         -1546 66.2 327 -23.345  <.0001\n\nP value adjustment: tukey method for comparing a family of 6 estimates \n```\n\n\n:::\n\n```{.r .cell-code}\nplot(tukey_pair_comp)\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-107-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n### Scheffe\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nscheffe_pair_comp <- pairs(mdl_cc_emm, adjust = \"scheffe\")\n\nscheffe_pair_comp\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n contrast                          estimate   SE  df t.ratio p.value\n Adelie female - Chinstrap female      -158 64.2 327  -2.465  0.3014\n Adelie female - Gentoo female        -1311 54.4 327 -24.088  <.0001\n Adelie female - Adelie male           -675 51.2 327 -13.174  <.0001\n Adelie female - Chinstrap male        -570 64.2 327  -8.875  <.0001\n Adelie female - Gentoo male          -2116 53.7 327 -39.425  <.0001\n Chinstrap female - Gentoo female     -1153 66.8 327 -17.246  <.0001\n Chinstrap female - Adelie male        -516 64.2 327  -8.037  <.0001\n Chinstrap female - Chinstrap male     -412 75.0 327  -5.487  <.0001\n Chinstrap female - Gentoo male       -1958 66.2 327 -29.564  <.0001\n Gentoo female - Adelie male            636 54.4 327  11.691  <.0001\n Gentoo female - Chinstrap male         741 66.8 327  11.085  <.0001\n Gentoo female - Gentoo male           -805 56.7 327 -14.188  <.0001\n Adelie male - Chinstrap male           105 64.2 327   1.627  0.7539\n Adelie male - Gentoo male            -1441 53.7 327 -26.855  <.0001\n Chinstrap male - Gentoo male         -1546 66.2 327 -23.345  <.0001\n\nP value adjustment: scheffe method with rank 5 \n```\n\n\n:::\n\n```{.r .cell-code}\nplot(scheffe_pair_comp)\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-108-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n### No Adjustment\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnone_pair_comp <- pairs(mdl_cc_emm, adjust = \"none\")\n\nnone_pair_comp\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n contrast                          estimate   SE  df t.ratio p.value\n Adelie female - Chinstrap female      -158 64.2 327  -2.465  0.0142\n Adelie female - Gentoo female        -1311 54.4 327 -24.088  <.0001\n Adelie female - Adelie male           -675 51.2 327 -13.174  <.0001\n Adelie female - Chinstrap male        -570 64.2 327  -8.875  <.0001\n Adelie female - Gentoo male          -2116 53.7 327 -39.425  <.0001\n Chinstrap female - Gentoo female     -1153 66.8 327 -17.246  <.0001\n Chinstrap female - Adelie male        -516 64.2 327  -8.037  <.0001\n Chinstrap female - Chinstrap male     -412 75.0 327  -5.487  <.0001\n Chinstrap female - Gentoo male       -1958 66.2 327 -29.564  <.0001\n Gentoo female - Adelie male            636 54.4 327  11.691  <.0001\n Gentoo female - Chinstrap male         741 66.8 327  11.085  <.0001\n Gentoo female - Gentoo male           -805 56.7 327 -14.188  <.0001\n Adelie male - Chinstrap male           105 64.2 327   1.627  0.1047\n Adelie male - Gentoo male            -1441 53.7 327 -26.855  <.0001\n Chinstrap male - Gentoo male         -1546 66.2 327 -23.345  <.0001\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(none_pair_comp)\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-109-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n::: \n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n## Logistic Regression \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-57' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-57', 'opt-start-57')\"> <span class=\"olab\">Probability, Odds, Log-Odds</span></span></div><div class=\"optional-body\" id = \"opt-body-57\" style=\"display: none;\">\n\n\n\n-   The **probability** $p$ ranges from 0 to 1.\n\n-   The **odds** $\\frac{p}{1-p}$ ranges from 0 to $\\infty$.\n\n-   The **log-odds** (sometimes called “logits”) $\\ln \\left( \\frac{p}{1-p} \\right)$ ranges from $-\\infty$ to $\\infty$. \n\n::: callout-note\nIn the labs, we sometimes used \"log\" to denote log-odds. In the lectures, and above, you will have seen this denoted as \"ln\". \n:::\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Probability, Odds and Log-odds](images/glm/plo.png){fig-align='center' width=95%}\n:::\n:::\n\n\n\n\n**Conversions**\n\nBetween probabilities, odds and log-odds (\"logit\"):    \n\n$$\n\\begin{align}\n&\\text{for probability p of Y for observation i:}\\\\\n\\qquad \\\\\nodds_i & = \\frac{p_i}{1-p_i} \\\\\n\\qquad \\\\\nlogit_i &= ln(odds_i) = ln(\\frac{p_i}{1-p_i}) \\\\\n\\qquad \\\\\np_i & = \\frac{odds_i}{1 + odds_i} = \\frac{e^{logit_i}}{(1+e^{logit_i})}\n\\end{align}\n$$\n\nIn order to understand the connections among these concepts, lets work with an example where the *probability $(p)$* of an event occurring is 0.2:\n\n-   Odds of event occurring:\n\n$$\n\\text{odds} \\quad = \\quad (\\frac{0.2}{1-0.2}) \\quad = \\quad (\\frac{0.2}{0.8}) \\quad = \\quad 0.25\n$$\n\n-   Log-odds of the event occurring:\n\n$$\n\\text{logit} \\quad = \\quad ln(\\frac{0.2}{1-0.2}) \\quad = \\quad ln(\\frac{0.2}{0.8}) \\quad = \\quad -1.3863\n$$\n\n<center>\n**OR**\n</center>\n\n$$\nln(0.25) \\quad = \\quad -1.3863\n$$\n\n-   Probability can be reconstructed as:\n\n$$\n\\text{p} \\quad = \\quad (\\frac{0.25}{1+0.25}) \\quad = \\quad 0.2 \n$$\n<center>\n**OR**\n</center>\n\n$$\n\\text{p} \\quad = \\quad \\frac{e^{-1.3863}}{1+e^{-1.3863}} \\quad = \\quad \\frac{0.25}{1.25} \\quad = \\quad 0.2\n$$\n\n::: blue\nIn **R**\n\n-   Odds of event occurring:\n\n    `odds <- 0.2 / (1 - 0.2)`\n\n-   Log-odds of the event occurring:\n\n    `log_odds <- log(0.25)`\n    \n     **OR**\n\n    `log_odds <- qlogis(0.2)`\n\n-   obtain the probability from the odds\n\n    `prob_O <- odds / (1 + odds)`\n\n-   obtain the probability from the log-odds\n\n    `prob_LO <- exp(log_odds) / (1 + exp(log_odds))`\n\n     **OR**\n\n    `prob_LO <- plogis(log_odds)`\n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-58' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-58', 'opt-start-58')\"> <span class=\"olab\">Non-Continuous Outcome Variables (DVs)</span></span></div><div class=\"optional-body\" id = \"opt-body-58\" style=\"display: none;\">\n\n\n\nThere are lots of outcome variables that we typically assess within Psychology that are not captured on a continuous scale. For example:\n\n**Binary Variables**\n\n+ Failure vs success\n+ No vs yes\n+ Fail vs pass\n+ Unemployed vs employed\n+ Not depressed vs depressed \n   \nFor binary variables, values can only take one of two values, which we often encode as 0 or 1. Values can’t be 0.5, -2, or 1.3, they can only be 0 or 1.\n\n**Count Variables**\n\n+ Number of times a person experiences a panic attack in a week\n+ Number of passes\n+ Frequency of negative thoughts reported by an individual\n  \nFor count data, values can’t take any real number, they can only take integers (0, 1, 2, 3, …).\n\nNeither type of outcome (i.e., binary or count) is continuous, and therefore a linear regression model is not suitable. If we were to incorrectly fit a linear model to an outcome variable measured on a non-continuous scale, then the model would likely return estimated values that are simply impossible to observe, and we'd likely be violating a few assumptions too (e.g., constant variance).\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br>\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-59' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-59', 'opt-start-59')\"> <span class=\"olab\">Generalized Linear Models</span></span></div><div class=\"optional-body\" id = \"opt-body-59\" style=\"display: none;\">\n\n\n\nThe generalized linear model allows us to be able to talk about linear associations between predictors and the log-odds of an event (or between predictors and log-counts).\n\nIn its general form, the GLM looks pretty similar to the standard LM. We can write it as:  \n\n$$\n\\text{g(}\\text{y)}\\ \\quad = \\quad b_0 + b_1 \\cdot x_1 + ... + b_p \\cdot x_p\n$$\nThe difference is that $\\text{g()}$ is a function (like log, or logit) that links the expected value of $\\text{y}$ to the linear prediction of $b_0 + b_1 \\cdot x_1 + ... + b_p \\cdot x_k$. \n\nIt's important to note that when specifying a generalized linear model, just like with a linear model, the predictors can either be continuous and/or categorical.\n\n:::blue\n**In R**\n\nIn order to fit these models in `R`, we need to use the `glm()` function. This is a generalized form of the `lm()` function we have used elsewhere in the course. The only difference is that we need to also tell the function the `family` of the outcome variable, and the “`link` function”.\n\nThe family argument takes (the name of) a family function which specifies the link function and variance function (as well as a few other arguments not entirely relevant to the purpose of this course).\n\nThe exponential family functions available in **R** are:\n\n-   `binomial` (link = \"logit\")\n-   `gaussian` (link = \"identity\")\n-   `poisson` (link = \"log\")\n-   `Gamma` (link = \"inverse\")\n-   `inverse.gaussian` (link = \"1/mu2\")\n\nSee `?glm` for other modeling options. See `?family` for other allowable link functions for each family.\n\n:::\n\nThere are three key components to consider when selecting the family function to use when fitting GLMs:\n\n-   Random component / probability distribution - The distribution of the response/outcome variable. Can be from any family of distributions as listed above\n-   Systematic component / linear predictor - the explanatory/predictor variable(s) \n-   Link function - specifies the link between a random and systematic components  \n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br>\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-60' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-60', 'opt-start-60')\"> <span class=\"olab\">Binary Logistic Regression</span></span></div><div class=\"optional-body\" id = \"opt-body-60\" style=\"display: none;\">\n\n\n\nWhen a response $(y)$ is binary coded (i.e., 0/1) we must use logistic regression.\n\nOutcome $y$ is binary, $y \\in [0,1]$  \n\n$$\n\\begin{align}\n{ln \\left( \\frac{p}{1-p} \\right) } &= b_0 + b_1 \\cdot x_1 + ... + b_p \\cdot x_p \\\\\n\\qquad \\\\\n\\text{where } {p} &= \\text{probability of event }y\\\\\n\\end{align}\n$$\n\n:::blue\n**In R**\n\nThe outcome (in our example below, `binary_y`) can either be 0s and 1s, or coded as a factor with 2 levels.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nglm(binary_y ~ x1 + x2, data = df, family = binomial(link=\"logit\"))\n```\n:::\n\n\n\n\n**OR**\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nglm(binary_y ~ x1 + x2, data = df, family = binomial)\n```\n:::\n\n\n\n\nAs just putting `family = binomial`  will also work (as it will by default use the “logit” link)\n\n:::\n\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br>\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-61' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-61', 'opt-start-61')\"> <span class=\"olab\">Interpretation of Coefficients</span></span></div><div class=\"optional-body\" id = \"opt-body-61\" style=\"display: none;\">\n\n\n\n::: {.panel-tabset}\n\n### Interpretation Steps\n\nTo interpret the fitted coefficients, we first exponentiate the model:\n$$\n\\begin{aligned}\n\\log \\left( \\frac{p_x}{1-p_x} \\right) &= \\beta_0 + \\beta_1 x \\\\\ne^{ \\log \\left( \\frac{p_x}{1-p_x} \\right) } &= e^{\\beta_0 + \\beta_1 x } \\\\\n\\frac{p_x}{1-p_x} &= e^{\\beta_0} \\ e^{\\beta_1 x}\n\\end{aligned}\n$$\n\nand recall that the probability of success divided by the probability of failure is the odds of success\n\n$$\n\\frac{p_x}{1-p_x} = \\text{odds}\n$$\n\n\nWhen we exponentiate coefficients from a model fitted to the log-odds, the resulting association is referred to as an “odds ratio” $(OR)$. There are various ways of describing odds ratios:\n\n- \"for a 1 unit increase in $x$ the odds of $y$ change by _a ratio_ of `exp(b)`\"   \n- \"for a 1 unit increase in $x$ the odds of $y$ are multiplied by `exp(b)`\"  \n- \"for a 1 unit increase in $x$ there are `exp(b)` increased/decreased odds of $y$\"  \n\nInstead of thinking of a coefficient of 0 as indicating \"no association\", in odds ratios this when the $OR = 1$. \n\n- __OR = 1__ : equal odds ($1 \\times odds = odds \\text{ don't change}$)   \n- __OR < 1__ : decreased odds ($0.5 \\times odds = odds \\text{ are halved}$)  \n- __OR > 1__ : increased odds ($2 \\times odds = odds \\text{ are doubled}$)  \n\n\n::: blue\n**In R**\n\nTo translate log-odds to odds in order to aid interpretation, we can exponentiate (i.e., by using `exp()`) the coefficients from a model using `R` via the following command:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nexp(coef(wais_mdl))\n```\n:::\n\n\n\n\nWe can also use `R` to extract predicted probabilities from our models.\n\n-   Calculate the predicted log-odds (probabilities on the logit scale): `predict(model, type=\"link\")`\n-   Calculate the predicted probabilities: `predict(model, type=\"response\")`\n:::\n\n### Common Interpretation Mistakes\n\n**OR are not \"exp(b) times more likely\"** \n\nOften you will hear people interpreting odds ratios as \"$y$ is `exp(b)` times as likely\". Although it is true that increased odds is an increased likelihood of $y$ occurring, double the odds does not mean you will see _twice_ as many occurrences of $y$ - i.e. it does not translate to doubling the probability.  \n\nHere's a little more step-by-step explanation to explain:  \n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"kfhgqjpzqw\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#kfhgqjpzqw table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#kfhgqjpzqw thead, #kfhgqjpzqw tbody, #kfhgqjpzqw tfoot, #kfhgqjpzqw tr, #kfhgqjpzqw td, #kfhgqjpzqw th {\n  border-style: none;\n}\n\n#kfhgqjpzqw p {\n  margin: 0;\n  padding: 0;\n}\n\n#kfhgqjpzqw .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#kfhgqjpzqw .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#kfhgqjpzqw .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#kfhgqjpzqw .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#kfhgqjpzqw .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#kfhgqjpzqw .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#kfhgqjpzqw .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#kfhgqjpzqw .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#kfhgqjpzqw .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#kfhgqjpzqw .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#kfhgqjpzqw .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#kfhgqjpzqw .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#kfhgqjpzqw .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#kfhgqjpzqw .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#kfhgqjpzqw .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#kfhgqjpzqw .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#kfhgqjpzqw .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#kfhgqjpzqw .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#kfhgqjpzqw .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#kfhgqjpzqw .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#kfhgqjpzqw .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#kfhgqjpzqw .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#kfhgqjpzqw .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#kfhgqjpzqw .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#kfhgqjpzqw .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#kfhgqjpzqw .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#kfhgqjpzqw .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#kfhgqjpzqw .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#kfhgqjpzqw .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#kfhgqjpzqw .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#kfhgqjpzqw .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#kfhgqjpzqw .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#kfhgqjpzqw .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#kfhgqjpzqw .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#kfhgqjpzqw .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#kfhgqjpzqw .gt_left {\n  text-align: left;\n}\n\n#kfhgqjpzqw .gt_center {\n  text-align: center;\n}\n\n#kfhgqjpzqw .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#kfhgqjpzqw .gt_font_normal {\n  font-weight: normal;\n}\n\n#kfhgqjpzqw .gt_font_bold {\n  font-weight: bold;\n}\n\n#kfhgqjpzqw .gt_font_italic {\n  font-style: italic;\n}\n\n#kfhgqjpzqw .gt_super {\n  font-size: 65%;\n}\n\n#kfhgqjpzqw .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#kfhgqjpzqw .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#kfhgqjpzqw .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#kfhgqjpzqw .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#kfhgqjpzqw .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#kfhgqjpzqw .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#kfhgqjpzqw .gt_indent_5 {\n  text-indent: 25px;\n}\n\n#kfhgqjpzqw .katex-display {\n  display: inline-flex !important;\n  margin-bottom: 0.75em !important;\n}\n\n#kfhgqjpzqw div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {\n  height: 0px !important;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"coefficient\">coefficient</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"b\">b</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"exp(b)\">exp(b)</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"coefficient\" class=\"gt_row gt_left\">(Intercept)</td>\n<td headers=\"b\" class=\"gt_row gt_right\">3.76</td>\n<td headers=\"exp(b)\" class=\"gt_row gt_right\">43.13</td></tr>\n    <tr><td headers=\"coefficient\" class=\"gt_row gt_left\">age</td>\n<td headers=\"b\" class=\"gt_row gt_right\">-0.62</td>\n<td headers=\"exp(b)\" class=\"gt_row gt_right\">0.54</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n\n:::\n:::\n\n\n\n\n1. For children aged 2 years old the log-odds of them taking the marshmallow are 3.76 + -0.62*2 = 2.52.  \n2. Translating this to odds, we exponentiate it, so the odds of them taking the marshmallow are $e^{(3.76 + -0.62*2)} = e^{2.52} = 12.43$.   \n(This is the same^[$e^{a+b} = e^a \\times e^b$. For example: $2^2 \\times 2^3 = 4 \\times 8 = 32 = 2^5 = 2^{2+3}$] as $e^{3.76} \\times e^{-0.62*2}$)   \n3. These odds of 12.43 means that (rounded to nearest whole number) if we take 13 children aged 2 years, we would expect 12 of them to take the marshmallow, and 1 to not take it.  \n4. If we consider how the odds change for every extra year of age (i.e. for 3 year old as opposed to 2 year old children):\n    - the log-odds of taking the marshmallow decrease by -0.62.  \n    - the odds of taking the marshmallow are multiplied by 0.54.  \n    - so for a 3 year old child, the odds are $12.43 \\times 0.54 = 6.69$.  \n    (And we can also calculate this as $e^{2.52 + -0.62}$)  \n5. So we have gone from odds of 12.4-to-1 for 2 year olds, and 6.7-to-1 for 3 year olds. The odds have been multiplied by 0.54.    \nBut those odds, when converted to probability, these are 0.93 and 0.87. So $0.54 \\times odds$ is not $0.54 \\times probability$.  \n\n\n### Converting to Probability\n\n**The intercept (but not slopes) can be converted to a probability**\n\nBecause our intercept is at a single point (it's not an _association_), we can actually convert this to a probability. Remember that $odds = \\frac{p}{1-p}$, which means that $p = \\frac{odds}{1 + odds}$. So the probability of taking the marshmallow for a child aged zero is $\\frac{43.13}{1 + 43.13} = 0.98$.  \n\n\nUnfortunately, we can't do the same for any slope coefficients. This is because while the intercept is \"odds\", the slopes are \"odds ratios\" (i.e. changes in odds), and changes in odds are different at different levels of probability.  \n\nConsider how when we multiply odds by 2, the increase in probability is not constant:  \n\n| Odds     | Probability |\n| ----------- | ----------- |\n| 0.5   | $\\frac{1}{1+0.5} = 0.33$  |\n| 1   | $\\frac{1}{1+1} = 0.5$  |\n| 2   | $\\frac{2}{1+2} = 0.66$  |\n| 4   | $\\frac{4}{1+4} = 0.8$  |\n| 8   | $\\frac{8}{1+8} = 0.88$  |\n\n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-62' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-62', 'opt-start-62')\"> <span class=\"olab\">Binary Logistic Regression - Example</span></span></div><div class=\"optional-body\" id = \"opt-body-62\" style=\"display: none;\">\n\n\n\nImagine that we are trying to determine whether the probability of having senility symptoms (0 = not present; 1 = present) changes as a function of Wechsler Adult Intelligence Scale (WAIS) score, where we fit the following model:\n\n$$\n\\begin{aligned}\n\\text{Senility}: \\qquad \\log \\left( \\frac{p}{1 - p}\\right) = \\beta_0 + \\beta_1 \\cdot \\text{WAIS Score} + \\epsilon\n\\end{aligned}\n$$\n\n__Intercept__\n\n$$\n\\text{If }x = 0, \\qquad \\frac{p_0}{1-p_0} = e^{\\beta_0} \\ e^{\\beta_1 x} = e^{\\beta_0}\n$$\n\nThat is, $e^{\\beta_0}$ represents the odds of having symptoms of senility for individuals with a WAIS score of 0. \n\nIn other words, for those with a WAIS score of 0, the probability of having senility symptoms is $e^{\\beta_0}$ times that of non having them.\n\n__Slope__\n\n$$\n\\text{If}~~x = 1, \\quad \\frac{p_1}{1-p_1} \\quad = \\quad e^{\\beta_0} \\ e^{\\beta_1 x} \\quad = \\quad e^{\\beta_0} \\ e^{\\beta_1}\n$$\n\nNow consider taking the ratio of the odds of senility symptoms when $x=1$ to the odds of senility symptoms when $x = 0$:\n\n$$\n\\frac{\\text{odds}_{x=1}}{\\text{odds}_{x=0}} = \\frac{p_1 / (1 - p_1)}{p_0 / (1 - p_0)} \n= \\frac{e^{\\beta_0} \\ e^{\\beta_1}}{e^{\\beta_0}}\n= e^{\\beta_1}\n$$\n\nSo, $e^{\\beta_1}$  represents the odds ratio for a 1 unit increase in WAIS score. We could interpret this by saying that for a one-unit increase in WAIS score, the odds of senility symptoms changed by a ratio of $e^{\\beta_1}$.\n\n:::blue\n\n**In R**\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#build glm model\nsen_mdl1 <- glm(senility ~ wais, family = \"binomial\", data = sendata)\n\n#examine summary\nsummary(sen_mdl1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = senility ~ wais, family = \"binomial\", data = sendata)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)   \n(Intercept)   2.4040     1.1918   2.017  0.04369 * \nwais         -0.3235     0.1140  -2.838  0.00453 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 61.806  on 53  degrees of freedom\nResidual deviance: 51.017  on 52  degrees of freedom\nAIC: 55.017\n\nNumber of Fisher Scoring iterations: 5\n```\n\n\n:::\n\n```{.r .cell-code}\n#convert to odds ratio\nexp(coef(sen_mdl1))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept)        wais \n   11.06784     0.72359 \n```\n\n\n:::\n\n```{.r .cell-code}\n#get confidence intervals\nexp(confint(sen_mdl1))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                2.5 %      97.5 %\n(Intercept) 1.2309116 145.2386561\nwais        0.5618693   0.8860248\n```\n\n\n:::\n:::\n\n\n\n\n:::\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n**Example Interpretation**\n\nFor an individual with a WAIS score of 0, the probability of having senility symptoms was 92%. \n\nWAIS scores were a significant predictor of whether or not individuals experienced senility symptoms, where for every additional point scored on the WAIS, the odds of having senility symptoms decreased by a factor of $\\text{0.72 }(CI_\\text{95 }\\text{[0.56,0.89]})$.\n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n## General\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-63' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-63', 'opt-start-63')\"> <span class=\"olab\">Comparing lm() and glm() summary output</span></span></div><div class=\"optional-body\" id = \"opt-body-63\" style=\"display: none;\">\n\n\n\n:::{.panel-tabset}\n\n#### `lm()` summary, annotated\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![lm summary, annotated (you may want to open the image in a new tab to zoom in)](images/lmsummary.png){#fig-summarylman fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n#### `glm()` summary, annotated\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![glm summary, annotated (you may want to open the image in a new tab to zoom in)](images/glmsummary.png){#fig-summaryglman fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n\n::: \n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Model Predicted Values & Residuals\n\nModel predicted values are the estimates generated by a regression model for the dependent variable based on the independent variable(s), whilst residuals are the differences between these predicted values and the actual observed values (in turn indicating the accuracy of the model's predictions).\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-64' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-64', 'opt-start-64')\"> <span class=\"olab\">Predicted Values</span></span></div><div class=\"optional-body\" id = \"opt-body-64\" style=\"display: none;\">\n\n\n\n### Model predicted values ($\\hat y_i$) for sample data\n\nWe can get out the model predicted values for $y$, the \"y hats\" ($\\hat y$), for the data in the sample using various functions:\n\n- `predict(<fitted model>)`\n- `fitted(<fitted model>)`\n- `fitted.values(<fitted model>)`\n- `mdl$fitted.values`\n\nFor example, this will give us the estimated recall accuracy (point on our regression line) for each observed value of age for each of our 20 participants.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npredict(recall_simp)\n```\n:::\n\n\n\n\nFor space saving purposes (i.e., we don't need to see all 20 values for this demonstration!), we can return the first six predicted values via `head()`:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhead(predict(recall_simp))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       1        2        3        4        5        6 \n62.23045 73.42542 69.49205 68.28179 70.09719 71.61002 \n```\n\n\n:::\n:::\n\n\n\n\n### Model predicted values for other (unobserved) data\n\nTo compute the model-predicted values for unobserved data (i.e., data not contained in the sample), we can use the following function:\n\n- `predict(<fitted model>, newdata = <dataframe>)`\n\nFor this example, we first need to remember that the model predicts `recall_accuracy` using the independent variable `age`. Hence, if we want predictions for new (unobserved) data, we first need to create a tibble with a column called `age` containing the age of individuals for which we want the prediction, and store this as a dataframe.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#Create dataframe 'newdata' containing the age values of 19, 32, and 99\nnewdata <- tibble(age = c(19,32,99))\nnewdata\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 1\n    age\n  <dbl>\n1    19\n2    32\n3    99\n```\n\n\n:::\n:::\n\n\n\n\nThen we take `newdata` and add a new column called `accuracy_hat`, computed as the prediction from the fitted `recall_simp` using the `newdata` above:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnewdata <- newdata %>%\n  mutate(\n    accuracy_hat = predict(recall_simp, newdata = newdata)\n  )\nnewdata\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 2\n    age accuracy_hat\n  <dbl>        <dbl>\n1    19         78.3\n2    32         74.3\n3    99         54.1\n```\n\n\n:::\n:::\n\n\n\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br>  \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-65' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-65', 'opt-start-65')\"> <span class=\"olab\">Residuals</span></span></div><div class=\"optional-body\" id = \"opt-body-65\" style=\"display: none;\">\n\n\n\nThe residuals ($\\hat \\epsilon_i$) represent the deviations between the actual responses and the predicted responses and can be obtained either as\n\n- `mdl$residuals`\n- `resid(mdl)`\n- `residuals(mdl)`\n- computing them as the difference between the response ($y_i$) and the predicted response ($\\hat y_i$)\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-66' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-66', 'opt-start-66')\"> <span class=\"olab\">Predicted Values - Example</span></span></div><div class=\"optional-body\" id = \"opt-body-66\" style=\"display: none;\">\n\n\n\nLets estimate (or predict) recall accuracy of two individuals with the following ages (a) 18, and (b) 118. There are a few ways we can do this, but first, let's recall our fitted model:\n\n$$\n\\widehat{Recall~Accuracy} = 84.02 - 0.31 \\cdot \\text{Age}\n$$\n\n\nFrom here we can:\n\n::: {.panel-tabset}\n\n## Substitute in Values\n\n- The predicted average recall accuracy for individuals who are aged 18 is:\n<br />\n$84.02 - (0.31 * 18) = 78.44$\n<br />\n<br />\n- The predicted average recall accuracy for individuals who are aged 118 is:\n<br />\n$84.02 - (0.31 * 118) = 47.44$\n\n## Use the `predict()` Function\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnewdata <- tibble(age = c(18, 118))\n\naccuracy_hat <- predict(recall_simp, newdata = newdata)\naccuracy_hat\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       1        2 \n78.56906 48.31237 \n```\n\n\n:::\n:::\n\n\n\n\n:::\n\nWe can see that both approaches (manually substituting values into the regression equation or using the `predict()` function) both give us the same values (slightly different due to rounding). \n\nBut, be careful to not go too far off the range of the available data (I don't know many 118 year olds, do you?). If you do, you will extrapolate. This is very dangerous...\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Source: Randall Munroe, xkcd.com](https://imgs.xkcd.com/comics/extrapolating.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Statistical Power & Effect Size\n\nStatistical power and effect size are key in designing and interpreting studies. Statistical power refers to the likelihood that a study will detect an effect when there is one present; whilst effect size measures the strength of an association or magnitude of a difference. Together, they allow researchers to draw meaningful conclusions about the statistical and practical significance of their research.\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-67' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-67', 'opt-start-67')\"> <span class=\"olab\">Errors and Power in Hypothesis Testing</span></span></div><div class=\"optional-body\" id = \"opt-body-67\" style=\"display: none;\">\n\n\n\nWhen testing a hypothesis, we reach one of the following two decisions:\n\n- failing to reject $H_0$ as the evidence against it is not sufficient  \n- rejecting $H_0$ as we have enough evidence against it  \n\nHowever, irrespective of our decision, the underlying truth can either be that\n\n- $H_0$ is actually false  \n- $H_0$ is actually true  \n\nHence, we have four possible outcomes following a hypothesis test:\n\n1. We failed to reject $H_0$ when it was true, meaning we made a __Correct__ decision  \n1. We rejected $H_0$ when it was false, meaning we made a __Correct__ decision  \n1. We rejected $H_0$ when it was true, committing a __Type I error__   \n1. We failed to reject $H_0$ when it was false, committing a __Type II error__   \n\nIn the first two cases we are correct, while in the latter two we committed an error.\n\nWhen we reject the null hypothesis, we never know if we were correct or committed a Type I error, however we can control the chance of us committing a Type I error.  \n\nSimilarly, when we fail to reject the null hypothesis, we never know if we are correct or we committed a Type II error, but we can also control the chance of us committing a Type II error.  \n\nThe following table summarises the two types of errors that we can commit:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/ht-errors-table-2.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\nA Type I error corresponds to a false discovery, while a type II error corresponds to a failed discovery/missed opportunity.  \n\nEach error has a corresponding probability:  \n\n- The probability of incorrectly rejecting a true null hypothesis is $\\alpha = P(\\text{Type I error})$  \n- The probability of incorrectly not rejecting a false null hypothesis is $\\beta = P(\\text{Type II error})$  \n\nA related quantity is __Power__, which is defined as the probability of correctly rejecting a false null hypothesis.\n\n:::yellow\n__Power__\n\nPower is the probability of rejecting a false null hypothesis. That is, it is the probability that we will find an effect when it is in fact present.\n$$\n\\text{Power} = 1 - P(\\text{Type II error}) = 1 - \\beta\n$$\n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-68' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-68', 'opt-start-68')\"> <span class=\"olab\">Factors Affecting Power</span></span></div><div class=\"optional-body\" id = \"opt-body-68\" style=\"display: none;\">\n\n\n\nIn practice, it is ideal for studies to have high power while using a relatively small significance level such as .05 or .01. For a fixed $\\alpha$, the power increases in the same cases that $P(Type II error)$ decreases, namely as the sample size increases and as the parameter value moves farther into the $H_1$ values away from the $H_0$ value.\n\nThe __power__ of a test is affected by the following factors:\n\n- __sample size.__ Power increases as the sample size increases.\n- __effect size.__ Power increases as the parameter value moves farther into the $H_1$ values away from the $H_0$ value.\n- __significance level.__ Power increases as the significance level increases.\n\nOut of these, increasing the significance level $\\alpha$ is never an acceptable way to increase power as it leads to more Type I errors, i.e. a higher chance of incorrectly rejecting a true null hypothesis (false discoveries).   \n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-69' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-69', 'opt-start-69')\"> <span class=\"olab\">Effect Size</span></span></div><div class=\"optional-body\" id = \"opt-body-69\" style=\"display: none;\">\n\n\n\nEffect size refers to the \"detectability\" of your alternative hypothesis. In simple terms, it compares the distance between the alternative and the null hypothesis to the variability in your data.\n\nFor simplicity consider comparing a mean: $H_0: \\mu = 0$ vs $H_1: \\mu \\neq 0$. If the sample mean were really 0.1 and the null hypothesis is 0, the distance is 0.1 - 0 = 0.1.\n\nNow, a distance of 0.1 has a different weight in the following two scenarios.\n\n__Scenario 1.__ Data vary between -1 and 1.\n\n__Scenario 2.__ Data vary between -1000 and 1000.\n\nClearly, in Scenario 1 a distance of of 0.1 is a big difference.\nConversely, in Scenario 2 a distance of 0.1 is not an interesting difference, it's negligible compared to the magnitude of the data.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-124-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br>\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-70' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-70', 'opt-start-70')\"> <span class=\"olab\">The pwr Package</span></span></div><div class=\"optional-body\" id = \"opt-body-70\" style=\"display: none;\">\n\n\n\nThere are lots of different ways to conduct basic power calculations, but one of the most common (and straightforward!) packages available to use is the **pwr** package.\n\nThe following functions are available:\n\nFunction | Description \n:--------|:------------\n `pwr.2p.test    ` | Two proportions (equal n)\n `pwr.2p2n.test  ` | Two proportions (unequal n)\n `pwr.anova.test ` | Balanced one-way ANOVA\n `pwr.chisq.test ` | Chi-square test\n `pwr.f2.test    ` | General linear model\n `pwr.p.test     ` | Proportion (one sample)\n `pwr.r.test     ` | Correlation\n `pwr.t.test     ` | t-tests (one sample, two samples, paired)\n `pwr.t2n.test   ` | t-test (two samples with unequal n)\n\nFor each function, you can specify three of four arguments (sample size, alpha, effect size, power) and the fourth argument will be calculated for you.\n\nOf the four quantities, effect size is often the most difficult to specify. Calculating effect size typically requires some experience with the measures involved and knowledge of past research. \n\nTypically, specifying effect size requires you to read published literature or past papers on your research topic, to see what effect sizes were found and what significant results were reported. Other times, this might come from previous collected data or subject-knowledge from your colleagues.\n\nBut what can you do if you have no clue what effect size to expect in a given study? Cohen (1988) provided guidelines for what a small, medium, or large effect typically is in the behavioral sciences.\n\nType of test | Small | Medium | Large\n:---|:---:|:---:|:---:|:---:\nt-test | 0.20 | 0.50 | 0.80\nANOVA | 0.10 | 0.25 | 0.40 \nLinear regression | 0.02 | 0.15 | 0.35\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-71' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-71', 'opt-start-71')\"> <span class=\"olab\">Power for t-tests</span></span></div><div class=\"optional-body\" id = \"opt-body-71\" style=\"display: none;\">\n\n\n\nWe compare the mean of a response variable between two groups using a t-test. For example, if you are comparing the mean response between two groups, say treatment and control, the null and alternative hypotheses are:\n$$\nH_0 : \\mu_t - \\mu_c = 0\n$$\n\n$$\nH_1 : \\mu_t - \\mu_c \\neq 0  \n$$\n\nThe effect size in this case is Cohen's $D$:\n$$\nD = \\frac{(\\bar x_t - \\bar x_c) - 0}{s_p}  \n$$\nwhere\n\n- $\\bar x_t$ and $\\bar x_c$ are the sample means in the treatment and control groups, respectively\n- $s_p$ is the \"pooled\" standard deviation\n\n\nCohen's $D$ measures the distance between (a) the observed difference in means from (b) the hypothesised value 0, and compares this to the variability in the data.\n\n:::blue \n\nIn **R**\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npwr.t.test(n = , d = , sig.level = , power = , type = , alternative = )\n```\n:::\n\n\n\n\nwhere\n\n- `n` = the sample size\n- `d` = the effect size\n- `sig.level` = the significance level $\\alpha$ (the default is 0.05)\n- `power` = the power level\n- `type` = the type of t-test to perform: either a two sample t-test (`\"two.sample\"`), a one sample t-test (`\"one.sample\"`), or a dependent sample t-test (`\"paired\"`). A two sample test is the default.=\n- `alternative` = whether the alternative hypothesis is two-sided (`\"two.sided\"`) or one-sided (`\"less\"` or `\"greater\"`). A two-sided test is the default\n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-72' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-72', 'opt-start-72')\"> <span class=\"olab\">Power for Linear Regression</span></span></div><div class=\"optional-body\" id = \"opt-body-72\" style=\"display: none;\">\n\n\n\nIn linear regression, the formula for the effect size $f^2$ is different depending on your goal:\n\n::: {.panel-tabset}\n\nThe formula for the effect size $f^2$ is different depending on your goal.\n\n### Goal 1. Test on all slopes\n\nHere you have one model, \n\n$$\ny = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_k x_k + \\epsilon  \n$$\n\nand you wish to find the minimum sample size required to answer the following test of hypothesis with a given power: \n\n$$\n\\begin{aligned}\nH_0 &: \\beta_1 = \\beta_2 = \\dots = \\beta_k = 0 \\\\  \nH_1 &: \\text{At least one } \\beta_i \\neq 0 \\\\  \n\\end{aligned}\n$$\n\nThe appropriate formula for the effect size is: \n\n$$\nf^2 = \\frac{R^2}{1 - R^2}  \n$$\n\nAnd the numerator degrees of freedom are $\\texttt u = k$, the number of predictors in the model.\n\nThe denominator degrees of freedom returned by the function will give you: \n\n$$\n\\texttt v = n - (k + 1) = n - k - 1 \\\\    \n$$\n\nFrom which you can infer the sample size as \n\n$$\nn = \\texttt v + k + 1 \\\\  \n$$\n\n### Goal 2. Test on a subset of slopes\n\nIn this case you would have a smaller model $m$ with $k$ predictors and a larger model $M$ with $K$ predictors: \n\n$$\n\\begin{aligned}\nm &: \\quad y = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_{k} x_k + \\epsilon \\\\  \nM &: \\quad y = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_{k} x_k \n+ \\underbrace{\\beta_{k + 1} x_{k+1} + \\dots + \\beta_{K} x_K}_{\\text{extra predictors}}\n+ \\epsilon \\\\   \n\\end{aligned}\n$$\n\nThis case is when you wish to find the minimum sample size required to answer the following test of hypothesis: \n\n$$\n\\begin{aligned}\nH_0 &: \\beta_{k+1} = \\beta_{k+2} = \\dots = \\beta_K = 0 \\\\  \nH_1 &: \\text{At least one of the above } \\beta \\neq 0 \\\\  \n\\end{aligned}\n$$\n\nYou need to use the $R^2$ from the larger model $R^2_M$ and the $R^2$ from the smaller model $R^2_m$. The appropriate formula for the effect size is: \n\n$$\nf^2 = \\frac{R^2_{M} - R^2_{m}}{1 - R^2_M}  \n$$\n\nHere, the numerator degrees of freedom are the extra predictors: $\\texttt u = K - k$.\n\nThe denominator degrees of freedom returned by the function will give you (here you use $K$ the number of all predictors in the larger model): \n\n$$  \n\\text v = n - (K + 1) = n - K - 1  \n$$\n\nFrom which you can infer the sample size as \n\n$$\nn = \\text v + K + 1  \n$$\n\n:::\n\n:::blue\n\nIn **R**\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(pwr)\npwr.f2.test(u = , v = , f2 = , sig.level = , power = )\n```\n:::\n\n\n\n\nwhere\n\n- `u`: numerator degrees of freedom = number predictors in the model $(k)$\n- `v`: denominator degrees of freedom = $n - k - 1$\n- `f2`: effect size. See the above [the pwr package flashcard](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#statistical-power-effect-size) to review Cohen's suggested effect size cut-off values\n- `sig.level`: significance level $\\alpha$ (the default is .05)\n- `power`: power level\n\nOne of the above the parameters - `u`, `v`, `f2`, `sig.level`, or `power` - must be passed as NULL (or in other words not specified), as that parameter will be determined from the others.\n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Data Transformations\n\nThere are many transformations we can do to a continuous variable, but the most common ones are centering and scaling. These transformations can help to aid interpretability of our statistical models.  \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-73' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-73', 'opt-start-73')\"> <span class=\"olab\">Centering</span></span></div><div class=\"optional-body\" id = \"opt-body-73\" style=\"display: none;\">\n\n\n\nCentering simply means moving the entire distribution to be centered on some new value. We achieve this by subtracting our desired center from each value of a variable. \n\nA common option is to mean center (i.e. to subtract the mean from each value). This makes our new values all relative to the mean. We can center a variable on other things, such as the minimum or maximum value of the scale we are using, or some judiciously chosen value of interest.\n\n:::blue\n\nIn **R**\n\n::: {.panel-tabset}\n\n## Manually mean center variable\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata_name <- data_name %>%\n  mutate(\n   mc_variable = variable - mean(variable)\n    )\n```\n:::\n\n\n\n\n## Add mean centered variable to data set via `scale()` function\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata_name <- data_name %>%\n    mutate(\n   mc_variable = scale(variable, scale = FALSE)\n   )\n```\n:::\n\n\n\n\n## Use `scale()` function within `lm` argument\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel <- lm(scale(DV, scale = FALSE) ~ scale(IV, scale = FALSE), data = data_name)\n```\n:::\n\n\n\n  \n:::\n\n\n:::   \n\n\n:::frame\n\n[**Important to Note for Interaction Models**]{style=\"color:red;\"}\n\nIf we have the interaction `y ~ x1 + x2 + x1:x2`, then mean centering `x1` will make the coefficient for `x2` now represent “the association between `x2` and `y` for someone at the average of `x1`”. When working with models that contain interaction terms, it is generally a good idea to center your continuous predictor variables. This is because:\n\n- centering helps to address issues of multicollinearity  \n- centering makes the model coefficients easier to interpret  \n\nRemember that the underlying model **does not** change, it is just extracting different information as we have changed what “zero” represents. \n\n:::\n\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-74' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-74', 'opt-start-74')\"> <span class=\"olab\">Scaling</span></span></div><div class=\"optional-body\" id = \"opt-body-74\" style=\"display: none;\">\n\n\n\nScaling changes the units of the variable, and we do this by dividing the observations by some value. E.g., moving from “36 months” to “3 years” involves multiplying (scaling) the value by 1/12.\n\nThe most common transformation that involves scaling is called **standardisation**. \n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-75' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-75', 'opt-start-75')\"> <span class=\"olab\">Standardisation</span></span></div><div class=\"optional-body\" id = \"opt-body-75\" style=\"display: none;\">\n\n\n\nThis involves subtracting the mean and then dividing by the standard deviation. So standardisation centers on the sample mean and scales by the sample standard deviation. Recall that a standardized variable has mean of 0 and standard deviation of 1.\n\n**$z$-score Formula:**\n\n$$\nz_x = \\frac{x - \\bar{x}}{s_x}, \\qquad z_y = \\frac{y - \\bar{y}}{s_y}\n$$\n\n:::blue\n\nIn **R**\n\n::: {.panel-tabset}\n\n## Manually create z-scored variables and then use these in model\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata_name <- data_name %>%\n  mutate(\n   z_variable = (variable - mean(variable)) / sd(variable)\n    )\n```\n:::\n\n\n\n\n\n## Add scaled variable to data set via `scale()` function\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata_name <- data_name %>% \n    mutate(\n   z_variable = scale(variable)\n   )\n```\n:::\n\n\n\n\n\n## Use `scale()` function within `lm` argument\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel <- lm(scale(DV) ~ scale(IV), data = data_name)\n```\n:::\n\n\n\n\n:::\n\n:::\n\nWhen we standardise variables in a regression model, it means we can talk about all our coefficients in terms of “standard deviation units”. To the extent that it is possible to do so, this puts our coefficients on scales of the similar magnitude, making qualitative comparisons between the sizes of effects a little more easy.\n\nWe tend to refer to coefficients using standardised variables as (unsurprisingly), “standardised coefficients”\n\nThere are two main ways that people construct standardised coefficients. One of which standardises just the predictor, and the other of which standardises both predictor and outcome:\n\n\n| predictor    | outcome      | in lm                     | coefficient                       | interpretation                                   |\n| ------------ | ------------ | ------------------------- | --------------------------------- | ------------------------------------------------ |\n| standardised | raw          | `y ~ scale(x)`            | $\\beta = b \\cdot s_x$             | \"difference in Y for a 1 SD increase in X\"       |\n| standardised | standardised | `scale(y) ~ scale(x)`     | $\\beta = b \\cdot \\frac{s_x}{s_y}$ | \"difference in SD of Y for a 1 SD increase in X\" |\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Model Fit\n\n## Linear Models\n\nAssessing model fit involves examining metrics like the sum of squares to measure variability explained by the model, the $F$-ratio to evaluate the overall significance of the model by comparing explained variance to unexplained variance, and $R$-squared / Adjusted $R$-squared to quantify the proportion of variance in the dependent variable explained by the independent variable(s).\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-76' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-76', 'opt-start-76')\"> <span class=\"olab\">Sums of Squares</span></span></div><div class=\"optional-body\" id = \"opt-body-76\" style=\"display: none;\">\n\n\n\nTo quantify and assess a model’s utility in explaining variance in an outcome variable, we can split the total variability of that outcome variable into two terms: the variability explained by the model plus the variability left unexplained in the residuals.\n\nThe sum of squares measures the deviation or variation of data points away from the mean (i.e., how spread out are the numbers in a given dataset). We are trying to find the equation/function that best fits our data by varying the least from our data points. \n\n##### Total Sum of Squares\n\n**Formula**: \n\n$$\nSS_{Total} = \\sum_{i=1}^{n}(y_i - \\bar{y})^2\n$$\nCan also be derived from:\n\n$$\nSS_{Total} = SS_{Model} + SS_{Residual}\n$$\n\n**In words**: \n\nSquared distance of each data point from the mean of $y$.\n\n**Description**: \n\nHow much variation there is in the DV.\n\n##### Residual Sum of Squares\n\n**Formula**: \n\n$$\nSS_{Residual} = \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2\n$$\n\n**In words**: \n\nSquared distance of each point from the predicted value.\n\n**Description**: \n\nHow much of the variation in the DV the model did not explain - a measure that captures the unexplained variation in your regression model. Lower residual sum of squares suggests that your model fits the data well, and higher suggests that the model poorly explains the data (in other words, the lower the value, the better the regression model). If the value was zero here, it would suggest the model fits perfectly with no error.\n\n##### Model Sum of Squares\n\n**Formula**: \n\n$$\nSS_{Model} = \\sum_{i=1}^{n}(\\hat{y}_i - \\bar{y})^2\n$$\n\nCan also be derived from:\n\n$$\nSS_{Model} = SS_{Total} - SS_{Residual}\n$$\n**In words**: \n\nThe deviance of the predicted scores from the mean of $y$.\n\n**Description**: \n\nHow much of the variation in the DV your model explained - like a measure that captures how well the regression line fits your data.\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-77' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-77', 'opt-start-77')\"> <span class=\"olab\">F-ratio</span></span></div><div class=\"optional-body\" id = \"opt-body-77\" style=\"display: none;\">\n\n\n\n**Overview:**\n\nWe can perform a test to investigate if a model is ‘useful’ — that is, a test to see if our explanatory variable explains more variance in our outcome than we would expect by just some random chance variable.  \n\nWith one predictor, the $F$-statistic is used to test the null hypothesis that the regression slope for that predictor is zero:\n\n$$\nH_0: \\text{the model is ineffective, }b_1 = 0 \\\\  \n$$\n$$\nH_1 : \\text{the model is effective, }b_1  \\neq 0 \\\\  \n$$\n\nIn multiple regression, the logic is the same, but we are now testing against the null hypothesis that **all** regression slopes are zero. Our test is framed in terms of the following hypotheses:\n\n$$ \nH_0: \\text{the model is ineffective, }b_1,...., b_k = 0 \\\\    \n$$\n\n$$\nH_1 : \\text{the model is effective, }b_1,...., b_k  \\neq 0 \\\\  \n$$\n\nThe relevant test-statistic is the $F$-statistic, which uses “Mean Squares” (these are Sums of Squares divided by the relevant degrees of freedom). We then compare that against (you guessed it) an $F$-distribution! $F$-distributions vary according to two parameters, which are both degrees of freedom.\n\n**Formula:** \n\n$$\nF_{(df_{model},~df_{residual})} = \\frac{MS_{Model}}{MS_{Residual}} = \\frac{SS_{Model}/df_{Model}}{SS_{Residual}/df_{Residual}} \\\\\n\\quad \\\\\n$$\n\n$$\n\\begin{align}\n& \\text{Where:} \\\\\n& df_{model} = k \\\\\n& df_{residual} = n-k-1 \\\\\n& n = \\text{sample size} \\\\\n& k  = \\text{number of explanatory variables} \\\\\n\\end{align}\n$$\n\n\n**Description:**\n\nTo test the significance of an overall model, we can conduct an $F$-test. The $F$-test compares your model to a model containing zero predictor variables (i.e., the intercept only model), and tests whether your added predictor variables significantly improved the model.\n\nIt is called the $F$-ratio because it is the ratio of the how much of the variation is explained by the model (per parameter) versus how much of the variation is unexplained (per remaining degrees of freedom). \n\nThe $F$-test involves testing the statistical significance of the $F$-ratio.   \n\n**Q:** What does the $F$-ratio test?  \n**A:** The null hypothesis that all regression slopes in a model are zero (i.e., explain no variance in your outcome/DV). The alternative hypothesis is that **at least one of the slopes is not zero**. \n\n\nThe $F$-ratio you see at the bottom of `summary(model)` is actually a comparison between two models: your model (with some explanatory variables in predicting $y$) and the *null model*. \n\nIn regression, the null model can be thought of as the model in which all explanatory variables have zero regression coefficients. It is also referred to as the __intercept-only model__, because if all predictor variable coefficients are zero, then we are only estimating $y$ via an intercept (which will be the mean - $\\bar y$). \n\n**Interpretation:** \n\nAlongside viewing the $F$-ratio, you can see the results from testing the null hypothesis that all of the coefficients are $0$ (the alternative hypothesis is that at least one coefficient is $\\neq 0$. Under the null hypothesis that all coefficients = 0, the ratio of explained:unexplained variance should be approximately 1)\n\nIf your model predictors do explain some variance, the $F$-ratio will be significant, and you would reject the null, as this would suggest that your predictor variables included in your model improved the model fit (in comparison to the intercept only model).\n\n\n*Points to note:*\n\n- The larger your $F$-ratio, the better your model\n- The $F$-ratio will be close to 1 when the null is true (i.e., that all slopes are zero)\n\n:::blue\n\nIn **R**\n\nWe can see the $F$-statistic and associated $p$-value at the bottom of the output of `summary(<modelname>)`:\n\n\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![Multiple regression output in R, F statistic highlighted](images/recall_mdl_output_f.PNG){fig-align='left' width=80%}\n:::\n:::\n\n\n\n\n:::\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\n**Example Interpretation**\n\nThe linear model with recall confidence and age explained a significant amount of variance in recall accuracy beyond what we would expect by chance $F(2, 17) = 12.92, p < .001$. \n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-78' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-78', 'opt-start-78')\"> <span class=\"olab\">R-squared and Adjusted R-squared</span></span></div><div class=\"optional-body\" id = \"opt-body-78\" style=\"display: none;\">\n\n\n\n**Overview:**\n\n$R^2$ represents the proportion of variance in $Y$ that is explained by the model predictor variables. \n\n**Formula:**\n\nThe $R^2$ coefficient is defined as the proportion of the total variability in the outcome variable which is explained by our model:\n$$\nR^2 = \\frac{SS_{Model}}{SS_{Total}} = 1 - \\frac{SS_{Residual}}{SS_{Total}}\n$$\n\nThe Adjusted $R^2$ coefficient is defined as:\n$$\n\\hat R^2 = 1 - \\frac{(1 - R^2)(n-1)}{n-k-1}\n\\quad \\\\\n$$\n\n$$\n\\begin{align}\n& \\text{Where:} \\\\\n& n = \\text{sample size} \\\\\n& k = \\text{number of explanatory variables} \\\\\n\\end{align}\n$$\n\n<br>\n\n**When to report Multiple $R^2$ vs. Adjusted $R^2$:**\n\nThe Multiple $R^2$ value should be reported for a simple linear regression model (i.e., one predictor).   \n\nUnlike $R^2$, Adjusted-$R^2$ does not necessarily increase with the addition of more explanatory variables, by the inclusion of a penalty according to the number of explanatory variables in the model. Since Adjusted-$R^2$ is adjusted for the number of predictors in the model, this should be used when there are 2 or more predictors in the model. As a side note, the Adjusted-$R^2$ should always be less than or equal to $R^2$.\n\n\n:::blue\n\nIn **R**\n\nWe can see both $R^2$ and Adjusted-$R^2$ in the second bottom row of the `summary(<modelname>)`:\n\n\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![Multiple regression output in R, R^2 statistic highlighted](images/recall_mdl_output_r.PNG){fig-align='left' width=80%}\n:::\n:::\n\n\n\n\n:::\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\n**Example Interpretation**\n\nTogether, recall confidence and age explained approximately 55.66% of the variance in recall accuracy. \n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n## Logistic Models\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-79' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-79', 'opt-start-79')\"> <span class=\"olab\">Deviance</span></span></div><div class=\"optional-body\" id = \"opt-body-79\" style=\"display: none;\">\n\n\n\nDeviance is a measure of deviation/discrepancy/mismatch between the data and the model. You can think of it as a generalisation of the terms making up the residual sum of squares in simple linear regression, in that it measures the misfit, or badness of fit.   \n\n**Null Deviance**\n  \n+ The deviance of a model with no predictors, just the intercept  \n+ It acts as a baseline, and measures how well the null model fits the data  \n\n**Residual Deviance**\n  \n+ The deviance of the model with the predictors included  \n+ Shows how well the model with those predictors fits the data compared to the null model  \n\n**Interpretation**\n  \n+ By comparing the null deviance with the residual deviance, you can assess the improvement provided by the predictors  \n+ Lower deviance values indicate a better fit. If you wanted to know whether the difference in deviance was *significantly* different, you would need to *statistically* compare your models (see [model comparisons - logistic models](https://uoepsy.github.io/dapr2/2425/labs/1_b4_reading.html#logistic-models)). \n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Model Comparisons\n\n## Linear Models\n\nOne useful thing we might want to do is compare our models with and without some predictor(s).There are numerous ways we can do this, but the method chosen depends on the models and underlying data:\n\n\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](images/comparisons_chart.png){fig-align='left' width=100%}\n:::\n:::\n\n\n\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-80' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-80', 'opt-start-80')\"> <span class=\"olab\">Nested vs Non-Nested Models</span></span></div><div class=\"optional-body\" id = \"opt-body-80\" style=\"display: none;\">\n\n\n\n**Nested Models**\n\nConsider that you have two regression models where Model 1 contains a subset of the predictors contained in the other Model 2 and is fitted to the same data. More simply, Model 2 contains all of the predictors included in Model 1, **plus** additional predictor(s). This means that Model 1 is *nested* within Model 2, or that Model 1 is a *submodel* of Model 2. These two terms, at least in this setting, are interchangeable - it might be easier to think of Model 1 as your null and Model 2 as your alternative.\n\n**Non-Nested Models**\n\nConsider that you have two regression models where Model 1 contains different variables to those contained in Model 2, where both models are fitted to the same data. More simply, Model 1 and Model 2 contain unique variables that are not shared. This means that Model 1 and Model 2 are **not** nested.\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-81' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-81', 'opt-start-81')\"> <span class=\"olab\">Incremental F-test</span></span></div><div class=\"optional-body\" id = \"opt-body-81\" style=\"display: none;\">\n\n\n\nIf (*and only if*) two models are __nested__, can we compare them using an __incremental F-test__.  \n\nThis is a formal test of whether the additional predictors provide a better fitting model.  \nFormally this is the test of:  \n\n+ $H_0:$ coefficients for the added/omitted variables are all zero.\n\n+ $H_1:$ at least one of the added/omitted variables has a coefficient that is not zero. \n\nThe $F$-ratio for comparing the residual sums of squares between two models can be calculated as:\n\n$$\nF_{(df_R-df_F),~df_F} = \\frac{(SSR_R-SSR_F)/(df_R-df_F)}{SSR_F / df_F} \\\\\n\\quad \\\\\n$$\n$$\n\\begin{align}\n& \\text{Where:} \\\\\n\\\\\n& SSR_R = \\text{residual sums of squares for the restricted model} \\\\\n& SSR_F = \\text{residual sums of squares for the full model} \\\\\n& df_R = \\text{residual degrees of freedom from the restricted model} \\\\\n& df_F = \\text{residual degrees of freedom from the full model} \\\\\n\\end{align}\n$$\n\n:::blue\n**In R**\n\nWe can conduct an incremental $F$-test to compare two models by fitting both models using `lm()`, and passing them to the `anova()` function:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel1 <- lm( ... )\nmodel2 <- lm( ... )\nanova(model1, model2)\n```\n:::\n\n\n\n\n\nIf we wanted to, for example, compare a model with just one predictor, $x1$, to a model with 2 predictors: $x1$, and $x2$, we can assess the extent to which the variable $x2$ improves model fit:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel1 <- lm(y ~ x1, data = data_name)\nmodel2 <- lm(y ~ x1 + x2, data = data_name)\nanova(model1, model2)\n```\n:::\n\n\n\n\n:::\n\nFor example:\n\n\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![Model Comparisons using Incremental F-test](images/recall_mdl_anova_comp.PNG){fig-align='left' width=80%}\n:::\n:::\n\n\n\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\n**Example Interpretation**\n\nRecall confidence explained a significant amount of variance in recall accuracy beyond age $(F(1, 17) = 21.95, p < .001)$. \n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-82' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-82', 'opt-start-82')\"> <span class=\"olab\">AIC & BIC</span></span></div><div class=\"optional-body\" id = \"opt-body-82\" style=\"display: none;\">\n\n\n\nAIC (Akaike Information Criterion) and BIC (Bayesian Information Criterion) combine information about the sample size, the number of model parameters, and the residual sums of squares ($SS_{residual}$). Models do not *need* to be nested to be compared via AIC and BIC, __but__ they need to have been fit to the same dataset.  \n\nFor both of these fit indices, lower values are better, and both include a penalty for the number of predictors in the model (although BIC's penalty is harsher):\n\n$$\n\\begin{align}\nAIC = n\\,\\text{ln}\\left( \\frac{SS_{residual}}{n} \\right) + 2k \\\\\n\\end{align}\n\\quad \\\\\n$$\n\n$$\n\\begin{align}\nBIC = n\\,\\text{ln}\\left( \\frac{SS_{residual}}{n} \\right) + k\\,\\text{ln}(n) \\\\\n\\end{align}\n\\quad \\\\\n$$\n\n$$\n\\begin{align}\n& \\text{Where:} \\\\\n& SS_{residual} = \\text{sum of squares residuals} \\\\\n& n = \\text{sample size} \\\\\n& k = \\text{number of explanatory variables} \\\\\n& \\text{ln} = \\text{natural log function} \n\\end{align}\n$$\n\n:::blue\n**In R**\n\nWe can calculate AIC and BIC by using the `AIC()` and `BIC()` functions respectively:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#AIC\nAIC(<modelname>)\n\n#BIC\nBIC(<modelname>)\n```\n:::\n\n\n\n\n\n:::\n\nFor example:\n\n\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![Model Comparisons using AIC and BIC](images/recall_mdl_aic_bic.PNG){fig-align='left' width=80%}\n:::\n:::\n\n\n\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\n**Example Interpretation**\n\nBased on both AIC and BIC, the model predicting recall accuracy that included both recall confidence and age was better fitting ($AIC = 152.28; BIC = 156.27$) than the model with age alone ($AIC = 166.86; BIC = 169.85$). \n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br>\n\n## Logistic Models\n\nWhen moving from linear regression to more advanced and flexible models, testing of goodness of fit is more often done by comparing a model of interest to a simpler one. This is called a likelihood ratio test.  \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-83' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-83', 'opt-start-83')\"> <span class=\"olab\">Drop-in-Deviance Test to Compare Nested Models</span></span></div><div class=\"optional-body\" id = \"opt-body-83\" style=\"display: none;\">\n\n\n\nIn the generalized linear model world, we don't have straightforward residuals, and we compare models on a different metric, known as __deviance__. With a big enough sample size, reductions in deviance are $\\chi^2$ distributed, meaning that we can compare them to an appropriate $\\chi^2$ distribution to compute a p-value.\n\nThe only caveat is that the two models **must be nested**, i.e. one model needs to be a simplification of the other, and all predictors of one model needs to be within the other.\n\nWe want to compare the model we previously fitted against a model where all slopes are 0, i.e. a baseline model: \n\n$$\n\\begin{aligned}\nM_1 : \\qquad\\log \\left( \\frac{p}{1 - p} \\right) &= \\beta_0 \\\\\nM_2 : \\qquad \\log \\left( \\frac{p}{1 - p} \\right) &= \\beta_0 + \\beta_1 x\n\\end{aligned}\n$$ \n\n:::blue \n\n**In R**\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmdl_reduced <- glm(DV ~ 1, family = \"binomial\", data = dataset)\nmdl_main <- glm(DV ~ IV1 + IV2 ... + IV4, family = \"binomial\", data = dataset)\n\nanova(mdl_red, mdl_main, test = 'Chisq')\n```\n:::\n\n\n\n\nIn the output you can see the residual deviance of each model. Remember the deviance is the equivalent of residual sum of squares in linear regression.\n\n:::\n\n**Example** \n\nHere we'll continue with our senility and wais score example. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#create null model\nsen_mdl0 <- glm(senility ~ 1, family = \"binomial\", data = sendata)\n\n#compare models \nanova(sen_mdl0, sen_mdl1, test = \"Chisq\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table\n\nModel 1: senility ~ 1\nModel 2: senility ~ wais\n  Resid. Df Resid. Dev Df Deviance Pr(>Chi)   \n1        53     61.806                        \n2        52     51.017  1   10.789 0.001021 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\n**Example Interpretation**\n\nWe performed a deviance goodness-of-fit test to compare our fitted model to the null. At the 5% significance level, the addition of information about the participants’ WAIS resulted in a significant decrease in model deviance $\\chi^2(1) = 10.78, p = .001$. Hence, we have strong evidence that the subjects’ WAIS was a helpful predictor of whether or not participants will experience symptoms of senility.\n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br>\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-84' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-84', 'opt-start-84')\"> <span class=\"olab\">AIC & BIC</span></span></div><div class=\"optional-body\" id = \"opt-body-84\" style=\"display: none;\">\n\n\n\nDeviance measures lack of fit, and it can be reduced to zero by making the model more and more complex, effectively estimating the value at each single data point. However, this involves adding more and more predictors, which makes the model more complex (and less interpretable).\n\nTypically, the simpler model should be preferred when it can still explain the data almost as well. This is why information criteria were devised, exactly to account for both the model misfit but also its complexity.\n\n$$\n\\text{Information Criterion} = \\text{Deviance} + \\text{Penalty for model complexity}\n$$\n\nDepending on the chosen penalty, you get different criteria. Two common ones are the Akaike and Bayesian Information Criteria, AIC and BIC respectively: \n\n$$\n\\begin{aligned}\n\\text{AIC} &= \\text{Deviance} + 2 p \\\\\n\\text{BIC} &= \\text{Deviance} + p \\log(n)\n\\end{aligned}\n$$\n\nwhere $n$ is the sample size and $p$ is the number of regression coefficients in the model. **Models that produce smaller values of these fit criteria should be preferred.**\n\nAIC and BIC differ in their degrees of penalization for number of regression coefficients, with BIC usually favouring models with fewer terms.\n\n:::blue\n**In R**\n\nWe can calculate AIC and BIC by using the `AIC()` and `BIC()` functions respectively:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#AIC\nAIC(sen_mdl0, sen_mdl1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         df      AIC\nsen_mdl0  1 63.80632\nsen_mdl1  2 55.01738\n```\n\n\n:::\n\n```{.r .cell-code}\n#BIC\nBIC(sen_mdl0, sen_mdl1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         df      BIC\nsen_mdl0  1 65.79530\nsen_mdl1  2 58.99535\n```\n\n\n:::\n:::\n\n\n\n\n:::\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n**Example Interpretation**\n\nBased on both AIC and BIC, the model including the subjects’ WAIS as a predictor of symptoms of senility was better fitting ($AIC = 55.017;~ BIC = 59.00$) than the model with age alone ($AIC = 63.81;~ BIC = 66.00$). However, since the difference in $BIC$ values was $<~10$, we would conclude that the difference in models was not practically significant. \n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Model Assumptions\n\n## Linear Models\n\nLinear models rely on numerous underlying assumptions about the data. These assumptions ensure that the association between variables is appropriately captured, and that inferences drawn from the model are accurate and valid. Model diagnostics can help further assess whether these assumptions hold. When these assumptions are violated, there are numerous techniques that can be employed, such as through data transformations or using robust alternatives, to ensure reliable model interpretations.\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-85' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-85', 'opt-start-85')\"> <span class=\"olab\">Linearity</span></span></div><div class=\"optional-body\" id = \"opt-body-85\" style=\"display: none;\">\n\n\n\n### Simple Linear Regression\nIn simple linear regression with only one explanatory variable, we could assess linearity through a simple scatterplot of the outcome variable against the explanatory. This would allow us to check if the errors have a mean of zero. If this assumption was met, the residuals would appear to be randomly scattered around zero.  \n  \nThe rationale for this is that, once you remove from the data the linear trend, what's left over in the residuals should not have any trend, i.e. have a mean of zero.\n\n### Multiple Regression\nIn multiple regression, however, it becomes more necessary to rely on diagnostic plots of the model residuals. This is because we need to know whether the relations are linear between the outcome and each predictor _after accounting for the other predictors in the model._   \n\nIn order to assess this, we use **partial-residual plots** (also known as 'component-residual plots'). This is a plot with each explanatory variable $x_j$ on the x-axis, and **partial residuals** on the y-axis***.\n\nPartial residuals for a predictor $x_j$ are calculated as:\n$$\n\\hat \\epsilon + \\hat \\beta_j x_j\n$$\n\n:::blue\n\nIn **R**\n\n::: {.panel-tabset}\n\n### Simple Linear Regression\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#specify model\nrecall_simp <- lm(recall_accuracy ~ age, data = recalldata)\n\n#create plot\nggplot(recalldata, aes(x = age, y = recall_accuracy)) + \n    geom_point() + \n    geom_smooth(method = \"lm\", se = FALSE, colour = \"blue\") + #fit straight line to data\n    geom_smooth(method = \"loess\", se = FALSE, colour = \"red\") + #fit loess line to data\n    labs(x = \"Age\", y = \"Recall Accuracy\")\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-139-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n:::frame\n\n[**Interpretation Guidance**]{style=\"color:red;\"}\n\nThe loess line should closely follow the data.\n\n:::\n\n### Multiple Linear Regression\n\nWe can create these plots for all predictors in the model by using the `crPlots()` function from the **car** package:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#specify model\nrecall_mdl <- lm(recall_accuracy ~ recall_confidence + age, data = recalldata)\n\n#create plots\ncrPlots(recall_mdl)\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-140-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n\n:::frame\n\n[**Interpretation Guidance**]{style=\"color:red;\"}\n\nYou are looking for the pink line to follow a linear trend line (i.e., follow the blue line). In other words, the loess line should closely follow the linear line. \n\n:::\n\n:::\n\n\n:::\n\n\n[**Important to Note for Interaction Models**]{style=\"color:darkred;\"}\n\n***When there is an interaction in the model, assessing linearity becomes difficult. In fact, `crPlots()` will not work. To assess, you can create a residuals-vs-fitted plot.\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-86' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-86', 'opt-start-86')\"> <span class=\"olab\">Independence (of errors)</span></span></div><div class=\"optional-body\" id = \"opt-body-86\" style=\"display: none;\">\n\n\n\nThe 'independence of errors' assumption is the condition that the errors do not have some underlying relationship which is causing them to influence one another. \n<br>\n\nThere are many sources of possible dependence, and often these are issues of study design. For example, we may have groups of observations in our data which we would expect to be related (e.g., multiple trials from the same participant). Our modelling strategy would need to take this into account.\n<br>\n\nOne form of dependence is **autocorrelation** - this is when observations influence those adjacent to them. It is common in data for which *time* is a variable of interest (e.g, the humidity today is dependent upon the rainfall yesterday). \n\nTesting for the independence of errors can be pretty difficult, unless you know the potential source of correlation between cases (more on this in DAPR3!). \n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-87' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-87', 'opt-start-87')\"> <span class=\"olab\">Normality (of errors)</span></span></div><div class=\"optional-body\" id = \"opt-body-87\" style=\"display: none;\">\n\n\n\nThe normality assumption is the condition that the errors $\\epsilon$ are normally distributed in the population.  \n\nWe can visually assess this condition through histograms, density plots, and quantile-quantile plots (QQplots) of our residuals $\\hat \\epsilon$.  \n\n::: {.panel-tabset}\n\n### Histogram\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhist(recall_mdl$residuals)\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-141-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n\n### QQPlot\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(recall_mdl, which = 2)\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-142-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n:::\n\n:::frame\n\n[**Interpretation Guidance**]{style=\"color:red;\"}\n\nRemember that departures from a linear trend in QQ plots indicate a lack of normality.\n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-88' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-88', 'opt-start-88')\"> <span class=\"olab\">Equal Variances (Homoscedasticity)</span></span></div><div class=\"optional-body\" id = \"opt-body-88\" style=\"display: none;\">\n\n\n\nThe equal variances assumption is that the error variance $\\sigma^2$ is constant across values of the predictor(s) $x_1, \\dots,  x_k$, and across values of the fitted values $\\hat y$. This sometimes gets termed \"Constant\" vs \"Non-constant\" variance. This is presented visually in @fig-ncv-violate and @fig-ncv-noviolate. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Non-constant variance for numeric and categorical X](1_b4_reading_files/figure-html/fig-ncv-violate-1.png){#fig-ncv-violate fig-align='center' width=90%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Constant variance for numeric and categorical X](1_b4_reading_files/figure-html/fig-ncv-noviolate-1.png){#fig-ncv-noviolate fig-align='center' width=90%}\n:::\n:::\n\n\n\n\n:::blue\n\nIn **R**\n\nWe can create plots of the _Pearson residuals_ against the predicted values $\\hat y$ and against the predictors $x_1$, ... $x_k$ by using the `residualPlots()` function from the **car** package. This function also provides the results of a lack-of-fit test for each of these relationships (note when it is the fitted values $\\hat y$ it gets called \"Tukey's test\"). \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(car)\nresidualPlots(recall_mdl)\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-145-1.png){fig-align='center' width=80%}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  Test stat Pr(>|Test stat|)\nrecall_confidence    1.4473           0.1671\nage                 -0.0474           0.9627\nTukey test           0.8769           0.3805\n```\n\n\n:::\n:::\n\n\n\n\nAlternatively, we can use:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(recall_mdl, which = 1)\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-146-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n:::\n\n:::frame\n\n[**Interpretation Guidance**]{style=\"color:red;\"}\n\nIf the assumption is met, you should see a random scatter of $(x,y)$ points with constant mean and variance functions i.e., the vertical spread of the residuals should roughly be the same everywhere.\n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-89' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-89', 'opt-start-89')\"> <span class=\"olab\">Useful Assumption Plots</span></span></div><div class=\"optional-body\" id = \"opt-body-89\" style=\"display: none;\">\n\n\n\n::: {.panel-tabset}\n\n### `plot(modelname)`\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\nWe can run `plot(mymodel)` which will cycle through these plots (asking us to press enter each time to move to the next plot), or we can arrange these plots in a matrix via `par(mfrow)`, for example in a 2 x 2 matrix as shown below (make sure to always reset your graphical parameters! If needed, we could also extract specific plots using, for instance: `plot(mymodel, which = 3)` for the third plot.\n\n:::blue\n**In R**\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npar(mfrow=c(2,2))\nplot(recall_mdl)\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-148-1.png){fig-align='center' width=80%}\n:::\n\n```{.r .cell-code}\npar(mfrow=c(1,1))\n```\n:::\n\n\n\n\n:::\n\n:::frame\n\n[**Interpretation Guidance**]{style=\"color:red;\"}\n\n\n- Top Left: For the __Residuals vs Fitted__ plot, we want the red line to be horizontal at close to zero across the plot. We don't want the residuals (the points) to be fanning in/out.  \n- Top Right: For the __Normal Q-Q__ plot, we want the residuals (the points) to follow closely to the diagonal line, indicating that they are relatively normally distributed.^[QQplots plot the values against the associated percentiles of the normal distribution. So if we had ten values, it would order them lowest to highest, then plot them on the y against the 10th, 20th, 30th.. and so on percentiles of the standard normal distribution (mean 0, SD 1)]\n- Bottom Left: For the __Scale-Location__ plot, we want the red line to be horizontal across the plot. These plots allow us to examine the extent to which the variance of the residuals changes across the fitted values. If it is angled, we are likely to see fanning in/out of the points in the residuals vs fitted plot.\n- Bottom Right: The __Residuals vs Leverage__ plot indicates points that might be of individual interest as they may be unduly influencing the model. There are funnel-shaped lines on this plot (sometimes out of scope of the plotting window). Ideally, we want our residuals inside the funnel - the further the residual is to the right (the more leverage it has), the closer to the 0 we want it to be.  \n\n*Note, if we have only categorical predictors in our model, many of these will show vertical lines of points. This doesn't indicate that anything is wrong, and the same principles described above continue to apply*\n\n:::\n\n### `check_model(modelname)`\n\nThe `check_model()` function from the **performance** package is a useful way to check the assumptions of models, as it also returns some useful notes to aid your interpretation. However, it is important to check each assumption individually with plots that are more suitable for a statistics report.\n\n:::blue\n**In R**\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(performance)\ncheck_model(recall_mdl)\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-149-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n:::\n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-90' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-90', 'opt-start-90')\"> <span class=\"olab\">Multicollinearity</span></span></div><div class=\"optional-body\" id = \"opt-body-90\" style=\"display: none;\">\n\n\n\nFor the linear model with **multiple** explanatory variables, we need to also think about **multicollinearity** - this is when two (or more) of the predictors in our regression model are moderately or highly correlated.  \n\nWe can assess multicollinearity using the **variance inflation factor (VIF)**, which for a given predictor $x_j$ is calculated as:  \n\n$$\nVIF_j = \\frac{1}{1-R_j^2} \\\\\n$$\n\n[**Important to Note for Interaction Models**]{style=\"color:darkred;\"}\n\nInteraction terms often result in multicollinearity, because these terms are made up of the product of some ‘main effects’. Mean-centering the variables will help to reduce this source of structural multicollinearity (“structural” here refers to the fact that multicollinearity is due to our model specification, rather than the data itself).\n\n:::frame\n\n[**Interpretation Guidance**]{style=\"color:red;\"}\n\nSuggested cut-offs for VIF are varied. Some suggest 10, others 5. Define what you will consider an acceptable value _prior_ to calculating it. You could loosely interpret VIF values $>5$ as moderate multicollinearity and values $>10$ as severe multicollinearity. \n\n:::\n\n:::blue\n\nIn **R**  \n  \nThe `vif()` function from the **car** package will provide VIF values for each predictor in your model. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nvif(INSERT_MODEL_NAME)\n```\n:::\n\n\n\n\n\n:::\n\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-91' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-91', 'opt-start-91')\"> <span class=\"olab\">Individual Case Diagnostics</span></span></div><div class=\"optional-body\" id = \"opt-body-91\" style=\"display: none;\">\n\n\n\nWe have seen that some specific individual cases in our data can influence our model more than others. We can identify these as:\n\n+ **Regression outliers:** A large residual $\\hat \\epsilon_i$ - i.e., a big discrepancy between their predicted y-value and their observed y-value.  \n    + **Standardised residuals:** For residual $\\hat \\epsilon_i$, divide by the estimate of the standard deviation of the residuals. In R, the `rstandard()` function will give you these\n    + **Studentised residuals:** For residual $\\hat \\epsilon_i$, divide by the estimate of the standard deviation of the residuals excluding case $i$. In R, the `rstudent()` function will give you these.\n+ **High leverage cases:** These are cases which have considerable _potential_ to influence the regression model (e.g., cases with an unusual combination of predictor values). \n    + **Hat values:** are used to assess leverage. In R, The `hatvalues()` function will retrieve these. \n+ **High influence cases:** When a case has high leverage *and* is an outlier, it will have a large influence on the regression model. \n    + **Cook's Distance:** combines *leverage* (hatvalues) with *outlying-ness* to capture influence: $D_i = \\text{Outlyingness} \\times \\text{Leverage}$. Cook's distance refers to the average distance the $\\hat{y}$ values will move if a given case is removed. In `R`, the `cooks.distance()` function will provide these values. \nAlongside Cook's Distance, we can examine the extent to which model estimates and predictions are affected when an entire case is dropped from the dataset and the model is refitted.  \n+ **DFFit:** the change in the predicted value at the $i^{th}$ observation with and without the $i^{th}$ observation is included in the regression.  \n+ **DFbeta:**  the change in a specific coefficient with and without the $i^{th}$ observation is included in the regression.  DFbeta represents the difference in the beta coefficients when a case is excluded from the model versus when it’s included. A large DFbeta value would suggest that a case has a substantial impact on the estimated coefficients, and thus a high influence on the model results; a small DFbeta value would suggest that the case has less influence on the estimated coefficients. A commonly used cut-off or threshold to compare $|DFBETA|$ values (absolute values) against is $\\frac{2}{\\sqrt{n}}$ (see Belsley et al., (1980) p. 28 for more info)^[Belsley, D. A., Kuh, E., & Welsch, R. E. (2005). Regression diagnostics: Identifying influential data and sources of collinearity. John Wiley & Sons. DOI: 10.1002/0471725153]. \n+ **DFbetas:**  the change in a specific coefficient divided by the standard error, with and without the $i^{th}$ observation is included in the regression.  \n+ **COVRATIO:** measures the effect of an observation on the covariance matrix of the parameter estimates. In simpler terms, it captures an observation's influence on standard errors. Values which are $>1+\\frac{3(k+1)}{n}$ or $<1-\\frac{3(k+1)}{n}$ are considered as having strong influence. \n\n:::blue\n\nIn **R**, we can get lots of these measures with the `influence.measures()` function:\n\n\n+ `influence.measures(my_model)` will give you out a dataframe of the various measures.\n+ `summary(influence.measures(my_model))` will provide a nice summary of what R deems to be the influential points.\n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-92' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-92', 'opt-start-92')\"> <span class=\"olab\">Next Steps: What to do with Violations of Assumptions / Problematic Case Diagnostic Results</span></span></div><div class=\"optional-body\" id = \"opt-body-92\" style=\"display: none;\">\n\n\n\nThere are lots of different options available, and there is no one right answer. Assuming that we have no issues with model specification (i.e., are not missing variables, have modeled appropriately), then we may want to consider one of the below approaches (note: this is **not** an exhaustive list!)\n\n::: {.panel-tabset}\n\n## Investigate Observations\n\nThe first step is to re-examine your data. It is important to be familiar with your dataset, as you need to know what values are typical, normal, and possible. Could it be the case that you have missed some impossible values (e.g., a negative value of a persons height), values outwith the possible range (e.g., a score of 55 on a survey where scores can only range 10-50), values that don't make any sense (e.g., an age of 200), or maybe there are even typos / data entry errors (e.g., forgetting to put a decimal point, so having a height of 152m instead of 1.52m)! \n\nIf there is a simple error in the data, it could be that you can fix the typo. If that is not possible (maybe you didn't collect the data, so are unsure of what the value(s) should/could be), you will need to delete the value (i.e., set as an `NA`), because you know that it is incorrect. \n\nWe should aim to never change a legitimate value where possible (and remember that if you have a large dataset, a small number of extreme values will be unlikely to have a strong influence on your results). \n\nIf there is an extreme, but legitimate value that you have determined is adversely influencing your model (i.e., by examining the assumptions and diagnostics as outlined above), you may want to consider ways to reduce this influence (e.g., **winsorizing** -  which essentially truncates or caps the identified extreme values to a specified percentile, in turn reducing their influence on the model without completely eliminating the observation(s). For example, you could replace values below the 5th percentile with the 5th percentile value, and values above the 95th percentile with the 95th percentile value).\n\nIf after re-examining your data you cannot identify any atypical, non-normal, or impossible values, you may need to select a different approach as outlined below. \n\n## Sensitivity Analysis\n\nThis allows us to assess the **sensitivity** of our results (i.e., parameter estimates, p-values, confidence intervals) to changes in our modelling approach (i.e., the removal of observations).\n\nWe can re-fit our model after excluding our identified outliers and potentially influential observations, and compare these results to the original model.\n\n::: {.callout-important icon=false collapse=true}\n\n# Process of Removing Observations\n\nThe current example involves removing all identified outliers and potentially influential observations at the same time. Ideally, and to ensure a more thorough sensitivity analysis, you would remove each of these observations one at a time, assess the effects on the model by comparing to your original, reassessing the remaining pre-identified observations, and repeating the process if necessary. \n\n:::\n\n::: {.panel-tabset}\n\n### Original Model\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n## wellbeing model\nwb_mdl1 <- lm(wellbeing ~ outdoor_time + social_int, data = mwdata) \nsummary(wb_mdl1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = wellbeing ~ outdoor_time + social_int, data = mwdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.7611  -3.1308  -0.4213   3.3126  18.8406 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  28.62018    1.48786  19.236  < 2e-16 ***\noutdoor_time  0.19909    0.05060   3.935 0.000115 ***\nsocial_int    0.33488    0.08929   3.751 0.000232 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.065 on 197 degrees of freedom\nMultiple R-squared:  0.1265,\tAdjusted R-squared:  0.1176 \nF-statistic: 14.26 on 2 and 197 DF,  p-value: 1.644e-06\n```\n\n\n:::\n:::\n\n\n\n\n\n### Model with Observations Removed\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n## wellbeing model\nwb_mdl2 <- lm(wellbeing ~ outdoor_time + social_int, data = mwdata[-c(16, 25, 50, 53, 56, 58, 59, 60, 62, 72, 73, 75, 76, 78, 79, 85, 101, 109, 125, 126, 127, 131, 149, 151, 159, 163, 165, 169, 173, 176, 179, 197), ])\nsummary(wb_mdl2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = wellbeing ~ outdoor_time + social_int, data = mwdata[-c(16, \n    25, 50, 53, 56, 58, 59, 60, 62, 72, 73, 75, 76, 78, 79, 85, \n    101, 109, 125, 126, 127, 131, 149, 151, 159, 163, 165, 169, \n    173, 176, 179, 197), ])\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.7700 -2.6445 -0.6073  2.8586  9.6605 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  27.91311    1.42612  19.573  < 2e-16 ***\noutdoor_time  0.19356    0.04901   3.950 0.000116 ***\nsocial_int    0.39830    0.08964   4.443 1.62e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.044 on 165 degrees of freedom\nMultiple R-squared:  0.1774,\tAdjusted R-squared:  0.1675 \nF-statistic:  17.8 on 2 and 165 DF,  p-value: 1.004e-07\n```\n\n\n:::\n:::\n\n\n\n\n\n### Compare `summary()` output\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntab_model(wb_mdl1, wb_mdl2,\n          dv.labels = c(\"Wellbeing (WEMWBS Scores)\", \"Wellbeing (WEMWBS Scores)\"),\n          pred.labels = c(\"outdoor_time\" = \"Outdoor Time (hours per week)\",\n                          \"social_int\" = \"Social Interactions (number per week)\"),\n          title = \"Regression Table for Wellbeing Models wb1 and wb2\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<caption style=\"font-weight: bold; text-align:left;\">Regression Table for Wellbeing Models wb1 and wb2</caption>\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">Wellbeing (WEMWBS Scores)</th>\n<th colspan=\"3\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">Wellbeing (WEMWBS Scores)</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col7\">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">28.62</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">25.69&nbsp;&ndash;&nbsp;31.55</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">27.91</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">25.10&nbsp;&ndash;&nbsp;30.73</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Outdoor Time (hours per<br>week)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.20</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.10&nbsp;&ndash;&nbsp;0.30</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.19</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.10&nbsp;&ndash;&nbsp;0.29</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">Social Interactions<br>(number per week)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.33</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.16&nbsp;&ndash;&nbsp;0.51</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.40</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.22&nbsp;&ndash;&nbsp;0.58</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7\"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">200</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"3\">168</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> / R<sup>2</sup> adjusted</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.126 / 0.118</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"3\">0.177 / 0.167</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n\n\n\n:::\n\n::: {.callout-important icon=false appearance=\"minimal\"}\n\nWe conducted a sensitivity analysis to assess how robust our conclusions were regarding outdoor time and the weekly number of social interactions in the presence of previously identified outliers and potentially influential observations. We re-fit the model, excluding these 28 observations (14% of our original sample), and compared these model results (`wb_mdl2`) to those of our original model (`wb_mdl1`). \n\nThere was little difference in the estimates from `wb_mdl1` and `wb_mdl2`, and so we can conclude that after conducting a sensitivity analysis, there were no meaningful differences in our results, and hence our conclusions from our original model hold. Specifically:\n\n+ The direction of all model estimates are the same in `wb_mdl1` and `wb_mdl2` (i.e., all positive)\n+ There is no difference in statistical significance, and the p-values were of a similar magnitude (i.e., all < .001)\n+ The estimate and confidence intervals for `outdoor_time` are very similar\n+ There are some quantitative differences in the estimate and confidence intervals for `social_int`. The estimate differs slightly in magnitude by 0.07), but given that this remains positive and significant, we do not need to be too concerned about this. \n\n:::\n\n## Bootstrapping\n\nThe bootstrap method is an alternative non-parametric method of constructing a standard error. Instead of having to rely on calculating the standard error with a formula and potentially applying fancy mathematical corrections, bootstrapping involves mimicking the idea of “repeatedly sampling from the population”. It does so by repeatedly **re**sampling with **replacement** from our original sample.\n\nWhat this means is that we don’t have to rely on any assumptions about our model residuals, because we actually generate an actual distribution that we can take as an approximation of our sampling distribution, meaning that we can actually look at where 95% of the distribution falls, without having to rely on any summing of squared deviations.\n\nNote, the bootstrap may provide us with an alternative way of conducting inference, but our model may still be mis-specified. It is also very important to remember that bootstrapping is entirely reliant on utilising our original sample to pretend that it is a population (and mimic sampling from that population). If our original sample is not representative of the population that we’re interested in, bootstrapping doesn’t help us at all.\n\n## OLS vs WLS Regression\n\nThe method of ordinary least squares regression (OLS: i.e., the type of regression model you have been fitting on the course) assumes that there is constant variance in the errors (*homoscedasticity*). The method of weighted least squares (WLS) can be used when the ordinary least squares assumption of constant variance in the errors is violated (i.e., you have evidence of *heteroscedasticity*, like we do in Q3 of this lab).\n\nIf we have some specific belief that your non-constant variance is due to differences in the variances of the outcome between various groups, then it might be better to use Weighted Least Squares.   \n\nAs an example, imagine we are looking at weight of different dog breeds (@fig-dogweight). The weights of chihuahuas are all quite close together (between 2 to 5kg), but the weight of, for example, spaniels is anywhere from 8 to 25kg - a much bigger variance. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![The weights of 49 dogs, of 7 breeds](1_b4_reading_files/figure-html/fig-dogweight-1.png){#fig-dogweight fig-align='center' width=80%}\n:::\n:::\n\n\n\n\nRecall that the default way that `lm()` deals with categorical predictors such as `dog breed`, is to compare each one to a reference level. In this case, that reference level is \"beagle\" (first in the alphabet). Looking at @fig-dogweight above, which comparison do you feel more confident in? \n\n- **A:** Beagles (14kg) vs Pugs (9.1kg). A difference of 4.9kg.  \n- **B:** Beagles (14kg) vs Spaniels (19kg). A difference of 5kg.  \n\nHopefully, your intuition is that **A** looks like a clearer difference than **B** because there's less overlap between Beagles and Pugs than between Beagles and Spaniels. Our standard linear model, however, assumes the standard errors are identical for each comparison:  \n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = weight ~ breed, data = dogdf)\n...\nCoefficients:\n                      Estimate Std. Error t value Pr(>|t|)    \n(Intercept)             13.996      1.649   8.489 1.17e-10 ***\nbreedpug                -4.858      2.332  -2.084   0.0433 *  \nbreedspaniel             5.052      2.332   2.167   0.0360 *  \nbreedchihuahua         -10.078      2.332  -4.322 9.28e-05 ***\nbreedboxer              20.625      2.332   8.846 3.82e-11 ***\nbreedgolden retriever   17.923      2.332   7.687 1.54e-09 ***\nbreedlurcher             5.905      2.332   2.533   0.0151 *  \n---\n```\n\n\n:::\n:::\n\n\n\n\nFurthermore, we can see that we have heteroscedasticity in our residuals - the variance is not constant across the model:  \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(dogmodel, which=3)\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-156-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\nWeighted least squares is a method that allows us to apply weights to each observation, where the size of the weight indicates the precision of the information contained in that observation.  \n\nWe can, in our dog-breeds example, allocate different weights to each breed. Accordingly, the Chihuahuas are given higher weights (and so Chihuahua comparisons result in a smaller SE), and Spaniels and Retrievers are given lower weights. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(nlme)\nload(url(\"https://uoepsy.github.io/data/dogweight.RData\"))\ndogmod_wls = gls(weight ~ breed, data = dogdf, \n                 weights = varIdent(form = ~ 1 | breed))\nsummary(dogmod_wls)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\nCoefficients:\n                           Value Std.Error   t-value p-value\n(Intercept)            13.995640  1.044722 13.396516  0.0000\nbreedpug               -4.858097  1.271562 -3.820576  0.0004\nbreedspaniel            5.051696  2.763611  1.827933  0.0747\nbreedchihuahua        -10.077615  1.095964 -9.195207  0.0000\nbreedboxer             20.625429  1.820370 11.330351  0.0000\nbreedgolden retriever  17.922779  2.976253  6.021927  0.0000\nbreedlurcher            5.905261  1.362367  4.334559  0.0001\n```\n\n\n:::\n:::\n\n\n\n\nWe _can_ also apply weights that change according to continuous predictors (e.g. observations with a smaller value of $x$ are given more weight than observations with larger values). \n\n## Data Transformations\n\nA data transformation involves the replacement of a variable (e.g., $y$) by a function of that variable in order to change the shape of a distribution or association (e.g., to help reduce skew). We can transform the outcome variable prior to fitting the model, using something such as `log(y)` or `sqrt(y)`. This will sometimes allow us to estimate a model for which our assumptions are satisfied.\n\nSome of the most common (not an exhaustive list) transformations are:\n\n+ **Log (`log(y)`)**: Often used for reducing right skewness. Note, this transformation cannot be applied to zero or negative values (make sure to check your data!)\n+ **Square root (`sqrt(y)`)**: Also often used for reducing right skewness. This transformation can be applied to zero values (but not negative), and is commonly applied to count data\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![A model of a transformed outcome variable can sometimes avoid violations of assumptions that arise when modeling the outcome variable directly. Data from https://uoepsy.github.io/data/trouble1.csv](1_b4_reading_files/figure-html/fig-trouble1-1.png){#fig-trouble1 fig-align='center' width=80%}\n:::\n:::\n\n\n\n\nThe major downside of this is that we are no longer modelling $y$, but some transformation $f(y)$ ($y$ with some function $f$ applied to it). Interpretation of the coefficients changes accordingly, such that we are no longer talking in terms of changes in y, but changes in $f(y)$. When the transformation function used is non-linear (see the Right-Hand of @fig-logtr) a change in $f(y)$ is **not the same** for every $y$. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![The log transformation is non-linear](1_b4_reading_files/figure-html/fig-logtr-1.png){#fig-logtr fig-align='center' width=80%}\n:::\n:::\n\n\n\n\nFor certain transformations, we _can_ re-express coefficients to be interpretable with respect to $y$ itself. For instance, the model using a log transform $ln(y) = b_0 + b_1(x)$ gives us a coefficient that represents statement __A__ below. We can re-express this by taking the opposite function to logarithm, the exponent, `exp()`. Similar to how this works in logistic regression, the exponentiated coefficients obtained from `exp(coef(model))` are _multiplicative_, meaning we can say something such as statement __B__\n\n:::int\n\n- __A:__ \"a 1 unit change in $x$ is associated with a $b$ unit change in $ln(y)$\".  \n- __B:__ \"a 1 unit change in $x$ is associated with $e^b$ __percent__ change in $y$.\"\n\n:::\n\nFinding the optimal transformation to use can be difficult, but there are methods out there to help you. One such method is the BoxCox transformation, which can be conducted using `BoxCox(variable, lambda=\"auto\")`, from the __forecast__ package.^[This method finds an appropriate value for $\\lambda$ such that the transformation $(sign(x) |x|^{\\lambda}-1)/\\lambda$ results in a close to normal distribution.] \n\n## Using Non-Linear Models\n\n::: {.panel-tabset}\n\n### Generalized Linear Models\n\nGeneralized Linear Models (GLMs) can appropriately deal with data that do not follow a normal distribution (which is a requirement for traditional linear models). They can accommodate various types of distributions, including the Poisson, binomial, and gamma distributions. This makes them suitable for modelling count data (e.g., number of sunny days Edinburgh has per year - yes, count data can include 0!), binary data (where there are only two possible values e.g., doesn't wear glasses vs wear glasses, smoker vs non-smoker, i.e., values that are yes/no or 0/1), and other types of non-normal data.\n\nWe will explore some GLMs later in the course (Semester 2 Block 4), where we will work with logistic regression models. \n\n### Higher Order Terms\n\nHigher order regression terms refer to the inclusion of polynomial terms of degree higher than one in a regression model. In a linear regression model, the association between the dependent variable ($Y$) and the independent variable ($X$) is assumed to be linear, which means the association can be represented by a straight line. However, in many real-world scenarios, associations between variables are not strictly linear, and including higher order regression terms can help capture more complex relationships. Higher order terms that you could incorporate include quadratic, cubic, or higher degree polynomial terms. \n\nFor example, in a quadratic regression model, the relationship between $Y$ and $X$ can be represented as:\n\n$$\nY = \\beta_0 + \\beta_1 \\cdot X + \\beta_2 \\cdot X^2 + \\epsilon\n$$\n$$\n\\begin{align}\n& \\text{Where:} \\\\\n& Y = \\text{Dependent Variable} \\\\\n& X = \\text{Independent Variable} \\\\\n\\end{align}\n$$\n\nAs in our models we've seen so far, $\\beta_0$, $\\beta_1$, and $\\beta_2$ are the coefficients to be estimated in the above model. What is different from what we've seen in DAPR2 is the term $\\beta_2 \\cdot X^2$, and this represents the *quadratic term*. This allows for a curved as opposed to straight line to represent the association between $Y$ and $X$, and hence can allow us to capture more complex relationships. For example, we can model the association between height and age:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Two linear models, one with a quadratic term (right)](1_b4_reading_files/figure-html/fig-nonlin-1.png){#fig-nonlin fig-align='center' width=100%}\n:::\n:::\n\n\n\n\nPlease note that these types of models are beyond the scope of the DAPR2 course, but if you want to know more, please do read up on these in your own time. \n:::\n\n## Removing Observations\n\nRemoving outliers and potentially influential observations should be a last resort - not all outliers are inherently 'bad' - we do expect natural variation in our population(s) of interest. Outliers can be informative about the topic under investigation, and this is why you need to be very careful about excluding outliers due only to their 'extremeness'. In doing so, you can distort your results by removing variability - i.e., by forcing the data to be more normal and less variable than it actually is, and reduce statistical power by reducing the size of your sample. \n\nIf you do decide to remove observations, you will need to document what specific data points you excluded, and provide an explanation as to why these were excluded. \n\nTo set specific values to `NA` in our dataset (and save this updated dataset in a new object named `mwdata2`), we could use the following code. For the purpose of this demonstration, lets say that we wanted to set any `age` values of <20 as `NA`. In the original dataset `mwdata`, we had 3 individuals aged 18, and 6 aged 19, so we should end up with 9 `NA` values in `mwdata2` column `age`:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#specify age column in original dataset, where age is < 20, for values to be set to NA and save to new object named mwdata2 to avoid overwriting original data\nmwdata2 <-  mwdata %>% \n    mutate(age = replace(age, age < 20, NA))\n\n#check how many NA values we have - there should be 9 (so 9 TRUEs):\ntable(is.na(mwdata2$age))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nFALSE  TRUE \n  191     9 \n```\n\n\n:::\n:::\n\n\n\n\nIf we wanted to remove a full row from the datset, we could use the following code. For the purpose of this demonstration, lets say that we wanted to remove all rows that were highlighted in the above assumption and diagnostic checks as potentially having an adverse influence on our model estimates:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# create new dataset 'mwdata3' without (by specifying -) identified outliers and potentially influential observations\nmwdata3 <- mwdata[-c(16, 25, 50, 53, 56, 58, 59, 60, 62, 72, 73, 75, 76, 78, 79, 85, 101, 109, 125, 126, 127, 131, 149, 151, 159, 163, 165, 169, 173, 176, 179, 197), ]\n\n# check dimensions - should now have 32 rows less than original dataset 200 - 32 = 168\ndim(mwdata3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 168   7\n```\n\n\n:::\n:::\n\n\n\n\n:::\n\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n## Logistic Models\n\nBecause logistic regression models don’t have the same expected error distribution (we don’t expect residuals to be normally distributed around the mean, with constant variance), checking the assumptions of logistic regression is a little different.\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-93' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-93', 'opt-start-93')\"> <span class=\"olab\">Deviance Residuals</span></span></div><div class=\"optional-body\" id = \"opt-body-93\" style=\"display: none;\">\n\n\n\nTypically, we look at the \"deviance residuals\". But we __don't__ examine plots for patterns, we simply examine them for potentially outlying observations. If we use a standardised residual, it makes it easier to explore extreme values as we expect most residuals to be within -2, 2 or -3, 3 (depending on how strict we feel). \n\n__Deviance Residuals__  \n\nThere are three ways we can get out deviance residuals, each scaled differently: \n\n- $i$th residual = measure of deviance contributed from the $i$th observation\n- $i$th standardized residual = residual / SD(residual)\n- $i$th studentized residual = residual / SD(residual from model fitted without observation $i$)\n\n:::blue\n\n**In R**\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# deviance residuals\nresiduals(sen_mdl1, type = 'deviance')\n\n# studentised residuals\nrstudent(sen_mdl1, type = 'deviance')\n\n# standardised residuals\nrstandard(sen_mdl1, type = 'deviance')\n```\n:::\n\n\n\n\n:::\n\nWe can visually assess whether any residuals are larger than 2 or 3 in absolute value:\n\n:::blue\n\n**In R**\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(rstandard(sen_mdl1, type = \"deviance\"), ylab = \"Standardised Deviance Residuals\")\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-165-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n:::\n\n:::frame\n\n[**Interpretation Guidance**]{style=\"color:red;\"}\n\nMost residuals should be within -2, 2 or -3, 3. \n\nYou must specify your criteria (e.g., \"we expected residuals to fall within the range of -2 to 2\") before you conduct your analysis.\n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-94' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-94', 'opt-start-94')\"> <span class=\"olab\">High Influence Cases</span></span></div><div class=\"optional-body\" id = \"opt-body-94\" style=\"display: none;\">\n\n\n\nJust like in linear regression, to check for influential observations, we can use `cooks.distance()`, and plot this using `plot()`. Alternatively, you can specify `which = 4` when plotting your fitted model (i.e., `plot(model, which = ?)`.\n\n:::blue\n\n**In R**\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(sen_mdl1, which = 4)\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/unnamed-chunk-166-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n:::\n\n:::frame\n\n[**Interpretation Guidance**]{style=\"color:red;\"}\n\nIn logistic regression, we can use the arbitrary cut-offs of $> 0.5$ (moderately influential) or $>1$ (highly influential) to describe influential points.\n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Bootstrap\n\nThe _bootstrap_ is a general approach to assessing whether the sample results are statistically significant or not, and allows us to draw inferences to the population from a regression model. This method is assumption-free and does not rely on conditions such as normality of the residuals.\n\nIt is based on sampling repeatedly with replacement (to avoid always getting the original sample exactly) from the data at hand, and then computing the regression coefficients from each re-sample. We will equivalently use the word \"bootstrap sample\" or \"resample\" (for **sample** with **re**placement).\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-95' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-95', 'opt-start-95')\"> <span class=\"olab\">Overview</span></span></div><div class=\"optional-body\" id = \"opt-body-95\" style=\"display: none;\">\n\n\n\nThe basic principle is:\n\n<center>\n__The population is to the original sample__\n\n__as__\n\n__the original sample is to the bootstrap samples.__\n\n</center>\n\n\nBecause we only have one sample of size $n$, and we do not have access to the data for the entire population, we consider our original sample as our best approximation to the population. \n\nTo be more precise, we assume that the population is made up of many, many copies of our original sample. Then, we take multiple samples each of size $n$ from this assumed population. This is equivalent to sampling _with replacement_ from the original sample.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/reg-boot.png){fig-align='center' width=90%}\n:::\n:::\n\n\n\n\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-96' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-96', 'opt-start-96')\"> <span class=\"olab\">Terminology</span></span></div><div class=\"optional-body\" id = \"opt-body-96\" style=\"display: none;\">\n\n\n\n- A _parameter_ is a numerical summary for the population, e.g. the population slope $\\beta_1$.\n- A _statistic_ is a numerical summary calculated from the sample data, e.g. the estimated slope in the sample $\\widehat \\beta_1$. We use the sample statistic as a best guess, or estimate, for the unknown population parameter.\n- A _bootstrap sample_ is chosen with replacement from an existing sample, using the same sample size.\n- A _bootstrap statistic_ is a statistic computed for each bootstrap sample.\n- A _bootstrap distribution_ collects bootstrap statistics for many bootstrap samples.\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-97' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-97', 'opt-start-97')\"> <span class=\"olab\">In R</span></span></div><div class=\"optional-body\" id = \"opt-body-97\" style=\"display: none;\">\n\n\n\nFollow these steps:\n\n* 1: Load the **car** package.    \n  \n* 2: Use the `Boot()` function (do not forget the uppercase B!) which takes as arguments:\n    - the fitted model\n    - `f`, saying which bootstrap statistics to compute on each bootstrap sample. By default `f = coef`, returning the regression coefficients.\n    - `R`, saying how many bootstrap samples to compute. By default `R = 999` but this could be any number. To experiment we recommend 1000, when you want to produce results for journals, it is typical to go with 10,000 or more.\n    - `ncores`, saying if to perform the calculations in parallel (and more efficiently). However, this will depend on your PC, and you need to find how many cores you have by running `parallel::detectCores()` on your PC. By default the function uses `ncores = 1`.  \n     \n* 3: Run the code. However, please remember that the `Boot()` function does **not** want a model which was fitted using data with `NAs`. To remove, for example, you could use `na.omit`.  \n  \n* 4: Look at the `summary()` of the bootstrap results. When doing so the output will show, for each regression coefficient, the value in the original sample in the column `original`, and in the `bootSE` column, the estimate of the variability of the coefficient from bootstrap sample to bootstrap sample. The `bootSE` provides us the bootstrap standard error, or bootstrap SE in short. We can use this to answer the key question of how accurate our estimate is. \n  \n* 5: Compute confidence intervals via the `Confint()` function. Use your preferred confidence level (usually, and by default, 95%) by specifying `level = `. If you select 95% confidence intervals, by also specifying the `type = \"perc\"` argument, `R` will return the values that comprise 95% of all values in between them, i.e. the value with 2.5% of observations below it and the value with 2.5% of observations above it and 97.5% of observations below it.  \n  \n* 6: Provide interpretation in the context of your research question and report results in APA format. *(Note: the actual estimates are those from our original model, it is just the bounds of the interval that bootstrapping is providing us with)*. \n\n:::blue\n\n**In R**\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#specify model\nrecall_mdl <- lm(recall_accuracy ~ recall_confidence + age, data = recalldata)\n\n#step 1: load car package\nlibrary(car)\n\n#step 2/3: bootstrap model (asking to resample 1000 times, i.e., getting a distribution of 1000 values for the coefficients)\nbootmymodel <- Boot(recall_mdl, R = 1000)\n\n#step 4: check summary\nsummary(bootmymodel)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nNumber of bootstrap replications R = 1000 \n                  original   bootBias   bootSE  bootMed\n(Intercept)       36.15959 -3.2711632 16.47382 34.86127\nrecall_confidence  0.89573  0.0522770  0.25721  0.92141\nage               -0.33916  0.0027399  0.11400 -0.32973\n```\n\n\n:::\n\n```{.r .cell-code}\n#step 5: confidence intervals\nConfint(bootmymodel, level = 0.95, type = \"perc\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nBootstrap percent confidence intervals\n\n                    Estimate      2.5 %     97.5 %\n(Intercept)       36.1595862 -1.0225793 61.5221101\nrecall_confidence  0.8957292  0.5188793  1.5129003\nage               -0.3391577 -0.5824887 -0.1458007\n```\n\n\n:::\n:::\n\n\n\n\n:::\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<br> \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-98' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-98', 'opt-start-98')\"> <span class=\"olab\">Visualisation</span></span></div><div class=\"optional-body\" id = \"opt-body-98\" style=\"display: none;\">\n\n\n\nYou can visualise the uncertainty in the estimates by plotting histograms using the built-in function from the **car** package, which simply takes the bootstrap results `bootmymodel`. The bootstrap distribution should appear to be normal, and if non-normal, results are likely untrustworthy (note the distribution can be somewhat ambiguous with a small number of resamples). \n\n:::blue\n\n**In R**\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhist(bootmymodel, ci = \"perc\", legend = \"separate\")\n```\n\n::: {.cell-output-display}\n![](1_b4_reading_files/figure-html/eval-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n:::\n\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# General Formatting & Presenting of Results\n\n## LaTeX Symbols & Equations\n\nBy embedding LaTeX into RMarkdown, you can accurately and precisely format mathematical expressions, ensuring that they are not only technically correct but also visually appealing and easy to interpret.\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-99' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-99', 'opt-start-99')\"> <span class=\"olab\">LaTeX Guide</span></span></div><div class=\"optional-body\" id = \"opt-body-99\" style=\"display: none;\">\n\n\n\nFor an overview of how to integrate LaTeX symbols and equations, review [Lesson 9 of the RMD bootcamp](https://uoepsy.github.io/scs/rmd-bootcamp/09-latex.html). \n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n  \n## APA Formatting\n\nAPA format is a writing/presentation style that is often used in psychology to ensure consistency in communication. APA formatting applies to all aspects of writing - from formatting of papers (including tables and figures), citation of sources, and reference lists. This means that it also applies to how you present results in your Psychology courses, including DAPR2.\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-100' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-100', 'opt-start-100')\"> <span class=\"olab\">APA Formatting Guides</span></span></div><div class=\"optional-body\" id = \"opt-body-100\" style=\"display: none;\">\n\n\n\nAll results should be presented following [APA guidelines](https://apastyle.apa.org/instructional-aids/numbers-statistics-guide.pdf). \n\nYou also need to follow APA style rules for [tables and figures](https://apastyle.apa.org/style-grammar-guidelines/tables-figures). \n\nMake sure to familiarise yourself with the above guides, and practice presenting your results following these rules.\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n## Tables\n\nWe want to ensure that we are presenting results in a well formatted table. To do so, there are lots of different packages available (see [Lesson 4 of the RMD bootcamp](https://uoepsy.github.io/scs/rmd-bootcamp/04-prettytab.html)). \n\nOne of the most convenient ways to present results from regression models is to use the `tab_model()` function from **sjPlot**\n\n\n\n<div class=\"optional-begin\"><span id='opt-start-101' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-101', 'opt-start-101')\"> <span class=\"olab\">Creating tables via tab_model</span></span></div><div class=\"optional-body\" id = \"opt-body-101\" style=\"display: none;\">\n\n\n\nWithin `tab_model()`, there are lots of different ways that you can customise your table. The most common arguments that you should use are `dv.labels`, `pred.labels`, and `title`. \n\nYou can rename your DV and IV labels by specifying `dv.labels` and `pred.labels`. To do so, specify your variable name on the left, and what you would like this to be named in the table on the right. For `title`, you can simply specify in \"\"'s what you want your title to be e.g., `title = \"This is my title\"`. \n\nHere's an example if I had fitted a model with the following information:\n\n- Model name = `mdl_test`\n- Model DV = `cognitive_score`\n- Model IVs = `SES` and `age`\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmdl_test <- lm(cognitive_score ~ SES + age, data = data_name)\n```\n:::\n\n\n\n\nI want to change the names of `SES` and `age` to be `socio-economic status` and `age - in years` respectively. What we need to pay attention to here is the ordering of the IVs - the ordering in our `lm()` must match that in `tab_model()`. I also want to name my table *Regression Table for Cognitive Scores Model*. Here is how we would do this in **R**:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(sjPlot)\ntab_model(mdl_test,\n          pred.labels = c('Intercept', 'socio-economic status', 'age - in years'),\n          title = \"Regression Table for Cognitive Scores Model\")\n```\n:::\n\n\n\n\nSee [here](https://uoepsy.github.io/scs/rmd-bootcamp/zz-packs.html) for another short example. \n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n## Cross Referencing\n\nCross-referencing is a very helpful way to direct your reader through your document, and the good news is that this can be done automatically in RMarkdown. \n\n\n\n<div class=\"optional-begin\"><span id='opt-start-102' class=\"fa-solid fa-circle-right optional-icon clickable\" onclick=\"toggle_visibility('opt-body-102', 'opt-start-102')\"> <span class=\"olab\">Cross Referencing</span></span></div><div class=\"optional-body\" id = \"opt-body-102\" style=\"display: none;\">\n\n\n\nThere are three key components to allow you to successfully cross-reference within your RMarkdown document:\n\n+ A bookdown output format\n+ A caption to your figure or table\n+ A named/labeled code chunk\n\nOnce you have the above, you will be able to cross-reference using the syntax \\@ref(type:label), where label is the chunk name/label,  and type is the environment being referenced (e.g. tab for table, fig for figure, etc.).\n\nFor an in-depth overview and example of how to cross-reference, see [Lesson 7 of the RMD bootcamp](https://uoepsy.github.io/scs/rmd-bootcamp/07-refs.html). \n\n\n\n\n</div><p class=\"optional-end\"></p>\n\n\n\n",
    "supporting": [
      "1_b4_reading_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n<link href=\"site_libs/htmltools-fill-0.5.8.1/fill.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/htmlwidgets-1.6.4/htmlwidgets.js\"></script>\n<script src=\"site_libs/plotly-binding-4.10.4/plotly.js\"></script>\n<script src=\"site_libs/typedarray-0.1/typedarray.min.js\"></script>\n<script src=\"site_libs/jquery-3.5.1/jquery.min.js\"></script>\n<link href=\"site_libs/crosstalk-1.2.1/css/crosstalk.min.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/crosstalk-1.2.1/js/crosstalk.min.js\"></script>\n<link href=\"site_libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/plotly-main-2.11.1/plotly-latest.min.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}