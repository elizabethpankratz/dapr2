---
title: "Simple Linear Regression"
link-citations: true
params: 
    SHOW_SOLS: TRUE
    TOGGLE: TRUE
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
source('assets/setup.R')

# knitr::opts_chunk$set(cache = TRUE)
set.seed(1)
```

:::lo
### <i class="fa fa-graduation-cap"></i> Learning Objectives
At the end of this lab, you will:

1. Be able to specify a simple linear model. 
2. Understand what fitted values and residuals are. 
3. Be able to interpret the coefficients of a fitted model.

### <i class="fa fa-check-square-o fa-2"></i> Requirements

1. Be up to date with lectures from Weeks 1 & 2
2. Have completed [Week 1 lab exercises](https://uoepsy.github.io/dapr2/2223/labs/1_01_function.html) 

### <i class="fab fa-r-project"></i> Required R Packages
Remember to load all packages within a code chunk at the start of your RMarkdown file using `library()`. If you do not have a package and need to install, do so within the console using `install.packages(" ")`. For further guidance on installing/updating packages, see Section C [here](https://uoepsy.github.io/files/install-update-r#update-pkgs). 

For this lab, you will need to load the following package(s):

* **tidyverse** 
* **sjPlot**

### <i class="fa fa-pencil-square-o" aria-hidden="true"></i> Presenting Results
All results should be presented following [APA guidelines](https://apastyle.apa.org/instructional-aids/numbers-statistics-guide.pdf).If you need a reminder on how to hide code, format tables/plots, etc., make sure to review the [rmd bootcamp](https://uoepsy.github.io//rmd-bootcamp/).

### <i class="fa fa-file"></i> Lab Data
You can download the data required for this lab [here](https://uoepsy.github.io/data/riverview.csv) or read it in via this link https://uoepsy.github.io/data/riverview.csv. 
:::

# Study Overview 

> **Research Question**
> 
> Is there an association between income and education level in the city of Riverview?  

Let’s imagine a study into income disparity for workers in a local authority. We might carry out interviews and find that there is an association between the level of education and an employee’s income. Those with more formal education seem to be better paid. 

In this lab, we will use the riverview data (see below codebook) to examine whether education level is related to income among the employees working for the city of Riverview, a hypothetical midwestern city in the US.

`r optbegin('Riverview data codebook.', FALSE, show = TRUE, toggle = params$TOGGLE)`

__Description__

The riverview data come from @Lewis-Beck2015 and contain five attributes collected from a random sample of employees working in the hypothetical city of Riverview ($n=32$). The attributes include:

- `education`: Years of formal education
- `income`: Annual income (in thousands of U.S. dollars)
- `seniority`: Years of seniority
- `gender`: Employee's gender
- `male`: Dummy coded gender variable (0 = Female, 1 = Male)
- `party`: Political party affiliation

__Preview__

The first six rows of the data are:

```{r echo=FALSE, message = FALSE}
library(tidyverse)
library(kableExtra)

riverview <- read_csv('https://uoepsy.github.io/data/riverview.csv')
kable(head(riverview), align='c') %>% kable_styling(full_width = FALSE)
```
`r optend()`

<div class="divider div-transparent div-dot"></div>

# Setup
`r qbegin("Setup", qlabel = FALSE)`  

1. Create a new RMarkdown file
2. Load the required package(s)
3. Read the riverview dataset into R, assigning it to an object named `riverview`

`r qend()`

`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`
```{r, warning=FALSE, message=FALSE}
#Loading the required package(s)
library(tidyverse)
library(sjPlot)

#Reading in riverview data and storing in object named 'riverview'
riverview <- read_csv("https://uoepsy.github.io/data/riverview.csv")

#check first six rows
head(riverview)
```
`r solend()`

<div class="divider div-transparent div-dot"></div>

# Exercises 

## Data Exploration

The common first port of call for almost any statistical analysis is to explore the data, and we can do this visually and/or numerically.

+----------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|                |  Marginal Distributions                                                                                                                                         | Bivariate Associations                                                                                                                                                       |
+================+=================================================================================================================================================================+==============================================================================================================================================================================+
|**Description** |  The distribution of each variable (e.g., employee incomes and education levels) *without* reference to the values of the other variables                       | Describing the relationship between two numeric variables                                                                                                                    |
+----------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|**Visually**    | Plot each variable individually.                                                                                                                                | Plot associations among two variables.                                                                                                                                       |
|  <br>          | <br>                                                                                                                                                            | <br>                                                                                                                                                                         |
|  <br>          | <br>                                                                                                                                                            | <br>                                                                                                                                                                         |
|                | You could use, for example, `geom_density()` for a density plot or `geom_histogram()` for a histogram to comment on and/or examine:                             | You could use, for example, `geom_point()` for a scatterplot  to comment on and/or examine:                                                                                                     |
|  <br>          | <br>                                                                                                                                                            | <br>                                                                                                                                                                         |
|  <br>          | <br>                                                                                                                                                            | <br>                                                                                                                                                                         |
|                |<ul><li> The *shape* of the distribution. Look at the shape, centre and spread of the distribution. Is it symmetric or skewed? Is it unimodal or bimodal? </li>  | <li>The *direction* of the association indicates whether there is a positive or negative association  </li>                                                                 
|                |<li> Identify any *unusual observations*. Do you notice any extreme observations (i.e., outliers)? </li>                                                         | <li>The *form* of association refers to whether the relationship between the variables can be summarized well with a straight line or some more complicated pattern </li>   
|                |                                                                                                                                                                 | <li>The *strength* of association entails how closely the points fall to a recognizable pattern such as a line  </li>                                                       
|                |                                                                                                                                                                 | <li>*Unusual observations* that do not fit the pattern of the rest of the observations and which are worth examining in more detail </li></ul>                              |
+----------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|**Numerically** | Compute and report summary statistics e.g., mean, standard deviation, median, min, max, etc.                                                                    | Compute and report the correlation coefficient.                                                                                                                              |
|  <br>          | <br>                                                                                                                                                            | <br>                                                                                                                                                                         |
|  <br>          | <br>                                                                                                                                                            | <br>                                                                                                                                                                         |
|                | You could, for example, calculate summary statistics such as the mean (`mean()`) and standard deviation (`sd()`), etc. within `summarize()`                     | <br>                                                                                                                                                                         |
|                |                                                                                                                                                                 | You can use the `cor()` function to calculate this                                                                                                                           |   
+----------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

### Marginal Distributions

`r qbegin(2)`

Visualise and describe the marginal distributions of employee incomes and education level.

`r qend()`

`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`

::: {.panel-tabset}

## Employee Incomes

Visualisation of distribution:
```{r}
#| label: fig-densbox-income
#| fig-cap: "Density plot and boxplot of employee incomes"
#| fig-alt: |
#|   Density and boxplot of employee incomes.
#|   Unimodal distribution, with most incomes around $45,000-70,000.
#|   No outliers suggested based on boxplot.

ggplot(data = riverview, aes(x = income)) +
  geom_density() +
  geom_boxplot(width = 1/300) +
  labs(x = "Income (in thousands of U.S. dollars)", 
       y = "Probability density")
```

Initial observations from plot:

+ The distribution of employee incomes was unimodal
+ Most of the incomes were between roughly \$45,000 and \$63,000
+ The lowest income in the sample was approximately \$25,000 and the highest approximately \$83,000. This suggested there was a fair high degree of variation in the data. 
+ The boxplot did not highlight any outliers in the data.

Descriptive (or summary) statistics for the employees' incomes:

```{r}
desc_income <- riverview %>% 
  summarize(
    M = mean(income), 
    SD = sd(income)
    )
desc_income
```

Following the exploration above, we can describe the income variable as follows:

::: {.callout-important icon=false appearance="minimal"}

The marginal distribution of income was unimodal with a mean of approximately \$53,700. There was variation in employees' salaries (SD = \$14,553). 

:::

## Employee Education Levels

Visualisation of distribution:

```{r}
#| label: fig-densbox-education
#| fig-cap: "Density plot and boxplot of employee education levels"

ggplot(data = riverview, aes(x = education)) +
  geom_density() +
  geom_boxplot(width = 1/100) +
  labs(x = "Education (in years)", 
       y = "Probability density")
```

Initial observations from plot:

+ The distribution of employee education was unimodal
+ Most of the employees received formal education for between 12 and 20 years
+ The fewest formal years of education was approximately 8 years, and the highest approximately 25. This suggested there was a fair high degree of variation in the data.
+ The boxplot did not highlight any outliers in the data

Descriptive (or summary) statistics for the employees' level of education:

```{r}
desc_education <- riverview %>%
  summarize(
    M = mean(education),
    SD = sd(education)
    )
desc_education
```

Following the exploration above, we can describe the education variable as follows:

::: {.callout-important icon=false appearance="minimal"}

The marginal distribution of education was unimodal with an average of of 16 years. There was variation in employees' level of education (SD = 4.4 years).

:::

:::

`r solend()`

### Associations among Variables

`r qbegin(3)`
Create a scatterplot of income and education level *before* calculating the correlation between income and education level. 

Making reference to both the plot and correlation coefficient, describe the association between income and level of education among the employees in the sample.

:::{.callout-tip appearance="simple" collapse="true"}

### Hint

We are trying to investigate how income varies when varying years of formal education. Hence, income is the dependent variable (on the y-axis), and education is the independent variable (on the x-axis).

:::

`r qend()`

`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`

Let's produce a scatterplot:

```{r}
#| label: fig-riverview-scatterplot
#| fig-cap: "The association between employees' education level and income"

ggplot(data = riverview, aes(x = education, y = income)) +
  geom_point() +
  labs(x = "Education (in years)", 
       y = "Income (in thousands of U.S. dollars)")
```

To comment on the strength of the linear association we compute the correlation coefficient:
```{r}
corr <- riverview %>%
  select(education, income) %>%
  cor()
corr
```

that is, 
$$
r_{\text({education, income})} = 0.79
$$
<br>

::: {.callout-important icon=false appearance="minimal"}

There was a strong positive linear association between education level and income for the employees in the sample. High incomes tended to be observed, on average, with more years of formal education ($r$ = .79).

:::

<br>

`r solend()`

<div class="divider div-transparent div-dot"></div>

## Model Specification and Fitting

The scatterplot highlighted a linear relationship, where the data points were scattered around an underlying linear pattern with a roughly-constant spread as x varied.

Hence, we will try to fit a simple (i.e., one x variable only) linear regression model:

$$
y_i = \beta_0 + \beta_1 x_i + \epsilon_i 
\\
\quad \text{where} \quad \epsilon_i \sim N(0, \sigma) \text{ independently}
$$

::: {.callout-important icon=false collapse=true}
# What does $y_i = \beta_0 + \beta_1 x_i + \epsilon_i \quad \text{where} \quad \epsilon_i \sim N(0, \sigma) \text{ independently}$ mean?
Lets break the statement down into smaller parts:

###### $y_i = \beta_0 + \beta_1 x_i + \epsilon_i$
+ $y_i$ is our measured outcome variable (our DV)
+ $x_i$ is our measured predictor variable (our IV)
+ $\beta_0$ is the model intercept
+ $\beta_1$ is the model slope

###### $\epsilon \sim N(0, \sigma) \text{ independently}$
+ $\epsilon$ is the residual error 
+ $\sim$ means 'distributed according to'
+ $\sim N(0, \sigma) \text{ independently}$ means 'normal distribution with a mean of 0 and a variance of $\sigma$' 
+ Together, we can say that the errors around the line have a mean of zero and constant spread as x varies. 

:::

<br>

`r qbegin(4)`

First, write the equation of the fitted line. 

Next, using the `lm()` function, fit a simple linear model to predict income (DV) by Education (IV), naming the output `mdl`.

Lastly, add update your equation of the fitted line to include the estimated coefficients.

:::{.callout-tip appearance="simple" collapse="true"}

### Hint

The syntax of the `lm()` function is:

```{r eval = FALSE}

[model name] <- lm([response variable i.e., dependent variable] ~ [explanatory variable i.e., independent variable], data = [dataframe])
```

:::

`r qend()`

`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`

First, lets specify the fitted model, which can be written either as:

::: {.panel-tabset}

## Option A

$$
\widehat{Income} = \hat \beta_0 + \hat \beta_1 \cdot Education
$$

## Option B

$$
\widehat{Income} = \hat \beta_0 \cdot 1 + \hat \beta_1 \cdot Education
$$
:::

To fit the model in `R`, as the variables are in the `riverview` dataframe, we would write:

::: {.panel-tabset}

## Option A

```{r}
mdl <- lm(income ~ education, data = riverview)
mdl
```

## Option B

```{r}
mdl <- lm(income ~ 1 + education, data = riverview)
mdl
```


:::

::: {.callout-important icon=false collapse=true}
## Why is there a 1 in the Option B's? 
When we specify the linear model in `R`, we include after the tilde sign ($\sim$), the variables that appear to the right of the $\hat \beta$s. The intercept, or $\beta_0$, is a constant. That is, we could write it as multiplied by 1.

Including the 1 explicitly is not necessary because it is included by default (you can check this by comparing the outputs of A & B above with and without the 1 included - the estimates are the same!). After a while, you will find you just want to drop the 1 (i.e., Option B) when calling `lm()` because you know that it’s going to be there, but in these early weeks we tried to keep it explicit to make it clear that you want to the intercept to be estimated. 
:::

Note that by calling the name of the fitted model, `mdl`, you can see the estimated regression coefficients $\hat \beta_0$ and $\hat \beta_1$. We can add these values to the fitted line: 

$$
\widehat{Income} = 11.32 + 2.65 \cdot Education \\
$$

`r solend()`

<br>

`r qbegin(5)`
Explore the following equivalent ways to obtain the estimated regression coefficients --- that is, $\hat \beta_0$ and $\hat \beta_1$ --- from the fitted model:

- `mdl`
- `mdl$coefficients`
- `coef(mdl)`
- `coefficients(mdl)`
- `summary(mdl)`

`r qend()`

`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`

The estimated parameters returned by the below methods are all equivalent. However, `summary()` returns more information.

::: {.panel-tabset}

## mdl()
Simply invoke the name of the fitted model:
```{r}
mdl
```

## mdl$coefficients

```{r}
mdl$coefficients
```

## coef(mdl)
```{r}
coef(mdl)
```


## coefficients(mdl)

```{r}
coefficients(mdl)
```

## summary(mdl)
Look under the “Estimate” column:
```{r}
summary(mdl)
```

:::

::: {.callout-important icon=false appearance="minimal"}

The estimated intercept is $\hat \beta_0 = 11.32$ and the estimated slope is $\hat \beta_1 = 2.65$.

:::

`r solend()`

<br>

`r qbegin(6)`
Explore the following equivalent ways to obtain the estimated standard deviation of the errors --- that is, $\hat \sigma$ --- from the fitted model `mdl`:

- `sigma(mdl)`
- `summary(mdl)`

`r optbegin('Huh? What is $\\sigma$?', FALSE)`
The standard deviation of the errors, denoted by $\sigma$, is an important quantity that our model estimates. It represents how much individual data points tend to deviate above and below the regression line. 

A small $\sigma$ indicates that the points hug the line closely and we should expect fairly accurate predictions, while a large $\sigma$ suggests that, even if we estimate the line perfectly, we can expect individual values to deviate from it by substantial amounts.

The *estimated* standard deviation of the errors is denoted $\hat \sigma$, and is estimated by essentially averaging squared residuals (giving the variance) and taking the square-root: 

$$
\begin{align}
& \hat \sigma = \sqrt{\frac{SS_{Residual}}{n - k - 1}} \\
\qquad \\
& \text{where} \\
& SS_{Residual} = \textrm{Sum of Squared Residuals} = \sum_{i=1}^n{(\epsilon_i)^2}
\end{align}
$$
`r optend()`

`r qend()`

`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`

The estimated standard deviation of the errors can be equivalently obtained by the below methods. However, `summary()` returns more information.

::: {.panel-tabset}

## sigma(mdl)

```{r}
sigma(mdl)
```

## summary(mdl)

Look at the "Residual standard error" entry of the `summary(mdl)` output:
```{r}
summary(mdl)
```

:::{.callout-note}

The term "Residual standard error" is a misnomer, as the help page for `sigma` says (check `?sigma`). However, it's hard to get rid of this bad name as it has been used in too many books showing R output.

:::

:::

::: {.callout-important icon=false appearance="minimal"}


The estimated standard deviation of the errors is $\hat \sigma = 8.98$.

:::

`r solend()`

<br>

`r qbegin(7)`

Interpret the estimated intercept, slope, and standard deviation of the errors in the context of the research question.

:::{.callout-tip appearance="simple" collapse="true"}

### Hint

To interpret the estimated standard deviation of the errors we can use the fact that about 95\% of values from a normal distribution fall within two standard deviations of the centre.

:::

`r qend()`

`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`

::: {.panel-tabset}

## Intercept

The estimated income associated to zero years of formal education is \$11,321.

## Slope

The estimated increase in income associated to a one year increase in education is \$2,651.

## Standard deviation of the errors

For any particular level of education, employee incomes should be distributed above and below the regression line with standard deviation estimated to be $\hat \sigma = 8.98$. Since $2 \hat \sigma = 2 (8.98) = 17.96$, we expect most (about 95\%) of the employee incomes to be within about \$18,000 from the regression line.

:::

`r solend()`

<br>

`r qbegin(8)`
Plot the data and the fitted regression line. To do so:

- Extract the estimated regression coefficients e.g., via `betas <- coef(mdl)`
- Extract the first entry of `betas` (i.e., the intercept) via `betas[1]`
- Extract the second entry of `betas` (i.e., the slope) via `betas[2]`
- Provide the intercept and slope to the function

:::{.callout-tip appearance="simple" collapse="true"}

### Hint

Extracting values:
The function `coef(mdl)` returns a *vector*: that is, a sequence of numbers all of the same type. To get the first element of the sequence you append `[1]`, and `[2]` for the second.

Plotting:
In your `ggplot()`, you will need to specify `geom_abline()`. This might help get you started:

```{r eval = FALSE}

geom_abline(intercept = <intercept>, slope = <slope>)
```

:::

`r qend()`

`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`

First extract the values required:
```{r}
betas <- coef(mdl)
intercept <- betas[1]
slope <- betas[2]
```

We can plot the model as follows:
```{r}
ggplot(data = riverview, aes(x = education, y = income)) +
  geom_point() +
  geom_abline(intercept = intercept, slope = slope, color = 'blue') + 
  labs(x = "Education (in years)", y = "Income (in thousands of U.S. dollars)")
```
`r solend()`

<div class="divider div-transparent div-dot"></div>

## Predicted Values & Residuals

:::statbox 

### Predicted Values

#### Model predicted values for sample data:

We can get out the model predicted values for $y$, the "y hats" ($\hat y$), for the data in the sample using various functions:

- `predict(<fitted model>)`
- `fitted(<fitted model>)`
- `fitted.values(<fitted model>)`
- `mdl$fitted.values`

For example, this will give us the estimated income (point on our regression line) for each observed value of education level.

```{r}
predict(mdl)
```

#### Model predicted values for other (unobserved) data:

To compute the model-predicted values for unobserved data (i.e., data not contained in the sample), we can use the following function:

- `predict(<fitted model>, newdata = <dataframe>)`

For this example, we first need to remember that the model predicts `income` using the independent variable `education`. Hence, if we want predictions for new (unobserved) data, we first need to create a tibble with a column called `education` containing the years of education for which we want the prediction, and store this as a dataframe.


```{r}
#Create dataframe 'newdata' containing education years of 7, 11 and 25
newdata <- tibble(education = c(7, 11, 25))
newdata
```

Then we take `newdata` and add a new column called `income_hat`, computed as the prediction from the fitted `mdl` using the `newdata` above:

```{r}
newdata <- newdata %>%
  mutate(
    income_hat = predict(mdl, newdata = newdata)
  )
newdata
```

### Residuals

The residuals represent the deviations between the actual responses and the predicted responses and can be obtained either as

- `mdl$residuals`
- `resid(mdl)`
- `residuals(mdl)`
- computing them as the difference between the response ($y_i$) and the predicted response ($\hat y_i$)

:::

<br>

`r qbegin(9)`

Use `predict(mdl)` to compute the fitted values and residuals. Mutate the `riverview` dataframe to include the fitted values and residuals as extra columns.

Assign to the following symbols the corresponding numerical values:

- $y_{3}$ (response variable for unit $i = 3$ in the sample data)
- $\hat y_{3}$ (fitted value for the third unit)
- $\hat \epsilon_{5}$ (the residual corresponding to the 5th unit, i.e., $y_{5} - \hat y_{5}$)

`r qend()`

`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`
```{r}
riverview_fitted <- riverview %>%
  mutate(
    income_hat = predict(mdl),
    resid = income - income_hat
  )

head(riverview_fitted)
```

- $y_{3}$ = 47.03 (see row 3, column 2)
- $\hat y_{3}$ = 37.83 (see row 3, column 7)
- $\hat \epsilon_{5} = y_{5} - \hat y_{5}$ = -12.36 (see row 5, columns 2 and 7)

`r solend()`

<br>

`r qbegin(10)`

Describe the design of the study, and the analyses that you undertook. Interpret your results in the context of the research question and report your model results in full.

Provide key model results in a formatted table.

:::{.callout-tip appearance="simple" collapse="true"}

### Hint 

Use `tab_model()` from the __sjPlot__ package. 

Remember that you can rename your DV and IV labels by specifying `dv.labels` and `pred.labels`.

Make sure to write your results up following [APA guidelines](https://apastyle.apa.org/instructional-aids/numbers-statistics-guide.pdf)

:::

`r qend()`

`r solbegin(show = params$SHOW_SOLS, toggle = params$TOGGLE)`

Before we write up our analyses & results, lets first create the table of results:

```{r}
#| label: tbl-income-modresults
#| tbl-cap: Regression Table for Income Model
tab_model(mdl,
          dv.labels = "Income (in thousands of US dollars)",
          pred.labels = c("education" = "Education (years)"),
          title = "Regression Table for Income Model")
          
```


::: {.callout-important icon=false appearance="minimal"}

The `riverview` dataset contained information on 32 participants who worked in the hypothetical city of Riverview, US. Using a between-subjects design, the researchers collected information on participants' sex, income, education, and seniority level. 

To investigate whether there was an association between income and education level, the following simple linear regression model was used:

$$
\text{Income}= \beta_0 + \beta_1 \cdot \text{Education}
$$

Full regression results are displayed in @tbl-income-modresults. The estimated income associated with no formal years of education was \$11,321. Each additional year of formal education was associated with an income increase of \$2,651. 
:::

`r solend()`
