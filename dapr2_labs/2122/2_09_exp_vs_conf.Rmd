---
title: "Exploratory vs Confirmatory Data Analysis"
bibliography: references.bib
biblio-style: apalike
link-citations: yes
params: 
  SHOW_SOLS: TRUE
  TOGGLE: TRUE
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
source('assets/setup.R')
```

```{r echo=FALSE}
set.seed(3)
```



:::lo
**LEARNING OBJECTIVES**

1. Understand the difference between exploratory vs confirmatory analyses
1. Understand how to select models by comparing test-data MSE
1. Understand how to compute MSE via k-fold cross validation

:::

# Wine Quality

This week's lab explores wine quality based on physiochemical properties/attributes, using data that was collected between 2004 and 2007. Specifically, the data concern white and red **vinho verde**. 

## The Data

Download the following datasets about wine quality:

- Red wine:  
https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv 
- White wine:  
https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv

If you open them on your PC, you will notice that the data values are separated by semicolons, rather than colons. We have to tell R this by using `read_delim` to read a file with delimited values, and specify the delimiter by saying `delim = ";"`:

```{r}
library(tidyverse)

red <- 
    read_delim("https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv", 
               delim = ";")

white <- 
    read_delim("https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv", 
               delim = ";")
```

We will also add a column to each dataset specifying the wine color:

```{r}
red <- red %>% mutate(col = "red")
white <- white %>% mutate(col = "white")
```

The `bind_rows` function is used to combine the datasets (as the name suggests, we will be combining by row). Let's call the combined data `wine`:
 
```{r}
wine <- bind_rows(
    red %>% mutate(col="red"),
    white %>% mutate(col="white")
)
```

`r qbegin(1)`

Inspect the data and check the dimensions. How many observations and how many variables are there?

`r qend()`

`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
# Inspect top 6 rows
head(wine)
# Check data dimensions
dim(wine)
```

There are `r nrow(wine)` observations on `r ncol(wine)` variables.

`r solend()`

# Exploratory analysis

For this section of the lab, we do not have a fixed research question and/or hypothesis, but will instead be exploring associations among variables. We have randomly selected two variables (`alcohol`, and `col`) to predict the outcome `quality`:

```{r echo = FALSE}
library(kableExtra)

tibble(
    Variable = c('`quality`', '`alcohol`', '`col`'),
    Description = c('Quality rating of wine - assessed on a scale  ranging from 0 (very bad) to 10 (excellent).',
                    'Alcohol volume - measured as a percentage.',
                    'Colour of wine - red or white.')
) %>%
    kable() %>%
    kable_styling(full_width = FALSE)
```

`r qbegin(2)`

Subset the data to only include these three variables we want to explore further - `quality`, `alcohol`, `col`.

`r qend()`

`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

```{r}
wine <- wine %>%
    select(quality, alcohol, col)
```

`r solend()`

`r qbegin(3)`

Visualise each variable individually, and note down your observations.

`r qend()`

`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r, out.width='100%', fig.height=5, fig.width = 10}
# To create multiple panels
library(patchwork)

# Quality Rating
p1 <- ggplot(wine, aes(x = quality)) +
    geom_histogram(color = 'white') +
    labs(x = 'Quality Rating', 
         y = 'Frequency')

# Alcohol (%)
p2 <- ggplot(wine, aes(x = alcohol)) +
    geom_histogram(color = 'white') +
    labs(x = 'Alcohol (%)', 
         y = 'Frequency')

# Colour
p3 <- ggplot(wine, aes(x = col)) + 
    geom_bar() + 
    labs(x = 'Colour', 
         y = 'Frequency')

# Stack the plots horizontally with vertical bars
p1 | p2 | p3
```

:::int
* Quality rating appears to be heavily set in mid-range scores (i.e., no extremely low or high)
* Alcohol (%) rather skewed, although this makes sense given that we don't expect many wines to have a very high alcohol volume
* White wines make up the majority of the wine colours sampled - more than double that of reds

:::

`r solend()`


`r qbegin(4)`

Produce a visualisation of the relationship between quality and alcohol. Consider either presenting with separate facets for wine colour, or add the `colour` argument within your `aes()` statement.

`r qend()`

`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r fig.width=12, fig.height=4, out.width = '95%'}
p4 <- ggplot(wine, aes(alcohol, quality)) +
    geom_point() +
    facet_wrap(~col) +
    scale_x_continuous(limits = c(5, 15)) + 
    scale_y_continuous(limits = c(0, 10)) + 
    labs(x = 'Alcohol (%)', y = 'Quality Rating')

p5 <- ggplot(wine, aes(alcohol, quality, colour = col)) +
    geom_point(size = 1, alpha = 0.5) +
    scale_x_continuous(limits = c(5, 15)) + 
    scale_y_continuous(limits = c(0, 10)) + 
    labs(x = 'Alcohol (%)', y = 'Quality Rating')

p4 | p5
```

:::int 

From the plots, it appears that there is a positive association between alcohol percentage and quality rating. It is not so clear if there is an association between quality and colour, but white wines do seem to have more high ratings.

:::

`r solend()`


Our goal is to compare the following models to find if some of those variables are good predictors of quality ratings.

$$
\begin{aligned}
M_A : \text{Quality} &= \beta_{A,0} + \beta_{A,1} \text{Alcohol} + \epsilon \\
M_B : \text{Quality} &= \beta_{B,0} + \beta_{B,1} \text{Col} + \epsilon \\
M_C : \text{Quality} &= \beta_{C,0} + \beta_{C,1} \text{Alcohol} + \beta_{C,2} \text{Col} + \epsilon 
\end{aligned}
$$

To do so, we need to compute the k-fold cross validation MSE for each of those models:

$$
MSE_A = MSE(M_A) \\ 
MSE_B = MSE(M_B) \\
MSE_C = MSE(M_C)
$$

We will begin by constructing the MSE for model A by hand, using $k = 3$ folds.

`r qbegin(5)`
As a first step, we need to randomise our data, and then divide into $k$ groups, or "folds", of roughly equal size. We will subset into 3 groups.  
Recall that we have `nrow(wine)`, and so need to create two datasets of 2166 observations, and one with 2165 observations.
`r qend()`

`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
set.seed(1234)

# create the indices of the data rows and shuffle them
idx <- sample(1:nrow(wine))

# randomise the data
wine_shuffle <- wine[idx, ]

# split into three data frames 
wine1 <- wine_shuffle[1:2166, ]
wine2 <- wine_shuffle[2167:4332, ]
wine3 <- wine_shuffle[4333:6497, ]
```

`r solend()`

`r qbegin(6)`

We are going to work through the following models:

* $MA_{1}$: trained on `bind_rows(wine2, wine3)`, tested on `wine1`
* $MA_{2}$: trained on `bind_rows(wine1, wine3)`, tested on `wine2`
* $MA_{3}$: trained on `bind_rows(wine1, wine2)`, tested on `wine3`

Recall model A involves fitting:

$$
M_A : \text{Quality} = \beta_{A,0} + \beta_{A,1} \text{Alcohol} + \epsilon 
$$
`r qend()`

`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

```{r}
mA_1 <- lm(quality ~ alcohol, data = bind_rows(wine2, wine3))
mA_2 <- lm(quality ~ alcohol, data = bind_rows(wine1, wine3))
mA_3 <- lm(quality ~ alcohol, data = bind_rows(wine1, wine2))
```

`r solend()`


`r qbegin(7)`
Calculate the test MSE on the observations in the fold that was held out. Remember that the MSE is the average squared distance between the observed and predicted values.

`r qend()`

`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`

```{r}
yhat_1 <- predict(mA_1, newdata = wine1)
yhat_2 <- predict(mA_2, newdata = wine2)
yhat_3 <- predict(mA_3, newdata = wine3)

err_1 <- wine1$quality - yhat_1
err_2 <- wine2$quality - yhat_2
err_3 <- wine3$quality - yhat_3

mseA_1 <- mean(err_1^2)
mseA_2 <- mean(err_2^2)
mseA_3 <- mean(err_3^2)

mse_A_folds <- tibble(
    Fold = 1:3,
    MSE = c(mseA_1, mseA_2, mseA_3)
)
mse_A_folds

mse_A <- mean(mse_A_folds$MSE)
mse_A
```

The MSE of model A is `r round(mse_A, 2)`.

`r solend()`


We now need to compute the same for the other 2 models too, in order to compare them.

For the next two models, we will use the cross-validation functions from the `modelr` package, as shown in the lecture.

:::blue

In **R**, as demonstrated in the lectures, you can use the `crossv_kfold()` function from the `modelr` package to conduct K-Folding. You also need to use the `map()` function too.

```{r}
library(modelr)

# example of three folds
CV <- crossv_kfold(wine, k = 3)
CV
```

:::


:::frame
Important! We selected two variables at random from the original `wine` dataset. If you would like more practice, feel free to 'explore' the associations of other variables that you think sound intriguing! 
:::


```{r}
mB <- map(CV$train, ~lm(quality ~ col, data = .))
mB

# helper function from lecture
get_pred <- function(model, test_data){
  data = as.data.frame(test_data)
  pred = add_predictions(data, model)
  return(pred)
}

predB <- map2_df(mB, CV$test, get_pred, .id = "Run")
predB

mse_B_folds <- predB %>% 
    group_by(Run) %>%
    summarise(MSE = mean((quality - pred)^2))
mse_B_folds

mse_B <- mean(mse_B_folds$MSE)
mse_B
```

As you see, model B leads to a MSE of `r round(mse_B, 2)`.


`r qbegin(8)`
Calculate the MSE for model C using 3-fold cross validation.
`r qend()`

`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
mC <- map(CV$train, ~lm(quality ~ alcohol + col, data = .))

predC <- map2_df(mC, CV$test, get_pred, .id = "Run")
predC

mse_C_folds <- predC %>% 
    group_by(Run) %>%
    summarise(MSE = mean((quality - pred)^2))
mse_C_folds

mse_C <- mean(mse_C_folds$MSE)
mse_C
```
`r solend()`

`r qbegin(9)`
Which model is the best model?
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
tibble(
    Model = c("A", "B", "C"),
    MSE = c(mse_A, mse_B, mse_C)
)
```

According to the 3-fold cross validation MSE results, $M_C$ has the lowest mean squared error: $MSE_C =$ `r round(mse_C, 2)`.
`r solend()`



# Confirmatory 

You have already conducted many confirmatory analyses during the DAPR2 course - you have been asked to complete specific analyses, test pre-determined hypotheses, etc.

If you have a strong research question, and you approach the problem using an exploratory analysis approach, you may end up finding that the model with the lowest MSE is not a model that includes the variables that are required to test your hypothesis.

For example, suppose in the exploratory analysis above you also included a $M_D$ that included the interaction between alcohol content and wine color.
It could happen that the model with the lowest MSE was not $M_D$, meaning that you would not be working with that model. 

However, suppose you wanted to perform a confirmatory analysis aimed at testing whether the effect of alcohol percentage on wine quality rating is dependent on the color of the wine.

To answer such question your model __must__ have the interaction term as the question directly relates to the interaction term.

`r qbegin(10)`
Fit a model that can answer the stated research hypothesis, and interpret the results.
`r qend()`
`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`
```{r}
fit <- lm(quality ~ alcohol * col, data = wine)
summary(fit)
```

```{r}
library(sjPlot)
plot_model(fit, type = "int")
```

According to the interaction model, the effect of alcohol content on quality rating does dependent on the wine color. 

The rate of change in wine quality rating seems to be significantly higher for red wines than white wines: $t(6493) = -0.05, p = 0.02$, two-sided.
`r solend()`



<!-- Formatting -->

<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>
